{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "import pandas as pd\n",
    "import requests\n",
    "from requests import get\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pulling all links off of the search pages (up to 3000) and putting them in a dataframe to scrape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_template=\"http://www.indeed.com/jobs?q=%22Data+Scientist%22&l=Bellevue%2C+WA&start={}\"\n",
    "max_results=250\n",
    "Linkdf=[]\n",
    "\n",
    "for start in range(0, max_results, 7):\n",
    "    url=url_template.format(start)\n",
    "    html=requests.get(url)\n",
    "    soup=BeautifulSoup(html.content,'html.parser', from_encoding=\"utf-8\")\n",
    "    \n",
    "    #for each in soup.find_all(a_=\"href\"):\n",
    "    page_links=soup.find_all('a',{'href':re.compile(\"/rc/\")})\n",
    "    for items in page_links:\n",
    "        Linkdf.append(items['href'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "351"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity Check\n",
    "len(Linkdf)\n",
    "#print(Linkdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "351"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This code allows the code to display the full website instead of truncating\n",
    "pd.set_option('display.max_colwidth',-1)\n",
    "\n",
    "#Moving it to a data frame\n",
    "data = {'links':Linkdf}\n",
    "df = pd.DataFrame(data, columns=['links'])\n",
    "\n",
    "#append indeed.com to the front of each\n",
    "df['Web'] = 'https://www.indeed.com'\n",
    "df['URL'] = df.Web.str.cat(df.links)\n",
    "\n",
    "#pull out just a list of the websites.\n",
    "websites=list(df['URL'])\n",
    "\n",
    "#Sanity Check\n",
    "#print(websites)\n",
    "len(websites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "websites1=set(websites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(websites1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looping through websites...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Title=[]\n",
    "Descriptions=[]\n",
    "Location=[]\n",
    "FullDescriptions=[]\n",
    "\n",
    "for url in websites1:\n",
    "    response=get(url)\n",
    "    soup=BeautifulSoup(response.text,'html.parser')\n",
    "    \n",
    "    description_containers= soup.find(class_='jobsearch-jobDescriptionText')\n",
    "    title_containers=soup.find('h3')\n",
    "    try:\n",
    "        location_containers=soup.find('',{'class':'jobsearch-CompanyInfoWithoutHeaderImage'}).find_all('div')[-1]\n",
    "    except:\n",
    "        location_containers='None Found'\n",
    "    \n",
    "    job_descriptions=str(description_containers)\n",
    "    job_title=str(title_containers.text)\n",
    "    try:\n",
    "        locations=str(location_containers.text)\n",
    "    except AttributeError:\n",
    "        locations = 'None Found'\n",
    "    try:\n",
    "        full_descriptions = str(description_containers.text)\n",
    "    except AttributeError:\n",
    "        full_descriptions= 'None Found'\n",
    "    \n",
    "    Descriptions.append(job_descriptions)\n",
    "    Title.append(job_title)\n",
    "    Location.append(locations)\n",
    "    FullDescriptions.append(full_descriptions)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting what we want from the Descriptions Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'Location' left in for sanity check. Should be removed once code is confirmed to work\n",
    "Descriptions_df = pd.DataFrame(columns = ['Title', 'Location','City', 'State', 'Zip', 'Country', 'Qualifications', 'Skills', 'Responsibilities', 'Education', 'Requirement', 'FullDescriptions'])\n",
    "Country = ['US', 'USA', 'United States', 'United States of Americal']\n",
    "States = ['AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', 'IA',\n",
    "          'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND',\n",
    "          'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY']\n",
    "\n",
    "for index, element in enumerate(Descriptions):\n",
    "    soup=BeautifulSoup(element,'lxml')\n",
    "    for values in list(Descriptions_df):\n",
    "        temp_tag = soup.find('b', text=re.compile(values))\n",
    "        try:\n",
    "            ul_tag = temp_tag.find_next('ul')\n",
    "            Descriptions_df.at[index,values] = ul_tag.text\n",
    "        except AttributeError:\n",
    "            Descriptions_df.at[index,values]=\"None Found\"\n",
    "        Descriptions_df.at[index,\"Title\"]=Title[index]\n",
    "        Descriptions_df.at[index,\"Location\"]=Location[index]\n",
    "        Descriptions_df.at[index,\"FullDescriptions\"]=FullDescriptions[index]\n",
    "        words = '|'.join(Country)\n",
    "        temp = re.findall(words, Location[index])\n",
    "        if len(temp) != 0:\n",
    "            Descriptions_df.at[index,\"Country\"] = temp[0]\n",
    "        words = '|'.join(States)\n",
    "        temp = re.findall(words, Location[index])\n",
    "        if len(temp) != 0:\n",
    "            Descriptions_df.at[index,\"State\"] = temp[0]\n",
    "        temp = re.findall(r'\\d+', Location[index])\n",
    "        if len(temp) != 0:\n",
    "            Descriptions_df.at[index,\"Zip\"] = temp[0]  \n",
    "            \n",
    "        temp = re.findall(r'[\\w w]+,', Location[index])\n",
    "        if len(temp) != 0:\n",
    "            Descriptions_df.at[index,\"City\"] = re.sub(',', '', temp[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Country</th>\n",
       "      <th>Qualifications</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Responsibilities</th>\n",
       "      <th>Education</th>\n",
       "      <th>Requirement</th>\n",
       "      <th>FullDescriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Engineer I</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>A desire to work in a collaborative, intellectually curious environment.Degree in Computer Science, Engineering, Mathematics, or a related field and 4-5+ years industry experienceOne year of experience in the following skill(s):Developing and operating large-scale data structures for business intelligence analytics using: ETL/ELT processes; OLAP technologies; data modeling; SQL;Experience with at least one relational database technology such as Redshift, Oracle, MySQL or MS SQLExperience with at least one massively parallel processing data technology such as Redshift, Teradata, Netezza, Spark, or Hadoop based big data solution\\n\\nHealth, Safety, Security, and Compliance (HS3C) is responsible for keeping our Customers and partners safe, and ensuring we maintain WW compliance. We build scalable solutions that grow with the Amazon business. HS3C-Compliance team collects petabytes of data from thousands of data sources inside and outside Amazon including the Amazon catalog system, inventory system, customer order system, and page views on the website. We provide interfaces for our internal customers to access and query the data hundreds of thousands of times per day, using Amazon Web Service’s (AWS) Redshift, Hive, and Spark.\\n\\nHS3C-Compliance is growing, and the data processing landscape is shifting. Our data is consumed by teams across HS3C including Research Scientists, Machine Learning Specialists, Business Analysts, and Data Engineers. We are seeking an outstanding Data Engineer to join the HS3C-Compliance data technologies team. The HS3C-Compliance data technologies team manages the core HS3C business data from hundreds of source systems. Amazon has culture of data-driven decision-making, and demands business intelligence that is timely, accurate, and actionable. If you join the HS3C-Compliance data technologies team, your work will have an immediate influence on day-to-day decision making at Amazon.\\n\\nAs an Amazon Data Engineer II, you will be working in one of the world's largest cloud-based data lakes. You should be skilled in the architecture of data warehouse solutions for the Enterprise using multiple platforms (EMR, RDBMS, Columnar, Cloud). You should have extensive experience in the design, creation, management, and business use of extremely large datasets. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions, and to build data sets that answer those questions. Above all you should be passionate about working with huge data sets and someone who loves to bring datasets together to answer business questions and drive change.\\nAs a Data Engineer II on the HS3C-Compliance data technologies team, you will design, develop, implement, test, document, and operate large-scale, high-volume, high-performance data structures for analytics and deep learning. Implement data ingestion routines both real time and batch using best practices in data modeling, ETL/ELT processes leveraging AWS technologies and Big data tools. Gather business and functional requirements and translate these requirements into robust, scalable, operable solutions that work well within the overall data architecture. Analyze source data systems and drive best practices in source teams. Participate in the full development life cycle, end-to-end, from design, implementation and testing, to documentation, delivery, support, and maintenance. Produce comprehensive, usable dataset documentation and metadata. Evaluate and make decisions around dataset implementations designed and proposed by peer data engineers. Evaluate and make decisions around the use of new or existing software products and tools. Mentor junior data engineers.\\n\\nIndustry experience as a Data Engineer or related specialty (e.g., Software Engineer, Business Intelligence Engineer, Data Scientist) with a track record of manipulating, processing, and extracting value from large datasets.Coding proficiency in at least one modern programming language (Python, Ruby, Java, etc)Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data setsExperience building data products incrementally and integrating and managing datasets from multiple sourcesQuery performance tuning skills using Unix profiling tools and SQLExperience leading large-scale data warehousing and analytics projects, including using AWS technologies – Redshift, S3, EC2, Data-pipeline and other big data technologiesExperience providing technical leadership and mentor other engineers for the best practices on the data engineering spaceLinux/UNIX including to process large data sets.Experience with AWS\\nOpportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Lead Data Scientist</td>\n",
       "      <td>Bellevue, WA</td>\n",
       "      <td>Bellevue</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>BA / BS degree or equivalent practical experience\\n3 years of experience working with statistical packages (e.g. R, SAS, Stata, MATLAB, etc.)\\nExperience with articulating product questions, pulling data from datasets (SQL) and using statistics to arrive at an answer\\n</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nConduct data analysis to make business recommendations (cost-benefit, invest-divest, forecasting, impact analysis)\\nDeliver effective presentations of findings and recommendations to multiple levels of stakeholders, creating visual displays of quantitative information\\nDevelop and automate reports, iteratively build and prototype dashboards to provide insights at scale, solving for analytical needs\\nCollaborate with cross-functional stakeholders to understand their business needs, formulate and complete end-to-end analysis that includes data gathering, analysis, ongoing scaled deliverables and presentations\\nHelp our customer to focus on key decisions to improve products and services\\n</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>We are constantly looking for intelligent members to join our AI and data intelligence team to either lead or implement exciting POCs for our customers.\\n\\nResponsibilities\\nConduct data analysis to make business recommendations (cost-benefit, invest-divest, forecasting, impact analysis)\\nDeliver effective presentations of findings and recommendations to multiple levels of stakeholders, creating visual displays of quantitative information\\nDevelop and automate reports, iteratively build and prototype dashboards to provide insights at scale, solving for analytical needs\\nCollaborate with cross-functional stakeholders to understand their business needs, formulate and complete end-to-end analysis that includes data gathering, analysis, ongoing scaled deliverables and presentations\\nHelp our customer to focus on key decisions to improve products and services\\nQualifications\\nBA / BS degree or equivalent practical experience\\n3 years of experience working with statistical packages (e.g. R, SAS, Stata, MATLAB, etc.)\\nExperience with articulating product questions, pulling data from datasets (SQL) and using statistics to arrive at an answer\\nPreferred Qualifications\\nBA / BS or Master degree with emphasis on coursework of a quantitative nature (e.g., statistics, computer science, engineering, mathematics, data sciences)\\nSufficient hand-on experiences in R and Python\\nExperience in scripting with SQL, extracting large sets of data, and design of ETL flows\\nWork experience in an interdisciplinary / cross-functional field\\nExtraordinary problem-solving skills be able to lead a team to achieve business objectives\\nCapable of translating analysis results into business goals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist, Medical Imaging</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>5+ years of programming experience in Python, R, JS and C/C++\\n5+ years of development in data modeling and machine learning, including practical experience of deep learning methods (CNN, RNN) and/or natural language processing\\n3+ years of experience in agile development\\n2+ year of experience with machine learning toolkits (TensorFlow, scikit-learn, Keras)\\n1+ years of experience with cloud-based storage and computing tools for machine learning\\nExperience with at least one of the public cloud providers such as GCP, AWS, Azure or IBM Cloud\\n</td>\n",
       "      <td>Build and maintain large medical imaging databases\\nDevelop data cleaning and pre-processing methods to normalize data and detect outliers\\nOptimize data transfer, data flows and data operations\\nImplement and document API’s for machine learning algorithms\\nDevelop and deploy machine learning algorithms for medical imaging use cases\\nCollaborate with academic and industrial partners to collect and optimize data collection\\nAssist with product integration of machine learning solutions\\nAssist in development of machine learning web/UI applications\\n</td>\n",
       "      <td>None Found</td>\n",
       "      <td>5+ years in software development, preferably in medical imaging\\n5+ years of machine learning experience\\n</td>\n",
       "      <td>Transforming the future of healthcare isn’t something we take lightly. It takes teams of the best and the brightest, working together to make an impact.\\nAs one of the largest healthcare technology companies in the U.S., we are a catalyst to accelerate the journey toward improved lives and healthier communities.\\nHere at Change Healthcare, we’re using our influence to drive positive changes across the industry, and we want motivated and passionate people like you to help us continue to bring new and innovative ideas to life.\\n\\n\\nIf you’re ready to embrace your passion and do what you love with a company that’s committed to supporting your future, then you belong at Change Healthcare.\\nPursue purpose. Champion innovation. Earn trust. Be agile. Include all.\\nEmpower Your Future. Make a Difference.\\nPosition Description\\nThe Data Scientist is a key contributor to the success of the Artificial Intelligence (AI) Medical Imaging team, the Imaging, Enterprise Imaging Solutions business unit, and Change Healthcare (CHC). This individual with versatile data science skills will create commercial-grade AI solutions for medical imaging products. He/she will participate to the optimization of our AI operations from data ingestion and machine learning modeling to integration into the end product.\\nThe AI Medical Imaging team is responsible for creating AI enabled solutions, maintaining a culture of innovation with a startup mindset, and providing subject matter expertise for the benefit of Change Healthcare. While the AI Medical Imaging team has stakeholders throughout the business unit, it works most closely with academic and industrial partners and those parts of the organization responsible for product conception, design and development. The Data Scientist will work with all stakeholders to fulfill Company’s business needs.\\nResponsibilities:\\nBuild and maintain large medical imaging databases\\nDevelop data cleaning and pre-processing methods to normalize data and detect outliers\\nOptimize data transfer, data flows and data operations\\nImplement and document API’s for machine learning algorithms\\nDevelop and deploy machine learning algorithms for medical imaging use cases\\nCollaborate with academic and industrial partners to collect and optimize data collection\\nAssist with product integration of machine learning solutions\\nAssist in development of machine learning web/UI applications\\nMinimum Requirement (Required):\\n5+ years in software development, preferably in medical imaging\\n5+ years of machine learning experience\\nCritical Skills (Required):\\n5+ years of programming experience in Python, R, JS and C/C++\\n5+ years of development in data modeling and machine learning, including practical experience of deep learning methods (CNN, RNN) and/or natural language processing\\n3+ years of experience in agile development\\n2+ year of experience with machine learning toolkits (TensorFlow, scikit-learn, Keras)\\n1+ years of experience with cloud-based storage and computing tools for machine learning\\nExperience with at least one of the public cloud providers such as GCP, AWS, Azure or IBM Cloud\\nAdditional Knowledge &amp; Skills (Preferred / Not Required):\\nExperience developing commercial Web/UI applications\\nDevelopment experience with topological data analysis\\nExperience in CI/CD tools\\nExperience in automated functional/load/integration test tools\\nExperience of declarative languages such as XML, JSON, and YAML\\nExperience in ‘Linux/Unix’ OS and shell scripting\\nSoft Skills:\\nStrong written and verbal communication, and interpersonal skills\\nHighly self-motivated and directed. Results oriented\\nCross-cultural and team player who enjoys working in a fast-paced environment\\nEducation / Training:\\nPhD or MS in computer science, electrical engineering or related discipline or equivalent industry\\nexperience.\\nPhysical Requirements:\\nLimited domestic and international travel required (up to 5%).\\nJoin our team today where we are creating a better coordinated, increasingly collaborative, and more efficient healthcare system!\\nEqual Opportunity/Affirmative Action Commitment\\n\\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Software Engineering Manager, Backend (Data Analytics)</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nBachelor’s degree or above in computer science or related field\\n2+ years of demonstrated ability to grow and lead a team of engineers in a fast-paced startup environment\\n5+ years hands-on experience developing robust back-end services using Agile, Scrum, Kanban or similar development/management practices\\nExperience in architecting and playing a part in the design and code review processes for consumer-facing applications</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Position Overview:\\nThe Climate Corporation is revolutionizing the agriculture industry with a platform and products that are helping the world’s farmers sustainably increase productivity with digital tools. We are looking for an individual to lead and grow a team of experienced and talented engineers in the delivery of Climate’s analytics platform to provide a solid foundation for the delivery of Climate’s next generation data science based products. This role is a unique opportunity to leverage Climate’s powerful cloud services, massive depth of data, and cutting edge scientific modeling to deliver a disruptive platform that makes a real world difference.\\nWhat You Will Do:\\nLead, grow, and inspire a talented team of engineers focused on building and managing a cutting edge analytics platform that powers the Climate platform\\nCollaborate with product, data scientist, and engineering on the next generation of the industry-leading agriculture platform\\nFearlessly drive an efficient and effective Agile software development process to manage a deep backlog and launch iteratively developed solutions\\nMotivate and provide necessary tools for engineers to work with the confidence to create simple solutions to complex problems\\nEnsure stability of Climate’s product through robust, scalable and fault tolerant software development practices\\nHelp your team meet their goals and strive to be their best\\nWork with cutting edge open source platforms such as Hadoop, YARN, Flink, Spark, etc.\\nAct as an active source of engineering talent and work with recruiting teams to build and scale the future of engineering at The Climate Corporation\\nAlign the team’s goals and objectives towards the “Bigger Picture” of the Climate Corporation\\nRepresent Climate and present at local Meetups, User Groups and Conferences\\nBasic Qualifications:\\nBachelor’s degree or above in computer science or related field\\n2+ years of demonstrated ability to grow and lead a team of engineers in a fast-paced startup environment\\n5+ years hands-on experience developing robust back-end services using Agile, Scrum, Kanban or similar development/management practices\\nExperience in architecting and playing a part in the design and code review processes for consumer-facing applications\\nPreferred Qualifications:\\nAt least 2 years experience with deployment in large cloud-based distributed environments\\nAt least 2 years experience working with distributed platforms such as YARN, Flink, Spark, etc.\\nKnowledge of functional programming (Strong Plus)\\nExperience with dynamic language (Python) (Desired)\\nExperience with compiled JVM language (Java, Scala) (Strong Plus)\\nExperience with open source schedulers (Airflow)\\nExperience with AWS or similar distributed architecture\\nWhat We Offer:\\nOur teams are composed of industry experts, top scientists, and talented engineers. The environment is extremely engaging and fast-paced, with dozens of specialties coming together to provide the best possible products and experiences for our customers.\\nWe provide competitive salaries and some of the best perks in the industry, including:\\nSuperb medical, dental, vision, life, disability benefits, and a 401k matching program\\nA stocked kitchen with a large assortment of snacks &amp; drinks to get you through the day\\nEncouragement to get out of the office and into the field with agents and farmers to see first-hand how our products are being used\\nWe take part and offer various workshops, conferences, meet-up groups, tech-talks, and hackathons to encourage participation and growth in both community involvement and career development\\nWe also hinge our cultural DNA on these five values:\\nInspire one another\\nInnovate in all we do\\nLeave a mark on the world\\nFind the possible in the impossible\\nBe direct and transparent\\nAs part of our dedication to the diversity of our workforce, The Climate Corporation is committed to Equal Employment Opportunity without regard for race, color, national origin, ethnicity, gender, protected veteran status, disability, sexual orientation, gender identity, or religion. If you need assistance or accommodation due to a disability, you may contact us at accommodations@climate.com\\nLearn more about our team and our mission:\\nThe Climate Corporation - The Technology Behind Making A Difference\\nhttps://youtu.be/c5TgbpE9UBI or visit https://climate.com/careers\\n#LI-TF1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Engineer II (L5) - Business Data Technologies</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>A desire to work in a collaborative, intellectually curious environment.Degree in Computer Science, Engineering, Mathematics, or a related field and 4-5+ years industry experienceMust have one year of experience in the following skill(s):Developing and operating large-scale data structures for business intelligence analytics using: ETL/ELT processes; OLAP technologies; data modeling; SQL;Experience with at least one relational database technology such as Redshift, Oracle, MySQL or MS SQLExperience with at least one massively parallel processing data technology such as Redshift, Teradata, Netezza, Spark or Hadoop based big data solution\\n\\nAmazon’s eCommerce Foundation (eCF) organization is responsible for the core components that drive the Amazon website and customer experience. Serving millions of customer page views and orders per day, eCF builds for scale.\\nAs an organization within eCF, the Business Data Technologies (BDT) group is no exception. We collect petabytes of data from thousands of data sources inside and outside Amazon including the Amazon catalog system, inventory system, customer order system, page views on the website and Alexa systems. We also support Amazon subsidiaries such as IMDB and Audible. We provide interfaces for our internal customers to access and query the data hundreds of thousands of times per day, using Amazon Web Service’s (AWS) Redshift, Hive, and Spark. We build scalable solutions that grow with the Amazon business.\\n\\nBDT is growing, and the data processing landscape is shifting. Our data is consumed by thousands of teams across Amazon including Research Scientists, Machine Learning Specialists, Business Analysts and Data Engineers. Amazon.com is seeking an outstanding Data Engineer to join the BDT Content team. The BDT Content team manages the core Amazon business data from hundreds of source systems. Amazon.com has culture of data-driven decision-making, and demands business intelligence that is timely, accurate, and actionable. If you join the Amazon.com BDT Content team, your work will have an immediate influence on day-to-day decision making at Amazon.com.\\n\\nAs an Amazon.com Data Engineer II you will be working in one of the world's largest cloud-based data lakes. You should be skilled in the architecture of data warehouse solutions for the Enterprise using multiple platforms (EMR, RDBMS, Columnar, Cloud). You should have extensive experience in the design, creation, management, and business use of extremely large datasets. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions, and to build data sets that answer those questions. Above all you should be passionate about working with huge data sets and someone who loves to bring datasets together to answer business questions and drive change.\\n\\nAs a Data Engineer II on Amazon.com’s Business Data Technologies team, design, develop, implement, test, and operate large-scale, high-volume, high-performance data structures for analytics and deep learning. Implement data ingestion routines both real time and batch using best practices in data modeling, ETL/ELT processes leveraging AWS technologies and Big data tools. Gather business and functional requirements and translate these requirements into robust, scalable, operable solutions that work well within the overall data architecture. Analyze source data systems and drive best practices in source teams. Participate in the full development life cycle, end-to-end, from design, implementation and testing, to documentation, delivery, support, and maintenance. Produce comprehensive, usable dataset documentation and metadata. Evaluate and make decisions around dataset implementations designed and proposed by peer data engineers. Evaluate and make decisions around the use of new or existing software products and tools. Mentor junior data engineers.\\n\\nIndustry experience as a Data Engineer or related specialty (e.g., Software Engineer, Business Intelligence Engineer, Data Scientist) with a track record of manipulating, processing, and extracting value from large datasets.Coding proficiency in at least one modern programming language (Python, Ruby, Java, etc)Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data setsExperience building data products incrementally and integrating and managing datasets from multiple sourcesQuery performance tuning skills using Unix profiling tools and SQLExperience leading large-scale data warehousing and analytics projects, including using AWS technologies – Redshift, S3, EC2, Data-pipeline and other big data technologiesExperience providing technical leadership and mentor other engineers for the best practices on the data engineering spaceLinux/UNIX including to process large data sets.Experience with AWS\\nAmazon is an equal opportunities employer. We believe passionately that employing a diverse workforce is central to our success and we make recruiting decisions based on your experience and skills. We welcome applications from all members of society irrespective of age, gender, disability, sexual orientation, race, religion or belief.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sr. Data Scientist - AWS Demand Planning</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Masters in quantitative field (Data Science, Statistics, Analytics, Machine Learning, AI, Computer Science, Mathematics, or equivalent) or Bachelors with 2+ years additional experience3+ years of experience working in data science in a technology company3+ years of experience with R, Python, SAS, Matlab or other statistical/machine learning software3+ years of experience with data querying languages like SQL3+ years of communicating business results of analytical deep dives to senior leadershipUse of data visualization principles/tools which can integrate with data science outputs\\n\\nAt Amazon, we're working to be the most customer-centric company on earth. To get there, we need exceptionally talented, bright, and visionary people. We are looking for a Sr. Data Scientist with excellent analytical abilities, outstanding business acumen and judgment, intense curiosity, strong technical skills, and superior written and verbal communication skills to join the AWS Demand Planning team.\\n\\nAs a Sr. Data Scientist, you will generate insights that will guide operational excellence and product development for our customers. Data analysis is at the core Amazon’s culture, and your work will have a direct impact on decision making and strategy for our team. You will be gathering customer insights, mining data, making recommendations, and helping senior leaders make key business decisions. You will have the opportunity to work with large and diverse data sets to gather insights using data from across AWS Infrastructure. You will be working in a large, extremely complex, and dynamic, data-driven environment. We are looking for a data scientist with expertise and passion for analyzing data, designing and building predictive and decision models, and designing metrics to measure the performance of the business. You will interact directly with business leaders and groups that rely on the metrics and the decisions produced using predictive models.\\n\\nThe ideal candidate will have excellent analytical abilities, outstanding business acumen and judgment, intense curiosity, strong technical skills, and superior written and verbal communication skills. They will have a strong bias toward data driven decision making. They will be a self-starter, comfortable with ambiguity, able to think big and be creative (while paying careful attention to detail), and will enjoy working in a fast-paced dynamic environment. If you are excited about data, are results oriented, and want to join a growing analytics team within Amazon - this role is for you.\\n\\nKey Responsibilities Include:\\nInterface with business leaders and customers, gather requirements, and deliver complete reporting solutionsGenerate business insights autonomously based on interactions with business stakeholders and underlying domain knowledge and data science toolingDevelop a deep understanding of our vast data sources and know exactly how, when, and which data to use to solve particular business problemsWork with internal stakeholders to root cause identified defectsUnderstanding drivers, impacts, and key influences on the organizationHelping to build production systems that take inputs from multiple models and make decisionsAutomating feedback loops for algorithms in productionUtilizing Amazon systems and tools to effectively work with terabytes of dataPartner with data engineers to support production data analytics solutionsPartner with business intelligence engineers to support production visualizations for senior leadership\\n\\nMasters in quantitative field (Data Science, Statistics, Analytics, Machine Learning, AI, Computer Science, Mathematics, or equivalent)5+ years of experience working in data science in a technology company5+ years of experience with R, Python, SAS, Matlab or other statistical/machine learning software5+ years of experience with data querying languages like SQL5+ years of communicating business results of analytical deep dives to senior leadership, including some direct interaction with c-suite executives5+ years of experience with Tableau, PowerBI, QuickSight or other data visualization softwareMeets/exceeds Amazon’s leadership principles requirements for this roleMeets/exceeds Amazon’s functional/technical depth and complexity for this role\\nAmazon is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist, Amazon Devices</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Masters in quantitative field (Statistics, Applied Math, Operations Research, Economics or equivalent)3+ years of experience working in data scienceExtensive knowledge and practical experience in several of the following areas: machine learning, statistics, A/B testing, casual models, forecasting models, etc.Experience with R, Python or other statistical/machine learning software.\\n\\nThe Amazon Devices team designs and engineers high-profile consumer electronics, including the best-selling Kindle family of products. We have also produced groundbreaking devices like Fire tablets, Fire TV, Amazon Dash, and Amazon Echo.\\n\\nWhat will you help us create?\\n\\nThe Team: How often have you had an opportunity to be a founding member of a team that is solving a significant problem through innovative technology? Would you like to know more about how we are envisioning the use of machine learning, AI and linear programming to solve these problems? If this sounds intriguing, then we’d like to talk to you about a role on a new Amazon team that's tackling a set of problems requiring significant innovation and scaling.\\n\\nAs a data scientist, you will design, evangelize, and implement state-of-the-art solutions for never-before-solved problems, helping Amazon Device to provide customer great products. This role will be a key member of a Science and Data technology team based in Seattle, WA. You will work closely with other research scientists, machine learning experts, engineers to design and run experiments, research new algorithms, and find new ways to improve Amazon Device Services &amp; Software products. You will partner with technology and product leaders to solve business and technology problems using scientific approaches to build new services that surprise and delight our customers. Our scientists work closely with software engineers to put algorithms into practice. They also work on cross-disciplinary efforts with other scientists within Amazon.\\n\\nThe key responsibility for this role include:\\nDefine proper output business Metrics, and build input models to identify patterns and drivers of the output. Drive actions at scale using scientifically-based methods and decision making.Design and develop complex mathematical, statistical, simulation and optimization models and apply them to define strategic and tactical needs and drive the appropriate business and technical solutionsDesign experiments, test hypotheses, and build actionable modelsPrototype these models by using modeling languages such as R or in software languages such as Python.Work with software engineering teams to drive scalable, real-time implementationsUtilizing Amazon systems and tools to effectively work with terabytes of data\\n\\nA PhD in a quantitative field (Computer Science, Mathematics, Machine Learning, AI, Statistics, or equivalent)5+ years of experience working in data scienceSkilled with Java, C++, or other programming language, as well as with R, SAS, MATLAB, Python or similar scripting languageAbility to distill informal customer requirements into problem definitions, dealing with ambiguity and competing objectiveAbility to manage and quantify improvement in customer experience or value for the business resulting from research outcomesSuperior verbal and written communication skills, ability to convey rigorous mathematical concepts and considerations to non-expertsThrive in a fast-paced, innovative environmentAbility to distill informal customer requirements into problem definitions, dealing with ambiguity and competing objectives\\nAmazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Software Developer 4</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nBuild technical architectures and solutions required for optimal ingestion, transformation, and loading of data from a wide variety of data sources to our data warehouse and data lake environments\\nWork with various development and product teams to provide feedback surrounding data-related technical issues and support for data infrastructure needs uncovered during internal engagements\\nUnderstand and formulate processing pipelines for large, complex data sets that meeting functional / non-functional business requirements\\nCreate and maintain optimal data pipeline architecture\\nDevelop standards and controls for improving data quality / process efficiency\\nIdentify technical risks associated with a project/program and provide mitigation options\\nWork alongside data engineers, software development engineers, and data analysts to implement data engineering solutions that scale\\nCollaborate with data analyst, scientists, and stewards during design discussions to uncover more detailed business requirements related to data engineering\\nApply data visualization, market research, and performance measurement best practices to new and existing solutions.\\nDrive awareness and adoption across the organization on the importance of having a data-driven culture\\nEstablish a data governance model to standard and improve the use of data</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Software Developer 4-1900128X\\n\\n\\nPreferred Qualifications\\n\\nThe Oracle Cloud Infrastructure (OCI) team can provide you the opportunity to build and operate a suite of massive scale, integrated cloud services in a broadly distributed, multi-tenant cloud environment. OCI is committed to providing the best in cloud products that meet the needs of our customers who are tackling some of the world’s biggest challenges.\\nWe offer unique opportunities for smart, hands-on engineers with the expertise and passion to solve difficult problems in distributed highly available services and virtualized infrastructure. At every level, our engineers have a significant technical and business impact designing and building innovative new systems to power our customer’s business critical applications.\\nAre you interested in building large-scale distributed infrastructure for the cloud? Oracle’s Cloud Infrastructure team is based in downtown Seattle and is building new Infrastructure-as-a-Service technologies that operate at high scale in a broadly distributed multi-tenant cloud environment. Oracle’s extensive enterprise customer base is looking for rock solid cloud solutions that provide the same reliability and effectiveness that they have come to expect from Oracle. Our customers run their businesses on our cloud, and our mission is to provide them with best in class, foundational cloud services. Oracle's Cloud team is being built with an entrepreneurial spirit that promotes an energetic and creative environment.\\n\\nWe are specifically looking for a BI &amp; Analytics Data Architect to join the Operations BI and Reporting team in Seattle. The team provides accurate data and partners with teams to help them discover actionable narratives, both by describing the past and predicting the future. We believe information enables success, and we are committed to providing clear insights for all levels of the organization. The ideal candidate will have proven experience in creating reporting and data analysis, designing &amp; implementing database structures, enabling a “data driven culture” and providing technical leadership. The purpose of a Data Architect is to enable data scientist and analyst to gain insights into data by architecting and implementing data-driven solutions Challenges and opportunities are plentiful in this role! We need talented people to help us drive excellence using data to tell business stories.\\nIn this role, you will:\\nBuild technical architectures and solutions required for optimal ingestion, transformation, and loading of data from a wide variety of data sources to our data warehouse and data lake environments\\nWork with various development and product teams to provide feedback surrounding data-related technical issues and support for data infrastructure needs uncovered during internal engagements\\nUnderstand and formulate processing pipelines for large, complex data sets that meeting functional / non-functional business requirements\\nCreate and maintain optimal data pipeline architecture\\nDevelop standards and controls for improving data quality / process efficiency\\nIdentify technical risks associated with a project/program and provide mitigation options\\nWork alongside data engineers, software development engineers, and data analysts to implement data engineering solutions that scale\\nCollaborate with data analyst, scientists, and stewards during design discussions to uncover more detailed business requirements related to data engineering\\nApply data visualization, market research, and performance measurement best practices to new and existing solutions.\\nDrive awareness and adoption across the organization on the importance of having a data-driven culture\\nEstablish a data governance model to standard and improve the use of data This is a senior role, so part of the role will include mentorship of a team of budding Engineers and Architects\\nMandatory Qualifications:\\nBachelor’s or Master’s degree in Computer Science, Information Technology, Business Administration or related field\\nAbility to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy\\nExperience with object-oriented and/or functional programming languages, such as Python, Java and Scala\\nExperience in building scalable end-to-end data ingestion and processing solutions\\nGood understanding of data infrastructure and distributed computing principles\\nExperience with Machine Learning toolkits\\nProficient at implementing data processing workflows using Hadoop and frameworks such as Spark\\nGood understanding of data governance and how regulations can impact data storage and processing solutions such as GDPR and PCI\\nAbility to identify and select the right tools for a given problem, such as knowing when to use a relational or non-relational database\\nWorking knowledge of non-relational and row/columnar based relational databases\\nExcels in synthesizing complex elements into a crisp, yet robust story\\nSelf-driven, analytical, and results oriented with proven sound judgment.\\nExcellent organizational, verbal, and written communication skills\\nPreferred Qualifications:\\n6+ years as a Data Architect and/or DBA\\nA successful history of manipulating, processing and extracting value from large disconnected datasets\\nDemonstrated experience in data warehousing - including dimensional data modelling, fact and dimension tables, physical and logical data modeling\\nDemonstrated experience in data lake technology to improve data ingestion, storage, governance, security, quality, discovery, exploration, and auditing\\nAbility to gather data requirements and use data modeling to visualize patterns for analysis\\nConfidently taking responsibility for the technical output of a project\\nAbility to quickly pick up new skills and learn on the job\\nComfortably working with various stakeholders such as data scientists, architects and other developers\\nExperienced development skills using Oracle PL/SQL, Oracle Cloud ADW, Oracle Cloud Big Data, and Oracle Analytics Cloud\\n\\nDetailed Description and Job Requirements\\n\\nDesign, develop, troubleshoot and debug software programs for databases, applications, tools, networks etc.\\n\\nAs a member of the software engineering division, you will take an active role in the definition and evolution of standard practices and procedures. You will be responsible for defining and developing software for tasks associated with the developing, designing and debugging of software applications or operating systems.\\n\\nWork is non-routine and very complex, involving the application of advanced technical/business skills in area of specialization. Leading contributor individually and as a team member, providing direction and mentoring to others. BS or MS degree or equivalent experience relevant to functional area. 7 years of software engineering or related experience.\\n\\nOracle is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability and protected veterans status or any other characteristic protected by law.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sr. Technical Recruiter-Machine Learning</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>3+ years of technical recruiting experienceExperience managing and prioritizing multiple searches, projects and client relationships.Experience building and driving talent sourcing initiatives.Experience working with recruiting and people-related tools and systems, including applicant tracking systems, resume databases, internet sourcing tools and complex spreadsheets.\\n\\nThe Scientist Economist Design Team (SEDT) is looking for a Technical Recruiter to join its forces in either Seattle, Austin and Palo Alto.\\n\\nIf you are passionate about recruiting and hiring Applied Scientist, Research Scientist and Data Scientist role across Consumer organization, we hope you will apply.\\nCore Responsibilities:\\nPartner with hiring teams to build effective sourcing, assessment, and closing approaches with an ability to manage customer/partner expectations through a deep understanding of return on investment.Recruit passive candidates and assess candidates for fit and motivation.Build and maintain network of potential candidates through pro-active market research and on-going relationship management; conducts in-depth interviews of potential candidates.Recommend ideas and strategies related to recruitment of talent that will contribute to the long-range growth of the company, implementing new processes and fine-tuning current processes.Articulate in writing a plan with deliverables, timelines and a formal tracking process.Screen, interview and prepare a candidate slate within an appropriate and consistent timeline.Participate in special projects/recruiting initiatives, including assessment of best practices in interviewing techniques, leveraging of internal sources of talent and identification of top performers.\\nAmazon is an Equal Opportunity-Affirmative Action Employer - Female/Minority/Disability/Veteran/Gender Identity/Sexual Orientation\\n\\nScience RecruitingSourcing RecruiterBachelor’s degreeStrong client focus and commitment to continuous improvement; ability to proactively network and establish effective working relationships, must pursue conscious cost-containment efforts in recruiting, continually seek new sourcing options, and develop creative approaches to delivering candidates to the customer.Strong communication skills, organizational and negotiation skills, with a keen focus on delivering business results.Ability to execute recruiting strategy, including employer promotion in the marketplace, candidate management, diversity sourcing, and interview process management.Self-sufficient and able to work with little direct supervision.Strong consulting skills and demonstrated ability to work in a team environment, as a team leader and member.Strong analytic skills with ability to create, measure, and scale the right workflow between candidates, hiring managers, and the recruiting team.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Machine Learning Intern (ML-Computer Vision), AI@Unity</td>\n",
       "      <td>Bellevue, WA</td>\n",
       "      <td>Bellevue</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Using our industry-leading game engine, we are creating a whole new line of products and services centered around running massively scaled simulations in the cloud. This will impact multiple industries like Robotics and Autonomous Vehicles, and contribute to the advancement of artificial intelligence.\\n\\nWe are looking for exceptional interns to join the visual Machine Learning team, under AI@Unity.\\n\\nThis is an opportunity to be one of the early members behind an innovative product that will define a new standard for how computer vision systems are trained, tested and validated. We're looking for interns who are entrepreneurial, adaptable and enjoy challenging the status quo.\\n\\nResponsibilities\\n\\n\\nImplement algorithms for understanding visual content and help our users discover the most relevant packages in our asset store catalog\\nContribute to state of the art computer vision models to generate visual content for environments made with unity\\nImplement state of the art computer vision models trained on synthetic data to solve common perception problems in the autonomous vehicle space\\n\\nRequirements\\n\\n\\nProgramming experience in one of the following languages: Python, C#, Java, or C++\\nExperience in one of the following libraries: TensorFlow or PyTorch\\nStrong background in linear algebra, calculus, and probability theory\\nProficiency in data structures, algorithms, and software design\\nExcellent verbal and written communication skills\\n\\nBonus points\\n\\n\\nPublished research in one of the following areas: Deep Learning, Computer Vision\\nExperience with contributing to open-source projects\\nExperience with Unity Engine, 3D simulators, and game development\\n\\nWho we are\\n\\nUnity is the creator of the world's most widely-used real-time 3D (RT3D) development platform, providing content creators around the world with the tools they need to build rich, interactive 2D, 3D, VR and AR experiences. In fact, apps made with Unity reach 2.7 billion devices worldwide, and were installed more than 24 billion times in the last 12 months.\\n\\nThe global engineering team keeps Unity at the forefront of technology and — working alongside partners like Magic Leap, Google, Facebook, Oculus and Microsoft — ensures optimized support for the latest technology and platforms. Unity is powering the real-time revolution, expanding beyond games and breaking into other industries including automotive, film, architecture, engineering, construction and more.\\n\\nUnity is an equal opportunity employer committed to fostering an inclusive, innovative environment with the best employees. Therefore, we provide employment opportunities without regard to age, race, color, ancestry, national origin, religion, disability, sex, gender identity or expression, sexual orientation, or any other protected status in accordance with applicable law. If there are preparations we can make to help ensure you have a comfortable and positive interview experience, please let us know.\\n\\nHeadhunters and recruitment agencies may not submit resumes/CVs through this Web site or directly to managers. Unity does not accept unsolicited headhunter and agency resumes. Unity will not pay fees to any third-party agency or company that does not have a signed agreement with Unity.\\n\\n#LI-KE1 #INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist I-III, Spatial Single-Cell RNA Sequencing</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nExperience in analysis of next generation sequencing (NGS) data\\nExcellent programming skills (Python, R, C/C++, Java) including best software development practices (e.g. design, unit tests, documentation, code review)\\nExcellent interpersonal, oral and written communication skills\\nStrong work ethic\\nAbility to work in a team\\nAbility to manage multiple projects and to meet deadlines</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Consult with Fred Hutch researchers collaborating with iLab to solve their data science problems\\nManage and set scientific priorities across projects\\nDevelop and optimize computational pipelines to enable the integration and management of large and complex data sets generated in the iLab\\nTest and potentially develop open-source software for reproducible research\\nInterpret results from computational and statistical analysis\\nAssist with study design and analysis of pre-clinical and clinical trials\\nParticipate in the dissemination of research findings\\nCo-author manuscripts for publication</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Overview\\nCures Start Here. At Fred Hutchinson Cancer Research Center, home to three Nobel laureates, interdisciplinary teams of world-renowned scientists seek new and innovative ways to prevent, diagnose and treat cancer, HIV/AIDS and other life-threatening diseases. Fred Hutch’s pioneering work in bone marrow transplantation led to the development of immunotherapy, which harnesses the power of the immune system to treat cancer. An independent, nonprofit research institute based in Seattle, Fred Hutch houses the nation’s first cancer prevention research program, as well as the clinical coordinating center of the Women’s Health Initiative and the international headquarters of the HIV Vaccine Trials Network. Careers Start Here.\\nThe Innovation Laboratory (iLab) at Fred Hutch is seeking a Masters- or PhD-level data scientist. The iLab is a new collaborative initiative of the Immunotherapy and Translational Data Science Integrated Research Centers (IIRC and TDS_IRC) with a mission to advance the introduction and development of new immuno-oncology research technologies. The iLab will spur in-house development and early adoption of novel techniques, including advanced single cell RNA spatial sequencing, T- and B-cell receptor sequencing, and other DNA/RNA-based technologies. The data scientist will work closely with lab personnel and immunotherapy researchers to develop data analysis methods for new technologies.\\nOver the past three years, Fred Hutch has launched three Integrated Research Centers (IRCs) to increase collaborative research across the Center and stimulate transformative cancer discovery. The IIRC, led by Dr. Stanley Riddell, and the TDS_IRC, led by Dr. Raphael Gottardo, have joined together and created the iLab to speed adoption of novel technologies, particularly those that generate large datasets of high utility to immunotherapy. The successful candidate will be embedded in the iLab, but will also have close ties to the Gottardo Lab and the TDS_IRC. The iLab will initially be housed in the Bielas Lab. Working closely with Drs. Bielas and Gottardo, the successful candidate will function with a high degree of independence as they manage daily activities. We see the integration of computational work within the iLab as an integral part of its success, providing computational innovation.\\nAs a Fred Hutch strategic initiative, we value inclusion and a diversity of backgrounds and perspectives to inform our work. We believe in supporting each other through mentorship and providing resources for professional development. Given these values, we strive to make our recruitment and promotion processes fair and transparent. Therefore, we strongly encourage all individuals with an interest in the position to apply. To learn more about the IRCs: Immunotherapy ; Translational Data Science\\nWe are seeking a Masters- or PhD-level data scientist to work with the iLab to develop workflows and data analysis pipelines, from novel genomics technologies developed in-house to collaboration with select industry partners. The data scientist may also support some projects more broadly, creating workflows and analyses that also include data sets generated outside of the iLab, clinical data, and other translation data sources. The ideal candidate will support large collaborative projects in a wide range of problems in oncology research and serve as a consultant/link between the iLab, laboratory and clinical scientists. The incumbent will collaborate with laboratory-based scientists, clinical investigators, biostatisticians, data scientists, programmers and computational biologists in two ways:\\nAs member of the iLab, creating novel workflows and data analysis pipelines for novel technologies being tested and developed in the laboratory.\\nAs a contributing member on teams using novel technologies in the iLab, creating and using computational tools for analyzing clinical and pre-clinical samples.\\nThrough these multi-disciplinary collaborations, the data scientist will support and expand opportunities to apply novel tools and technologies to innovative pre-clinical and clinical studies.\\nResponsibilities\\nConsult with Fred Hutch researchers collaborating with iLab to solve their data science problems\\nManage and set scientific priorities across projects\\nDevelop and optimize computational pipelines to enable the integration and management of large and complex data sets generated in the iLab\\nTest and potentially develop open-source software for reproducible research\\nInterpret results from computational and statistical analysis\\nAssist with study design and analysis of pre-clinical and clinical trials\\nParticipate in the dissemination of research findings\\nCo-author manuscripts for publication\\nQualifications\\nData Scientist I - Bachelor's degree in bioinformatics, computational biology, biostatistics, statistics, computer science, or a related field and a minimum of 2+ years of hands-on data science experience\\n\\nData Scientist II - Bachelor's degree (Master's or PhD preferred) in bioinformatics, computational biology, biostatistics, statistics, computer science, or a related field and a minimum of 5+ years of hands-on data science experience\\n\\nData Scientist III - Bachelor's degree (Master's or PhD preferred) in bioinformatics, computational biology, biostatistics, statistics, computer science, or a related field and a minimum of 8+ years of hands-on data science experience\\n\\nMinimum qualifications (all levels):\\nExperience in analysis of next generation sequencing (NGS) data\\nExcellent programming skills (Python, R, C/C++, Java) including best software development practices (e.g. design, unit tests, documentation, code review)\\nExcellent interpersonal, oral and written communication skills\\nStrong work ethic\\nAbility to work in a team\\nAbility to manage multiple projects and to meet deadlines\\n\\nPreferred qualifications:\\nExperience in high-dimensional data, particularly with NGS and single-cell NGS (e.g. scRNA-seq)\\nExperience in cloud computing (e.g. AWS)\\nExperience in immunology\\nOur Commitment to Diversity\\nWe are committed to cultivating a workplace in which diverse perspectives and experiences are welcomed and respected. We are proud to be an Equal Opportunity and VEVRAA Employer. We do not discriminate on the basis of race, color, religion, creed, ancestry, national origin, sex, age, disability, marital or veteran status, sexual orientation, gender identity, political ideology, or membership in any other legally protected class. We are an Affirmative Action employer. We encourage individuals with diverse backgrounds to apply and desire priority referrals of protected veterans. If due to a disability you need assistance/and or a reasonable accommodation during the application or recruiting process, please send a request to our Employee Services Center at escmail@fredhutch.org or by calling 206-667-4700.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Software Development Engineer 2</td>\n",
       "      <td>Bellevue, WA 98004</td>\n",
       "      <td>Bellevue</td>\n",
       "      <td>WA</td>\n",
       "      <td>98004</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nBS in CS/CSE or related technical area\\n2+ years professional experience developing web applications in Typescript</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nDevelop web applications using Typescript, React, Electron, and Node to produce innovative and effective solutions.\\nBreak down large technical problems and solve them systematically.\\nDebug and analyze any quality and performance issues across the stack.\\nWork independently and collaborate to identify requirements, specify designs, and deliver on a regular cadence.\\nLearn new programming languages, new technologies, new approaches.\\nCommunicate and develop new ideas with the team.\\nProduce product-quality code integrated with new innovations.</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>The Machine Teaching Innovation Group is seeking a thoughtful and talented web UI developer to help us empower everyone to harness machine learning without needing to be a data scientist.\\n\\nAs a developer on our team you will develop web UI, application state management, and services for our machine teaching application. We leverage modern web libraries to create the platform for machine teaching innovation. We deliver these innovations to the Language Understanding and Intelligence Service (LUIS) and we partner with groups exploring and experimenting with machine teaching.\\n\\nBy joining our friendly and awesome team of engineers, you can:\\nHave a huge impact in a wide-open field where you can try out innovative ideas.\\nProduce high-quality code on cutting edge technology that creates a magical experience for users.\\nLearn from experienced web developers and some of the top researchers in the world.\\nDeliver compelling value across Microsoft.\\n\\nYou don’t need to be knowledgeable in machine teaching nor machine learning algorithms. You don’t have to be an expert every web technology. You will need passion for web development, interest machine teaching, and commitment to the practice of professional development.\\n\\nResponsibilities\\nDevelop web applications using Typescript, React, Electron, and Node to produce innovative and effective solutions.\\nBreak down large technical problems and solve them systematically.\\nDebug and analyze any quality and performance issues across the stack.\\nWork independently and collaborate to identify requirements, specify designs, and deliver on a regular cadence.\\nLearn new programming languages, new technologies, new approaches.\\nCommunicate and develop new ideas with the team.\\nProduce product-quality code integrated with new innovations.\\nQualifications\\nRequired qualifications:\\nBS in CS/CSE or related technical area\\n2+ years professional experience developing web applications in Typescript\\n\\nPreferred Qualifications:\\nExperience with modern web frameworks like React, Angular, Node JS, or Electron.\\nExperience with C#/.NET or other strongly typed languages\\nExperience working on innovation/research/v1 teams\\n\\nMicrosoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.\\n\\nBenefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Staff Data Scientist / Machine Learner</td>\n",
       "      <td>Bellevue, WA</td>\n",
       "      <td>Bellevue</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nBuild industry leading models in one of the following:\\nImage Detection\\nNatural Language Processing\\nLocalized Pricing\\nAd Optimization\\nFraud Detection\\nBuild data pipelines using:\\nSpark\\nAirflow\\n</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\n5+ years of demonstrated experience with machine learning or data science\\nExpertise around scalable programming languages Java, Spark, Flink, TensorFlow, or other data science pipeline technologies.\\nHands on experience solving real business problems are required.\\nHands on experience solving real business problems are required. Ph.D. or Master's Degree in Computer Science, Mathematics, Statistics or another STEM-related field is also required.\\nMust be eligible to work in the United States\\n</td>\n",
       "      <td>From the very beginning, OfferUp has believed that the right people united by the right mission can redefine the possible.\\n\\nOfferUp is dedicated to building the simplest and most trustworthy way for people to buy and sell in their communities. Every year, millions of people use OfferUp to buy and sell locally, resulting in billions of dollars of local commerce. As the largest mobile marketplace for local buyers and sellers in the U.S., our iOS and Android app has been in the top five most popular shopping apps lists for more than three years. Join us as we build the marketplace of the future and help more people discover value right where they are.\\n\\nAt a Glance\\n-----------\\n\\n\\n85+ Million Downloads\\nGeekwire App of Year\\n15%+ of adults in several markets use OfferUp every month (LA, Miami, Phoenix, Seattle, Las Vegas, Riverside, Orlando)\\n\\nOfferUp is looking for a Principal Data Scientist to join our team.\\nWe seek to delight our users with the safest, simplest and most effective local marketplace app on the planet. Your role as a Data Scientist will be to help OfferUp use the most cutting edge technology to maintain its market lead in customer trust and product enthusiasm.\\n\\nOfferUp is a startup. Applicants are expected to understand the business and contribute their ideas and manage many of their own data extractions and data transforms.\\n\\nResponsibilities:\\n\\nBuild industry leading models in one of the following:\\nImage Detection\\nNatural Language Processing\\nLocalized Pricing\\nAd Optimization\\nFraud Detection\\nBuild data pipelines using:\\nSpark\\nAirflow\\n\\nRequirements:\\n\\n5+ years of demonstrated experience with machine learning or data science\\nExpertise around scalable programming languages Java, Spark, Flink, TensorFlow, or other data science pipeline technologies.\\nHands on experience solving real business problems are required.\\nHands on experience solving real business problems are required. Ph.D. or Master's Degree in Computer Science, Mathematics, Statistics or another STEM-related field is also required.\\nMust be eligible to work in the United States\\n\\nNice to Have:\\n\\nExperience working in e-commerce and mobile marketplaces\\nExperience integrating code into a live production environment\\nSome experience in some the following: entity extraction, semantics in text, image recognition, recommender systems, ranking, LDA, classification\\n\\nOfferUp is changing the way people buy and sell locally...Come do work that matters. join the team and take the ride of your life!\\n\\nOfferUp provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, OfferUp complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, transfer, leaves of absence, compensation, and training.\\n\\nOfferUp expressly prohibits any form of workplace harassment based on race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, genetic information, disability, or veteran status. Improper interference with the ability of OfferUp's employees to perform their job duties may result in discipline up to and including discharge.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sr. Research Scientist, Alexa NLU</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Master's degree in Computational Linguistics, Engineering, or related technical field5+ years industry experience with data mining and analytics techniques5+ years industry experience in programming in R, Python, SAS or similar languages\\n\\nThe Alexa Natural Language Understanding (NLU) Interpretations team enables tens of thousands of internal and external developers to increase Alexa’s capabilities much more rapidly, in every language. We’re building a new team to support technology transfer and training for Alexa Domain teams to build their own NLU models, using the NLU Interpretations tools and services. Our team is made up of inspired product managers, strong technical leaders, and motivated, autonomous software engineers and scientists.\\n\\nAs a Senior Research Scientist on the team, you will help our customers build NLU models using our technology and help us launch a new product across the company. You will be diving deep into the details while providing strategic inputs for the product.\\n\\nOther responsibilities include:\\nHelp drive the ML models and technology choices that enable a world-class user experienceUtilize various metric sources to deliver rapid iterations of modelsPropose new modeling solutions and run experiments to prove their efficacyCollaborate with colleagues from science, engineering, and business backgrounds,Ensure data quality throughout all stages of acquisition and processing, including such areas as data sourcing/collection\\n\\nGraduate degree in Computational Linguistics, Engineering, Statistics or related field8+ years experience in data scientist, analyst or NLP specialist role with a large technology companyExperience in two or more of these or similar Natural Language Processing topics: word categorization and tagging, syntactic parsing, word sense disambiguation, topic modeling; contextual text mining, application of machine learning to NLP, semantic similarity, phrasal semantic analysis, text matching and similarity, word embedding, lexicon normalization, named entity recognitionExcellent communication, analytical and collaborative problem-solving skillsDemonstrable track record dealing well with ambiguity, prioritizing needs, and delivering results in an agile, dynamic environmentExperience collaborating with software development teams, data scientists, business intelligence or other technical roles\\nAmazon is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Business Intelligence Engineer</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Bachelors in engineering, science, math, statistics or computer science3+ years of work experience as a business intelligence engineer, data engineer or data scientist role3+ years of experience in SQL programming3+ years of experience in building data warehouses and dimensional modeling3+ years of experience with business intelligence and data visualization tools (e.g. Tableau)3+ years of experience with a modern programming language (e.g. Python, R, Scala etc.)Experience with AWS Suite\\n\\nAmazon Lab126 is an inventive research and development company that designs and engineers high-profile consumer electronics. Lab126 began in 2004 as a subsidiary of Amazon.com, Inc., originally creating the best-selling Kindle family of products. Since then, we have produced groundbreaking devices like Fire tablets, Fire TV, Amazon Echo and Amazon Show. The Amazon Devices group delivers delightfully unique Amazon experiences, giving customers instant access to everything, digital or physical.\\n\\nAre you interested in a fast-paced, high-growth environment with the opportunity to work on business-critical decisions? Amazon Device Accessories is looking for an outstanding Business Intelligence Engineer to join our Operational Excellence Team. We’re looking for someone who can provide insight on KPI’s, understand inferential statistics and advise business teams on how to optimize for profit.\\n\\nAs an engineer on the team, you'll leverage tools and services including Amazon Redshift, Tableau, AWS Glue, AWS Athena, Spark, EMR, Machine Learning and Time Series models to build solutions that deliver data-driven reports, dashboards, and recommendations to high level leadership.\\n\\nYou'll work directly with business leaders and stakeholders to understand different business problems and use cases. You'll work with Finance, Tech and Business teams to identify and consume data sources, transform the data, and build the reports and visualizations needed to meet the requirements. You’ll have the opportunity to get hands on experience with Machine Learning, Time Series Modelling and high impact business analysis.\\n\\nDeveloping this capability will provide insights that are used to lead decision making around product allocation, product effectiveness, productivity analysis and business impact. Consumers of these insights will include Directors, VP’s and SVP’s.\\n\\nOur tenets for analytics team members are as follows:\\nUtilizing the Scientific Method to make tangible business impactMetrics before Messes\\no Ensuring we’re measuring the right business metrics to guide the business\\nForecast or be Last\\no Developing state of the art predictive models for ensuring we’re moving in the right direction\\n\\nRoles and Responsibilities:\\nBuild data solutions using AWS services that deliver data-driven reports, dashboards, and tools.Develop and implement Time Series and Machine Learning Forecast ModelsManage marketing and sales data for the organizationManage ETL pipelines using AWS EMR and SparkDistill problem definitions, models, and constraints from informal business requirements.Provide innovative self-service tools to our customers to self-serve and scale dataFollow established engineering best practices and define new best practices where required.Identify critical metrics/reports that measure product performance, efficiency/effectiveness and create client facing dashboards to facilitate decision making.Collaborate on the design, development, maintenance, and delivery/presentation of forecasting models, metrics, reports, analyses, tools, and dashboardsPerform proactive diagnostic analysis on the various product measures and surface meaningful insights to the leadership team.Collaborate with Data Scientists, Data Engineers and Economists to develop Product Insights on Marketing and Sales data.\\n\\nMasters in engineering, science, math, statistics or computer scienceExperience using AWS services for data analytics (i.e., Athena, Glue, Redshift, EMR, etc.)Experience developing custom ETL solutions using Python and SQLExperience with Tableau Desktop and Tableau ServerStrong written and verbal communications skills. Having the ability to translate scientific findings into business recommendations and outputs.The ability to influence stakeholders through delivering results and earning trustBasic statistical tests (but not limited to) t-tests, chi-square and regressionExpert SQLProficiency in PythonExperience delivering the best Products to customers\\nAmazon is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Program Manager/ Data Scientist</td>\n",
       "      <td>Redmond, WA 98052</td>\n",
       "      <td>Redmond</td>\n",
       "      <td>WA</td>\n",
       "      <td>98052</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Job Description\\n\\nThe team primarily works on developing and incorporating state-of-the-art AI/deep learning based natural language processing models to power compelling end-user scenarios.\\n\\nIn order to build good quality deep learning models, high-quality training data plays a critical role.\\n\\nWe use both user based and human judged data for model training.\\n\\nWe are looking for a candidate who can drive our human judged data generation process across multiple projects being worked on in the team. If interested, we would be interested in both a CV and a portfolio of prior works.\\n\\nResponsibilities include:\\nUnderstanding the requirements for data that needs to be collected from team members.\\n\\nWriting guidelines for the task that judges would need to do to create the training data.\\n\\nAnalyze, both manually as well as algorithmically, whether the generated data is of good quality.\\n\\nIterate by improving guidelines and identifying bad judges.\\n\\nBuild some simple webapp to facilitate the collection of the data.\\n\\nData science experience (familiarity with visualizing data is important but hands-on data science/machine learning experience is not necessary)Project management / Coordination required.\\n\\nStrong communication skills\\n\\nExperience with web technologies (JavaScript, HTML, CSS)Power BI/Data dashboards, python development experience good to have.\\n\\nPrevious experience (5+ years) in designing &amp; building data-driven products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Senior Marketing Data Scientist</td>\n",
       "      <td>Bellevue, WA 98004</td>\n",
       "      <td>Bellevue</td>\n",
       "      <td>WA</td>\n",
       "      <td>98004</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>6+ years experience in Data Science\\nExtensive experience in predictive analytics and machine learning for marketing, including time series analysis, supervised, unsupervised, and reinforcement learning\\nAdvanced SQL skills\\nAdvanced R or Python skills\\nAbility to create clear data visualizations for different audiences\\nConfidence to take the lead on a project and see it through to completion\\nAbility to effectively communicate highly-technical insights to a non-technical audience\\n</td>\n",
       "      <td>Design and implement analytical frameworks to measure and report out the ROI of marketing campaigns\\nGenerate prescriptive insights, tactical and strategic, to improve marketing effectiveness\\nExecute and maintain long-term modelling initiatives\\nEvaluate opportunities for international marketing investments\\nDesign A/B tests and analyse their results\\nCommunicate results to marketing and product management partners\\n</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Senior Marketing Data Scientist\\nAt Bungie, we create worlds that inspire friendships. We believe the potential of games is not just to entertain individuals, but to bring together players from all over the world to form lasting friendships and lifelong memories. We are looking for a Senior Marketing Data Scientist to collaborate with marketers and product managers to grow and engage our vibrant player community. This team member will lead the effort to develop our marketing analytics capability from the ground up.\\n\\nYou will deliver impartial, statistically sound insights backed by data, player feedback, and market research. You will leverage your expertise of machine learning and business reporting to quantify the impact of our marketing efforts, and deliver effective messages to the right players. Your work will be essential to informing and refining our marketing strategy.\\nResponsibilities\\nDesign and implement analytical frameworks to measure and report out the ROI of marketing campaigns\\nGenerate prescriptive insights, tactical and strategic, to improve marketing effectiveness\\nExecute and maintain long-term modelling initiatives\\nEvaluate opportunities for international marketing investments\\nDesign A/B tests and analyse their results\\nCommunicate results to marketing and product management partners\\nRequired Skills\\n6+ years experience in Data Science\\nExtensive experience in predictive analytics and machine learning for marketing, including time series analysis, supervised, unsupervised, and reinforcement learning\\nAdvanced SQL skills\\nAdvanced R or Python skills\\nAbility to create clear data visualizations for different audiences\\nConfidence to take the lead on a project and see it through to completion\\nAbility to effectively communicate highly-technical insights to a non-technical audience\\nNice To Have Skills\\nExperience with Tableau\\nExperience cleansing data sets\\nPassion to stay up-to-date on the latest industry trends and methods\\nBachelor’s degree in computer science, engineering, statistics, mathematics or related field\\nMaster’s degree in computer science, mathematics, statistics, marketing science or related field\\nA love of games!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Senior Data Scientist - Aerial Imagery</td>\n",
       "      <td>Bothell, WA 98021</td>\n",
       "      <td>Bothell</td>\n",
       "      <td>WA</td>\n",
       "      <td>98021</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Where good people build rewarding careers.\\nThink that working in the insurance field can’t be exciting, rewarding and challenging? Think again. You’ll help us reinvent protection and retirement to improve customers’ lives. We’ll help you make an impact with our training and mentoring offerings. Here, you’ll have the opportunity to expand and apply your skills in ways you never thought possible. And you’ll have fun doing it. Join a company of individuals with hopes, plans and passions, all using and developing our talents for good, at work and in life.\\nJob Family Summary\\nData Science incorporates techniques across many disciplines – including mathematics/statistics, computer programming, data engineering and ETL, software development, and high performance computing – with traditional business expertise with the goal of extracting meaning from data to optimize future business decisions. Individuals in this field should be an expert/fluent in several of these disciplines and sufficiently proficient in others to effectively design, build, and deliver end to end predictive analytics products to optimize future decisions. Individual demonstrates sufficient analytic agility to quickly develop new skills across these disciplines as those disciplines evolve. Data, Discovery &amp; Decision is responsible for aligning with and contributing to corporate objectives by identifying and developing growth and profitability opportunities that will enable Allstate to generate profitable market share growth. The Data Scientist family is accountable for using data to make decisions, which includes building predictive models and developing new machine learning techniques that enable Allstate to make better decisions to achieve its goals. The Data Scientist Family requires Analytic Agility, the ability to quickly learn new modeling/machine learning techniques, programming languages, and see how these ideas can integrate to optimize the business.\\nJob Description\\nThis role is responsible for leading a cross-functional project team building Allstate’s platform for deep learning on photographic images of homes. The Data Scientist Manager/Data Product Lead must coordinate the efforts of Data Scientists and Engineers to build an end-to-end system including the pipeline for image and data ingestion, suite of deep learning models, and integration of outputs into downstream systems. The right individual will be fluid with machine learning modeling choices and techniques as well as engineering considerations for building production-ready services. This role is focused on technical build of data modeling products, but the right individual must also be able to fluidly converse with the business users of the predictions delivered by those products. This role is a manager of people and a leader of project teams including contributors from many departments.\\nKey Responsibilities\\nDirect the build of Allstate’s platform for deep learning on photographic images of homes\\nManage a team of Data Scientists developing computer vision models\\nGuide choices on modeling techniques\\nLead a multi-department virtual team building a production-ready system that meets requirements for performance, accuracy, and robustness\\nGuide the design of data pipelines and services for performance and scalability\\nHelp to manage vendors and weigh in on build versus buy decisions\\nCollaborate with outside business units in order to improve the effectiveness of business decisions through the use of data and machine learning/predictive modeling\\nEffectively understand the business problems and requirements to identify the optimal modeling approach\\nCommunicate findings to ensure models are well understood and incorporated into business processes\\nUtilize effective project planning techniques to break down complex projects into tasks, manage scope of projects, and ensure deadlines are kept\\nWork with stakeholders to ensure the project will meet their needs\\nIdentify and develop data sources to solve business problems\\nReview, evaluate, and make recommendations on appropriateness of techniques to senior leadership\\nInfluence business partners and senior leadership on the effectiveness of machine learning/predictive modeling to solve their business problems\\nCurate the career development of amazing talent on your team and across Allstate\\n\\nJob Qualifications\\nMaster’s or PhD preferred in a quantitative field such as statistics, mathematics, computer science, finance, or economics Proven experience in using statistical modeling and/or machine learning techniques to build models that have driven company decision making\\nProven experience in managing and manipulating large, complex datasets\\nExperience writing production-ready code; familiarity with modern architectures, production deployment, and quality assurance requirements\\nUnderstanding of the Insurance market place; economics and regulation preferred\\nBackground in Computer Vision applications preferred\\nProven ability to code in languages such as Python, R, Java, C\\nProven knowledge of advanced modeling techniques\\nAbility to train, develop, and teach more junior modelers\\nAbility to analyze and interpret moderate to complex concepts\\nAbility to provide written and oral interpretation of highly specialized terms and data, and ability to present this data to others with different levels of expertise\\nAbility to lead a project team of various skills levels\\nAbility to manage a wide range of loosely defined moderate to complex situations, which require application of creativity and originality, where guidance and counsel may be unavailable\\n\\nThe candidate(s) offered this position will be required to submit to a background investigation, which includes a drug screen.\\nGood Work. Good Life. Good Hands®.\\nAs a Fortune 100 company and industry leader, we provide a competitive salary – but that’s just the beginning. Our Total Rewards package also offers benefits like tuition assistance, medical and dental insurance, as well as a robust pension and 401(k). Plus, you’ll have access to a wide variety of programs to help you balance your work and personal life - including a generous paid time off policy.\\nLearn more about life at Allstate. Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video.\\nAllstate generally does not sponsor individuals for employment-based visas for this position.\\nEffective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.\\nFor jobs in San Francisco, please click “here” for information regarding the San Francisco Fair Chance Ordinance.\\nFor jobs in Los Angeles, please click “here” for information regarding the Los Angeles Fair Chance Initiative for Hiring Ordinance.\\nTo view the “EEO is the Law” poster click “here”. This poster provides information concerning the laws and procedures for filing complaints of violations of the laws with the Office of Federal Contract Compliance Programs\\nTo view the FMLA poster, click “here”. This poster summarizing the major provisions of the Family and Medical Leave Act (FMLA) and telling employees how to file a complaint.\\nIt is the Company’s policy to employ the best qualified individuals available for all jobs. Therefore, any discriminatory action taken on account of an employee’s ancestry, age, color, disability, genetic information, gender, gender identity, gender expression, sexual and reproductive health decision, marital status, medical condition, military or veteran status, national origin, race (include traits historically associated with race, including, but not limited to, hair texture and protective hairstyles), religion (including religious dress), sex, or sexual orientation that adversely affects an employee's terms or conditions of employment is prohibited. This policy applies to all aspects of the employment relationship, including, but not limited to, hiring, training, salary administration, promotion, job assignment, benefits, discipline, and separation of employment.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sr. Associate, Data Scientist, NLP, Financial Services</td>\n",
       "      <td>Seattle, WA 98101</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>98101</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Innovate. Collaborate. Shine. Lighthouse – KPMG's Center of Excellence for Advanced Analytics – has both applied data science, AI, and big data architecture capabilities. Here, you'll work with a diverse team of sophisticated data and analytics professionals to explore the solutions for clients in a platform-diverse environment. This means your ability to find answers is limited only by your creativity in leveraging a vast array of techniques and tools. Be a part of a high-energy, diverse, fast-paced, and innovative culture that delivers with the agility of a tech startup and the backing of a leading global consulting firm. For you, that translates into the chance to work on a wide range of projects – covering technologies and solutions from AI to optimization – and the power to have a real impact in the business world. So, bring your creativity and pioneering spirit to KPMG Lighthouse.\\nKPMG is currently seeking a Senior Associate Data Scientist to join our KPMG Lighthouse - Center of Excellence for Advanced Analytics to work with our Financial Services team.\\nResponsibilities:\\nWork in multi-disciplinary and cross-functional teams to translate business requirements into artificial intelligence goals and modeling approaches\\nRapidly iterate models and results to refine and validate approach working across different areas (risk management, financial services, mergers and acquisitions, and public policy)\\nWork in a fast-paced and dynamic environment with both virtual and face-to-face interactions utilizing structured approaches to solving problems, managing risks, documenting assumptions, communicating results, and educating others through insightful visualizations, reports and presentations\\nBuild ingestion processes to, prepare, extract, and annotate a rich data variety of unstructured data sources (social media, news, internal/external documents, images, video, voice, emails, financial data, and operational data)\\nLeverage a variety of tools and approaches to solve complex business objectives, from Statistical Natural Language Processing, Information Retrieval/Extraction, Machine Learning/Deep Learning, Image Processing, Rules Engines, Knowledge Graphs, and Semantic Search\\nRefactor deploy and validate models; work with clients iteratively to validate performance metrics, and sample output to drive towards a business-first solution; utilize APIs, platforms, containers, multi-threading, and distributed processing to achieve throughput goals\\nQualifications:\\nMinimum of two years of experience leading work streams with at least two data scientists, engineers, and other data &amp; analytics professionals, including innovation, quality management, utilizing analytics and software development processes for natural language processing, machine learning on unstructured data, and/or information retrieval; Multidisciplinary backgrounds\\nMasters degree from an accredited college/university in Computer Science, Engineering, or related fields. PhD from an accredited college/university is preferred\\nAbility to apply artificial intelligence techniques to achieve concrete business goals while understanding available resources and constraints around data (sources, integrity, and definitions), processing platforms, and security; Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices (testing, code design, complexity, and code optimization)\\nSolid experience performing data science from data discovery, cleaning, model selection, validation, and deployment; experience coding artificial intelligence methods using object-oriented programming in a software development process, and ability to restructure, refactor and optimize code for efficiency\\nFluency in Python; Proficiency in AI related frameworks (NLTK, Spacy, Scikit-Learn, and Tensorflow); Experience with platforms (Google Cloud, Azure, and AWS); Ability to pick up new languages and technologies quickly and to work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Ability to work with a variety of databases (SQL, ElasticSearch, Solr, Neo4j)\\nAbility to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future\\nKPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package. KPMG is an affirmative action-equal opportunity employer. KPMG complies with all applicable federal, state and local laws regarding recruitment and hiring. All qualified applicants are considered for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other category protected by applicable federal, state or local laws. The attached link contains further information regarding the firm's compliance with federal, state and local recruitment and hiring laws. No phone calls or agencies please.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data Science (Telematics) Intern</td>\n",
       "      <td>Redmond, WA</td>\n",
       "      <td>Redmond</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Job ID: 5078\\nLocation: US-WA Redmond-B33 (HUB) HR\\nDepartment: Marketing\\n\\nIntern Program Overview:\\nThe Terex Intern Program immerses high potential students in challenging real-world projects which directly help drive business results at our global organization. Our rich beliefs in innovation and continuous improvement, paired with the diverse and creative mindsets of our students, leads to the development of our best-in-class products, positively impacting the lives of people all around the world.\\nWe are committed to the personal and professional development of our students and are proud to encourage their growth into our leaders of tomorrow.\\nHighlights:\\nPartner with team members from global locations - more than 50 manufacturing locations worldwide.\\nIntern/Co-op opportunities can lead to full time careers\\nReal World Responsibilities:\\nDuring your time with us you will:\\nWork with the software, product management, product support, and engineering teams to identify areas for leveraging machine and company data to drive business solutions internally and for our customers\\nCreate data visualizations\\nUnderstand Genie products and the data they produce\\nDevelop custom data models and algorithms to apply to internal and external data sources\\nProvide insight and input into future Genie machine data projects\\nAs part of our team we will:\\nDevelop the future Genie telematics analytics strategy\\nWork together to learn cross-functional processes and solve problems with IoT data\\nMust haves:\\nPursuing or entering a masters degree program in STEM or alternative degree combined with comparable experience\\nExperience using R, Python, or other software / language to manipulate and extract insights from data\\nExperience querying relational databases (MySQL, SQL Server, Etc.)\\nFamiliarization with RShiny and other data visualization tools\\nStrong analytics and critical thinking skills\\nWillingness to learn Genie products and processes\\nStrong written and verbal communication skills for presenting complex concepts to senior managers\\nNice to haves:\\nExperience / relevant coursework with a cloud computing environment such as AWS, Google Cloud Platform, or Microsoft Azure\\nExperience creating and deploying advanced machine learning and reliability algorithms\\nDesire to work with IoT data and product engineers in order to develop end-to-end data science solutions\\n\\nLocation: US-WA Redmond-B33 (HUB) HR\\nDepartment: Marketing\\nJob ID: 5078\\n\\nTerex Overview:\\nTerex Corporation is a $4.5 billion, publicly traded global manufacturer of lifting and material processing products and services. The company is passionate about producing equipment that improves the lives of people around the world. Terex operations are global, yet each office or factory is a close-knit community. Terex provides team members with a rewarding career and the opportunity to make an impact. The company values diversity and inclusion, safety, integrity, respect, servant leadership, courage and citizenship. It encourages continuous improvement and offers free courses available through Terex University. Women@Terex provides a supportive network for Terex women in their jobs and careers. It’s an exciting time to be part of the expanding manufacturing sector. Terex is a place where you can work and grow. Come talk to us!\\n\\nAdditional Information:\\nIt is the policy of the company to attract and retain the best qualified employees. We are committed to providing employment opportunities to the most qualified internal or external candidate based on work-related factors and without regard to non work-related factors including race, color, religion, national origin, gender, sexual orientation, gender identity, age, disability, or veteran status as a special disabled veteran, Vietnam Era Veteran, or other qualifying veteran.\\n\\nThe Company offers competitive salaries, advancement opportunities, and a full range of benefits, including paid vacation, 401(k), medical, dental, and vision.\\n\\nTerex Corporation is an Equal Opportunity Employer and Affirmative Action Employer M/F/D/V.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Lead Data Scientist\\nJoin an expert team that is breaking records in real-time Big Data performance\\nChange the way the world manipulates and analyzes large quantities of data\\nAddress our customer’s data pain points and delight them with your solutions\\nSpaceCurve is building Big Data analytic solutions focused on spatial, temporal, sensor and graph applications. Targeting mobile, life sciences, oil and gas and government markets. Our unique database technology can power real-time models of reality. We are enabling completely new applications and radical enhancements to existing applications.\\nThe role:\\nOur product is a distributed database and data platform purpose-built to parallelize storage and retrieval of realtime geospatial data on clusters of shared-nothing commodity hardware. We’re looking for a Principal Data Scientist with the vision and hands-on skills to drive early adoption as a key person in the core technical team. You will be working to fuse a wide variety of feeds and data sources, including geospatial/geotemporal, vehicle and industrial sensors, social networks, and place and personal data.\\nYour recent experience must be directly with Terabyte class datasets or larger. You should be adept at managing the full life cycle of massive datasets including ETL, EDA, cleaning, model building and deployment. You should be thoughtful and knowledgeable about algorithm performance and maximizing throughput. You should be very solid with open source and/or commercial technologies like Linux/Unix, SQL, Python and R/S-PLUS, ESRI, Octave/MATLAB, SciPy, NumPy or SAS.\\nTo be considered for our Lead Data Scientist, you will need:\\n\\n5+ years in the field; you’ve been a data scientist longer than the term’s been in vogue.\\n2+ years of recent experience working with terabyte or larger datasets.\\nVision! You must be able to design, articulate and create something new. You will be a key member of the team that anticipates, researches and understands the needs of stakeholders like data suppliers, data consumers, privacy advocates, regulatory agencies, general public, etc.\\nAdvanced degree in Math, Statistics, CS, a related field or equivalent experience.\\nHands-on, current experience with data analysis life cycle tools.\\nPractical experience working on Linux.\\nPython and/or other popular scripting languages.\\nSQL and ETL tools – you must be a strong SQL programmer.\\nAdditionally, our ideal candidate will possess:\\n\\nBroad exposure to data analysis in multiple contexts with deep expertise in at least one.\\nExperience with multiple database technologies (relational, EDW, NoSQL).\\nExperience with geospatial and/or graph analytic databases.\\nExperience with streaming APIs and SOA products.\\nExperience with real-time analytics (e.g. mobile marketing).\\nEDA and modeling tools.\\nDBMS operations, security, administration and multi-tenancy.\\nBusiness &amp; contractual aspects of working with large data suppliers.\\nA good cultural fit on our team is a professional and results-oriented individual that can initiate and complete tasks under tight deadlines and changing priorities. Flexibility with hours and workload is key!\\nAbout SpaceCurve\\nOur product is revolutionary. Many have said it, but seldom is it true.\\nSpaceCurve is a well-funded startup on our way to changing the economics, nature, usefulness and significance of Big Data across many market segments. The next ten years will bring explosive growth in mobility and location-based services, and increasing volumes of geospatial and sensor data will drive demand for real-time models of reality. SpaceCurve is uniquely positioned at the intersection of the growing geospatial and intelligent-location trends that are creating immense opportunities for the rapid implementation of its technologies.\\nWe are smart, engaged and passionate about what we do. We believe world-class employees should be rewarded as such. Our employees are offered competitive wages, 401K, premium insurance benefits, flexible PTO, early stage stock options and more!\\nApply now or contact us for a confidential discussion!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Software Engineer II</td>\n",
       "      <td>Redmond, WA</td>\n",
       "      <td>Redmond</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\n3+ years of software development experience and shipping products\\n1+ years experience with data analysis, statistical methodologies, text analysis, machine learning, and other areas of data science\\n2+ years engineering experience using large data systems on SQL, Hadoop, Spark, etc.\\n</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\n3+ years of software development experience and shipping products\\n1+ years experience with data analysis, statistical methodologies, text analysis, machine learning, and other areas of data science\\n2+ years engineering experience using large data systems on SQL, Hadoop, Spark, etc.\\n</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>It’s an exciting time to be working on Windows at Microsoft. We’ve gone from a release every 3 years with Windows 7 to a 2 releases of Windows 10 last year. We are driving excitement in the technology market via Surface, Xbox, HoloLens and other innovations. Windows has transformed from a boxed product that came with your PC to an always up-to-date operating system that powers all Microsoft devices and enables a diverse ecosystem of 3rd party PCs, laptops, tablets, AR/MR devices, game consoles and more.\\nAs the compatibility team, we ensure applications and devices you use daily continue to work seamlessly even as we change and improve the underlying OS at ever faster rates. We are at the center of shipping new Windows versions to every capable device in the ecosystem, and our team is integral to successfully shipping new Windows releases on new devices.\\nIf improving the experience for hundreds of millions of users excites you, if you have the passion for using data to transform understanding of customer problems, if you are interested in understanding OS complexities, developing marketable system experience, and working across large sections of Windows and Devices teams then this is the job for you.\\nWe are looking for highly motivated and passionate data scientist/data engineer to apply scientific methodology to data to improve our products. Top candidates have a demonstrable record of using data to improve the world around them. We hire people with a desire to improve product quality and business outcomes using statistical analysis of data, machine learning, data mining, data engineering, data visualization, and more. You will formulate approaches to solve problems using well-defined algorithms and data sources in context of customer, engineering, and business needs. You will use data exploration techniques to discover new opportunities within your problem area. You will interpret the results of analyses, validate approaches, and learn to monitor, analyze, and iterate to continuously improve. You will engage with stakeholders to produce clear, compelling, and actionable insights that influence product and service improvements that will impact millions of customers.\\nResponsibilities\\n In this role, you’ll be using insights from data to assess and improve the quality of user experiences on Windows, and to drive efficiencies in how we release Windows to millions of customers worldwide. We combine data science and data engineering work with business knowledge to provide unique insights into customer scenarios and drive decision making based on these insights.\\nYou’ll help drive our transformation from being reliant on lab based testing to becoming service and data driven by leveraging the latest technology that data science has to offer. You’ll build features and technologies to scale our efforts. You’ll help ensure we ship each successive Windows version with the highest levels of quality and enable our ecosystem of applications and devices to “just work”.\\nQualifications\\nRequired qualifications:\\n3+ years of software development experience and shipping products\\n1+ years experience with data analysis, statistical methodologies, text analysis, machine learning, and other areas of data science\\n2+ years engineering experience using large data systems on SQL, Hadoop, Spark, etc.\\nPreferred qualifications:\\nFamiliarity with data analysis tools and languages like R, Python, or similar\\nProficiency using one or more programming languages like C#, …\\nExperience with product and service telemetry systems\\nAbility to interact with peers and stakeholders to drive product and business impact\\nStrong interpersonal and communications skills\\nAbility to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to, the following specialized security screenings:\\nMicrosoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter.\\nMicrosoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.\\n\\nBenefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.\\n\\n#cosinedijobs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>Bellevue, WA</td>\n",
       "      <td>Bellevue</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>We are looking for a Data Scientist Intern to join our centralized data science team for the summer! Data is the foundation of our business in AI @ Unity, and we harness it to solve business problems for multiple teams and products. We analyze large volumes of data, applying statistical techniques to extract insights and to inform decisions. We develop and implement machine learning models into production and intuitively make decisions around what approaches to take in solving hard problems.\\n\\nAmong some of the problems we solve are player and developer profiling, improving Unity developer retention, personalizing developer experiences, content recommendations, and overall improving the use of the Unity engine!\\n\\nResponsibilities\\n\\n\\nPerform in-depth statistical analysis and extract insights from big data\\nDevelop machine learning models\\nEffectively communicate technical concepts and analyses to stakeholders\\nThink creatively and to be able to test out new ideas and iterate rapidly\\n\\nRequirements\\n\\n\\nWorking towards a degree in Data Science, Analytics, Statistics, Computer Science or other quantitative discipline, preferably a MS/PhD\\nPrevious internship experience\\nPython, R &amp; SQL\\nUnderstanding of statistical concepts and applying them\\n\\nBonus points\\n\\n\\nExperience with deep learning\\nExperience with big data (Spark)\\n\\nWho we are\\n\\nUnity is the creator of the world's most widely-used real-time 3D (RT3D) development platform, providing content creators around the world with the tools they need to build rich, interactive 2D, 3D, VR and AR experiences. In fact, apps made with Unity reach 2.7 billion devices worldwide, and were installed more than 24 billion times in the last 12 months.\\n\\nThe global engineering team keeps Unity at the forefront of technology and — working alongside partners like Magic Leap, Google, Facebook, Oculus and Microsoft — ensures optimized support for the latest technology and platforms. Unity is powering the real-time revolution, expanding beyond games and breaking into other industries including automotive, film, architecture, engineering, construction and more.\\n\\nUnity is an equal opportunity employer committed to fostering an inclusive, innovative environment with the best employees. Therefore, we provide employment opportunities without regard to age, race, color, ancestry, national origin, religion, disability, sex, gender identity or expression, sexual orientation, or any other protected status in accordance with applicable law. If there are preparations we can make to help ensure you have a comfortable and positive interview experience, please let us know.\\n\\nHeadhunters and recruitment agencies may not submit resumes/CVs through this Web site or directly to managers. Unity does not accept unsolicited headhunter and agency resumes. Unity will not pay fees to any third-party agency or company that does not have a signed agreement with Unity.\\n\\n#LI-KE1 #INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Graduate degree (MS or equivalent) in Mathematics, Statistics, Operations Research, Economics or a related quantitative field5+ years' of experience with data querying languages (e.g. SQL), scripting languages (e.g. Python), and statistical/mathematical software (e.g. R, SAS, Matlab, etc.)Experience with managing large and disparate data sourcesFamiliarity with AWS data solutions such as S3 and RedshiftExperience articulating business questions and using quantitative techniques to arrive at a solution using available dat\\n\\nAmazon’s Inventory Planning and Control (IPC) team is looking for data scientists with experience and aptitude in using large datasets, mathematics, and simulation tools to solve real world problems. IPC owns Amazon’s global inventory planning systems: we decide what, when, where, and how much inventory we should carry to meet Amazon’s strategic business goals and make our customers happy. We do this for billions of dollars of inventory across millions of items and hundreds of product lines world-wide. We’re simultaneously developing the science of supply chain planning and solving some of the toughest computational challenges at Amazon. Our team members have an opportunity to work on some of the most difficult problems in the industry with some of the best scientists and software developers in the business, to drive real impact on Amazon's long-term success.\\n\\nAs a Sr. Data Scientist, you will discover and solve real world problems by analyzing large amounts of business data, defining new metrics and business cases, designing simulations and experiments, creating models, and collaborating with colleagues in business, software, and research. The successful candidate will have a strong quantitative background and can thrive in an environment that leverages statistics, machine learning, operations research, econometrics, and business analysis.\\n\\nExcellent written and oral communication skillsExperience processing, filtering, and presenting large quantities (Millions to Billions of rows) of dataDepth and breadth in quantitative knowledge. Excellent quantitative modeling, statistical analysis skills and problem-solving skills.Experience applying machine learning conceptsKnowledge of optimization and supply chain / inventory management conceptsExperience building complex data visualization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Data Scientist, Analytics - Messenger Performance</td>\n",
       "      <td>Seattle, WA 98101</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>98101</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Facebook's mission is to give people the power to build community and bring the world closer together. Through our family of apps and services, we're building a different kind of company that connects billions of people around the world, gives them ways to share what matters most to them, and helps bring people closer together. Whether we're creating new products or helping a small business expand its reach, people at Facebook are builders at heart. Our global teams are constantly iterating, solving problems, and working together to empower people around the world to build community and connect in meaningful ways. Together, we can help people build stronger communities — we're just getting started.\\nAs Messenger and Messenger Lite continues to expand to all corners of the world, having performant apps matters more than ever. The vast majority of our users access Messenger using old devices and unreliable networks, and bad performance leads to less engaged users and a poor user experience. In this role you will be working closely with the team responsible for making sure the Messenger app delivers the best possible performance across iOS, Android and Web platforms. Our team works cross-functionally with product and infrastructure teams across Messenger to improve app start time, scrolling performance as well as reduce crashes and minimize resources consumption. We’re looking for a thought leader in this space to help us frame up and prioritize all the performance investments that we’re making across the company. This position will directly engage with the CTO for the Messenger app and have the opportunity to directly shape our investments and roadmap for the next 3 years. Some key challenges we’re looking to solve in the next year include: How often do users have a “bad experience” while using the app? How can we quantify this and how does it affect engagement? What sectors of the population are the most sensitive to performance regressions and how should we adapt our strategy as a result? How should we prioritize our efforts across different users and performance metrics to deliver the best possible performing app?\\n\\n\\nRESPONSIBILITIES\\nApply your expertise in quantitative analysis, data mining, and the presentation of data to see beyond the numbers and understand how our users interact with both our consumer and business products\\nPartner with Product and Engineering teams to solve problems and identify trends and opportunities\\nInform, influence, support, and execute our product decisions and product launches\\nThe Data Scientist Analytics role has work across the following four areas:\\nProduct Operations\\nForecasting and setting product team goals\\nDesigning and evaluating experiments\\nMonitoring key product metrics, understanding root causes of changes in metrics\\nBuilding and analyzing dashboards and reports\\nBuilding key data sets to empower operational and exploratory analysis\\nEvaluating and defining metrics\\nExploratory Analysis\\nProposing what to build in the next roadmap\\nUnderstanding ecosystems, user behaviors, and long-term trends\\nIdentifying new levers to help move key metrics\\nBuilding models of user behaviors for analysis or to power production systems\\nProduct Leadership\\nInfluencing product teams through presentation of data-based recommendations\\nCommunicating state of business, experiment results, etc. to product teams\\nSpreading best practices to analytics and product teams\\nData Infrastructure\\nWorking in Hadoop and Hive primarily, sometimes MySQL, Oracle, and Vertica\\nAutomating analyses and authoring pipelines via SQL and python based ETL framework\\nMINIMUM QUALIFICATIONS\\n7+ years experience doing quantitative analysis\\nBA/BS in Computer Science, Math, Physics, Engineering, Statistics or other technical field\\nExperience in SQL or other programming languages\\nDevelopment experience in any scripting language (PHP, Python, Perl, etc.)\\nExperience communicating the results of analyses with product and leadership teams to influence the strategy of the product\\nKnowledge of statistics (e.g., hypothesis testing, regressions)\\nExperience manipulating data sets through statistical software (ex. R, SAS) or other methods\\nPREFERRED QUALIFICATIONS\\nAdvanced degrees\\nExperience with distributed computing (Hive/Hadoop)\\nFacebook is committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, you may contact us at accommodations-ext@fb.com.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Data Science Analyst</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nA minimum of a Bachelor’s Degree is required (Analytics, Data Science, Statistics, Computer Science, Information Technology, Engineering, or similar field. MS or MBA preferred)\\nMinimum three years of related experience in logistics, analytics, data science, or data management is required\\nKnowledge of relational databases\\nSolid ability to clean, transform, and join both structured and unstructured data sets to deliver analysis\\nKnowledge of advanced analytical visualization software\\nProject management experience required\\nA solid understanding of the data science industry</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>We are North America’s leading security services provider with over 200,000 phenomenal employees. At Allied Universal, we pride ourselves on fostering a promote from within culture. There are countless examples of individuals who began their career as Security Professionals and today hold positions on our senior leadership team. In fact, over 65% of our managerial positions are filled by internal candidates.\\nFor all full-time positions, we offer medical, dental and vision coverage, life insurance, 401K, employee assistance programs, company discounts, perks and more! We also offer part-time and flexible schedules!\\nStart your phenomenal career with Allied Universal today!\\nAnalyst: Data Science (ADS)\\nThe Analyst for Data Scientist (ADS) will help the client build a sustainable data classification and reporting apparatus for a dispersed global team. The Analyst will be responsible for conducting statistical analysis and optimization of financial and non-financial data available within the client’s security department. The ADS will work with stakeholders across the globe and execute complex statistical analyses in support of operational programming including travel and intelligence. The Analyst will prepare data visualizations, use algorithms, or create simulations to discover and classify patterns that help in business decision making and presenting findings to business audiences.\\nFocus:\\nThe focus for this role is in translating complex data into meaningful and digestible insights for a broad and diverse audience of clients and decision-makers across the organization. The Analyst will support existing and bespoke programs through analysis of large disparate datasets such as log files of activity or aggregated lists of incidents. A previous background in security, investigations, cyber security, anomaly detection (such as outliers) or similar is advantageous.\\nKey Responsibilities:\\nDevelop analysis-ready datasets by ingesting, staging, curating, mining, combining, cleansing, transforming, and analyzing data from a multitude of structured and unstructured disparate data sources\\nMust be able to build a data science program from disparate analytical parts\\nAttend meetings and provide the necessary support to ensure new projects are provide with the necessary data and/or insights to make informed and timely decisions\\nPartner closely with team members to ensure the success of key initiatives related to data source management and development for network design, key performance indicator monitoring, and business integration\\nLead projects directly related to designing, testing, and deploying analytical solutions or initiatives\\nServe as data management point of contact for collaborative initiatives within the department\\nPerform other duties and analysis as assigned by management\\nQualifications: Strong background in statistical techniques such as parameter estimation and hypothesis testing is required. Requirements also include programming experience for data analysis, data processing, and statistical tools such as SQL (Working knowledge of: Oracle, SAS, Hadoop Platform, R, or Python). Fluency in English and very good written and verbal communication skills are necessary.\\nA minimum of a Bachelor’s Degree is required (Analytics, Data Science, Statistics, Computer Science, Information Technology, Engineering, or similar field. MS or MBA preferred)\\nMinimum three years of related experience in logistics, analytics, data science, or data management is required\\nKnowledge of relational databases\\nSolid ability to clean, transform, and join both structured and unstructured data sets to deliver analysis\\nKnowledge of advanced analytical visualization software\\nProject management experience required\\nA solid understanding of the data science industry\\nPHYSICAL/MENTAL REQUIREMENTS AND WORKING ENVIRONMENT:\\nWhile performing the duties of this job, the employee is regularly required to use both hands, is frequently required to stand, sit, stoop, talk and hear (communicate verbally in person and via regular telephone equipment), and must be able to read computer screens, correspondence and reports in English.\\nThe employee must constantly walk, stand, reach with both hands and arms, and must be able to drive a vehicle. The employee may occasionally lift and/or move up to 25 pounds. May be required to climb stairs on an intermittent basis at client sites.\\nThe job is generally performed in an office setting; however, during site visits the employee may be subject to adverse conditions such as rain, cold or heat for short periods of time.\\nThe ambient noise level is usually quiet, consisting of normal conversations, business machines (copiers, printers, etc.) and telephones, but occasionally may be above-normal for portions of the shift.\\nThe employee must be able to concentrate on details, work under deadline pressures, apply sound logic and judgment, and prioritize tasks and responsibilities.\\nMust be able to focus and multi-task in a busy environment, with the ability to successfully handle stressful situations in a calm and professional manner. Includes being able to effectively manage multiple employees with diverse personalities and engage them to perform at optimum levels.\\nMust be able to clearly speak, read and write English.\\nAllied Universal provides unparalleled service, systems and solutions to the people and business of our communities, and is North America’s leading security services provider. With over 200,000 employees, Allied Universal delivers high-quality, tailored solutions, which allows clients to focus on their core business. For more information: www.AUS.com.\\n\\nWe proudly support the Veteran Jobs Mission, a group of over 200 companies that have committed to collectively hiring a total of one million military veterans.EOE/Minorities/Females/Vet/Disability Allied Universal Services is an Equal Opportunity Employer committed to hiring a diverse workforce.\\nCB-NWSAJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Data Scientist II - Payment Products</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Bachelor’s degree in Computer Science, Mathematics, Statistics, Finance or related technical field.5+ years of relevant employment experience.3+ years of hands on experience in SQL, Excel, Linux and OLAP3+ years of hands on experience in SAS, R and/or Python (data extraction, manipulation, statistical analysis and predictive modeling)2+ years of experience in projects involving cross-functional teams and successfully completing 3-6 projects5+ years of experience in data mining using databases in a business environment with large-scale, complex datasets5+ years of experience in driving actionable insights and successful completion of 5-10 high business impact projectsProven track record of strong verbal/written communication &amp; data presentation skills, including an ability to effectively communicate with both business and technical teams across the world\\n\\nThe Amazon Payments Team manages all Amazon branded payment offerings, globally. These offerings are growing rapidly and we are continuously adding new market-leading features and launching new products. Our payments products (Amazon Co-Branded Credit Cards, Private Labeled Credit Cards, Non-Amazon Branded Credit Cards, Shop with Points and Foreign Exchange) provide the most innovative payment experience on and off Amazon. We manage a financial services ad serving platform (billions of impressions per year) through Amazon’s purchase path where we offer Amazon branded and non-branded payment products and services. Our team of high caliber software developers, statisticians, analysts and product managers use rigorous quantitative approaches to ensure that we target the right product to the right customer at the right moment, managing tradeoffs between click through rate, approval rates and lifetime value. We leverage the wealth of Amazon’s information to build a wide range of probabilistic models, set up experiments that ensure that we are thriving to reach global optimums and leverage Amazon’s technological infrastructure to display the right offerings in real time. We work closely with product managers to understand their business, collect requirements and deliver high value analytics and insights for the Amazon Payments team that drive acquisition, usage and loyalty. Our petabytes of data has the ability to improve the shopping experience for hundreds of millions of consumers worldwide. Our goal is to delight our customers with their purchasing experience. Those of us who love to work with data see this as the pinnacle of opportunities that you cannot find anywhere else in the world.\\n\\nWe are looking for an outstanding Data Scientist that is able to comprehend the details behind the Amazon Payments Products business, understand/clarify business requirements, transform volumes of data into actionable insights, serve as the technical/statistics SME, help us improve our targeting methods/models by initiating innovative/creative projects, lead analytical discussions and road map, work across teams and influence the analytical direction of external teams, combine expert statistical/modeling knowledge with programming skills to manage and deliver on complex/critical analysis projects, independently identify and resolve business/technical issues, develop best practices and support our product managers across the world. Amazon.com has a culture of data-driven decision-making, and demands business intelligence that is timely, accurate, innovative and actionable.\\n\\nResponsibilities\\n\\nYou know and love working with business intelligence tools, can build statistical models using multidimensional datasets and can partner with business owners to answer key questions. You are analytical, innovative, creative, disruptive, and you don’t give up. In this role you will have an opportunity to launch new features in our machine learning engine, add new products to our inventory, influence targeting strategy for our products, implement end to end reporting solutions and support product managers in their day to day testing and business needs.\\n\\nYou will also have the opportunity to display your skills in the following areas:\\n\\nInterface with product managers, data engineers and software developers, gather requirements and deliver complete analytics/reporting solutions.Own the design, development, and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisions.Use data mining, model building, and other analytical techniques to develop and maintain customer segmentation and predictive models to drive the business and improve our machine learning engine.Make recommendations for new metrics, techniques, and strategies to improve campaign targeting and measurement.Improve Amazon Payment Product’s targeting capabilities/products and help business owners uncover hidden opportunities using data, analytics and machine learning.Provide ad-hoc and automated access to large data sets.Understand business and product strategies, goals and objectives. Set the analytics roadmap to drive the goals of the business.Own the analytics for one or more product areas, lead planning, execution and delivery of projects for that area(s), manage stakeholders and internal customer/client needs/requestsAct as the point of contact and analytical thought leader for the business. Represent the Data Science team inside and outside of Amazon Payments Products\\n\\nAn MS or PhD degree in Computer Science, Mathematics, Statistics, Finance, Machine Learning or related technical field.Experience in gathering requirements and formulating business metrics for reporting and analysis.Experience in online advertising, loyalty programs or financial services (payments products, specifically credit cards would be ideal).Experience with big data and object oriented programming languages (python, ruby, etc.).Experience in Machine learning (decision trees, multivariate and logistic regression, kNN, kMeans, etc.).Experience with data visualization software such as Tableau.\\nAmazon is an equal opportunity employer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Lead Data &amp; Applied Scientist</td>\n",
       "      <td>Redmond, WA</td>\n",
       "      <td>Redmond</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\n2+ years of experience in at least 3 languages such as Python, R, SQL, Java or Scala.\\n2+ years of industry experience in handling high volumes of structured and unstructured data to drive business impact.\\n2+ Quantitative methods that include deep learning, statistical modeling, machine learning, optimization methods, recommendation systems, graph theories and NLP.\\nMasters or PhD in Computer science, Operations Research, Statistics, Applied Mathematics, Electrical Engineering, or Physics with strong knowledge of machine learning.</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nDevelop new predictive and prescriptive models using advanced research techniques with a goal of productionalized solutions.\\nCollaborate closely with Analytics, Engineering, and Experimentation teams by demonstrating cross-functional resource interaction to deliver ML models.\\nIdentify and investigate new technologies, prototype and test solutions for product features, and design and validate designs that deliver an exceptional user experience.\\nCombine broad and deep knowledge of relevant research domains with the ability to synthesize a wide range of requirements to make significant contributions to the feature roadmap for the applied machine learning platform.\\nTake responsibility for technical problem solving, including creatively meeting product objectives and developing best practices.\\nOwn strategic thought leadership for the subject of enterprise-wide machine learning capabilities</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Never before have information, analytics, and artificial intelligence been so important to business success. That momentum is matched with Microsoft’s investment in empowering business transformation for our customers. Microsoft’s Advanced Services Delivery (ASD) Engineering organization is infusing AI into the digital delivery channels for proactive support (product optimization), reactive support, and customer education across all Microsoft products. This role, Lead Data Scientist, will be key in realizing this vision.\\n\\nThis individual will be part of a team of high caliber Data Scientists (code named Monocle), chartered to both execute in an applied science paradigm by creating AI enabled product features and customer insights, and in a research capacity by leading new innovations and creating novel algorithms and publications. It requires agility, scientific thinking, and a wealth of curiosity. This is an opportunity to join a team with a culture fostering collaborations and partnerships across the research industry and Microsoft.\\n\\nMore broadly, the goal of the ASD organization, is to improve IT health outcomes for Microsoft’s largest business and enterprise customers, and to enable profitability of the Microsoft Services business via packaged, highly-scalable digital delivery assets. We do this through three primary deliverables: A platform for performing customer IT health assessments, a catalog of IP that includes digital learning assets and workshops to help educate customers, so they can make the most of their IT environments, and a portal called the Services Hub that ties it all together. We have over 20,000 active customers and are working to improve our platform and the services we deliver on top of it and driving the future of the entire Services business.\\nResponsibilities\\nRESPONSIBILITIES:\\nDevelop new predictive and prescriptive models using advanced research techniques with a goal of productionalized solutions.\\nCollaborate closely with Analytics, Engineering, and Experimentation teams by demonstrating cross-functional resource interaction to deliver ML models.\\nIdentify and investigate new technologies, prototype and test solutions for product features, and design and validate designs that deliver an exceptional user experience.\\nCombine broad and deep knowledge of relevant research domains with the ability to synthesize a wide range of requirements to make significant contributions to the feature roadmap for the applied machine learning platform.\\nTake responsibility for technical problem solving, including creatively meeting product objectives and developing best practices.\\nOwn strategic thought leadership for the subject of enterprise-wide machine learning capabilities\\nQualifications\\nREQUIRED QUALIFICATIONS:\\n2+ years of experience in at least 3 languages such as Python, R, SQL, Java or Scala.\\n2+ years of industry experience in handling high volumes of structured and unstructured data to drive business impact.\\n2+ Quantitative methods that include deep learning, statistical modeling, machine learning, optimization methods, recommendation systems, graph theories and NLP.\\nMasters or PhD in Computer science, Operations Research, Statistics, Applied Mathematics, Electrical Engineering, or Physics with strong knowledge of machine learning.\\nADDITIONAL QUALIFICATIONS:\\nAdapt ML and neural network algorithms and architectures to best exploit modern parallel environments (e.g. distributed clusters, multicore SMP and GPU).\\nStrong skills in at least 3 languages such as Python, R, SQL, Java or Scala.\\nExperience with open source tools like CNTK, Tensor flow, MxNet, Caffee and OpenCV and Big data technologies like Hive, PySpark, SparkR, Databricks etc.\\nOutstanding research track record in related areas, with evidence through academic publications and services\\nStrong theory/algorithmic background and good understanding on how to apply advanced knowledge to solve real problems\\nPREFERRED QUALIFICATIONS:\\n6+ years of industry experience in handling high volumes of structured and unstructured data\\nPhD in computer science with focus on machine learning, deep learning, reinforcement learning, natural language processing\\nScientific thinking and the ability to invent. Demonstrated track record of thought leadership and contributions that have advanced the field.\\nTop-tier publications (NIPS, PAMI, CVPR etc.)\\nSolid software development skills are plus.\\nKnowledge and experience working within cloud computing environments such as Azure or AWS.\\nHighly motivated to achieve results in a fast-paced environment.\\n\\nMicrosoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.\\n\\nBenefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Director of Global IT Operations</td>\n",
       "      <td>Bellevue, WA 98007</td>\n",
       "      <td>Bellevue</td>\n",
       "      <td>WA</td>\n",
       "      <td>98007</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>WHO WE ARE\\nSeagull Scientific has always done one thing—and done it exceptionally well. Its BarTender® software transforms information into labels, barcodes, RFID tags, smartcards, and documents that drive business and improve safety, security, efficiency and compliance.\\nHeadquartered in Bellevue, Washington, with branch offices in Madrid, Taipei, and Tokyo, Seagull Scientific's software is used in more than 150 countries and across virtually every industry. For more information about Seagull Scientific, please visit www.bartendersoftware.com.\\nThis position is located in Bellevue, Washington.\\nWHO YOU ARE\\nAn IT professional that has a successful track record with all aspects of managing a complex IT infrastructure, as well as Information Security and Compliance. As the Global IT Operations Director, you will provide strategic and tactical leadership for a global IT team, supporting systems and infrastructure, including:\\nNetworking\\nInformation Security and Compliance\\nHardware maintenance contracts\\nSoftware licensing &amp; maintenance\\nIT hardware acquisition and deployment\\nHelpdesk\\nSecurity\\nCloud services\\nVendor management\\nServers\\nRouting\\nVirtualization\\nDomain administration\\nFacilities\\nPurchasing &amp; budgeting\\nWHAT YOU WILL DO\\nOversee global IT operations, policies, procedures and assess them according to company goals\\nLead and manage your small global team to provide solutions for our global network: system monitoring and performance tuning, system administration, systems control and security, and technical documentation\\nIdentify and mitigate security vulnerabilities with strategic solutions that ensure data security\\nConduct analysis, investigate and recommend security technologies - including managed security services, firewalls, encryption, intrusion detection, VPN and solutions for incorporation into product/services\\nStrategize the deployment of cloud applications\\nEnsure proper staffing and skillsets are in place to deliver quality IT services\\nUnderstand the business requirements of all departments to determine their technology needs\\nEnsure capacity planning is in place\\nDetermine efficient and cost-effective IT hardware and software\\nIdentify the necessity for upgrades, configurations or current systems\\nCreate and monitor IT budgets and expenses\\nBuild relationships with vendors and oversee all contracts and maintenance agreements\\nEvaluate the costs and benefits of cloud services and subscriptions\\nProvide weekly status reports for CEO\\nWHAT WE REQUIRE\\n5+ years of experience in each of the following:\\nIT infrastructure and staff management\\nDefining and managing IT policies and procedures\\nWindows Server 2003/2008\\nTCP/IP (DNS, DHCP, routing, VPN)\\nSQL Server, Exchange, IIS, Office/Outlook\\nPC/Server/network hardware\\nManagement of cloud-hosted internal systems\\nManagement of end-user-facing, cloud-hosted applications\\nExperience in Regulatory Compliance and Quality Assurance preferred\\nWell versed in a broad set of technologies, including networking, storage, collaboration tools, service desk, cybersecurity, virtualization, (VMware or equivalent) cloud infrastructure (IaaS, PaaS), etc.\\nAbility to work well under pressure and to think creatively and strategically\\nKnowledge of Privacy Shield, European Union General Data Protection Regulation (GDPR)\\nFamiliarity with Data Management functional areas, including development, data scientist, security and engineering\\nWillingness to travel as required\\nADDITIONAL QUALIFICATIONS\\nBS in computer science or 10 years’ experience in a related field\\n5 years’ experience in managing staff and contractors in a technology environment\\n5 years’ experience in vendor management\\nExperience with Microsoft Dynamics CRM or AX helpful\\nGood organizational habits and outstanding attention to detail\\nExcellent documentation skills\\nStrong written/verbal communication and presentation skills\\nPositive, team-oriented attitude\\nFlexible, professional, highly motivated individual\\nTERMS OF EMPLOYMENT\\nThis is a full-time position\\nAt this time, we are looking at local candidates only, as we are not offering relocation packages\\nAbility to provide documentation that proves authorization to work in the US without visa sponsorship\\nBENEFITS\\nExcellent medical, dental, and vision plan\\n401K with 100% employer matching up to 3.0% with a 3-year vesting period\\nCompetitive PTO Package\\nPaid company holidays\\nCompetitive salary\\nOn-site fitness center and deli\\nFree parking or transportation subsidy (ORCA)\\nTuition-reimbursement benefits\\nCompany-paid life insurance, short term and long-term disability benefits\\nAccess to green space and Bellevue Open Space Trail System\\nFun staff and team-building activities—anniversary party, lunches and seasonal events\\nOUR CULTURE\\nWe are fair, we are passionate, we appreciate excellence and we act as a team. We offer a dynamic, culturally diverse and fun environment in which people with energy, creativity and passion work together to deliver amazing product experiences for our customers. You will be part of a team where your insights and ideas are valued.\\nDIVERSITY AND INCLUSION\\nSeagull Scientific has a company culture that respects a diverse and unified team from a range of backgrounds whose different perspectives enrich our business. Everyone at Seagull is treated fairly, with respect, and is encouraged to voice their opinion.\\nEQUAL EMPLOYMENT OPPORTUNITY\\nSeagull Scientific Inc. provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Director, Marketing Data Science</td>\n",
       "      <td>Bellevue, WA</td>\n",
       "      <td>Bellevue</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Job Description Summary\\nDo you want to have a huge impact in eCommerce? Are you interested in solving cutting-edge applied research problems that impact all of eBay’s advertising channels? Do you love to work with massive data sets, large-scale optimization, probabilistic inference, and machine learning? If you answered yes, the Marketing Science team at eBay is the right place for you. eBay’s Marketing Tech Data Science Team is an innovative and forward thinking team of Data Scientist/Machine Learning engineers that powers one of the largest digital marketing platforms in the world.\\neBay is looking for a Director, Marketing Data Science who will develop our Marketing Science strategy for Paid Search, Paid Social, Affiliate Marketing, and Display Advertising. eBay is aggressively building our big data and predictive analytics capabilities to augment our world class digital marketing strategy and deliver a higher return on investment of our multi-billion dollar marketing budget.\\nThe Director, Marketing Data Science is a visionary leader and has a background in statistical methodologies, data driven predictive analytics, machine &amp; deep learning strategies, computer science and validating models. In addition, the successful candidate will have strong knowledge on evolving a company’s big data platform and tools for data collection, data processing, exploration, visualization and insights. Further, the Director, Marketing Data Science will apply the latest data analysis and machine learning technologies to innovate applications such as target audience selection, personalization, bidding on ads, product recommendation, and content recommendations.\\nThe Director, Marketing Data Science will develop partnerships with a number of internal stakeholders and will ensure coordination and collaboration; they will be a subject matter expert on all of eBay’s marketing data and how we leverage our data to create and fuel models that improve our advertising efficiency. This role will report to the Vice President of Marketing Tech.\\nIndividuals with a talent for strategic leadership, interest in digital product development, and experience in people management are encouraged to apply. We are looking for creative, smart, and driven individuals who want to tackle tough machine learning problems, develop models and solutions to optimize eBay’s advertising efficiency, and strategically shape the future of digital marketing.\\n\\nJob Description\\nLeadershipDeep understanding preferred of multi-channel digital marketing, specifically Paid Search, Paid Social, Affiliate Marketing, Display Ads and CRM systemsAdvise and communicate to executives and leaders on deeply technical concepts across all marketing teams.Communication across multi-functional teams for technical and non-technical audiences.\\nThought Leader in Predictive Models, Statistical Methods, and Machine Learning strategies to leverage eBay’s data.Manage team of Data Scientists and set the technical direction of the Data Science team.Recruit, develop, and coach (performance reviews, distributing projects) a high-performing team of junior and senior individual contributors across multiple locations. The position is based in Seattle, and includes team members in San Jose and Shanghai.12+ years of relevant experience in a top technology company with at least several years leading innovative projects dealing with applications of data science\\nTechnologyBe the expert on emerging or existing Data Science technologies and techniques to enhance eBay’s advertising efficiency.Assist in designing a data and computational infrastructure that can handle near real time model execution, perform machine learning, and batch large scale data for our users including data pipelines, training environments and decreasing production runtimeExcellent understanding of computer science fundamentals, data structures, and algorithms. In-depth knowledge of one or more programming languages (including Java, C/C++, Python).Expertise in specialized areas such as Optimization, NLP, Probabilistic Inference, Machine Learning, Recommendation Systems.Proven experience with large data sets and related technologies, e.g., Hadoop/Spark. Knowledge of SQL is needed.Expert level experience in at least one of the ML libraries (such as PyTorch/Scikit-learn/ Tensorflow/SparkML) is required.\\nExpertise on eBay’s DataUnderstanding of what data is available and developing an action plan on how this will be leveraged to build near real-time models to increase advertising efficiency.Understanding customer behavior data at a deep level and what that means for making decisions on defining target audiences, bidding for ads, item recommendations, etc.Understand internal marketing and advertising KPI &amp; metrics in order to respond with appropriate problem solving to guide teams.\\nThis website uses cookies to enhance your experience. By continuing to browse the site, you agree to our use of cookies\\nView our privacy policy\\nView our accessibility info\\neBay Inc. is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, sex, sexual orientation, gender identity, veteran status, and disability, or other legally protected status. If you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at talent@ebay.com. We will make every effort to respond to your request for disability assistance as soon as possible.\\nFor more information see:\\nEEO is the Law Poster\\nEEO is the Law Poster Supplement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Interviewing is a universal experience, but it is no one's job\\n--------------------------------------------------------------------\\n\\nInterviews are the gateway between people and jobs--they are a critical connection point. And yet, while the interview is a universal experience, it has never been recognized as its own discipline. In fact, the vast majority of people conducting interviews receive no formal training in how to do so ( https://www.weforum.org/agenda/2019/05/interview-gap-economic-growth-tech-industry/ ).\\n\\nKarat is the market leader in Interview Engineering\\n---------------------------------------------------\\n\\nAt Karat, our mission is to make every interview predictive, fair, and enjoyable. To do so, we created and established the category of Interview Engineering.\\n\\nKarat conducts technical interviews on behalf of organizations hiring software engineers. We do this through a community of Interview Engineers who are equipped with Karat's interviewing infrastructure, battle-tested questions, and data-informed best practices. The result is highly predictive and fair interviews at scale that candidates truly enjoy. Karat has amassed the largest, most robust dataset of structured-interview intelligence to produce never-before-seen hiring analytics.\\n\\nFounded in 2014, Karat is a privately held and venture-funded company ( https://news.crunchbase.com/news/karat-raises-28m-series-b-led-by-tiger-global/ ) based in Seattle. Key clients include Pinterest, PayPal, Citrix, Intuit, and InVision.\\n\\nData Science at Karat\\n---------------------\\n\\nAs the principal individual contributor to data-driven insights at Karat, you would drive innovation in our understanding of multiple aspects of our business. Working on the internal tools and data engineering team you will help shape the future of how our company ingests, analyzes, and talks about data.\\n\\nCore Responsibilities\\n\\n---------------------\\n\\n\\nKarat's interview platform allows us to develop a deep understanding of both clients' needs as well as the skills and qualities of the candidates we interview. As we collect richer data about the conversations and user interactions during each interview, we strive to increase the signal captured in every minute of our interviews and maximize the value provided to clients.\\nEnsuring Karat interviews are fair, meaningful, and efficient is a product and theoretical problem backed by mathematical analysis. In this role you will help reduce the cognitive burden on all participants in the interview process while improving the quality and predictivity of our interview content and IP.\\nKarat's network of expert interview engineers poses unique supply and demand problems. You will help build the solutions to scale our platform to serve a constantly increasing number of interviews with a flexible network.\\n\\nAbout You\\n---------\\n\\n\\nBachelor's degree in mathematics, statistics, computer science, or a related field, or equivalent experience\\n2 or more years work experience in data analysis and modeling\\nDeep knowledge of statistics and rigorous analytical technique\\nExperience with and a knack for communicating technical work to stakeholders\\nExperience designing and refining machine learning models\\nStrong data analysis and scientific thinking skills\\nExperience constructing SQL queries (using Postgres or a similar platform)\\nComfortable in one or more (non-declarative) programming languages\\n\\nBonus Experience\\n----------------\\n\\n\\nExperience interviewing / recruiting / hiring technical candidates will help you understand our business.\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>Brand Analytics Data Scientist II</td>\n",
       "      <td>Bellevue, WA 98004</td>\n",
       "      <td>Bellevue</td>\n",
       "      <td>WA</td>\n",
       "      <td>98004</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Expedia\\nBrand Analytics Data Scientist II\\nWe are looking for a business facing Data Scientist to join our Brand marketing measurement function. You will deliver optimization and ROAS measurement tools for the Global Brand Marketing (GBM) team at Expedia.\\nWe structure problems, extract and analyze data and present the findings to our internal clients. In addition, our analysts handle the communication and relationships with internal customers across Expedia Worldwide. We are an award-winning team of analysts resolved to push the boundaries of analytics and embrace new technologies. The Analytics and Revenue Management team is essential to the company’s mission of becoming the world’s most intelligent travel marketplace.\\nDo you have a hunger to make a difference with one of the most loved consumer brands in the world? If so, this is the job for you!\\nWhat you will do:\\nDevelop methodologies and tools to optimize our existing Brand marketing performance, actively identify use-cases to apply data science techniques\\nEnhance and automate our existing ROAS methodologies for TV and other media, both online and offline\\nWork directly with internal engineering and external vendor resources where appropriate to ensure optimization findings are scalable and repeatable\\nInteract directly with multiple departments across the organization. Identify key analytical opportunities that deliver valuable business insight\\nWho you are:\\nYou have at least 4-5 years’ experience in a data science role, preferably in a marketing measurement context\\nYou have a deep understanding of advanced statistical modeling and/or machine learning techniques and have frequently applied these to drive business value\\nYou have a high level of proficiency in building data science tools in either R or Python, especially with large data sets. Experience working directly within or alongside engineering teams is highly desirable\\nYou have knowledge of and real passion for Big Data. Experience with SQL &amp; Hadoop required. Experience with unstructured data is highly preferred\\nYou have demonstrated the ability to work through complex business problems, identify opportunities to apply data science techniques, and partner with internal clients with a consultative approach\\nYou have well-rounded commercial knowledge covering product and marketing. Experience of ecommerce strongly preferred\\nWhy join us:\\nExpedia Group recognizes our success is dependent on the success of our people. We are the world's travel platform, made up of the most knowledgeable, hardworking, and creative people in our business. Our brands recognize the power of travel to break down barriers and make people's lives better – that responsibility inspires us to be the place where exceptional people want to do their best work, and to provide them to tools to do so.\\nWhether you're applying to work in engineering or customer support, marketing or lodging supply, at Expedia Group we act as one team, working towards a common goal; to bring the world within reach. We relentlessly strive for better, but not at the cost of the customer. We act with humility and optimism, respecting ideas big and small. We value diversity and voices of all volumes. We are a global organization but keep our feet on the ground so we can act fast and stay simple. Our teams also have the chance to give back on a local level and make a difference through our corporate social responsibility program, Expedia Cares.\\nIf you have a hunger to make a difference with one of the most loved consumer brands in the world and to work in the dynamic travel industry, this is the job for you.\\nOur family of travel brands includes: Brand Expedia®, Hotels.com®, Expedia® Partner Solutions, Egencia®, trivago®, HomeAway®, Orbitz®, Travelocity®, Wotif®, lastminute.com.au®, ebookers®, CheapTickets®, Hotwire®, Classic Vacations®, Expedia® Media Solutions, CarRentals.com™, Expedia Local Expert®, Expedia® CruiseShipCenters®, SilverRail Technologies, Inc., ALICE and Traveldoo®.LI-BSTEWARD\\nLPS-ARM-NA\\nExpedia is committed to creating an inclusive work environment with a diverse workforce. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. This employer participates in E-Verify. The employer will provide the Social Security Administration (SSA) and, if necessary, the Department of Homeland Security (DHS) with information from each new employee's I-9 to confirm work authorization.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>Product Data Scientist</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>3+ years of work experience in deep data analysis and/or data science in consumer behavior at scale3+ years experience in consumer Internet technologies\\n- Deep statistical skills - ideally utilized in A/B testing\\nExperience with distributed processing analytics tools (such as SageMaker, Hadoop, Hive, MapReduce, Spark)Experience working with product teams to inform product choicesExperience in user behavior analysis\\nCustomer obsessed and highly curious\\n\\nFire TV is the #1 best-selling streaming media player in the U.S. As we grow our product selection, we are looking for a Data Scientist to work in a data-driven product management team, helping define the user experience for our new Amazon Fire TV product line. In this role, you will have the opportunity to drive our user behavior analysis to help develop better methods for measuring business success and steering product vision. You will study user behavior in depth to validate critical features and user experiences. The role is inherently cross-functional: You will work closely with a high-energy team consisting of software engineering, data analytics, user experience, device marketing, customer service, and executive team members. This role is a good fit for someone who is creative yet highly data-driven and who has strong customer focus and ‘product sense’, combined with an established track record in user behavior analysis.\\nKey Responsibilities:\\n\\nDefine and implement our user behavior analysis data science methodology and roadmapPredict future customer behavior and business conditions through machine learning and predictive modeling.Use statistical and predictive techniques to build models for optimizing products and improving user experienceInform our AB testing experimentation for product innovation\\n\\nExperience in media entertainment user behaviorStrong strategic aptitude; ability to define and measure success of a product or feature based on user behavior analysis on large data sets\\nExcellent customer experience intuition; demonstrated success in inventing innovative and user-friendly products\\nKnowledge of general ML techniques\\nAt your best in a dynamic and rapidly changing environmentStrong programming skillsPassion for home entertainment\\nAmazon is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Masters with two years of experience or a Bachelors with five years of experience.Experience in SQL, R, Python, or another scripting language; command line usageTrack record of diving into data to discover hidden patterns and of conducting error/deviation analysisKnowledge of various machine learning techniques and key parameters that affect their performanceExperience developing experimental and analytic plans for data modeling processes, using strong baselines, and determining cause and effect relationsEvidence of using of relevant statistical measures such as confidence intervals, significance of error measurements, development and evaluation data sets, etc. in data analysis projectsExcellent written and verbal communication skills for both technical and non-technical audiences\\n\\nAmazon delights millions of customers around the world. Meet the behind the scenes team that enables our Human Resource and Operations Leaders to make informed decisions. The Amazon PeopleInsight team builds reporting and analytics tools for our teams that fulfill customer promise every day. Whether it is Fulfillment Center team that delivers your Prime order in two days, our Amazon Locker team that lets you pick up your package anytime that is convenient for you, our Prime Now team getting you lunch in under an hour, or one of many more, the PeopleInsight group is there providing people metrics along the employee lifecycle for our global operations businesses. The PeopleInsight team is a collaborative group of Business Analysts, Business Intelligence Engineers, Data Engineers, Data Scientists, Product Managers, and Program Managers dedicated to empowering leaders and enabling action through data and science. We deliver workforce, associate experience, and leadership insights so Amazon leaders can focus their efforts in ways that will engage, retain and grow their associates.\\n\\nWe are now recruiting for an exceptional Data Scientist, Worldwide Operations\\n\\nThe ideal candidate will be:\\nA Well-Rounded Athlete –Like a true athlete, you understand that we succeed or fail as a team. You are always ready to step up beyond your core responsibilities and go the extra mile for the project and your team. You nimbly overcome barriers to deliver the best products more quickly than expected.A Perpetual Student – You seek knowledge and insight. You challenge yourself to turn moments into master’s classes. Whether closing a gap, developing a new skill, or staying ahead of your industry, you revel in the joy of learning and growing.A Skilled Communicator – You excel when interacting with business and technical partners whether you are chatting, sending a written message, or conducting a presentation.A Trusted Advisor – You work closely with stakeholders to define key business needs and deliver on commitments. You enable effective decision making by retrieving and aggregating data from multiple sources and compiling it into a digestible and actionable format.An Inventor at Heart – You innovate on behalf of your customer by proactively implementing improvements, enhancements, and customizations. Your customers marvel at your creative solutions to challenges they had not yet identified.A Fearless Explorer – You are drawn to take on the hardest problems, navigate ambiguity, and battle skepticism. You never settle, even in the face of overwhelming obstacles.\\nRoles and Responsibilities\\nSuccess in this role will include influencing within your team and mentoring peers. The problems you will consider will be difficult to solve and often require a range of data science methodologies combined with subject matter expertise. You will need to be capable of gathering and using complex data set across domains. You will deliver artifacts on medium size projects, define the methodology, and own the analysis. Your findings will affect important business decisions. Solutions are testable and reproducible. You will create documents and share findings in line with scientific best practices for both technical and nontechnical audiences.\\n\\nAmazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation / Age.\\n\\nExperience in one or more natural language processing topics: tagging, syntactic parsing, word sense disambiguation, topic modeling; contextual text mining, and application of deep learning to NLPPrevious experience in a ML or data scientist role with a large technology company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>IMPLEMENTATION SCIENCE DATA ANALYST</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Notes: As a UW employee, you will enjoy generous benefits and work/life programs. For detailed information on Benefits for this position, click here.\\n\\n\\nAlthough open until filled, priority application date is September 27, 2019.\\n\\n\\nAs a UW employee, you have a unique opportunity to change lives on our campuses, in our state and around the world. UW employees offer their boundless energy, creative problem solving skills and dedication to build stronger minds and a healthier world.\\n\\n\\nUW faculty and staff also enjoy outstanding benefits, professional growth opportunities and unique resources in an environment noted for diversity, intellectual excitement, artistic pursuits and natural beauty. All of which has allowed the UW to be nationally recognized as a “Great College to Work For” for five consecutive years.\\n\\n\\nThe Department of Global Health was established in 2007, bridging the schools of Medicine and Public Health, with a mandate to harness the expertise and interdisciplinary power of all UW schools and colleges. Our mission is to improve health for all through research, education, training, and service; to understand and address the causes of disease and health inequities at multiple levels; and to collaborate with partners to develop and sustain locally-led, quality health systems, programs and policies. Driven by tremendous interest among both students and faculty, the Department has grown explosively to more than 400 graduate students and hundreds more undergraduates. We have more than 380 faculty and 1,000 staff working on projects across 130 countries with our deepest ties in United States, Kenya, Uganda, Peru, Mozambique, India, South Africa, Tanzania, Ethiopia, and Nicaragua. At the Department of Global Health at the University of Washington, diversity is integral to excellence. The Department recognizes that disparities in health around the globe stem from inequity. The Department encourages and supports the multiple identities of staff, faculty and students including, but not limited to, socioeconomic status, race, ethnicity, language, nationality, sex, sexual orientation, gender identity and expression, culture, spiritual practice, geography, mental and physical disability and age. The Department strives to become a local, national, and international leader in developing and maintaining increased representation and recognition of each of these dimensions of diversity among its faculty, staff, and students.\\n\\n\\nThis position will sit in the Global Center for the Integrated Health of Women, Adolescents, and Children (Global WACh) that is based in the University of Washington Departments of Global Health, Obstetrics/Gynecology, and Pediatrics. Our mission is to make scientific discoveries, cultivate leaders, and bridge disciplines to advance the tightly connected health and well-being of women, adolescents and children. Global WACh brings together expertise in maternal health from the Department of Obstetrics/Gynecology, neonatal and child health expertise from the Department of Pediatrics, and vast experience working in infectious disease, health metrics and evaluation, education, clinical research, and service delivery within the Department of Global Health. These disciplines combine under a methodology that views women, children, and adolescents as three populations interconnected along a shared life course.\\n\\n\\nThe Department of Global Health has an outstanding opportunity for a full-time Implementation Science Data Analyst. The Implementation Science Data Analyst will join the Global WACh Gut Health and Child Survival team to support implementation science activities across projects. Current projects include the DeWorm3 project, a five-year study to investigate the feasibility of interrupting the transmission of three types of parasitic worms and to evaluate sustainable and scalable models for delivering community-wide mass drug administration at scale. Other projects that the Implementation Science Data Analyst will work on include a study to improve linkages between nutritional and HIV services for pediatric populations in Kenya and a study in Benin to increase participation in mass drug administration programs for neglected tropical diseases in urban areas. All of these studies are mixed-methods, requiring analytical support for both qualitative and quantitative data.\\n\\n\\nThis newly created position is currently full-time and is based at the Ninth and Jefferson Building. The ideal candidate is passionate about implementation science, has a mixed-methods background, has excellent written and verbal communication skills, is proactive and results driven, and is highly organized with superb attention to detail.\\n\\n\\nRESPONSIBILITIES:\\n\\nResponsibilities include data collection, management, and (primarily) analysis support for qualitative, quantitative, and costing data for Gut Health and Child Survival investigators on their funded implementation science projects. Specific responsibilities may include:\\n\\n\\nQualitative Data: Analyze and interpret qualitative data (45%):\\n\\nManage qualitative data, including merging projects and organizing case memos\\n\\nReview and revising analysis plans, managing master codebooks\\n\\nCode qualitative study data, and prepare case memos as necessary\\n\\nAnalyze and interpret thematic content\\n\\nPrepare study reports\\n\\n\\nQuantitative Data: Design data collection instruments and analyze data (25%):\\n\\nDesign process mapping tools and analyze process mapping data, while leading the design of novel data visualization approaches for operational data\\n\\nDesign, monitor, and analyze other surveys capturing implementation and health systems dynamics influencing intervention delivery. Analyze associations between indicators of service delivery and key outcomes of coverage, fidelity, acceptability, and cost.\\n\\nConduct quantitative analysis in Stata or R to analyze, visualize, and interpret the data.\\n\\n\\nCosting Analyses (15%):\\n\\nMonitor data from financial and economic costing tools, and aggregate data into costing reports to be shared with research partners and collaborating Ministries of Health\\n\\nProcess and analyze data from time-and-motion studies\\n\\nConduct scenario analyses to identify costs associated with scale-up of different interventions\\n\\n\\nConduct data quality checks (10%):\\n\\nConduct data quality and assurance checks on a variety of data, including quantitative data, qualitative data, and costing data.\\n\\n\\nAssist in manuscript preparation (5%):\\n\\nContribute content for manuscripts including written and visual content\\n\\n\\nREQUIREMENTS:\\n\\nBachelor’s degree in public health, global health, epidemiology, biostatistics or other related field.\\n\\n3 years of experience analyzing quantitative and qualitative data using ATLAS.ti, Stata, R or other statistical software.\\n\\nExcellent written and verbal communications skills\\n\\n\\nEquivalent education/experience will substitute for all minimum qualifications except when there are legal requirements, such as a license/certification/registration.\\n\\n\\nDESIRED EXPERIENCE\\n\\nMaster’s degree in public health, global health, epidemiology, biostatistics or other related field.\\n\\nAdvanced background using ATLAS.ti or other equivalent programs to analyze qualitative data\\n\\nExperience using Stata, R, or other statistical software packages to analyze and visualize quantitative data\\n\\nExperience collecting or analyzing costs alongside a research project to feed into an economic evaluation\\n\\nFamiliarity with implementation science research methods\\n\\nHighly organized with superb attention to detail and ability to see projects through to completion\\n\\nWork experience in a fast-paced environment with demonstrated ability to juggle multiple demands, establish priorities, and meet deadlines\\n\\nHigh degree of professionalism and diplomacy; ability to work across cultures and remain personable, professional and organized under stressful situations\\n\\nAbility to operate in situations of uncertainty and trouble-shoot challenges demonstrating appropriate judgment and critical thinking\\n\\nExperience supporting academic researchers and familiarity with international global health research\\n\\n:\\n\\nPeriodically available for phone calls/meetings in the early morning and late evenings to accommodate worldwide time differences\\n\\nDeadline-driven environment, occasionally requiring extended hours\\n\\nSome international travel may be expected\\n\\n\\nApplication Process:\\n\\nThe application process for UW positions may include completion of a variety of online assessments to obtain additional information that will be used in the evaluation process. These assessments may include Workforce Authorization, Cover Letter and/or others. Any assessments that you need to complete will appear on your screen as soon as you select “Apply to this position”. Once you begin an assessment, it must be completed at that time; if you do not complete the assessment you will be prompted to do so the next time you access your “My Jobs” page. If you select to take it later, it will appear on your \"My Jobs\" page to take when you are ready. Please note that your application will not be reviewed, and you will not be considered for this position until all required assessments have been completed.\\n\\nCommitted to attracting and retaining a diverse staff, the University of Washington will honor your experiences, perspectives and unique identity. Together, our community strives to create and maintain working and learning environments that are inclusive, equitable and welcoming.\\nThe University of Washington is a leader in environmental stewardship &amp; sustainability, and committed to becoming climate neutral.\\nThe University of Washington is an equal opportunity, affirmative action employer. To request disability accommodation in the application process, contact the Disability Services Office at 206-543-6450 / 206-543-6452 (tty) or dso@uw.edu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>Research Scientist II</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Masters with four years of experience or a Bachelors with seven years of experience in the field of organizational psychology, I/O psychology, statistics, computer science, engineering, mathematics, or a related field.Experience in SQL, R, Python, or another scripting language; command line usage; experience in Java.Track record of diving into data to discover hidden patterns and of conducting error/deviation analysis.Knowledge of various machine learning techniques and key parameters that affect their performance.\\n\\nWhat does a healthy organization look like in Amazon? With the growing workforce, are we facilitating the right conversations on performance and talent management? What trends are we seeing in our employee and candidate data and what can managers do about it? What data and insights do our customers (business leaders, people managers, HR, Recruiting) need to enhance their ability to deliver results and improve the employee experience? If these challenges sound interesting to you, you want to be a part of building a ‘first of its kind’ product, and you are passionate about data, consider the Consumer People Analytics (CPA) team.\\n\\nAs a Research Scientist on the CPA team, you will partner closely with analytics and talent management teams in Amazon. You will build machine learning and statistical models, using our world class data systems, to identify patterns in people data. The ideal candidate will thrive and have demonstrated success in an environment which offers ambiguously defined problems, big challenges, and quick changes. This role goes beyond just model generation and you will be expected to integrate the results of the models into our world class web portal, People Analytics Online (PAO).\\n\\nPh.D. in an engineering, analytics, or scientific fieldExperience in creating data driven visualizations to describe an end-to-end system.Previous experience in a ML or data scientist role with a large technology company.Excellent written and verbal communication skills for both technical and non-technical audiences.\\nAmazon is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>Data scientist, Amazon Payment Products</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>We are looking for Data Scientist who has a passion for their customers and a passion for working with data. You like working with your customers, understanding their challenges, and partnering with them to invent great solutions. You like working with large data sets, and bringing data together from multiple systems to answer critical business questions and drive change. You are analytical and creative. You should also have the following skills or experiences:\\n3+ years developing end-to-end analytics solutions: data modeling, reporting and insight recommendations3+ years in relational database concepts with a solid knowledge of SQL, Big Data technologiesAdvanced Degree in Statistics, Economics, Operations Management, Finance, Computer Science, or a related field3+ years’ experience in Data Analysis, Business Analytics, Business Intelligence, or related technical field working as Research scientist/Data Scientist.Excellent written and spoken communication skill\\n\\nHundreds of millions of customers, billions of transactions, petabytes of data… How to use the world’s richest collection of e-commerce data to provide superior value and better paying experience to customers ? The Amazon Payments Team manages all Amazon branded payment offerings globally. These offerings are growing rapidly and we are continuously adding new market-leading features and launching new products. Amazon.com has a culture of data-driven decision-making and demands business intelligence that is timely, accurate, and actionable. This team provides a fast-paced environment where every day brings new challenges and new opportunities.\\n\\nOur team of high caliber software developers, data scientists, statisticians and product managers use rigorous quantitative approaches to ensure that we target the right product to the right customer at the right moment, managing tradeoffs between click through rate, approval rates and lifetime value. In order to accomplish this we leverage the wealth of Amazon’s information to build a wide range of probabilistic models, set up experiments that ensure that we are thriving to reach global optimums and leverage Amazon’s technological infrastructure to display the right offerings in real time.\\n\\nAs a Data Scientist you will be working in one of the world's largest and most complex data warehouse environments. You should be passionate about working with huge data sets and be someone who loves to bring datasets together to answer business questions. You should have deep expertise in creation and management of datasets. You will build data analytical solutions that will address increasingly complex business questions.\\n\\nYou should be expert at implementing and operating stable, scalable data flow solutions from production systems into end-user facing applications/reports. These solutions will be fault tolerant, self-healing and adaptive. You will be working on developing solutions that provide some of the unique challenges of space, size and speed. You will implement data analytics using cutting edge analytics patterns and technologies that are inclusive of but not limited to various AWS Offerings -EMR, Lambda, Kinesis, and Spectrum. You will extract huge volumes of structured and unstructured data from various sources (Relational /Non-relational/No-SQL database) and message streams and construct complex analyses. You will write scalable code and tune performance running over billion of rows of data. You will implement data flow solutions that process data on Spark ,Redshift and store in Redshift ,Filebased system (S3) for reporting and adhoc analysis.\\n\\nYou should be detail-oriented and must have an aptitude for solving unstructured problems. You should work in a self-directed environment, own tasks and drive them to completion.\\n\\nYou should have excellent business and communication skills to be able to work with business owners to develop and define key business questions and to build data sets that answer those questions. You own customer relationship about data and execute tasks that are manifestations of such ownership, like ensuring high data availability, low latency, documenting data details and transformations and handling user notifications and training.\\n\\nPhD in Statistics, Economics, Operations Management, Finance, Computer Science, or a related fieldProven experience in building statistical models using R, Python, Scala, or a related software (especially, Optimization and ML modeling), with a willingness to learn and develop additional skills in statistical model, machine learning, and large-scale scientific computing.Practical experience in implementing optimization models and tools through the use of high-level modeling languagesBusiness Intelligence systems and data presentation (Tableau, QlikView, MicroStrategy, PowerBI)Track record of diving into data to discover business insightsHigh-level knowledge of various machine learning techniques and key parameters that affect their performance.Ability to manage multiple competing priorities.Proven ability to influence without authority .Ability to work effectively within an interdisciplinary team of Data Engineers, BIEs, and Product Managers.Ability to communicate relevant scientific insights from data to senior business leaders, financial analysts, and product managers.Experience with large data sets, big data and analytics.Extensive theoretical statistical training, including the ability to carefully adapt/modify existing statistical tools to accommodate new applied use cases.Ability to distill problem definitions, models, and constraints from informal business requirements; and to deal with ambiguity and competing objectives.Prior background in machine learning and forecasting is a plus.Work experience at financial service industry is a plus.Meets/exceeds Amazon’s functional/technical depth and complexity for this roleMeets/exceeds Amazon’s leadership principles requirements for this role\\nAmazon is an equal opporunity employer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Senior Data Scientist, Agent Analytics</td>\n",
       "      <td>Seattle, WA 98101</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>98101</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>About the team\\nZillow Group is currently seeking a Senior Data Scientist to join the Agent Analytics team in our Seattle office. Our team is tasked with absorbing billions of rows of data from dozens of sources, organizing them, visualizing them, and analyzing them to help inform both short- and long-term decision-making.\\n\\nOur structure is very flat and you will soon find yourself communicating directly with Senior Leadership. Each team member focuses on a cross-section of the Zillow Group community. Below are some of the areas in which our Data Scientists focus their energy.\\n\\nBusiness. Build data-driven insights to fuel the future of Zillow Group’s Agent business. Find opportunities for innovation and assess performance of current initiatives.\\n\\nSales. Analyze the intersection of human behavior, incentive structures, and sales process to build a more efficient sales force.\\n\\nMarketing. Develop strategies for marketing efforts through a wide range of marketing channels and measure their performance.\\n\\nTools. Create data-focused information products from billions of data points we collect every single day for internal and external clients.\\nAbout the role\\nAre you passionate about using data to understand what makes people tick? Are you driven to understand not just WHAT they do, but more importantly, WHY? Do you understand the power of Insights and do you have the skills, knowledge and expertise to drive big research projects, and then bring results to life for an organization in a way that will fuel innovation, inspire creativity, and truly drive the business forward?\\nWe are looking for a Senior Data Scientist to join our Agent Analytics group. The ultimate goal for the position is to analyze data collected through various studies and assimilate resulting information into actionable insights to drive improvement of the business at Zillow Group.\\nYou are a strategic, entrepreneurial thinker with a strong background in data analysis and interpretation. In addition, you have the ability to serve as an evangelist of the customers, clearly translating between data and insights and collaborating with others to bring data to life for the company in a way that will inspire and inform our efforts across all aspects of the business.\\nDesign and implement custom approaches to analyzing complicated datasets which will produce actionable insights and recommendations to drive agent acquisition and sales for Premier Agent business.\\nLead the development of tools that modernize the ways internal partners access and gain insights from our data; lead tutorials to help spread the adoption and responsible use of these tools.\\nDive deep into new and existing data to provide valuable ad hoc analysis.\\nSynthesize insights and trends from multiple datasets to craft a richer, more vibrant picture of our consumers and customers.\\nPerform in-depth data analyses to inform and guide agent acquisition and sales strategy and operation.\\nDefine key metrics and leading indicators, develop tools and dashboards to make these metrics reliable and useful.\\nBuild key data sets to empower operational and exploratory analysis.\\nPartner with sales and marketing to implement, measure and improve sales and marketing operations.\\nBring more rigor to statistics/experimentation so that we make optimal decisions with the data we have in assessing the impact of sales and marketing initiatives.\\nBuild a testing culture/process and help evaluate potential use cases and solutions for A/B testing.\\nPerform exploratory analysis and modeling to support new initiatives.\\nAssist in preparing reports to communicate data analysis that will increase understanding and bring the insights to life.\\nWho you are\\nYou will not shy away from complexity and uncertainty, and you will develop a keen understanding of our mission, business models, and personas. We want you to use that intuition you’ve developed (both in business and real life) to use the data we have on hand to find opportunities for growth and to develop insights that help the broader organization meet its goals, improve its performance, and positively impact how our consumers navigate the real estate market. We’re looking for a Senior Data Scientist who has:\\nAn undergraduate or Master's degree in a quantitative field (e.g. science, engineering, economics, finance, statistics, or similar) or demonstrable experience within data science and analytics\\n4+ years of work experience involving quantitative data analysis and complex problem solving.\\nExperience designing and conducting quantitative analysis using a statistical package like R or SPSS to create cross tabs and perform higher analytics for segmentations and driver analyses.\\nStrong foundation of analytical skills (e.g., strong understanding of SQL or Python, total command of Excel and PowerPoint) and experience with data visualization tools (e.g. Tableau) and have used these skills and experiences to positively impact a business.\\nAn unquenchable thirst for investigating data; able to disaggregate and analyze problems, probe underlying questions, beliefs and assumptions, analyze issues from multiple perspectives.\\nFluency in coding and programming, but also have the innate ability to translate this data into actionable insights and meaningful recommendations for others in the organization.\\nAble to apply past experience with A/B testing, experimentation frameworks and best practices to guide org in building this capability\\nAble to effectively communicate and deliver findings and recommendations to non-technical stakeholders in a clear and compelling fashion\\nAbility to synthesize results from multiple sources to create a richer more complete perspective of the issue or opportunity, and related implications.\\nYou have strong oral and writing skills with the ability to find compelling ways to bring information to life.\\nExcellent project management, organizational skills and attention to detail; ability to handle multiple analytics requests against opposing (tight) timelines.\\nYou thrive in a fluid, fast-paced, and results-oriented environment; able to adapt to changing business needs.\\nMust love this stuff.\\nGet to know us\\nZillow Group houses the largest portfolio of real estate brands on mobile and the web. We are on a mission to rewire the real estate transaction and are building transformational tools and services that make it easier for everyone to find and get into a home they love. We are working to create an on-demand real estate transaction experience for every stage of the home lifecycle - for buyers, sellers, renters and borrowers - and we're well on our way. No matter what job you're in, you will play a critical role in making this vision a reality for millions of people.\\nAt Zillow Group, we're powered by our inclusive work culture, where everyone has the support and resources to do the best work of their careers. Our efforts to streamline the real estate transaction is supported by our passion to empower people and enrich lives around everything home, a deep-rooted culture of innovation, a fundamental commitment to Equity and Belonging, and world-class benefits. But, don't just take our word for it. Read our reviews on Glassdoor and recent recognition from multiple organizations, including: Fortune 100 Best Companies to Work For (#69), Fortune Best Workplaces for Diversity (#38), Fortune Best Workplaces for Parents (#31), Fortune Best Workplaces for Women (#20), Fatherly's Best Workplaces for New Dads (#37), JUST Capital 100 Company (#69), Bloomberg Gender Equality Index constituent.\\nZillow Group is an equal opportunity employer committed to fostering an inclusive, innovative environment with the best employees. Therefore, we provide employment opportunities without regard to age, race, color, ancestry, national origin, religion, disability, sex, gender identity or expression, sexual orientation, or any other protected status in accordance with applicable law. If there are preparations we can make to help ensure you have a comfortable and positive interview experience, please let us know.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Redmond, WA</td>\n",
       "      <td>Redmond</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nBS/MS in Computer Science, Engineering or related technical field\\n5 years of experience in using OR/OM techniques to solve real world problem and develop production grade optimization and model solutions.\\nAbility to use C#/python/R to develop proof of concepts and optimization/modeling solutions\\n</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nBS/MS in Computer Science, Engineering or related technical field\\n5 years of experience in using OR/OM techniques to solve real world problem and develop production grade optimization and model solutions.\\nAbility to use C#/python/R to develop proof of concepts and optimization/modeling solutions\\n</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Do you have background in operations research/operations management? Are you passionate about using mathematical programming, metaheuristics and other optimization techniques to solve real world problems? Do you thrive in highly ambiguous environments where innovation and creativity can translate into hundreds of millions of dollars saved for the company?\\nIf you answered yes, we are the team you should be talking to!\\nThe Azure Cloud Supply Chain &amp; Provisioning Engineering team builds the services that literally fuel cloud growth. We ensure Microsoft’s cloud data centers are properly seeded with all types of hardware required to meet Microsoft’s growing customer needs.\\nWe’ve built a highly asynchronous, event driven, distributed microservices platform that automates and optimizes weeks long business and physical processes and reacts to changes that happen during those weeks.\\nTo deliver on the customer promise of the infinite cloud, we’re looking for people to join an architect and a small team of people to push this architecture further, by exploring opportunities for optimization and modeling of existing processes and providing data driven support for decision making.\\nResponsibilities\\nLearning quickly from your peers, projects and interactions with business partners.\\nLearning and application of OR/OM skills in a production setting – researching, building and proving different optimization techniques using C#/Python/R.\\nBuilding system models and simulations to support decision making as well as what-if analysis\\nExtracting insights and actionable observations from large data sets\\nQualifications\\nBasic Qualifications:\\nBS/MS in Computer Science, Engineering or related technical field\\n5 years of experience in using OR/OM techniques to solve real world problem and develop production grade optimization and model solutions.\\nAbility to use C#/python/R to develop proof of concepts and optimization/modeling solutions\\nOther Qualifications:\\nStrong problem-solving skills\\nExperience with supply chains or similar business operations is a strong plus\\nFamiliarity with typical data management systems and tools such as Pandas, SQL, Azure Data Lake etc.\\nGreat written and verbal communication skills and ability to collaborate cross-group and work effectively within the team\\nAbility to simplify and disambiguate complex problem spaces\\nFamiliarity with Azure, or similar cloud solutions\\nAbility to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings: Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud Background Check upon hire/transfer and every two years thereafter.\\nMicrosoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.\\n\\nBenefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Data Scientist, Alexa Excellence</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Master’s in Engineering, Economics, Statistics, Applied Math or related field3+ years of professional work experience in Data Science and Statistical modellingExperience with math/stats software (R, Matlab, Python, SAS, Stata) or other domain specific software and some experience with SQL3+ years experience with data analytics applied to time series applications or expertise with ARIMA\\n\\nAlexa is seeking an outstanding Data Scientist to uncover key insights on how consumers use Alexa devices. As customers increasingly use Alexa voice features, we need to understand the usage patterns and build statistical models to forecast future usage. As a Data Scientist on the Alexa Excellence team at Amazon, you will have the opportunity to work on one of the world's largest customer data sets and influence the long-term evolution of our analytics capability.\\n\\nKey Responsibilities\\n\\nYou will have the following responsibilities within the scope of our global expansion:\\nSupport the analytical needs of the Alexa TPS team inclusive of routine reporting, ad hoc, statistical inference and predictive modeling for customer voice requests and developing scalable algorithms and models.Maintain and improve on our system for peak voice request rate.Analysis of complex datasets to make decisions, scientific research projects, creating visualizations to drive data insight or describe an end-to-end system.Work with central economics, machine learning, finance and other analytics team to ensure the most efficient and effective allocation of resources to tackle the WorldWide device usage patterns.Collaborate with Finance/Management to develop clear business and measurement objectivesEnsure that the quality and timeliness of analytic deliverables meet Alexa’s expectationsDevelop and present papers with insights and recommendations at senior audiencesProvide informal direction and guidance to more junior members of staff on all aspects of analytics from business context and prioritization to technical coaching\\n\\nDemonstrated experience of time series modelling such as ARIMA, structural models or similarStrong verbal/written communication &amp; data presentation skills, including an ability to effectively communicate with both business and technical teamsProven ability to work effectively in a cross-functional, fast paced environmentExperience communicating issues at multiple levels to include validating and correcting junior staff detailed work and explaining the implications of the analysis results to executives\\nAmazon is an Equal Opportunity-Affirmative Action Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>Data Science Curriculum Designer and Instructor - Bellevue</td>\n",
       "      <td>Bellevue, WA 98004</td>\n",
       "      <td>Bellevue</td>\n",
       "      <td>WA</td>\n",
       "      <td>98004</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>*\\nCurriculum Development\\n\\nInstruction\\nBellevue, WA, USA\\n\\nDESCRIPTION\\nCoding Dojo is looking to add an experienced curriculum designer and instructor to our team to create and design new courses on the cutting edge of technology. This role be two-fold: Curriculum Designer and Instructor. The primary responsibilities will be to lead the development of new Data Science and Machine Learning curriculum, and to deliver this content locally in the Greater Seattle Area, and potentially at locations all around the world, including London, Tel Aviv, Sydney and more.\\n\\nRESPONSIBILITIES\\n*\\nDesign and develop Data Science, Machine Learning and AI curriculum\\n\\nDesign and develop Azure cloud services curriculum\\nDeliver workshops on data science, data analytics, machine learning, Python, SQL, statistics, probability and data engineering\\nFacilitate group discussions, demos and in-class activities\\nFollow industry trends in big data, deep learning, machine learning and AI\\nPlay a hands-on role in curriculum development, use what you learn from working with students to make the curriculum world class\\nGather and report on student metrics\\nWork alongside Coding Dojo’s Online Instruction team to deliver remote training\\nParticipate in professional training, so you stay fresh!\\n\\nEDUCATIONAL AND EXPERIENCE REQUIREMENTS\\nYou must have proficient data science and machine learning experience. Please ensure you meet or exceed the following:\\n\\nB.S. degree in data science, engineering, mathematics, statistics, or a related degree from an accredited college or university\\nProficient in cloud computing services, specifically Azure\\nProfessional experience as a data scientist\\nExpertise in Python, Python libraries, SQL, statistics, mathematics, machine learning, data visualization tools and all of the data science topics that we teach\\nTeaching and leading teams experience a big plus\\nA combo of technology and education in your background is preferred\\n\\nWE'D LOVE TO WORK WITH YOU IF...\\n1. You are passionate about learning, helping others, and making a positive impact in the world. Your energy will be an important driver for the success of our students and staff.\\n2. You are an education fanatic. You understand different approaches to curriculum design and pedagogies.\\n3. You are a highly motivated individual with leadership skills who can guide and lead projects to completion.\\n4. You are willing to travel up to 25% of the time to other Reactor locations worldwide.\\n5. Teaching, mentorship, and coaching experience is a big plus!\\n\\nABOUT CODING DOJO\\nCoding Dojo is an industry-leading coding bootcamp whose flagship program is unmatched: we teach 3 full stacks in 3 months—a mixture of which can include iOS, Python, MEAN, Rails, C#, Java, or LAMP. If you have development and/or instruction experience and are looking for a new and exciting milestone in your career, this position is a rare opportunity to join a rapidly growing start-up and make a positive impact in many people's lives.\\n\\nCoding Dojo has campuses in Silicon Valley, Seattle, Los Angeles, Dallas, Arlington, Chicago, Tulsa, Boise, and online.\\n\\nCoding Dojo offers a competitive salary and standard benefits.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Seattle, WA 98101</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>98101</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nBachelor’s degree or equivalent experience in computer science, engineering, or information technology\\nExperience in a Unix-based environment\\nSolid knowledge of Linux toolchain, Python, JavaScript, and shell scripting\\nKnowledge of building scalable and high-performance systems\\nUnderstanding of various product-development life cycles</td>\n",
       "      <td>\\nWork closely with engineers throughout the development cycle to reproduce the small and large customer environments under which the ExtraHop system is run.\\nEmploy a mix of manual and automated data analysis techniques to collect data and analyze the operational environment of the ExtraHop system.\\nGenerate gigabits of network traffic on over-the-counter Intel hardware with OSS systems and networking tools for performance benchmarking of the ExtraHop system.\\nInstall, run, and benchmark emerging products and tools in a lab environment to provide product development and product management strategic data.</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>The ExtraHop platform is a novel approach to processing vast amounts of wire data in real-time. Want to join a collaborative team that builds solutions which provide deep performance insights, behavioral security analyses, and drive business analytics? Keep reading.\\nDo you like open source tools? Do you like assembling arrays of the latest and greatest technologies in networking/security and performance bench marking to solve difficult problems? Do you like to push systems to their limits to improve their quality? We are looking for people who have passion and expertise in these areas and want to aid our development effort to build one of the most performance and secure systems in the industry.\\nDuties &amp; Responsibilities\\nWork closely with engineers throughout the development cycle to reproduce the small and large customer environments under which the ExtraHop system is run.\\nEmploy a mix of manual and automated data analysis techniques to collect data and analyze the operational environment of the ExtraHop system.\\nGenerate gigabits of network traffic on over-the-counter Intel hardware with OSS systems and networking tools for performance benchmarking of the ExtraHop system.\\nInstall, run, and benchmark emerging products and tools in a lab environment to provide product development and product management strategic data.\\nRequired Skills &amp; Experience\\nBachelor’s degree or equivalent experience in computer science, engineering, or information technology\\nExperience in a Unix-based environment\\nSolid knowledge of Linux toolchain, Python, JavaScript, and shell scripting\\nKnowledge of building scalable and high-performance systems\\nUnderstanding of various product-development life cycles\\nDesired Skills &amp; Experience\\nSolid understanding of the OSI model and excellent working knowledge of the key protocols from Layer 2 through Layer 7 including ARP, IP, TCP, UDP, and HTTP\\nTCP/IP networking.\\nExperience using Linux networking tools such as tcpdump, tcpreplay, pcap tools, apache bench, etc.\\nExperience using and managing virtual infrastructure for VMware, Hyper-V, Xen, and KVM. Experience with OpenStack and related SDN framework a plus.\\nFamiliarity with embedded systems or other syste-ms-level development.\\nExperience standing up systems using Linux containers, Docker, Puppet, Chef, etc\\nABOUT EXTRAHOP\\nExtraHop is an enterprise cyber analytics and performance monitoring company helping the world’s leading organizations understand and secure their entire environment from core to edge to cloud. Our breakthrough approach to analytics and machine learning helps our customers investigate threats, ensure the delivery of critical applications, and secure their investment in the cloud, resulting in 95% faster threat detection and reducing unplanned downtime by 86% while providing the best possible customer experience.\\nExtraHop is recognized by leading organizations for both its innovation in the market and its commitment to building a world-class team. We’ve been named to Wealthfront’s Career-Launching Companies list for the last four years, and JMP Securities put ExtraHop on its 2018 Super 70 List as one of the most strategically positioned private companies in the cybersecurity industry. Credit Suisse recognized ExtraHop as a member of its inaugural Disruptive Technology Recognition Program, and SC Media named ExtraHop a 2019 Industry Innovator for enterprise network traffic analysis.\\nWith well over $100 million in bookings in 2018, and 10x growth in security, the opportunity with ExtraHop has never been greater. Are you ready to rise above the noise?\\nExtraHop is an Equal Opportunity Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, disability, military status, or national origin or any other characteristic protected under federal, state, or applicable local law.\\n#LI-DNP\\n#LI-DNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>As a UW employee, you have a unique opportunity to change lives on our campuses, in our state and around the world. UW employees offer their boundless energy, creative problem solving skills and dedication to build stronger minds and a healthier world.\\n\\n\\nUW faculty and staff also enjoy outstanding benefits, professional growth opportunities and unique resources in an environment noted for diversity, intellectual excitement, artistic pursuits and natural beauty. All of which has allowed the UW to be nationally recognized as a “Great College to Work For” for five consecutive years.\\n\\n\\nThe Joint Institute for the Study of the Atmosphere and Ocean (JISAO) has existed since 1977 for the purpose of fostering research collaboration between UW and the National Oceanic and Atmospheric Administration (NOAA). JISAO’s research is at the forefront of investigations on climate change, ocean acidification, fisheries assessments, and tsunami forecasting.\\n\\n\\nJISAO, in conjunction with NOAA’s Pacific Marine Environmental Laboratory (PMEL), conducts groundbreaking oceanographic and environmental research. The Science Data Integration Group (SDIG) at PMEL develops software and defines processes to integrate data management processes into research projects (such as the Surface Ocean CO2 Atlas project) and to preserve UW/JISAO and PMEL’s scientific data assets. In support of UW and PMEL scientists, SDIG develops applications and frameworks to facilitate the documentation, access, visualization, analysis and assessment of scientific data.\\n\\n\\nJISAO has an exciting opportunity for a Data Scientist.\\n\\n\\nThe Data Scientist will develop, install and maintain software in support of PMEL’s scientific data management and data analysis objectives. This includes development to support enhancements, installation and maintenance of the SDIG developed PyFerret scientific data visualization and analysis application. Understanding and competence in working with Python and Python scientific libraries is essential to supporting the PyFerret application. Other development efforts include Java backend server processes used to support management of PMEL’s scientific data assets as well as building interactive web-visualization tools using modern JavaScript frameworks. The developed tools and frameworks are designed to improve data management processes for various research projects, including the Surface Ocean CO2 Atlas (SOCAT) project, and to support efforts by groups such as NOAA’s Ocean Acidification Program. The incumbent will be expected to support and interact with developer and scientific communities through software repositories, collaboration hubs and occasional scientific and developer meetings. Presentations at scientific and data management conferences are encouraged. Support of scientific colleagues and SDIG members requires experience with close collaboration and open communication, including weekly group meetings and occasional presentations to the wider UW and PMEL community.\\n\\n\\nDUTIES and RESPONSIBILITIES:\\n\\n\\nPyFerret development and support: Assist in adding new features to PyFerret, creating distribution packages, maintenance of codebase, installation and user support. This requires experience with Python and Python modules, as well as familiarity with source code version control systems such as Git.\\n\\n\\nWeb Visualization development and testing: The Research Consultant will be involved in developing, improving and implementing web-based visualizations using modern Java and JavaScript frameworks.\\n\\n\\nDevelopment of Quality Control software: The Research Consultant will be involved in developing software to help implement quality control routines developed by scientists for biogeochemical data from various ocean observing platforms.\\n\\n\\nDataset Curation: The Science Data Integration Group works closely with a variety of projects to improve data and dataset management and the Research Consultant will join other group members in curating such datasets. This requires knowledge of modern scientific dataset formats such as NetCDF.\\n\\n\\nMeetings and Collaborations: The Research Consultant will be expected to participate in weekly group meetings to discuss status of current projects and raise any issues that may be hampering progress. The Research Consultant will be encouraged to occasionally present results of recent work at appropriate scientific conferences.\\n\\n\\nAs a UW employee, you will enjoy generous benefits and work/life programs. For detailed information on Benefits for this position, click here.\\n\\n\\nREQUIRED:\\n\\nMaster’s degree in computer science, engineering, earth science, applied mathematics or data science, with four or more years work experience in scientific data programing, graphical displays, and data management, with focus on oceanographic and meteorological applications.\\nHighly experienced programming in Python, Java, C and JavaScript with knowledge of computer graphics applications.\\nSoftware development experience in a web environment; experience using internet and WWW technologies (e.g. email, file transfer, content management) and standards (e.g. HTML, XML).\\nFamiliarity with common scientific data formats and programming interfaces (e.g. NetCDF, HDF).\\nAbility to work in a heterogeneous computing/IT environment comprised of Unix/Linux servers, Linux/MacOSX/MS Windows workstations and portable computers.\\nKnowledge of source code version control systems such as Git/Github.\\nExcellent verbal communication and technical writing skills\\n\\n\\nEquivalent education/experience will substitute for all minimum qualifications except where there are legal requirements such as license/certification/registration.\\n\\n\\nDESIRED:\\n\\nAbility to work in a heterogeneous computing/IT environment comprised of Unix/Linux servers, Linux/MacOSX/MS Windows workstations and portable computers.\\nKnowledge of Unidata’s THREDDS Data Server and NOAA’s ERDDAP data platform.\\nExperience with Fortran, R, Jupyter Notebooks, Matlab.\\nExperience with Machine Learning or Artificial Intelligence a plus\\n\\n\\nApplication Process:\\n\\nThe application process for UW positions may include completion of a variety of online assessments to obtain additional information that will be used in the evaluation process. These assessments may include Workforce Authorization, Cover Letter and/or others. Any assessments that you need to complete will appear on your screen as soon as you select “Apply to this position”. Once you begin an assessment, it must be completed at that time; if you do not complete the assessment you will be prompted to do so the next time you access your “My Jobs” page. If you select to take it later, it will appear on your \"My Jobs\" page to take when you are ready. Please note that your application will not be reviewed, and you will not be considered for this position until all required assessments have been completed.\\n\\nCommitted to attracting and retaining a diverse staff, the University of Washington will honor your experiences, perspectives and unique identity. Together, our community strives to create and maintain working and learning environments that are inclusive, equitable and welcoming.\\nThe University of Washington is a leader in environmental stewardship &amp; sustainability, and committed to becoming climate neutral.\\nThe University of Washington is an equal opportunity, affirmative action employer. To request disability accommodation in the application process, contact the Disability Services Office at 206-543-6450 / 206-543-6452 (tty) or dso@uw.edu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>Senior Data Scientist, IMDb TV</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Master's degree in Computer Science, Computer or Electrical Engineering, Mathematics, Physics, Statistics, Economics or a related field5+ years of experience producing models and analytics for business applicationsBreadth of experience in standard machine-learning and statistical modeling tools and techniques (e.g. random forests, gradient-boosted regression, LASSO, logistic regression)Experience in programming in R, Python, Scala or similar languages and maintaining code repositories in gitExperience with data visualization and presentation, turning complex analysis into insight\\n\\nThe IMDb TV team is shaping the future of digital video entertainment. Our mission is to build earth’s most customer centric ad supported premium free video service and make it trivially easy for hundreds of millions of customers to enjoy. Our team is re-inventing how to find content and building a new video destination.\\n\\nWe need to make agile decisions based on what content creates the most value for our customers and pursue the most efficient content acquisition strategies for our desired outcomes. We are seeking an innovative Data Scientist to predict and measure the benefit of different IMDb TV titles and their impact on customer engagement as well as advertiser value. This position will be responsible for designing and building the suite of models that will predict content performance as well as the interface used by our content acquisition team to assess content for use in real time deal evaluations.\\n\\nThis role requires a team member with strong quantitative modeling skills and the ability to apply statistical/machine learning methods to large amounts of customer and title level data. The candidate should have strong communication skills, be able to work closely with stakeholders and translate data-driven findings into actionable insights. The successful candidate will be a self-starter comfortable with ambiguity, with strong attention to detail and an ability to work in a fast-paced and ever-changing environment. This person will also be proficient in communicating their recommendations directly to advertising and video leadership.\\n\\nThis position will be part of the Prime Video Content Research team, which includes a diverse scientific team of computer scientists and economists as well as other data scientists who build statistical models using world-class data systems and partner directly with the business to implement the solutions. We use detailed customer behavioral data (e.g. streaming history) and detailed information about content (e.g. IMDb-sourced characteristics) to predict and understand what customers like to watch. As a Data Scientist at Amazon, you will have the opportunity to work on one of the world's largest consumer data sets and influence the long term evolution of our analytics capability.\\n\\nThis is very much Day 1 for IMDb TV. You would be joining an entrepreneurial and pioneering team working to reinvent ad supported television.\\n\\nExcellent quantitative modeling, statistical analysis skills and problem-solving skills. Sophisticated user of statistical toolsExperience collaborating with software development teams, data scientists, business intelligence or other technical rolesExcellent communication including direct correspondence with senior leadershipDemonstrable track record dealing well with ambiguity, prioritizing needs, and delivering results in an agile, dynamic environmentExperience with AWS features (S3, Redshift, Sagemaker)\\nAmazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>Associate, AI Engineer</td>\n",
       "      <td>Seattle, WA 98101</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>98101</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Innovate. Collaborate. Shine. Lighthouse – KPMG's Center of Excellence for Advanced Analytics – has both applied data science, AI, and big data architecture capabilities. Here, you'll work with a diverse team of sophisticated data and analytics professionals to explore the solutions for clients in a platform-diverse environment. This means your ability to find answers is limited only by your creativity in leveraging a vast array of techniques and tools. Be a part of a high-energy, diverse, fast-paced, and innovative culture that delivers with the agility of a tech startup and the backing of a leading global consulting firm. For you, that translates into the chance to work on a wide range of projects – covering technologies and solutions from AI to optimization – and the power to have a real impact in the business world. So, bring your creativity and pioneering spirit to KPMG Lighthouse.\\nKPMG is currently seeking an Associate to join our KPMG Lighthouse - Center of Excellence for Advanced Analytics.\\nResponsibilities:\\nWork in multi-disciplinary and cross-functional teams to translate business requirements into artificial intelligence goals and solution architecture; Rapidly iterate models and results to refine and validate approach across deployment options from KPMG-hosted, client, laptop, cloud, and container\\nWork in a fast-paced and dynamic environment with both virtual and face-to-face interactions utilizing structured approaches to solving problems, managing risks, and documenting assumptions; communicate results and educate others through insightful visualizations, reports, and presentations; Build ingestion processes to prepare, extract, and annotate a rich data variety of unstructured data sources (social media, news, internal/external documents, images, video, voice, emails, financial data, and operational data)\\nDesign, develop and maintain artificial intelligence-enabled managed services (APIs) with a team of Data Scientist, Software Engineers, and Project Managers; Architect, implement, and test data processing pipelines (e.g. Hadoop and Spark) and data mining/data science algorithms on a variety of hosted settings (Cloud, AWS, Azure, GCP, or KPMG's own clusters)\\nDevelop automated reporting for API and system health (process, memory, response time) utilizing leading processes for software development and analytics\\nTranslate advanced technical architectures into production systems and contribute to the continual maintenance and testing of processes, APIs and associated user interfaces; build continuous integration and automated deployment environments; Develop containers (Docker) to ensure that APIs and processing pipeline can be easily deployed across a variety of hardware and software architectures\\nQualifications:\\nMinimum two years of prior experience working in teams of data &amp; analytics professionals to deliver on business-driven analytics projects using big data methods on multiple programming languages and technologies; Direct experience or close working relationship with DevOps engineering; Multidisciplinary backgrounds preferred\\nBachelor's degree from an accredited college/university or Master's degree from an accredited college/university in Computer Science, Computer Engineering, or related field with good understanding of object oriented design and design patterns\\nAbility to work with local and international teams to understand available resources and constraints around data, architecture, platforms, tools, processes, and security; Provide support, and resolve problems, using excellent problem-solving skills, verbal/written communication\\nUnderstanding of cloud and distributed systems principles, including load balancing, networks, scaling, in-memory vs. disk; Experience with large-scale, big data methods, such as MapReduce, Hadoop, Spark, Hive, Impala, or Storm; Familiarity with agile software development practices, testing strategies and solid unit testing skills\\nFluency in several programming languages (Python, Scala, or Java), with the ability to pick up new languages and technologies quickly; Ability to work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Experience with cloud computing and virtualization, persistence technologies both relational and No-SQL and multi-layered distributed applications\\nAbility to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future\\nKPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package. KPMG is an affirmative action-equal opportunity employer. KPMG complies with all applicable federal, state and local laws regarding recruitment and hiring. All qualified applicants are considered for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other category protected by applicable federal, state or local laws. The attached link contains further information regarding the firm's compliance with federal, state and local recruitment and hiring laws. No phone calls or agencies please.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>Data Scientist, Credit Risk</td>\n",
       "      <td>Seattle, WA 98127</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>98127</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Possible Finance is seeking a Data Scientist to focus on credit risk to support our growth. Possible Finance is a Series A stage consumer fin-tech startup based in Seattle with a mission of improving financial wellness for underserved Americans. Our initial product is a mobile app that provides small dollar installment loans using machine learning and bank transaction data for underwriting. You can check us out here: techcrunch.com/2019/06/05/possible-finance-lands-10-5-million-to-provide-cons…\\n\\nAs a Data Scientist, you will work on interesting, high impact and intellectually stimulating credit risk projects. Key responsibilities including: Life cycle credit policy management ranging from acquisition to collections, underwriting / machine learning models development, credit risk portfolio reporting and monitoring, fraud management and prevention, new product analysis and definition, campaign management, and credit strategy testing.\\n\\nThis role requires a high level of analytical problem solving, project management, and collaboration as you work cross-functionally to answer key strategic questions and drive decision making. You’ll get to impact our business in its early days and set the direction that will allow us to grow rapidly into a household brand. This role reports directly to the Head of Risk.\\n\\nRoles &amp; Responsibilities:\\n\\nDrives improvements in underwriting performance\\n– Identifies and evaluates new data sources to improve underwriting decisioning\\n– Works holistically across the entire risk management continuum including marketing channel evaluation and preapproval criteria for existing customers\\n– Continue to test new credit strategies and underwriting models to improve underwriting decisioning.\\n\\nData Analytics\\n– Designing, developing, and implementing machine learning models / algorithms\\n– Builds underwriting models to increase loan funding rates while lowering losses\\n\\nManages credit risk reporting and portfolio monitoring\\n– Define and design KPI to track loan performance and portfolio monitoring\\n– Ensures proper management of credit risk profile of the loan portfolios\\n– Manages and optimizes collections performance\\n\\nDrives analysis and ongoing improvements to loss performance of new markets.\\n– Working with other departments (including marketing, loan operations, finance, etc) evaluates new product opportunities and forecasts likely loss performance.\\n– Evolves strategies and pricing recommendations to improve performance as the new products scale.\\n\\nWork experience and education, knowledge and skills\\n\\nFor this position we are looking for an experienced financial professional with:\\nSelf-starter with the ability to develop insightful financial models and quantitative analysis, paired with strong critical thinking and sound business judgmentAble to Manage multiple projects with strict deadline commitments2+ years of work experience in credit risk management in payments / banking industry is preferred.Excellent organizational skills with the ability to set priorities and to work simultaneously on several projects.Excellent analytical and numerate skills. Attention to detail.Experience in Python, R, SQLExperience in analyzing large scale data in both structured and unstructured</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Data Scientist I</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>M.A., M.S. in computational biology, biostatistics, computer science, data science, bioinformatics or a related field. Candidates with Ph.D. also encouraged to apply.\\n2 - 4 years of hands-on biological data science experience\\nProficiency in Python and/or R programming, with knowledge of the appropriate tools and libraries for working with biological data\\nDemonstrated rigor and reproducibility through well organized and well documented code and/or committed to a public code repository (e.g. github)\\nExperience analyzing next-generation sequencing data (e.g. transcriptomics, or immune repertoire)\\nPreference for candidates having familiarity with dimensionality reduction, regression models, machine learning and/or cloud infrastructure for scalable scientific computing\\nOutstanding organizational skills, attention to detail and effective communication are essential\\nEagerness to learn about immunology, vaccines, microbial ecology, biostatistics or whatever the science demands</td>\n",
       "      <td>None Found</td>\n",
       "      <td>M.A., M.S. in computational biology, biostatistics, computer science, data science, bioinformatics or a related field. Candidates with Ph.D. also encouraged to apply.\\n2 - 4 years of hands-on biological data science experience\\nProficiency in Python and/or R programming, with knowledge of the appropriate tools and libraries for working with biological data\\nDemonstrated rigor and reproducibility through well organized and well documented code and/or committed to a public code repository (e.g. github)\\nExperience analyzing next-generation sequencing data (e.g. transcriptomics, or immune repertoire)\\nPreference for candidates having familiarity with dimensionality reduction, regression models, machine learning and/or cloud infrastructure for scalable scientific computing\\nOutstanding organizational skills, attention to detail and effective communication are essential\\nEagerness to learn about immunology, vaccines, microbial ecology, biostatistics or whatever the science demands</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Overview\\nCures Start Here. At Fred Hutchinson Cancer Research Center, home to three Nobel laureates, interdisciplinary teams of world-renowned scientists seek new and innovative ways to prevent, diagnose and treat cancer, HIV/AIDS and other life-threatening diseases. Fred Hutch’s pioneering work in bone marrow transplantation led to the development of immunotherapy, which harnesses the power of the immune system to treat cancer. An independent, nonprofit research institute based in Seattle, Fred Hutch houses the nation’s first cancer prevention research program, as well as the clinical coordinating center of the Women’s Health Initiative and the international headquarters of the HIV Vaccine Trials Network. Careers Start Here.\\n\\nBiostatistics, Bioinformatics and Epidemiology (BBE) at Fred Hutch is seeking an experienced Data Scientist to work on multiple projects investigating the immunological correlates of vaccine protection for novel tuberculosis and HIV vaccine candidates. The immune response to a vaccine can be highly variable across individuals, particularly for new vaccines that are in active development. Understanding the factors that impact vaccine response and identifying the features of the immune response that confer protection can provide critical feedback for vaccine refinement. As part of the HIV Vaccine Trials Network supported by the NIH Division of AIDS and the Global Health Vaccine Accelerator Program, supported by the Bill and Melinda Gates Foundation we are leading major computational efforts to integrate immunological datasets generated from human vaccine trials. Analysis datasets include those generated by multicolor flow cytometry, transcriptomics/RNAseq, T cell receptor repertoire sequencing, mass spectrometry, microbiome 16S and metagenomic sequencing, and multiplexed systems serology among others.\\nResponsibilities\\nThe Data Scientist works closely with the PI, a computational biologist and biostatistician, and a growing team, to develop data pipelines, plan and conduct analyses, design and implement data visualizations, and help prepare figures for funding proposals and publication. The ideal candidate should have an appetite to understand and analyze new types of data.\\nQualifications\\nM.A., M.S. in computational biology, biostatistics, computer science, data science, bioinformatics or a related field. Candidates with Ph.D. also encouraged to apply.\\n2 - 4 years of hands-on biological data science experience\\nProficiency in Python and/or R programming, with knowledge of the appropriate tools and libraries for working with biological data\\nDemonstrated rigor and reproducibility through well organized and well documented code and/or committed to a public code repository (e.g. github)\\nExperience analyzing next-generation sequencing data (e.g. transcriptomics, or immune repertoire)\\nPreference for candidates having familiarity with dimensionality reduction, regression models, machine learning and/or cloud infrastructure for scalable scientific computing\\nOutstanding organizational skills, attention to detail and effective communication are essential\\nEagerness to learn about immunology, vaccines, microbial ecology, biostatistics or whatever the science demands\\nOur Commitment to Diversity\\nWe are committed to cultivating a workplace in which diverse perspectives and experiences are welcomed and respected. We are proud to be an Equal Opportunity and VEVRAA Employer. We do not discriminate on the basis of race, color, religion, creed, ancestry, national origin, sex, age, disability, marital or veteran status, sexual orientation, gender identity, political ideology, or membership in any other legally protected class. We are an Affirmative Action employer. We encourage individuals with diverse backgrounds to apply and desire priority referrals of protected veterans. If due to a disability you need assistance/and or a reasonable accommodation during the application or recruiting process, please send a request to our Employee Services Center at escmail@fredhutch.org or by calling 206-667-4700.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Senior Data Scientist, Consumer Analytics</td>\n",
       "      <td>Seattle, WA 98101</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>98101</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>About the team\\nZillow Group is currently seeking a Senior Data Scientist to join the Decision Science team in our Seattle office. Our team is tasked with absorbing billions of rows of data from dozens of sources, organizing them, analyzing them, and visualizing them to help inform both short- and long-term decision-making. Our structure is very flat and you will soon find yourself communicating directly with Senior Leadership. Each team member focuses on a cross-section of the consumer journey on Zillow Group platforms. We analyze how our consumers are interacting with our web and app products to ensure we are providing them with a delightful experience.\\nAbout the role\\nOnce you’re here, you’ll work to make important, strategic decisions that influence the direction of the company. More specifically, you will:\\nDive into Zillow's internal and third party data (think Hive, Presto, Python, R, Mode Analytics, Tableau) to make strategic recommendations on how to best understand and elevate our consumer experience.\\nLead analytical efforts to develop scalable and methodologically rigorous approaches to performance measurement (e.g., AB testing, incrementality testing), consumer clustering, propensity modeling, consumer journey analytics, and other applications of advanced analytics.\\nServe as a mentor to other Data Scientists on the team by leading learning academies and serving as an available resource for all things related to Data Science.\\nProvide thought leadership across a variety of technical and non-technical audiences to ensure that all levels of Zillow Group make objective decisions driven by data.\\nWork towards automating your routine work processes, which may include partnering with engineering teams to realize efficiencies and to scale your work for company-wide applications.\\nWho you are\\nYou will not shy away from complexity or uncertainty. You will develop a deep understanding of our mission, business models, and consumers. We want you to use that intuition you've developed (both in business and real life) to find opportunities for growth and to cultivate insights from our massive data sets. We expect you to have:\\nA degree in Statistics, Mathematics, Quantitative Sociology, Economics, Computer Science or related STEM discipline. Masters or PhD is highly regarded but not required.\\n6+ years of work experience involving quantitative data analysis and complex problem solving, preferably focused on consumer-facing internet products.\\nComplete command of SQL, Excel, and either Python or R, along with some experience with Tableau,Mode, or other visualization software.\\nExtensive experience directly querying multi-terabyte-sized data sets (with Hive and Presto) including click-stream data (like Google Analytics), third party data (like Facebook) and raw data ingested from non-standard platforms.\\nExperience with ETL pipelines, scheduling and productionalizing (e.g., Spark, Airflow) a plus.\\nA strong understanding of concepts, terminology, measurement issues, and experimentation related to web analytics along with a history of applying advanced analytical approaches to derive insights from data.\\nStrong written, verbal, and visual communication skills to concisely communicate in a way that provides context, offers insights, and minimizes misinterpretation.\\nThe skills to work cross-functionally and push business partners to focus on realistic goals and projects.\\nGet to know us\\nZillow Group houses the largest portfolio of real estate brands on mobile and the web. We are on a mission to rewire the real estate transaction and are building transformational tools and services that make it easier for everyone to find and get into a home they love. We are working to create an on-demand real estate transaction experience for every stage of the home lifecycle - for buyers, sellers, renters and borrowers - and we're well on our way. No matter what job you're in, you will play a critical role in making this vision a reality for millions of people.\\nAt Zillow Group, we're powered by our inclusive work culture, where everyone has the support and resources to do the best work of their careers. Our efforts to streamline the real estate transaction is supported by our passion to empower people and enrich lives around everything home, a deep-rooted culture of innovation, a fundamental commitment to Equity and Belonging, and world-class benefits. But, don't just take our word for it. Read our reviews on Glassdoor and recent recognition from multiple organizations, including: Fortune 100 Best Companies to Work For (#69), Fortune Best Workplaces for Diversity (#38), Fortune Best Workplaces for Parents (#31), Fortune Best Workplaces for Women (#20), Fatherly's Best Workplaces for New Dads (#37), JUST Capital 100 Company (#69), Bloomberg Gender Equality Index constituent.\\nZillow Group is an equal opportunity employer committed to fostering an inclusive, innovative environment with the best employees. Therefore, we provide employment opportunities without regard to age, race, color, ancestry, national origin, religion, disability, sex, gender identity or expression, sexual orientation, or any other protected status in accordance with applicable law. If there are preparations we can make to help ensure you have a comfortable and positive interview experience, please let us know.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>Data Scientist, Alexa Shopping NLU</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Bachelor or Master's degree in highly quantitative field (CS, machine learning, mathematics, statistics) or equivalent experience.Experience with R, Python, Weka, SAS, Matlab or other statistical/machine learning software.Experience applying various machine learning techniques, and understanding the key parameters that affect their performance.Experience developing experimental and analytic plans for data modeling processes, use of strong baselines, and the ability to accurately determine cause and effect relationships.Understanding of relevant statistical measures such as confidence intervals, significance of error measurements, development and evaluation data sets, etc.\\n\\nAt Alexa Shopping, we strive to enable shopping in everyday life. We allow customers to instantly order whatever they need, by simply interacting with their Smart Devices such as Amazon Show, Spot, Echo, Dot or Tap. Our Services allow you to shop, no matter where you are or what you are doing, you can go from 'I want that' to 'that's on the way' in a matter of seconds. We are seeking the industry's best to help us create new ways to interact, search and shop. Join us, and you'll be taking part in changing the future of everyday life\\n\\nWe are seeking a Data Scientist to be part of the NLU science team for Alexa Shopping. This is a strategic role to shape and deliver our technical strategy in developing and deploying NLU, Machine Learning solutions to our hardest customer facing problems. Our goal is to delight customers by providing a conversational interaction. These initiatives are at the heart of the organization and recognized as the innovations that will allow us to build a differentiated product that exceeds customer expectations. We're a high energy, fast growth business excited to have the opportunity to shape Alexa Shopping NLU is defined for years to come. If this role seems like a good fit, please reach out, we'd love to talk to you.\\n\\nThis role requires working closely with business, engineering and other scientists within Alexa Shopping and across Amazon to deliver ground breaking features. You will lead high visibility and high impact programs collaborating with various teams across Amazon. You will work with a team of Language Engineers and Scientists to launch new customer facing features and improve the current features.\\n\\n3+ years of experience with machine learning, statistical modeling, data mining, and analytics techniques.Experience in one or more natural language processing topics: tagging, syntactic parsing, word sense disambiguation, topic modeling; contextual text mining, and application of deep learning to NLP.Previous experience in a ML or data scientist role with a large technology company.Fluency in a language other than English\\nAmazon is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Chief Data Scientist</td>\n",
       "      <td>Bellevue, WA</td>\n",
       "      <td>Bellevue</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nBe an out-of-the-box thinker who is passionate about brainstorming innovative ways to use our unique data to answer business problems\\nCommunicate with internal and external clients to understand the challenges they face and convince them with data\\nExtract and understand data to form an opinion on how to best help our clients and derive relevant insights\\nDevelop visualizations to make your complex analyses accessible to a broad audience\\nPartner with a variety of Visa teams to provide comprehensive solutions\\nFind opportunities to craft products out of analyses that are suitable for multiple clients\\nContribute to the Data Platform strategies and roadmap development to meet business objectives with existing or emerging technologies. Ability to translate business concepts to technical terms. Understands and communicates company goals and objectives.\\nApply creative thinking/approach to determine technical solutions that further business goals and align with corporate technology strategies, keeping in mind performance, reliability, scalability, usability, security, flexibility, and cost.\\nEngage with Data Platform customers/partners to understand their needs and provide suggestions/guidance on what data platform techniques are appropriate to solve their problems with pros/cons articulated clearly.\\nDrive internal proof of concept initiatives. When needed, quickly design and implement a prototype of a system or component with a proper architecture, and then hand over to (may lead) a small group of devs to finish.\\nProvide mentorship and help team growth especially on technical side.</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Job Description\\n\\nYou may have noticed that payment has become a very active/hot area in the last several years. Given the strong demands and innovation, this will be a very exciting area in the next 5 to 10 years. VISA is clearly a very strong leader in the payment industry, and is in a fast pace of technology transformation. For a payment system to work well, advance technologies such as data platform, big data, data mining, machine learning, cloud, etc. are critical. In VISA, we have all of these. The Data Platform Department is in the center for many of these technologies and development.\\nThe Data Platform team is a key component of Visa's Technology organization that provides an enriched and valuable ecosystem of data platform and data services that drive innovation for our partners and clients, within Visa and globally. Data is the most valuable asset in Visa. The Data Platform Department is dedicated to develop advanced technology (e.g. Cloud, Machine Learning and Big Data), systems and services to make data secure, high quality, rich, fast, and easy to use, therefore enabling Visa the ability to leverage its data asset in an effective and timely manner to maximize technology/business development and differentiate Visa from others in the payment industry. The department maintains tens of petabytes of data supporting over 100 services for various internal lines of business and external clients.\\nPosition Summary:\\nTo ensure that Visa’s payment technology is truly available to everyone, everywhere requires the success of our key bank or merchant partners and internal business units. The data platform team supports these partners by using our extraordinarily rich data set that spans more than 3 billion cards globally and captures more than 100 billion transactions in a single year. Our focus lies on building creative solutions that have an immediate impact on the business of our highly analytical partners. We work in complementary teams comprising members from Data Science and various groups at Visa. To support our rapidly growing group we are looking for Data Scientists who are equally passionate about the opportunity to use Visa’s rich data to tackle meaningful business problems.\\nThis position reports to the Sr. Director of Architecture for Data as a Service team in Data Platform and will be based in Bellevue, WA.\\nResponsibilities\\nBe an out-of-the-box thinker who is passionate about brainstorming innovative ways to use our unique data to answer business problems\\nCommunicate with internal and external clients to understand the challenges they face and convince them with data\\nExtract and understand data to form an opinion on how to best help our clients and derive relevant insights\\nDevelop visualizations to make your complex analyses accessible to a broad audience\\nPartner with a variety of Visa teams to provide comprehensive solutions\\nFind opportunities to craft products out of analyses that are suitable for multiple clients\\nContribute to the Data Platform strategies and roadmap development to meet business objectives with existing or emerging technologies. Ability to translate business concepts to technical terms. Understands and communicates company goals and objectives.\\nApply creative thinking/approach to determine technical solutions that further business goals and align with corporate technology strategies, keeping in mind performance, reliability, scalability, usability, security, flexibility, and cost.\\nEngage with Data Platform customers/partners to understand their needs and provide suggestions/guidance on what data platform techniques are appropriate to solve their problems with pros/cons articulated clearly.\\nDrive internal proof of concept initiatives. When needed, quickly design and implement a prototype of a system or component with a proper architecture, and then hand over to (may lead) a small group of devs to finish.\\nProvide mentorship and help team growth especially on technical side.\\n\\nQualifications\\n\\nCan you take on the responsibilities described above? Then please apply! Independent of years of experience or educational background, successful candidates frequently have a mix of the following qualifications:\\nExperienced technology leader with a minimum of 15+ years of software development experience including 5+ years of data science experience.\\nBachelor’s degree in an analytical field such as statistics, operations research, economics, computer science or many others (graduate degree is a plus)\\nExperience with extracting and aggregating data from large data sets using SQL, Hive or other tools\\nCompetence in Excel, PowerPoint and Tableau\\nExperience in understanding and analyzing data using statistical software (e.g., Python, SAS, R, Stata or others)\\nPrevious exposure to financial services, credit cards or merchant analytics is a plus, but not required\\nTechnical background in data with deep understanding of issues in multiple areas such as data acquisition and processing, data management, distributed processing, and high availability is required. Experience in statistics, data mining, machine learning and operational excellence of production systems is a plus.\\nStrong at technical goal setting for a project with actionable success metrics. Good knowledge and experience on measuring a service from user experience angle.\\nStrong on driving for results and self-motivated, strong learning mindset, with good understanding of related advanced/new technology. Keep up with the technology development in the related areas in the industry, which could be leveraged to enhance current architectures and build durable new ones.\\nOutstanding verbal, written, presentation, facilitation, and interaction skills, including ability to effectively communicate architectural issues and concepts to multiple organization levels and executive management.\\nAdditional Information\\n\\nVisa will consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Data Scientist, Alexa Experience</td>\n",
       "      <td>Bellevue, WA</td>\n",
       "      <td>Bellevue</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Graduate degree (Masters or PhD) in computer science, computational linguistics, or a related field.Comprehensive knowledge of a relevant field of research, such as machine learning, statistical modeling, natural language understanding, machine translationAt least 1 year of experience with programming languages such as Java or scripting languages like PythonExperience using Unix/Linux.Dependable written and oral communication skills (English)\\n\\nThe Alexa Experience organization owns a number of programs and domains which drive high customer engagement and feature discovery, maintains customer trust, understands customers’ feedback, develops new features that provide utility value for customers with special needs, and develops locally relevant experiences.\\nOur team develop and train natural language understanding models to create new delighting Alexa experiences for customers.\\n\\nWe’re looking for a passionate Scientist to help design, develop and release to production NLU models that provide the best-possible experience for our customers. You will leverage Amazon’s heterogeneous data sources and large-scale computing resources to develop new features and predict key user behaviors, both offline and in real time.\\n\\nWhat You Will Do\\nBe the subject matter expert in NLU model authoring process, guiding multiple product teams toward delivering best customer experiences on Alexa.Develop and release to production Alexa NLU modelsContribute to the research vision of the team, develop and execute on a roadmap that addresses the technical challenges our product teams face.Raise the bar for research quality and impact. Stay up to date on research results both within and complementary to the Alexa technology space and helping your team and its partner to utilize tried patterns and state of the art results to work smarter and faster.Deliver reports and/or models to influence technical directions.Design processes and tools to simplify Alexa feature expansion for your team and partners.Perform data analysis, A/B experimentation and modeling with large data sets to develop insights that increase device usage and customer experience\\n\\nExplicit (industry or academic) experience with natural language understanding and/or dialogue management.PhD or 5+ years of relevant work experience3+ years of experience developing under Unix environmentExperience working effectively with science and data processing teamsExcellent written and oral communication skills on quantitative topicsFamiliarity with ASR concepts a plusExperience performing and interpreting A/B experiments a plusPublications in top venues such as EMNLP, ACL, NAACL, COLING a plus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Manager, Data Science</td>\n",
       "      <td>Mountlake Terrace, WA</td>\n",
       "      <td>Mountlake Terrace</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Join Our Team: Do Meaningful Work and Improve People’s Lives\\n\\nOur purpose, to improve customers’ lives by making healthcare work better, is far from ordinary. And so are our employees. Working at Premera means you have the opportunity to drive real change by transforming healthcare.\\n\\nTo better serve our customers, we’re creating a culture that promotes employee growth, collaborative innovation, and inspired leadership. We are committed to creating an environment where employees can do their best work and where best-in-class talent comes, stays, and thrives!\\nAs a Data Science Manager for our Corporate Data &amp; Analytics team , you will work on a small analytics team with a big mission. You will be drawing on your technical expertise in emerging data management technologies (Hadoop, Netezza Teradata, NoSQL, etc.) and experience building and implementing a data science strategy while providing foundational networking and securities with innovative technologies. You will define the landscape, space, and strategy for a team that is still in the build phase. The team’s approaches will set the standard for the industry and help make our customers’ lives better by improving their healthcare. The team leans toward innovation and rapid delivery of Advanced Analytics, Statistical Analysis, and game-changing Application Development. The work is key to Corporate Strategy decisions and leads the company with new, innovative approaches to make healthcare simpler for our customers.\\nWhat you’ll do:\\nSupervise, own and manage the execution and delivery of advanced predictive analytics through visualization, data modeling, forecasting, simulation and data analytics taken from complex, high-volume and high-dimensional datasets\\nDevelop and mentor the team of data scientists in the acquisition, manipulation, and presentation of data through data mining, machine learning, advanced algorithms, statistical modeling and/or mathematical methods\\nManage the ongoing development and implementation of the vision and strategy for data science-based decision making throughout the entire organization\\nBuild, lead, grow, and manage a data science team that will provide a consistent pattern of delivery of customer-centered improvements and innovation\\nDefine, prioritize, and manage data science opportunities and challenges for the company\\nAdvocate technical solutions to executive and senior level decision makers, business stakeholders, and engineering teams\\nMaintain a balance between building sound, mathematically rigorous solutions, and rapid delivery\\nWhat you’ll bring:\\nBachelor’s degree in Statistics, Operations Research, Mathematics, Computer Science, or another quantitative field\\nTen (10) years of relevant experience which includes the following:\\nPrior success as a senior level data scientist delivering solutions to challenging business problems by conducting and interpreting complex quantitative and qualitative analyses\\nExpertise in machine learning (supervised learning, unsupervised learning), statistical modeling, design of experiments and forecasting\\nExperience with common analysis tools - SQL, R, and Python\\nFull stack experience in data collection, aggregation, analysis, visualization, productionize, and monitoring of Data Science products\\nPrior leadership experience developing and implementing data science strategies\\nDemonstrable familiarity with code and programming concepts\\nExperience with natural language processing\\nBig data modeling work: Hadoop, Hive, Spark\\nData discovery: Pandas, Impala\\nHealthcare data knowledge would be a plus\\nAbility to utilize a strategic mindset to serve as the analytic thought leader that will shape the data science practice throughout the entire organization\\nSeasoned analytics expert who is passionate about using data and research to drive customer-centered improvements and innovation\\nStrong background in the usage of data science techniques, tools, and delivering solutions\\nProven experience evangelizing advanced analytics across a large organization\\nExperience delivering business value from large amounts of data, by leveraging scientific tools and quantitative techniques to drive insights and new opportunities\\n#LI-KK1\\nWhat we offer\\nMedical, vision and dental coverage\\nLife and disability insurance\\nRetirement programs (401K employer match and pension plan)\\nWellness incentives, onsite services, a discount program and more\\nTuition assistance for undergraduate and graduate degrees\\nGenerous Paid Time Off to reenergize\\nFree parking\\nEqual employment opportunity/affirmative action:\\nPremera is an equal opportunity/affirmative action employer. Premera seeks to attract and retain the most qualified individuals without regard to race, color, religion, sex, national origin, age, disability, marital status, veteran status, gender or gender identity, sexual orientation, genetic information or any other protected characteristic under applicable law.\\nIf you need an accommodation to apply online for positions at Premera, please contact Premera Human Resources via email at careers@premera.com or via phone at 425-918-4785.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>Internship Opportunities for Students: Cybersecurity</td>\n",
       "      <td>Redmond, WA</td>\n",
       "      <td>Redmond</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nCurrently pursuing a bachelor’s, master’s, or PhD degree in engineering, computer science, data science, cybersecurity or related field with at least one semester/quarter remaining after internship.\\nAbility to demonstrate knowledge of programming in C++, Java or other object-oriented computer programming languages preferred as well as some experience with a scripting language such as Python\\nAbility to demonstrate understanding of computer security related concepts such as network security, application security, or reverse engineering\\nAbility to demonstrate understanding of algorithms, data structures and other systems architecture factors that affect code security, quality, and customer experience\\nSome experience with projects or coursework related to security such as computer forensics, penetration testing, security investigations, incident response, or capture the flag events is preferred\\nDemonstrated skill in time management and completing software projects in a cooperative team environment</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nCurrently pursuing a bachelor’s, master’s, or PhD degree in engineering, computer science, data science, cybersecurity or related field with at least one semester/quarter remaining after internship.\\nAbility to demonstrate knowledge of programming in C++, Java or other object-oriented computer programming languages preferred as well as some experience with a scripting language such as Python\\nAbility to demonstrate understanding of computer security related concepts such as network security, application security, or reverse engineering\\nAbility to demonstrate understanding of algorithms, data structures and other systems architecture factors that affect code security, quality, and customer experience\\nSome experience with projects or coursework related to security such as computer forensics, penetration testing, security investigations, incident response, or capture the flag events is preferred\\nDemonstrated skill in time management and completing software projects in a cooperative team environment</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Microsoft’s Security teams are responsible for overseeing the security of Microsoft products and services that make the world a better place. At Microsoft, you will collaborate with others to solve problems and secure some of the world's most advanced services and devices.\\nDo you want to work on a meaningful and impactful project and make a difference? Are you willing to learn from others and open to new ideas? Do you want to support others to succeed and operate in a highly collaborative and global environment? If this sounds like you, Microsoft would like to invite you to come join us as you are, where you can find more than just a job. Read on to learn more about opportunities and apply online!\\n\\nApplications to this position are considered for all available Security focused roles including the ones described below, depending on education level and/or location. To be considered for an internship position, you need to be enrolled as a student majoring in an applicable field with at least one semester/quarter remaining after internship.\\nResponsibilities\\nRoles\\nSoftware Engineer (SWE)\\nSoftware Engineers are experts in building and shipping large-scale projects. They have good technical knowledge and strong design and development capabilities. Software Engineers build the products and cloud services that Microsoft customers use, as well as the internal systems that power our organization. Software Engineers have a passion for designing and building very large-scale systems and for building the best product and cloud services experiences to our customers.\\nProgram Manager (PM)\\nProgram Managers bring great teamwork, positive attitude, high-energy leadership, and engineering execution excellence to our customer-focused teams. Customer empathy and relentless drive to help customers feel more confident with our products and cloud services are key attributes for success. Program Managers strive to improve customer experience through listening to customers and landing insightful evidence with product teams that drive systemic improvements, while guiding the overall direction of a Microsoft product or cloud service.\\nData Scientist\\nData Scientists are experts at analyzing data and developing models across a breadth of technology platforms that power Microsoft’s products and cloud services. They drive end-to-end execution of the data science process, from understanding business requirements, data discovery and extraction, model development and evaluation, to production pipeline implementation. Data Scientists assist researchers in statistical debugging, core algorithm implementation and automated offline experimentation. They have a passion for data analysis, statistical modeling, time series, change point detection, data mining, data engineering, and experimentation that systematically improves Microsoft customer experience.\\nSecurity Engineer\\nRed Team, Penetration Testers, &amp; Reverse Engineers\\nSecurity Engineers are experts in testing and breaking the security of Microsoft products. They seek to discover and understand vulnerabilities and weaknesses in Microsoft products, services, systems, networks, and processes. Penetration Testers conduct simulated attacks to expose vulnerabilities in a product or service, while the Red Team conducts simulated attacks against Microsoft systems, networks, and processes to also test detection and response capabilities. Reverse Engineers study newly discovered vulnerabilities and exploits, seeking to understand their root cause, and design security enhancements to mitigate entire classes of vulnerabilities.\\nQualifications\\nCurrently pursuing a bachelor’s, master’s, or PhD degree in engineering, computer science, data science, cybersecurity or related field with at least one semester/quarter remaining after internship.\\nAbility to demonstrate knowledge of programming in C++, Java or other object-oriented computer programming languages preferred as well as some experience with a scripting language such as Python\\nAbility to demonstrate understanding of computer security related concepts such as network security, application security, or reverse engineering\\nAbility to demonstrate understanding of algorithms, data structures and other systems architecture factors that affect code security, quality, and customer experience\\nSome experience with projects or coursework related to security such as computer forensics, penetration testing, security investigations, incident response, or capture the flag events is preferred\\nDemonstrated skill in time management and completing software projects in a cooperative team environment\\n\\nMicrosoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.\\n\\nBenefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>SENIOR DATA SCIENTIST</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Notes: As a UW employee, you will enjoy generous benefits and work/life programs. For detailed information on Benefits for this position, click here.\\n\\n\\nFor more information on the eScience Institute, visit the eScience website.\\n\\n\\nAs a UW employee, you have a unique opportunity to change lives on our campuses, in our state and around the world. UW employees offer their boundless energy, creative problem solving skills and dedication to build stronger minds and a healthier world.\\n\\n\\nUW faculty and staff also enjoy outstanding benefits, professional growth opportunities and unique resources in an environment noted for diversity, intellectual excitement, artistic pursuits and natural beauty. All of which has allowed the UW to be nationally recognized as a “Great College to Work For” for five consecutive years.\\n\\n\\nThe eScience Institute at the University of Washington is seeking outstanding candidates for the position of Senior Data Scientist (Research Scientist – Senior). The ideal candidate will have expertise in one or more areas related to data science (machine learning, statistics, databases, large-scale data systems, visualization, and interfaces that facilitate large-scale data understanding), demonstrated experience in software engineering and open-source software, and demonstrated ability to use these skills to solve problems in an applied domain discipline. Aimed at top-notch candidates, this position offers the opportunity for world-class applied research – in collaboration with some of the best researchers in the world – tackling challenging data science problems in multiple domains.\\n\\n\\nThe eScience Institute’s mission is to engage researchers across disciplines in developing and applying advanced computational methods and tools to real world problems in data-driven science and research. With a newly announced sustainable core funding from the University of Washington and existing external funding from the Gordon and Betty Moore and the Alfred P. Sloan Foundations, we are significantly advancing our mission.\\n\\n\\nIn this role, the Senior Data Scientist will both plan and execute data science research, translate research results into solutions and produce practical applications that will deliver lasting impact across domains. Senior Data Scientists are expected to teach data science skills and methods through office hours, technical workshops, tutorials, and Incubator projects. Research projects will be sourced through joint collaborations with eScience faculty and other researchers, and through the independent research goals of the applicant. Working as part of an existing team, successful candidates will have ample opportunity to publish their research, pursue external funding with collaborators across disciplines, and contribute to collaborative software development, innovative technical consulting, development and delivery of training, and other activities designed to advance the research and practice of data-driven and data-intensive discovery across fields.\\n\\n\\nSuccessful candidates will have demonstrable experience in one or more applications of data science techniques and technologies – e.g. databases and data management technologies, machine learning and modern statistical methods, or data presentation and visualization.\\n\\n\\nRESPONSIBILITIES:\\n\\nContribute to significant open source software projects using appropriate technologies in large-scale data management, machine learning and statistics, interactive visualization, specialized data presentation interfaces, and/or other data science technique.\\n\\nProduce research products such as well-documented algorithms and code, software, and research publications.\\n\\nContribute to the Institute research program by seeking grants from both traditional agencies and novel channels to develop analytical and computational tools. Serve as the principle investigator (PI) or Co-PI on the projects funded by grants.\\n\\nWork to release open source software and open data, help ensure scientific reproducibility of all results, and contribute to a “culture of reproducibility” across campus.\\n\\nReview and evaluate potential projects for technical merit and feasibility.\\n\\nOrganize and conduct workshops and training events in data science techniques and technologies for diverse target audiences.\\n\\nMeet with potential collaborators to clarify goals, identify collaboration opportunities and recommend solutions.\\n\\nParticipate in Institute sponsor reporting and annual retreat activities.\\n\\nPrepare and deliver presentations on significant results, both internally and externally, representing the eScience Institute as well as specific projects.\\n\\nDevelop web materials communicating significant results, best practices and case studies with specific technologies, and documentation for significant software.\\n\\nAdvance a reputation outside of UW for excellence in data science methods and practice, contributing to the Institute’s overall portfolio of successful projects and programs.\\n\\n\\n\\nREQUIREMENTS:\\n\\nPhD or equivalent in any discipline, with a strong computational background\\n\\nA minimum of 6 years of experience in programming and software engineering and/or advanced statistical methods including experience:\\n\\nApplying one or more programming languages to construct full scientific pipelines, from data ingestion / clean-up to modeling, to visualization and analysis.\\n\\nCollaborating and coordinating work via an online platform, such as GitHub, GitLab, or BitBucket, and distributed revision control.\\n\\nSkills to communicate complex information in a clear and concise manner both verbally and in writing\\n\\nStrong capacity for teamwork, collaborative, critical thinking, and attention to detail.\\n\\n\\nEquivalent education/experience will substitute for all minimum qualifications except when there are legal requirements, such as a license/certification/registration.\\n\\n\\nDESIRED EXPERIENCE\\n\\nA successful research track record, especially through collaborations outside one’s own field, as evidenced by joint publications, joint grants, and collaborative software outputs\\n\\nLeadership in collaborative projects in open source software development\\n\\nExperience engaging with highly technical researchers across a variety of methodological fields, research domains, and computational platforms.\\n\\nExperience with seeking extramural funding to support research, education and training programs.\\n\\n\\nApplication Process:\\n\\nThe application process for UW positions may include completion of a variety of online assessments to obtain additional information that will be used in the evaluation process. These assessments may include Workforce Authorization, Cover Letter and/or others. Any assessments that you need to complete will appear on your screen as soon as you select “Apply to this position”. Once you begin an assessment, it must be completed at that time; if you do not complete the assessment you will be prompted to do so the next time you access your “My Jobs” page. If you select to take it later, it will appear on your \"My Jobs\" page to take when you are ready. Please note that your application will not be reviewed, and you will not be considered for this position until all required assessments have been completed.\\n\\nCommitted to attracting and retaining a diverse staff, the University of Washington will honor your experiences, perspectives and unique identity. Together, our community strives to create and maintain working and learning environments that are inclusive, equitable and welcoming.\\nThe University of Washington is a leader in environmental stewardship &amp; sustainability, and committed to becoming climate neutral.\\nThe University of Washington is an equal opportunity, affirmative action employer. To request disability accommodation in the application process, contact the Disability Services Office at 206-543-6450 / 206-543-6452 (tty) or dso@uw.edu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>Senior Data Scientist - AWS</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Bachelor's degree in Statistics, Applied Math, Operations Research, Economics, or a related quantitative field with 5 years of working experience as a Data ScientistProficient with data analysis and modeling software such as Spark, R etc.Proficient with using scripting language such as Python and data manipulation/analysis libraries such as Scikit-learn and Pandas for analyzing and modeling data.Experienced in using multiple data science methodologies to solve complex business problems.Experienced in handling large data sets using SQL and databases in a business environment.Excellent verbal and written communication.Strong troubleshooting and problem solving skills.Thrive in a fast-paced, innovative environment.\\n\\nDo you have broad and deep experience in both the analytical and technical aspects of cloud computing? Do you have rich experience influencing technology choices and building programs to accelerate IT adoption by providing visibility into IT costs? Do you enjoy working with customers to achieve cost efficiency through IT modernization and cloud technologies? Can you help business leaders and technologists adopt new cloud services?\\n\\nAmazon Web Services is looking for an experienced Sr Data Scientist to be a part of a team solving complex Customer cloud cost optimization problems and Customer insights (including segmentation analysis and personas building using big data, ML and potentially AI). This is a blue-sky role that gives you a chance to roll up your sleeves and dive into big data sets in order to build simulations and experimentation systems at scale, build optimization algorithms and leverage cutting-edge technologies across AWS. This is an opportunity to think big about how to optimize the world’s foremost cloud offerings and create new product opportunities. You will deliver tens of millions of dollars for Customers and Amazon annually through these analytical insights.\\n\\nYou will work closely with product and technical leaders throughout AWS and will be responsible for influencing funding decisions in areas of investment that you identify as critical future product offerings. You will identify both enablers and blockers of adoption, and build programs that accelerate adoption of both overall AWS services and our cloud cost management suite.\\n\\nThe ideal candidate will have extensive experience in Science work, business analytics and have the aptitude to incorporate new approaches and methodologies while dealing with ambiguities in sourcing processes. Excellent business and communication skills are a must to develop and define key business questions and to build data sets that answer those questions. You should have a demonstrated ability to think strategically and analytically about business, product, and technical challenges. Further, you must have the ability to build and communicate compelling value propositions, and work across the organization to achieve consensus. This role requires a strong passion for customers, a high level of comfort navigating ambiguity, and a keen sense of ownership and drive to deliver results.\\n\\nAmazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation\\n\\nMaster's degree in Statistics, Applied Math, Operations Research, Economics, or a related quantitative field with at least 2 years of working experience as a Data Scientist.Experienced in writing academic-styled papers for presenting both the methodologies used and results for data science projects.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>Data Scientist, AWS Training &amp; Certification</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Bachelor’s degree in Mathematics, Computer Science, Technology, or a similar discipline with analytical bias3+ years of relevant work experience as a data scientist, statistician, or similar position requiring analysis, statistics, machine learning, and data science.Proficient with mathematical programming libraries (e.g. R, Python)2+ years of experience wiring SQL and working within databases (e.g. Redshift or similar)Advanced proficiency with advanced data analyticsExperience with business intelligence and data visualization and reporting tools (e.g. Tableau)Experience creating white papers and documents describing model outputExperience developing and managing data science platform and toolsAbility to perform root cause analysis to uncover issues within dataAbility to distill problem definitions, models, and constraints from informal business requirements\\n\\nThe Amazon Web Services (AWS) Training and Certification organization educates customers, partners, and AWS Employees globally on AWS products, solutions, and best practices. We are seeking a talented and experienced Data Scientist to perform data analytics and create forecasting processes to influence business strategies and better understand a customer’s training &amp; certification journey.\\n\\nAs part of the AWS Training and Certification (T&amp;C) Business Intelligence and Data Analytics team you will analyze data provide insights using statistical methods and processes. We are looking for someone who is comfortable getting into data and understanding patterns and performance that can be leveraged in business strategies. The right candidate will be passionate about working with large datasets and should be someone who loves to bring data together to answer complex business questions that deepen our understanding of our business drivers. As a Data Scientist within AWS, you will have the exciting opportunity to help analyze and deliver data driven insights that will broaden AWS’s penetration in the cloud computing market.\\n\\nThe ideal candidate will have a background in analyzing and deriving insights from data by using SQL (e.g. Redshift), analytics (e.g. R, Python), statistical processes (e.g. machine learning, forecasting, and predictive analytics), and business intelligence tools (e.g. Tableau). A successful candidate should have the technical proficiency to develop code to produce processes that analyze our data and the business proficiency to summarize their findings and report to the AWS Training and Certification leadership team. This role will work closely with Business Intelligence Engineers, Business Analyst, Economists, Program Managers, and AWS T&amp;C Leadership.\\n\\nResponsibilities:\\nServe as a key member of the AWS Training &amp; Certification Business Intelligence and Data Analytics team by turning data into actionable insights and providing support for strategic initiatives.Conduct analysis of existing metrics and create new metrics that will be shared with the Global Operations Team and executive stakeholders.Recommend, develop, and manage machine learning/statistical processes and tools.Conducts data analyses with the appropriate statistical approach (regressions, linear and non-linear correlation, entropy, t-test, F-test, etc.)Identify needed data for projects and understand underlying structure (distribution, variable independence, outliers, etc.), and develop process to help improve data qualityInfluence the decisions of senior business leaders through effective verbal and written communication and logical reasoning.Able to discuss and present data science processes to business leaders and provide support to help with understanding of processes to non-tech individuals.Manage numerous requests concurrently and strategically, prioritizing when necessary.Drive and support projects that help build AWS into the most customer-centric technology platform\\n\\nMaster’s degree or PhD in Mathematics, Computer Science, Technology, or a similar discipline with analytical bias5+ years of relevant work experience as a data scientist, statistician, or similar position requiring analysis, statistics, machine learning, and data science.3+ years of experience writing SQL2+ years of experience with Tableau DesktopExpert proficiency with advanced data analyticsExperience forecasting large organizational goals and revenueExperience modeling customer journey throughout multiple systems, websites, and productsExperience developing and managing data science platform and tools within AWSExcellent communications skills including, presenting, editing, and writing as well as accuracy and attention to detail required.\\nAmazon.com is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>Principal Data Lab Architect</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Highly technical and analytical, possessing 10 or more years of Database and/or Analytics Systems development and deployment experience, IT systems and engineering experience, security and compliance experience, etc.Possess significant experience of software development and/or IT and implementation/consulting experience.Strong verbal and written communications skills are a must, as well as the ability to work effectively across internal and external organizations and virtual teams.Ability to think understand complex business requirements and render them as prototype systems with quick turnaround time.Implementation and tuning experience in the Big Data Ecosystem, (such as EMR, Hadoop, Spark, R, Presto, Hive), Database (such as Oracle, MySQL, PostgreSQL, MS SQL Server), NoSQL (such as DynamoDB, HBase, MongoDB, Cassandra, design principles) and Data Warehousing (such as Redshift, Teradata, Vertica, schema design, query tuning and optimization) and data migration and integration.Track record of implementing AWS services in a variety of business environments such as large enterprises and start-ups.Knowledge of foundation infrastructure requirements such as Networking, Storage, and Hardware Optimization.BS level technical degree required; Computer Science or Mathematics background preferred.AWS Certification, eg. AWS Solutions Architect, Developer, or SysOps Associate/Professional\\n\\nAre you a data and analytics specialist? Do you have deep expertise in AWS services for managing data at speed and scale? Do you think big about how data can change the world, and love building software? Would you like a career that gives you opportunities to help customers and partners use cloud computing services to build new solutions, faster, and at lower cost?\\n\\nAt AWS, we’re hiring highly technical cloud computing architects and engineers to collaborate with our customers on building solutions in database, data management, and analytics. AWS Data Labs are a Seattle, AWS headquarters based facility where customers come to build data and analytics platforms. You will focus on real time and batch-based data processing, business intelligence, analytics, and machine learning systems. These solutions are built alongside the customer and quickly put into production use in a matter of weeks. You'll work closely with AWS Field Teams including Solution Architects, Technical Account Managers, and AWS Service Developers to partner with customers to solve hard problems with data. Every day, you'll be working with AWS Services and Data Labs Customers to determine the optimal implementation, build it, prove it works, extract documents and CloudFormation templates to speed project delivery. If you are builder, and love data, then this could be your ideal job!\\n\\nHands on experience leading large-scale global database, data warehousing and analytics projects.\\nDemonstrated industry leadership in the fields of Database and/or Data Warehousing, Data Sciences and Big Data processing.Deep understanding of data, application, server, and network securityExperience with Statistics, Machine Learning and Predictive Modelling.Hands on experience as a database, data warehouse, big data/analytics developer or administrator, or work as a data scientist.Experience working within the software development or Internet industries is highly desired.Technical degrees in computer science, software engineering, or mathematicsWorking knowledge of modern software development practices and technologies such as agile methodologies and DevOps.\\nAmazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>Sr. Associate, AI Engineer</td>\n",
       "      <td>Seattle, WA 98101</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>98101</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Innovate. Collaborate. Shine. Lighthouse – KPMG's Center of Excellence for Advanced Analytics – has both applied data science, AI, and big data architecture capabilities. Here, you'll work with a diverse team of sophisticated data and analytics professionals to explore the solutions for clients in a platform-diverse environment. This means your ability to find answers is limited only by your creativity in leveraging a vast array of techniques and tools. Be a part of a high-energy, diverse, fast-paced, and innovative culture that delivers with the agility of a tech startup and the backing of a leading global consulting firm. For you, that translates into the chance to work on a wide range of projects – covering technologies and solutions from AI to optimization – and the power to have a real impact in the business world. So, bring your creativity and pioneering spirit to KPMG Lighthouse.\\nKPMG is currently seeking a Sr. Associate to join our KPMG Lighthouse - Center of Excellence for Advanced Analytics.\\nResponsibilities:\\nWork in multi-disciplinary and cross-functional teams to translate business requirements into artificial intelligence goals and solution architecture; Rapidly iterate models and results to refine and validate approach working across deployment options (KPMG-hosted, client, laptop, cloud, and container)\\nWork in a fast-paced and dynamic environment with both virtual and face-to-face interactions utilizing structured approaches to solving problems, managing risks, and documenting assumptions; Communicate results and educate others through insightful visualizations, reports, and presentations\\nBuild ingestion processes to prepare, extract, and annotate a rich data variety of unstructured data sources (social media, news, internal/external documents, images, video, voice, emails, financial data, and operational data)\\nDesign, develop, and maintain artificial intelligence-enabled managed services (APIs) with a team of Data Scientist, Software Engineers, and Project Managers; Architect, implement, and test data processing pipelines (e.g. Hadoop and Spark) and data mining/data science algorithms on a variety of hosted settings (Cloud (AWS, Azure, GCP) and KPMG's own clusters)\\nDevelop automated reporting for API and system health (process, memory, response time) utilizing leading processes for software development and analytics\\nTranslate advanced technical architectures into production systems and contribute to the continual maintenance and testing of processes, APIs and associated user interfaces; Build continuous integration and automated deployment environments; Develop containers (Docker) to ensure that APIs and processing pipeline can be easily deployed across a variety of hardware and software architectures\\nQualifications:\\nMinimum two years of experience leading workstreams with at least two data scientists, engineers, and other data &amp; analytics professionals, including innovation, quality management, utilizing analytics, and software development processes using big data methods on multiple programming languages and technologies; Multidisciplinary backgrounds preferred\\nMinimum of five years of direct experience or close working relationship with DevOps engineering; Solid understanding of object oriented design and design patterns; familiarity with agile software development practices, testing strategies and solid unit testing skills\\nBachelor's degree from an accredited college/university; Master's or PhD from an accredited college/university in Computer Science, Computer Engineering, or related field\\nUnderstanding of cloud and distributed systems principles (load balancing, networks, scaling, in-memory vs. disk); Experience with large-scale, big data methods (MapReduce, Hadoop, Spark, Hive, Impala, or Storm)\\nFluency in several programming languages (Python, Scala, or Java) with the ability to pick up new languages and technologies quickly and to work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Experience with cloud computing and virtualization, persistence technologies both relational and No-SQL and multi-layered distributed applications\\nAbility to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future\\nKPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package. KPMG is an affirmative action-equal opportunity employer. KPMG complies with all applicable federal, state and local laws regarding recruitment and hiring. All qualified applicants are considered for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other category protected by applicable federal, state or local laws. The attached link contains further information regarding the firm's compliance with federal, state and local recruitment and hiring laws. No phone calls or agencies please.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bellevue, WA</td>\n",
       "      <td>Bellevue</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Computational researchers with experience in genomics or other big data efforts are needed to develop and support our rare disease genomics program. Familiarity with biology, genetics, or healthcare is preferred. Applicants must be original thinkers comfortable exploring new concepts with thorough analytics. Data scientists will join the IDG team at our offices in Bellevue WA – relocation support may be discussed on an individual basis.\\n\\nWith your resume please submit a cover letter that captures how your research or training relates to healthcare genomics and your desire to partake in this project.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>Senior Data Scientist, Systems Intelligence</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>A desire to work in a collaborative, intellectually curious environment.Degree in Computer Science, Engineering, Mathematics, or a related field or 7+ years industry experienceDemonstrated strength in data modeling, ETL development, and data warehousing.Data Warehousing Experience with Oracle, Redshift, Teradata, etc.Experience with Big Data Technologies (Hadoop, Hive, Hbase, Pig, Spark, etc.)MS in Statistics, Computer Science, or MathematicsExperience in data mining, machine learning techniques and statisticsThe ability to distill problem definitions, models, constraints from informal business requirements; and to deal with ambiguity and competing objectives.Ability to translate business requirements into solutionsAbility to analyze mined data and extrapolate conclusions\\n\\nThe mission of the Systems Intelligence team is to provide situational awareness to Amazon’s leaders enabling them to make decisions that will directly impact the culture of software development. A Sr. Data Scientist is critical to the success of this program to analyze the data we collect and provide statistical correlations that will drive future business decisions. Our team must provide visibility into the metadata collected from Amazon’s internal systems, software development tools, developer output metrics, and internal surveys to highlight differences across organizations. These variances will help drive discussions and investigations into areas that present potential bottlenecks or risks to software delivery. Based on the learnings from these investigations, we will identify best practices that can be shared with all levels of the organization to drive continuous improvement. A Sr. Data Scientist will complete the feedback cycle for our team, synthesizing the data we collect, providing correlation analysis, and guiding future investigations.\\nAs a Data Scientist, your role will be to leverage the past data to make future predictions, thereby helping us mitigate the uncertainty of the future by making predictions of future performance. While business intelligence tends to be structured, data science leans more toward the unstructured. You must deal with incomplete, messy, unorganized data, not immediately usable without some degree of cleaning and prepping. You will generate predictive insights and new product innovations by applying advanced analytical tools and algorithms utilizing advanced statistical packages, SQL, Hadoop, and open source tools like Python and Perl.\\n\\nIn 2019, our team will deliver a dashboard for software development managers that provides in depth insights and business metrics about their teams, providing historical trending analysis along with comparisons against organizational averages, guiding managers toward improvement opportunities in development agility. By gathering datasets such as deployments, code submissions, code reviews, and team hierarchy, the dashboard will also provide a view for technical leaders to drive crosscutting initiatives such as SDE Ratios, remote code contributions, and migration to native AWS. Success will be measured by providing a dashboard built on Systems Intelligence (our internal data lake) that improves development agility. Examples include quantifying the efficiency gained by migrating to optimized platforms (pre-compute queries and deployment automation) along with identifying teams that could benefit from leveraging these services. Other examples include enabling teams to track increases in deployment velocity, increase in code coverage, and/or reduction in technical debt. With the cost of engineering resources constantly on the rise, leaders must seek opportunities to increase the efficiency of software development. Attempting to quantify software agility and baseline the maturity of software development teams has been a long-standing challenge because of the complexity in the development process and various forms of output. Providing visibility into the outcome of software development enables teams to identify maturity opportunities within their own processes and better understand the impact of changes.\\n\\nIndustry experience as a Data Scientist or related specialty (e.g., Software Engineer, Business Intelligence Engineer, Data Eningeer) with a track record of manipulating, processing, and extracting value from large datasets.Coding proficiency in at least one modern programming language (Python, Ruby, Java, etc)Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data setsExperience building data products incrementally and integrating and managing datasets from multiple sourcesQuery performance tuning skills using Unix profiling tools and SQLExperience leading large-scale data warehousing and analytics projects, including using AWS technologies – Redshift, S3, EC2, Data-pipeline and other big data technologiesExperience providing technical leadership and mentor other engineers for the best practices on the data engineering spaceLinux/UNIX including to process large data sets.Experience with AWS\\nAmazon.com is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>258 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Title  \\\n",
       "0    Data Engineer I                                          \n",
       "1    Senior Lead Data Scientist                               \n",
       "2    Data Scientist, Medical Imaging                          \n",
       "3    Software Engineering Manager, Backend (Data Analytics)   \n",
       "4    Data Engineer II (L5) - Business Data Technologies       \n",
       "..                                                  ...       \n",
       "253  Data Scientist, AWS Training & Certification             \n",
       "254  Principal Data Lab Architect                             \n",
       "255  Sr. Associate, AI Engineer                               \n",
       "256  Data Scientist                                           \n",
       "257  Senior Data Scientist, Systems Intelligence              \n",
       "\n",
       "              Location      City State         Zip     Country  \\\n",
       "0    Seattle, WA        Seattle   WA    None Found  None Found   \n",
       "1    Bellevue, WA       Bellevue  WA    None Found  None Found   \n",
       "2    Seattle, WA        Seattle   WA    None Found  None Found   \n",
       "3    Seattle, WA        Seattle   WA    None Found  None Found   \n",
       "4    Seattle, WA        Seattle   WA    None Found  None Found   \n",
       "..           ...            ...   ..           ...         ...   \n",
       "253  Seattle, WA        Seattle   WA    None Found  None Found   \n",
       "254  Seattle, WA        Seattle   WA    None Found  None Found   \n",
       "255  Seattle, WA 98101  Seattle   WA    98101       None Found   \n",
       "256  Bellevue, WA       Bellevue  WA    None Found  None Found   \n",
       "257  Seattle, WA        Seattle   WA    None Found  None Found   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                    Qualifications  \\\n",
       "0    None Found                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "1    BA / BS degree or equivalent practical experience\\n3 years of experience working with statistical packages (e.g. R, SAS, Stata, MATLAB, etc.)\\nExperience with articulating product questions, pulling data from datasets (SQL) and using statistics to arrive at an answer\\n                                                                                                                                                                   \n",
       "2    None Found                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "3    \\nBachelor’s degree or above in computer science or related field\\n2+ years of demonstrated ability to grow and lead a team of engineers in a fast-paced startup environment\\n5+ years hands-on experience developing robust back-end services using Agile, Scrum, Kanban or similar development/management practices\\nExperience in architecting and playing a part in the design and code review processes for consumer-facing applications   \n",
       "4    None Found                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "..          ...                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "253  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "254  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "255  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "256  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "257  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Skills  \\\n",
       "0    None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "1    None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "2    5+ years of programming experience in Python, R, JS and C/C++\\n5+ years of development in data modeling and machine learning, including practical experience of deep learning methods (CNN, RNN) and/or natural language processing\\n3+ years of experience in agile development\\n2+ year of experience with machine learning toolkits (TensorFlow, scikit-learn, Keras)\\n1+ years of experience with cloud-based storage and computing tools for machine learning\\nExperience with at least one of the public cloud providers such as GCP, AWS, Azure or IBM Cloud\\n   \n",
       "3    None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "4    None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "..          ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "253  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "254  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "255  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "256  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "257  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Responsibilities  \\\n",
       "0    None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "1    \\nConduct data analysis to make business recommendations (cost-benefit, invest-divest, forecasting, impact analysis)\\nDeliver effective presentations of findings and recommendations to multiple levels of stakeholders, creating visual displays of quantitative information\\nDevelop and automate reports, iteratively build and prototype dashboards to provide insights at scale, solving for analytical needs\\nCollaborate with cross-functional stakeholders to understand their business needs, formulate and complete end-to-end analysis that includes data gathering, analysis, ongoing scaled deliverables and presentations\\nHelp our customer to focus on key decisions to improve products and services\\n   \n",
       "2    Build and maintain large medical imaging databases\\nDevelop data cleaning and pre-processing methods to normalize data and detect outliers\\nOptimize data transfer, data flows and data operations\\nImplement and document API’s for machine learning algorithms\\nDevelop and deploy machine learning algorithms for medical imaging use cases\\nCollaborate with academic and industrial partners to collect and optimize data collection\\nAssist with product integration of machine learning solutions\\nAssist in development of machine learning web/UI applications\\n                                                                                                                                                  \n",
       "3    None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "4    None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "..          ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "253  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "254  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "255  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "256  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "257  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "\n",
       "      Education  \\\n",
       "0    None Found   \n",
       "1    None Found   \n",
       "2    None Found   \n",
       "3    None Found   \n",
       "4    None Found   \n",
       "..          ...   \n",
       "253  None Found   \n",
       "254  None Found   \n",
       "255  None Found   \n",
       "256  None Found   \n",
       "257  None Found   \n",
       "\n",
       "                                                                                                    Requirement  \\\n",
       "0    None Found                                                                                                   \n",
       "1    None Found                                                                                                   \n",
       "2    5+ years in software development, preferably in medical imaging\\n5+ years of machine learning experience\\n   \n",
       "3    None Found                                                                                                   \n",
       "4    None Found                                                                                                   \n",
       "..          ...                                                                                                   \n",
       "253  None Found                                                                                                   \n",
       "254  None Found                                                                                                   \n",
       "255  None Found                                                                                                   \n",
       "256  None Found                                                                                                   \n",
       "257  None Found                                                                                                   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              FullDescriptions  \n",
       "0    A desire to work in a collaborative, intellectually curious environment.Degree in Computer Science, Engineering, Mathematics, or a related field and 4-5+ years industry experienceOne year of experience in the following skill(s):Developing and operating large-scale data structures for business intelligence analytics using: ETL/ELT processes; OLAP technologies; data modeling; SQL;Experience with at least one relational database technology such as Redshift, Oracle, MySQL or MS SQLExperience with at least one massively parallel processing data technology such as Redshift, Teradata, Netezza, Spark, or Hadoop based big data solution\\n\\nHealth, Safety, Security, and Compliance (HS3C) is responsible for keeping our Customers and partners safe, and ensuring we maintain WW compliance. We build scalable solutions that grow with the Amazon business. HS3C-Compliance team collects petabytes of data from thousands of data sources inside and outside Amazon including the Amazon catalog system, inventory system, customer order system, and page views on the website. We provide interfaces for our internal customers to access and query the data hundreds of thousands of times per day, using Amazon Web Service’s (AWS) Redshift, Hive, and Spark.\\n\\nHS3C-Compliance is growing, and the data processing landscape is shifting. Our data is consumed by teams across HS3C including Research Scientists, Machine Learning Specialists, Business Analysts, and Data Engineers. We are seeking an outstanding Data Engineer to join the HS3C-Compliance data technologies team. The HS3C-Compliance data technologies team manages the core HS3C business data from hundreds of source systems. Amazon has culture of data-driven decision-making, and demands business intelligence that is timely, accurate, and actionable. If you join the HS3C-Compliance data technologies team, your work will have an immediate influence on day-to-day decision making at Amazon.\\n\\nAs an Amazon Data Engineer II, you will be working in one of the world's largest cloud-based data lakes. You should be skilled in the architecture of data warehouse solutions for the Enterprise using multiple platforms (EMR, RDBMS, Columnar, Cloud). You should have extensive experience in the design, creation, management, and business use of extremely large datasets. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions, and to build data sets that answer those questions. Above all you should be passionate about working with huge data sets and someone who loves to bring datasets together to answer business questions and drive change.\\nAs a Data Engineer II on the HS3C-Compliance data technologies team, you will design, develop, implement, test, document, and operate large-scale, high-volume, high-performance data structures for analytics and deep learning. Implement data ingestion routines both real time and batch using best practices in data modeling, ETL/ELT processes leveraging AWS technologies and Big data tools. Gather business and functional requirements and translate these requirements into robust, scalable, operable solutions that work well within the overall data architecture. Analyze source data systems and drive best practices in source teams. Participate in the full development life cycle, end-to-end, from design, implementation and testing, to documentation, delivery, support, and maintenance. Produce comprehensive, usable dataset documentation and metadata. Evaluate and make decisions around dataset implementations designed and proposed by peer data engineers. Evaluate and make decisions around the use of new or existing software products and tools. Mentor junior data engineers.\\n\\nIndustry experience as a Data Engineer or related specialty (e.g., Software Engineer, Business Intelligence Engineer, Data Scientist) with a track record of manipulating, processing, and extracting value from large datasets.Coding proficiency in at least one modern programming language (Python, Ruby, Java, etc)Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data setsExperience building data products incrementally and integrating and managing datasets from multiple sourcesQuery performance tuning skills using Unix profiling tools and SQLExperience leading large-scale data warehousing and analytics projects, including using AWS technologies – Redshift, S3, EC2, Data-pipeline and other big data technologiesExperience providing technical leadership and mentor other engineers for the best practices on the data engineering spaceLinux/UNIX including to process large data sets.Experience with AWS\\nOpportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age.                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "1    We are constantly looking for intelligent members to join our AI and data intelligence team to either lead or implement exciting POCs for our customers.\\n\\nResponsibilities\\nConduct data analysis to make business recommendations (cost-benefit, invest-divest, forecasting, impact analysis)\\nDeliver effective presentations of findings and recommendations to multiple levels of stakeholders, creating visual displays of quantitative information\\nDevelop and automate reports, iteratively build and prototype dashboards to provide insights at scale, solving for analytical needs\\nCollaborate with cross-functional stakeholders to understand their business needs, formulate and complete end-to-end analysis that includes data gathering, analysis, ongoing scaled deliverables and presentations\\nHelp our customer to focus on key decisions to improve products and services\\nQualifications\\nBA / BS degree or equivalent practical experience\\n3 years of experience working with statistical packages (e.g. R, SAS, Stata, MATLAB, etc.)\\nExperience with articulating product questions, pulling data from datasets (SQL) and using statistics to arrive at an answer\\nPreferred Qualifications\\nBA / BS or Master degree with emphasis on coursework of a quantitative nature (e.g., statistics, computer science, engineering, mathematics, data sciences)\\nSufficient hand-on experiences in R and Python\\nExperience in scripting with SQL, extracting large sets of data, and design of ETL flows\\nWork experience in an interdisciplinary / cross-functional field\\nExtraordinary problem-solving skills be able to lead a team to achieve business objectives\\nCapable of translating analysis results into business goals                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "2    Transforming the future of healthcare isn’t something we take lightly. It takes teams of the best and the brightest, working together to make an impact.\\nAs one of the largest healthcare technology companies in the U.S., we are a catalyst to accelerate the journey toward improved lives and healthier communities.\\nHere at Change Healthcare, we’re using our influence to drive positive changes across the industry, and we want motivated and passionate people like you to help us continue to bring new and innovative ideas to life.\\n\\n\\nIf you’re ready to embrace your passion and do what you love with a company that’s committed to supporting your future, then you belong at Change Healthcare.\\nPursue purpose. Champion innovation. Earn trust. Be agile. Include all.\\nEmpower Your Future. Make a Difference.\\nPosition Description\\nThe Data Scientist is a key contributor to the success of the Artificial Intelligence (AI) Medical Imaging team, the Imaging, Enterprise Imaging Solutions business unit, and Change Healthcare (CHC). This individual with versatile data science skills will create commercial-grade AI solutions for medical imaging products. He/she will participate to the optimization of our AI operations from data ingestion and machine learning modeling to integration into the end product.\\nThe AI Medical Imaging team is responsible for creating AI enabled solutions, maintaining a culture of innovation with a startup mindset, and providing subject matter expertise for the benefit of Change Healthcare. While the AI Medical Imaging team has stakeholders throughout the business unit, it works most closely with academic and industrial partners and those parts of the organization responsible for product conception, design and development. The Data Scientist will work with all stakeholders to fulfill Company’s business needs.\\nResponsibilities:\\nBuild and maintain large medical imaging databases\\nDevelop data cleaning and pre-processing methods to normalize data and detect outliers\\nOptimize data transfer, data flows and data operations\\nImplement and document API’s for machine learning algorithms\\nDevelop and deploy machine learning algorithms for medical imaging use cases\\nCollaborate with academic and industrial partners to collect and optimize data collection\\nAssist with product integration of machine learning solutions\\nAssist in development of machine learning web/UI applications\\nMinimum Requirement (Required):\\n5+ years in software development, preferably in medical imaging\\n5+ years of machine learning experience\\nCritical Skills (Required):\\n5+ years of programming experience in Python, R, JS and C/C++\\n5+ years of development in data modeling and machine learning, including practical experience of deep learning methods (CNN, RNN) and/or natural language processing\\n3+ years of experience in agile development\\n2+ year of experience with machine learning toolkits (TensorFlow, scikit-learn, Keras)\\n1+ years of experience with cloud-based storage and computing tools for machine learning\\nExperience with at least one of the public cloud providers such as GCP, AWS, Azure or IBM Cloud\\nAdditional Knowledge & Skills (Preferred / Not Required):\\nExperience developing commercial Web/UI applications\\nDevelopment experience with topological data analysis\\nExperience in CI/CD tools\\nExperience in automated functional/load/integration test tools\\nExperience of declarative languages such as XML, JSON, and YAML\\nExperience in ‘Linux/Unix’ OS and shell scripting\\nSoft Skills:\\nStrong written and verbal communication, and interpersonal skills\\nHighly self-motivated and directed. Results oriented\\nCross-cultural and team player who enjoys working in a fast-paced environment\\nEducation / Training:\\nPhD or MS in computer science, electrical engineering or related discipline or equivalent industry\\nexperience.\\nPhysical Requirements:\\nLimited domestic and international travel required (up to 5%).\\nJoin our team today where we are creating a better coordinated, increasingly collaborative, and more efficient healthcare system!\\nEqual Opportunity/Affirmative Action Commitment\\n\\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "3    Position Overview:\\nThe Climate Corporation is revolutionizing the agriculture industry with a platform and products that are helping the world’s farmers sustainably increase productivity with digital tools. We are looking for an individual to lead and grow a team of experienced and talented engineers in the delivery of Climate’s analytics platform to provide a solid foundation for the delivery of Climate’s next generation data science based products. This role is a unique opportunity to leverage Climate’s powerful cloud services, massive depth of data, and cutting edge scientific modeling to deliver a disruptive platform that makes a real world difference.\\nWhat You Will Do:\\nLead, grow, and inspire a talented team of engineers focused on building and managing a cutting edge analytics platform that powers the Climate platform\\nCollaborate with product, data scientist, and engineering on the next generation of the industry-leading agriculture platform\\nFearlessly drive an efficient and effective Agile software development process to manage a deep backlog and launch iteratively developed solutions\\nMotivate and provide necessary tools for engineers to work with the confidence to create simple solutions to complex problems\\nEnsure stability of Climate’s product through robust, scalable and fault tolerant software development practices\\nHelp your team meet their goals and strive to be their best\\nWork with cutting edge open source platforms such as Hadoop, YARN, Flink, Spark, etc.\\nAct as an active source of engineering talent and work with recruiting teams to build and scale the future of engineering at The Climate Corporation\\nAlign the team’s goals and objectives towards the “Bigger Picture” of the Climate Corporation\\nRepresent Climate and present at local Meetups, User Groups and Conferences\\nBasic Qualifications:\\nBachelor’s degree or above in computer science or related field\\n2+ years of demonstrated ability to grow and lead a team of engineers in a fast-paced startup environment\\n5+ years hands-on experience developing robust back-end services using Agile, Scrum, Kanban or similar development/management practices\\nExperience in architecting and playing a part in the design and code review processes for consumer-facing applications\\nPreferred Qualifications:\\nAt least 2 years experience with deployment in large cloud-based distributed environments\\nAt least 2 years experience working with distributed platforms such as YARN, Flink, Spark, etc.\\nKnowledge of functional programming (Strong Plus)\\nExperience with dynamic language (Python) (Desired)\\nExperience with compiled JVM language (Java, Scala) (Strong Plus)\\nExperience with open source schedulers (Airflow)\\nExperience with AWS or similar distributed architecture\\nWhat We Offer:\\nOur teams are composed of industry experts, top scientists, and talented engineers. The environment is extremely engaging and fast-paced, with dozens of specialties coming together to provide the best possible products and experiences for our customers.\\nWe provide competitive salaries and some of the best perks in the industry, including:\\nSuperb medical, dental, vision, life, disability benefits, and a 401k matching program\\nA stocked kitchen with a large assortment of snacks & drinks to get you through the day\\nEncouragement to get out of the office and into the field with agents and farmers to see first-hand how our products are being used\\nWe take part and offer various workshops, conferences, meet-up groups, tech-talks, and hackathons to encourage participation and growth in both community involvement and career development\\nWe also hinge our cultural DNA on these five values:\\nInspire one another\\nInnovate in all we do\\nLeave a mark on the world\\nFind the possible in the impossible\\nBe direct and transparent\\nAs part of our dedication to the diversity of our workforce, The Climate Corporation is committed to Equal Employment Opportunity without regard for race, color, national origin, ethnicity, gender, protected veteran status, disability, sexual orientation, gender identity, or religion. If you need assistance or accommodation due to a disability, you may contact us at accommodations@climate.com\\nLearn more about our team and our mission:\\nThe Climate Corporation - The Technology Behind Making A Difference\\nhttps://youtu.be/c5TgbpE9UBI or visit https://climate.com/careers\\n#LI-TF1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "4    A desire to work in a collaborative, intellectually curious environment.Degree in Computer Science, Engineering, Mathematics, or a related field and 4-5+ years industry experienceMust have one year of experience in the following skill(s):Developing and operating large-scale data structures for business intelligence analytics using: ETL/ELT processes; OLAP technologies; data modeling; SQL;Experience with at least one relational database technology such as Redshift, Oracle, MySQL or MS SQLExperience with at least one massively parallel processing data technology such as Redshift, Teradata, Netezza, Spark or Hadoop based big data solution\\n\\nAmazon’s eCommerce Foundation (eCF) organization is responsible for the core components that drive the Amazon website and customer experience. Serving millions of customer page views and orders per day, eCF builds for scale.\\nAs an organization within eCF, the Business Data Technologies (BDT) group is no exception. We collect petabytes of data from thousands of data sources inside and outside Amazon including the Amazon catalog system, inventory system, customer order system, page views on the website and Alexa systems. We also support Amazon subsidiaries such as IMDB and Audible. We provide interfaces for our internal customers to access and query the data hundreds of thousands of times per day, using Amazon Web Service’s (AWS) Redshift, Hive, and Spark. We build scalable solutions that grow with the Amazon business.\\n\\nBDT is growing, and the data processing landscape is shifting. Our data is consumed by thousands of teams across Amazon including Research Scientists, Machine Learning Specialists, Business Analysts and Data Engineers. Amazon.com is seeking an outstanding Data Engineer to join the BDT Content team. The BDT Content team manages the core Amazon business data from hundreds of source systems. Amazon.com has culture of data-driven decision-making, and demands business intelligence that is timely, accurate, and actionable. If you join the Amazon.com BDT Content team, your work will have an immediate influence on day-to-day decision making at Amazon.com.\\n\\nAs an Amazon.com Data Engineer II you will be working in one of the world's largest cloud-based data lakes. You should be skilled in the architecture of data warehouse solutions for the Enterprise using multiple platforms (EMR, RDBMS, Columnar, Cloud). You should have extensive experience in the design, creation, management, and business use of extremely large datasets. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions, and to build data sets that answer those questions. Above all you should be passionate about working with huge data sets and someone who loves to bring datasets together to answer business questions and drive change.\\n\\nAs a Data Engineer II on Amazon.com’s Business Data Technologies team, design, develop, implement, test, and operate large-scale, high-volume, high-performance data structures for analytics and deep learning. Implement data ingestion routines both real time and batch using best practices in data modeling, ETL/ELT processes leveraging AWS technologies and Big data tools. Gather business and functional requirements and translate these requirements into robust, scalable, operable solutions that work well within the overall data architecture. Analyze source data systems and drive best practices in source teams. Participate in the full development life cycle, end-to-end, from design, implementation and testing, to documentation, delivery, support, and maintenance. Produce comprehensive, usable dataset documentation and metadata. Evaluate and make decisions around dataset implementations designed and proposed by peer data engineers. Evaluate and make decisions around the use of new or existing software products and tools. Mentor junior data engineers.\\n\\nIndustry experience as a Data Engineer or related specialty (e.g., Software Engineer, Business Intelligence Engineer, Data Scientist) with a track record of manipulating, processing, and extracting value from large datasets.Coding proficiency in at least one modern programming language (Python, Ruby, Java, etc)Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data setsExperience building data products incrementally and integrating and managing datasets from multiple sourcesQuery performance tuning skills using Unix profiling tools and SQLExperience leading large-scale data warehousing and analytics projects, including using AWS technologies – Redshift, S3, EC2, Data-pipeline and other big data technologiesExperience providing technical leadership and mentor other engineers for the best practices on the data engineering spaceLinux/UNIX including to process large data sets.Experience with AWS\\nAmazon is an equal opportunities employer. We believe passionately that employing a diverse workforce is central to our success and we make recruiting decisions based on your experience and skills. We welcome applications from all members of society irrespective of age, gender, disability, sexual orientation, race, religion or belief.  \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ...  \n",
       "253  Bachelor’s degree in Mathematics, Computer Science, Technology, or a similar discipline with analytical bias3+ years of relevant work experience as a data scientist, statistician, or similar position requiring analysis, statistics, machine learning, and data science.Proficient with mathematical programming libraries (e.g. R, Python)2+ years of experience wiring SQL and working within databases (e.g. Redshift or similar)Advanced proficiency with advanced data analyticsExperience with business intelligence and data visualization and reporting tools (e.g. Tableau)Experience creating white papers and documents describing model outputExperience developing and managing data science platform and toolsAbility to perform root cause analysis to uncover issues within dataAbility to distill problem definitions, models, and constraints from informal business requirements\\n\\nThe Amazon Web Services (AWS) Training and Certification organization educates customers, partners, and AWS Employees globally on AWS products, solutions, and best practices. We are seeking a talented and experienced Data Scientist to perform data analytics and create forecasting processes to influence business strategies and better understand a customer’s training & certification journey.\\n\\nAs part of the AWS Training and Certification (T&C) Business Intelligence and Data Analytics team you will analyze data provide insights using statistical methods and processes. We are looking for someone who is comfortable getting into data and understanding patterns and performance that can be leveraged in business strategies. The right candidate will be passionate about working with large datasets and should be someone who loves to bring data together to answer complex business questions that deepen our understanding of our business drivers. As a Data Scientist within AWS, you will have the exciting opportunity to help analyze and deliver data driven insights that will broaden AWS’s penetration in the cloud computing market.\\n\\nThe ideal candidate will have a background in analyzing and deriving insights from data by using SQL (e.g. Redshift), analytics (e.g. R, Python), statistical processes (e.g. machine learning, forecasting, and predictive analytics), and business intelligence tools (e.g. Tableau). A successful candidate should have the technical proficiency to develop code to produce processes that analyze our data and the business proficiency to summarize their findings and report to the AWS Training and Certification leadership team. This role will work closely with Business Intelligence Engineers, Business Analyst, Economists, Program Managers, and AWS T&C Leadership.\\n\\nResponsibilities:\\nServe as a key member of the AWS Training & Certification Business Intelligence and Data Analytics team by turning data into actionable insights and providing support for strategic initiatives.Conduct analysis of existing metrics and create new metrics that will be shared with the Global Operations Team and executive stakeholders.Recommend, develop, and manage machine learning/statistical processes and tools.Conducts data analyses with the appropriate statistical approach (regressions, linear and non-linear correlation, entropy, t-test, F-test, etc.)Identify needed data for projects and understand underlying structure (distribution, variable independence, outliers, etc.), and develop process to help improve data qualityInfluence the decisions of senior business leaders through effective verbal and written communication and logical reasoning.Able to discuss and present data science processes to business leaders and provide support to help with understanding of processes to non-tech individuals.Manage numerous requests concurrently and strategically, prioritizing when necessary.Drive and support projects that help build AWS into the most customer-centric technology platform\\n\\nMaster’s degree or PhD in Mathematics, Computer Science, Technology, or a similar discipline with analytical bias5+ years of relevant work experience as a data scientist, statistician, or similar position requiring analysis, statistics, machine learning, and data science.3+ years of experience writing SQL2+ years of experience with Tableau DesktopExpert proficiency with advanced data analyticsExperience forecasting large organizational goals and revenueExperience modeling customer journey throughout multiple systems, websites, and productsExperience developing and managing data science platform and tools within AWSExcellent communications skills including, presenting, editing, and writing as well as accuracy and attention to detail required.\\nAmazon.com is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "254  Highly technical and analytical, possessing 10 or more years of Database and/or Analytics Systems development and deployment experience, IT systems and engineering experience, security and compliance experience, etc.Possess significant experience of software development and/or IT and implementation/consulting experience.Strong verbal and written communications skills are a must, as well as the ability to work effectively across internal and external organizations and virtual teams.Ability to think understand complex business requirements and render them as prototype systems with quick turnaround time.Implementation and tuning experience in the Big Data Ecosystem, (such as EMR, Hadoop, Spark, R, Presto, Hive), Database (such as Oracle, MySQL, PostgreSQL, MS SQL Server), NoSQL (such as DynamoDB, HBase, MongoDB, Cassandra, design principles) and Data Warehousing (such as Redshift, Teradata, Vertica, schema design, query tuning and optimization) and data migration and integration.Track record of implementing AWS services in a variety of business environments such as large enterprises and start-ups.Knowledge of foundation infrastructure requirements such as Networking, Storage, and Hardware Optimization.BS level technical degree required; Computer Science or Mathematics background preferred.AWS Certification, eg. AWS Solutions Architect, Developer, or SysOps Associate/Professional\\n\\nAre you a data and analytics specialist? Do you have deep expertise in AWS services for managing data at speed and scale? Do you think big about how data can change the world, and love building software? Would you like a career that gives you opportunities to help customers and partners use cloud computing services to build new solutions, faster, and at lower cost?\\n\\nAt AWS, we’re hiring highly technical cloud computing architects and engineers to collaborate with our customers on building solutions in database, data management, and analytics. AWS Data Labs are a Seattle, AWS headquarters based facility where customers come to build data and analytics platforms. You will focus on real time and batch-based data processing, business intelligence, analytics, and machine learning systems. These solutions are built alongside the customer and quickly put into production use in a matter of weeks. You'll work closely with AWS Field Teams including Solution Architects, Technical Account Managers, and AWS Service Developers to partner with customers to solve hard problems with data. Every day, you'll be working with AWS Services and Data Labs Customers to determine the optimal implementation, build it, prove it works, extract documents and CloudFormation templates to speed project delivery. If you are builder, and love data, then this could be your ideal job!\\n\\nHands on experience leading large-scale global database, data warehousing and analytics projects.\\nDemonstrated industry leadership in the fields of Database and/or Data Warehousing, Data Sciences and Big Data processing.Deep understanding of data, application, server, and network securityExperience with Statistics, Machine Learning and Predictive Modelling.Hands on experience as a database, data warehouse, big data/analytics developer or administrator, or work as a data scientist.Experience working within the software development or Internet industries is highly desired.Technical degrees in computer science, software engineering, or mathematicsWorking knowledge of modern software development practices and technologies such as agile methodologies and DevOps.\\nAmazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "255  Innovate. Collaborate. Shine. Lighthouse – KPMG's Center of Excellence for Advanced Analytics – has both applied data science, AI, and big data architecture capabilities. Here, you'll work with a diverse team of sophisticated data and analytics professionals to explore the solutions for clients in a platform-diverse environment. This means your ability to find answers is limited only by your creativity in leveraging a vast array of techniques and tools. Be a part of a high-energy, diverse, fast-paced, and innovative culture that delivers with the agility of a tech startup and the backing of a leading global consulting firm. For you, that translates into the chance to work on a wide range of projects – covering technologies and solutions from AI to optimization – and the power to have a real impact in the business world. So, bring your creativity and pioneering spirit to KPMG Lighthouse.\\nKPMG is currently seeking a Sr. Associate to join our KPMG Lighthouse - Center of Excellence for Advanced Analytics.\\nResponsibilities:\\nWork in multi-disciplinary and cross-functional teams to translate business requirements into artificial intelligence goals and solution architecture; Rapidly iterate models and results to refine and validate approach working across deployment options (KPMG-hosted, client, laptop, cloud, and container)\\nWork in a fast-paced and dynamic environment with both virtual and face-to-face interactions utilizing structured approaches to solving problems, managing risks, and documenting assumptions; Communicate results and educate others through insightful visualizations, reports, and presentations\\nBuild ingestion processes to prepare, extract, and annotate a rich data variety of unstructured data sources (social media, news, internal/external documents, images, video, voice, emails, financial data, and operational data)\\nDesign, develop, and maintain artificial intelligence-enabled managed services (APIs) with a team of Data Scientist, Software Engineers, and Project Managers; Architect, implement, and test data processing pipelines (e.g. Hadoop and Spark) and data mining/data science algorithms on a variety of hosted settings (Cloud (AWS, Azure, GCP) and KPMG's own clusters)\\nDevelop automated reporting for API and system health (process, memory, response time) utilizing leading processes for software development and analytics\\nTranslate advanced technical architectures into production systems and contribute to the continual maintenance and testing of processes, APIs and associated user interfaces; Build continuous integration and automated deployment environments; Develop containers (Docker) to ensure that APIs and processing pipeline can be easily deployed across a variety of hardware and software architectures\\nQualifications:\\nMinimum two years of experience leading workstreams with at least two data scientists, engineers, and other data & analytics professionals, including innovation, quality management, utilizing analytics, and software development processes using big data methods on multiple programming languages and technologies; Multidisciplinary backgrounds preferred\\nMinimum of five years of direct experience or close working relationship with DevOps engineering; Solid understanding of object oriented design and design patterns; familiarity with agile software development practices, testing strategies and solid unit testing skills\\nBachelor's degree from an accredited college/university; Master's or PhD from an accredited college/university in Computer Science, Computer Engineering, or related field\\nUnderstanding of cloud and distributed systems principles (load balancing, networks, scaling, in-memory vs. disk); Experience with large-scale, big data methods (MapReduce, Hadoop, Spark, Hive, Impala, or Storm)\\nFluency in several programming languages (Python, Scala, or Java) with the ability to pick up new languages and technologies quickly and to work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Experience with cloud computing and virtualization, persistence technologies both relational and No-SQL and multi-layered distributed applications\\nAbility to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future\\nKPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package. KPMG is an affirmative action-equal opportunity employer. KPMG complies with all applicable federal, state and local laws regarding recruitment and hiring. All qualified applicants are considered for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other category protected by applicable federal, state or local laws. The attached link contains further information regarding the firm's compliance with federal, state and local recruitment and hiring laws. No phone calls or agencies please.                                                                                                                                                                           \n",
       "256  Computational researchers with experience in genomics or other big data efforts are needed to develop and support our rare disease genomics program. Familiarity with biology, genetics, or healthcare is preferred. Applicants must be original thinkers comfortable exploring new concepts with thorough analytics. Data scientists will join the IDG team at our offices in Bellevue WA – relocation support may be discussed on an individual basis.\\n\\nWith your resume please submit a cover letter that captures how your research or training relates to healthcare genomics and your desire to partake in this project.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "257  A desire to work in a collaborative, intellectually curious environment.Degree in Computer Science, Engineering, Mathematics, or a related field or 7+ years industry experienceDemonstrated strength in data modeling, ETL development, and data warehousing.Data Warehousing Experience with Oracle, Redshift, Teradata, etc.Experience with Big Data Technologies (Hadoop, Hive, Hbase, Pig, Spark, etc.)MS in Statistics, Computer Science, or MathematicsExperience in data mining, machine learning techniques and statisticsThe ability to distill problem definitions, models, constraints from informal business requirements; and to deal with ambiguity and competing objectives.Ability to translate business requirements into solutionsAbility to analyze mined data and extrapolate conclusions\\n\\nThe mission of the Systems Intelligence team is to provide situational awareness to Amazon’s leaders enabling them to make decisions that will directly impact the culture of software development. A Sr. Data Scientist is critical to the success of this program to analyze the data we collect and provide statistical correlations that will drive future business decisions. Our team must provide visibility into the metadata collected from Amazon’s internal systems, software development tools, developer output metrics, and internal surveys to highlight differences across organizations. These variances will help drive discussions and investigations into areas that present potential bottlenecks or risks to software delivery. Based on the learnings from these investigations, we will identify best practices that can be shared with all levels of the organization to drive continuous improvement. A Sr. Data Scientist will complete the feedback cycle for our team, synthesizing the data we collect, providing correlation analysis, and guiding future investigations.\\nAs a Data Scientist, your role will be to leverage the past data to make future predictions, thereby helping us mitigate the uncertainty of the future by making predictions of future performance. While business intelligence tends to be structured, data science leans more toward the unstructured. You must deal with incomplete, messy, unorganized data, not immediately usable without some degree of cleaning and prepping. You will generate predictive insights and new product innovations by applying advanced analytical tools and algorithms utilizing advanced statistical packages, SQL, Hadoop, and open source tools like Python and Perl.\\n\\nIn 2019, our team will deliver a dashboard for software development managers that provides in depth insights and business metrics about their teams, providing historical trending analysis along with comparisons against organizational averages, guiding managers toward improvement opportunities in development agility. By gathering datasets such as deployments, code submissions, code reviews, and team hierarchy, the dashboard will also provide a view for technical leaders to drive crosscutting initiatives such as SDE Ratios, remote code contributions, and migration to native AWS. Success will be measured by providing a dashboard built on Systems Intelligence (our internal data lake) that improves development agility. Examples include quantifying the efficiency gained by migrating to optimized platforms (pre-compute queries and deployment automation) along with identifying teams that could benefit from leveraging these services. Other examples include enabling teams to track increases in deployment velocity, increase in code coverage, and/or reduction in technical debt. With the cost of engineering resources constantly on the rise, leaders must seek opportunities to increase the efficiency of software development. Attempting to quantify software agility and baseline the maturity of software development teams has been a long-standing challenge because of the complexity in the development process and various forms of output. Providing visibility into the outcome of software development enables teams to identify maturity opportunities within their own processes and better understand the impact of changes.\\n\\nIndustry experience as a Data Scientist or related specialty (e.g., Software Engineer, Business Intelligence Engineer, Data Eningeer) with a track record of manipulating, processing, and extracting value from large datasets.Coding proficiency in at least one modern programming language (Python, Ruby, Java, etc)Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data setsExperience building data products incrementally and integrating and managing datasets from multiple sourcesQuery performance tuning skills using Unix profiling tools and SQLExperience leading large-scale data warehousing and analytics projects, including using AWS technologies – Redshift, S3, EC2, Data-pipeline and other big data technologiesExperience providing technical leadership and mentor other engineers for the best practices on the data engineering spaceLinux/UNIX including to process large data sets.Experience with AWS\\nAmazon.com is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation              \n",
       "\n",
       "[258 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Descriptions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Descriptions_df.to_csv('Descriptions_df_DataScientist_Bellvue.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
