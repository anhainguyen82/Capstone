{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "import pandas as pd\n",
    "import requests\n",
    "from requests import get\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pulling all links off of the search pages (up to 3000) and putting them in a dataframe to scrape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_template=\"http://www.indeed.com/jobs?q=%22Data+Engineer%22&l=Atlanta%2C+GA&start={}\"\n",
    "max_results=250\n",
    "Linkdf=[]\n",
    "\n",
    "for start in range(0, max_results, 7):\n",
    "    url=url_template.format(start)\n",
    "    html=requests.get(url)\n",
    "    soup=BeautifulSoup(html.content,'html.parser', from_encoding=\"utf-8\")\n",
    "    \n",
    "    #for each in soup.find_all(a_=\"href\"):\n",
    "    page_links=soup.find_all('a',{'href':re.compile(\"/rc/\")})\n",
    "    for items in page_links:\n",
    "        Linkdf.append(items['href'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "338"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity Check\n",
    "len(Linkdf)\n",
    "#print(Linkdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "338"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This code allows the code to display the full website instead of truncating\n",
    "pd.set_option('display.max_colwidth',-1)\n",
    "\n",
    "#Moving it to a data frame\n",
    "data = {'links':Linkdf}\n",
    "df = pd.DataFrame(data, columns=['links'])\n",
    "\n",
    "#append indeed.com to the front of each\n",
    "df['Web'] = 'https://www.indeed.com'\n",
    "df['URL'] = df.Web.str.cat(df.links)\n",
    "\n",
    "#pull out just a list of the websites.\n",
    "websites=list(df['URL'])\n",
    "\n",
    "#Sanity Check\n",
    "#print(websites)\n",
    "len(websites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "websites1=set(websites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(websites1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looping through websites...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Title=[]\n",
    "Descriptions=[]\n",
    "Location=[]\n",
    "FullDescriptions=[]\n",
    "\n",
    "for url in websites1:\n",
    "    response=get(url)\n",
    "    soup=BeautifulSoup(response.text,'html.parser')\n",
    "    \n",
    "    description_containers= soup.find(class_='jobsearch-jobDescriptionText')\n",
    "    title_containers=soup.find('h3')\n",
    "    try:\n",
    "        location_containers=soup.find('',{'class':'jobsearch-CompanyInfoWithoutHeaderImage'}).find_all('div')[-1]\n",
    "    except:\n",
    "        location_containers='None Found'\n",
    "    \n",
    "    job_descriptions=str(description_containers)\n",
    "    job_title=str(title_containers.text)\n",
    "    try:\n",
    "        locations=str(location_containers.text)\n",
    "    except AttributeError:\n",
    "        locations = 'None Found'\n",
    "    try:\n",
    "        full_descriptions = str(description_containers.text)\n",
    "    except AttributeError:\n",
    "        full_descriptions= 'None Found'\n",
    "    \n",
    "    Descriptions.append(job_descriptions)\n",
    "    Title.append(job_title)\n",
    "    Location.append(locations)\n",
    "    FullDescriptions.append(full_descriptions)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting what we want from the Descriptions Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'Location' left in for sanity check. Should be removed once code is confirmed to work\n",
    "Descriptions_df = pd.DataFrame(columns = ['Title', 'Location','City', 'State', 'Zip', 'Country', 'Qualifications', 'Skills', 'Responsibilities', 'Education', 'Requirement', 'FullDescriptions'])\n",
    "Country = ['US', 'USA', 'United States', 'United States of Americal']\n",
    "States = ['AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', 'IA',\n",
    "          'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND',\n",
    "          'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY']\n",
    "\n",
    "for index, element in enumerate(Descriptions):\n",
    "    soup=BeautifulSoup(element,'lxml')\n",
    "    for values in list(Descriptions_df):\n",
    "        temp_tag = soup.find('b', text=re.compile(values))\n",
    "        try:\n",
    "            ul_tag = temp_tag.find_next('ul')\n",
    "            Descriptions_df.at[index,values] = ul_tag.text\n",
    "        except AttributeError:\n",
    "            Descriptions_df.at[index,values]=\"None Found\"\n",
    "        Descriptions_df.at[index,\"Title\"]=Title[index]\n",
    "        Descriptions_df.at[index,\"Location\"]=Location[index]\n",
    "        Descriptions_df.at[index,\"FullDescriptions\"]=FullDescriptions[index]\n",
    "        words = '|'.join(Country)\n",
    "        temp = re.findall(words, Location[index])\n",
    "        if len(temp) != 0:\n",
    "            Descriptions_df.at[index,\"Country\"] = temp[0]\n",
    "        words = '|'.join(States)\n",
    "        temp = re.findall(words, Location[index])\n",
    "        if len(temp) != 0:\n",
    "            Descriptions_df.at[index,\"State\"] = temp[0]\n",
    "        temp = re.findall(r'\\d+', Location[index])\n",
    "        if len(temp) != 0:\n",
    "            Descriptions_df.at[index,\"Zip\"] = temp[0]  \n",
    "            \n",
    "        temp = re.findall(r'[\\w w]+,', Location[index])\n",
    "        if len(temp) != 0:\n",
    "            Descriptions_df.at[index,\"City\"] = re.sub(',', '', temp[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Country</th>\n",
       "      <th>Qualifications</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Responsibilities</th>\n",
       "      <th>Education</th>\n",
       "      <th>Requirement</th>\n",
       "      <th>FullDescriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cloud Data Engineer, Google Professional Services</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nAct as a trusted technical advisor to customers and solve complex Big Data challenges.\\nCreate and deliver best practices recommendations, tutorials, blog articles, sample code, and technical presentations adapting to different levels of key business and technical stakeholders.\\nTravel up to 30% of the time.\\nCommunicate effectively via video conferencing for meetings, technical reviews and onsite delivery activities.</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Note: By applying to this position your application is automatically submitted to the following locations: Chicago, IL, USA; Atlanta, GA, USA\\nMinimum qualifications:\\n\\nBA/BS degree in Computer Science, Mathematics or related technical field, or equivalent practical experience.\\nExperience with data processing software (such as Hadoop, Spark, Pig, Hive) and with data processing algorithms (MapReduce, Flume).\\nExperience in writing software in one or more languages such as Java, C++, Python, Go and/or JavaScript.\\nExperience managing internal or client-facing projects to completion; experience troubleshooting clients' technical issues; experience working with engineering teams, sales, services, and customers.\\n\\nPreferred qualifications:\\nExperience working data warehouses, including data warehouse technical architectures, infrastructure components, ETL/ELT and reporting/analytic tools and environments.\\nExperience in technical consulting.\\nExperience working with big data, information retrieval, data mining or machine learning as well as experience in building multi-tier high availability applications with modern web technologies (such as NoSQL, MongoDB, SparkML, Tensorflow).\\nExperience architecting, developing software, or internet scale production-grade Big Data solutions in virtualized environments.\\nAbout the job\\nAs a Cloud Data Engineer, you'll guide customers on how to ingest, store, process, analyze and explore/visualize data on the Google Cloud Platform. You will work on data migrations and transformational projects, and with customers to design large-scale data processing systems, develop data pipelines optimized for scaling, and troubleshoot potential platform challenges.\\nIn this role you are the Google Engineer working with Google's most strategic Cloud customers. Together with the team you will support customer implementation of Google Cloud products through: architecture guidance, best practices, data migration, capacity planning, implementation, troubleshooting, monitoring and much more.\\nThe Google Cloud Platform team helps customers transform and evolve their business through the use of Google’s global network, web-scale data centers and software infrastructure. As part of an entrepreneurial team in this rapidly growing business, you will help shape the future of businesses of all sizes use technology to connect with customers, employees and partners.\\nResponsibilities\\nAct as a trusted technical advisor to customers and solve complex Big Data challenges.\\nCreate and deliver best practices recommendations, tutorials, blog articles, sample code, and technical presentations adapting to different levels of key business and technical stakeholders.\\nTravel up to 30% of the time.\\nCommunicate effectively via video conferencing for meetings, technical reviews and onsite delivery activities.\\nAt Google, we don’t just accept difference—we celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sr. Data Engineer</td>\n",
       "      <td>Atlanta, GA 30328</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>30328</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>We are looking for a Data Engineer for the Enterprise Data Organization to build and manage data pipeline (Data ingest, data transformation, data distribution, quality rules, data storage etc.) for Azure cloud based data platform. The candidate will require to possess strong technical, analytical, programming and critical thinking skills. Ideal candidate will have familiarity with data transformation, data modeling, Master data management, and Meta data management.\\n\\nKEY RESPONSIBILITIES:\\n\\nDesign, develop and maintain reliable automated data solutions based on the identification, collection and evaluation of business requirements. Including but not limited to data models, database objects, stored procedures and views.\\nDeveloping new and enhancing existing data processing (Data Ingest, Data Transformation, Data Store, Data Management, Data Quality ) components\\nEngage with IT teams such as DBAs, Security, Storage and Networking when their involvement is required to meet the project needs.\\nSupport and troubleshoot the data environment (including periodically on call)\\nDocument technical artifacts for developed solutions\\nMaintains professional and technical knowledge by attending educational workshops; reviewing professional publications; establishing personal networks; benchmarking state-of-the-art practices; participating in professional societies.\\nEDUCATION QUALIFICATIONS:\\n\\nBS in either Information Systems, Finance/Mathematics, or Computer Science or similar field\\nEXPERIENCE QUALIFICATION:\\n\\n10+ Years\\nREQUIRED KNOWLEDGE, SKILLS or ABILITIES:\\n\\nGood interpersonal skills; comfort and competence in dealing with different teams within the organization. Requires an ability to interface with multiple constituent groups and build sustainable relationships.\\nStrong and effective communication skills (verbal and written).\\nStrong analytical, problem solving skills.\\nExperience of working in a matrix organization, self-driven. A go getter and a problem solver.\\nAbility to prioritize, work to deadlines, work under pressure. Results oriented, flexible, adaptable.\\nWork well independently, and be a team player.\\nVersatile, creative temperament, ability to think out-of-the box while defining sound and practical solutions. Ability to master new skills.\\nProactive approach to problem solving with effective influencing skills.\\nTECHNICAL SKILLS:\\n\\nFamiliar with Agile practices and methodologies\\n5+ years professional data engineering experience focused on batch and real time data pipelines using Spark, PySpark, Python, SQL, Java\\n8+ Years of hands-on design and development experience in data space : data processing / data transformation using ETL tools, data warehouse (data modeling, programming), RDBMS\\nExposure in Microsoft technologies like SSIS, SQL Server, SSRS\\nExperience with a DevOps model utilizing a CI/CD tool\\nPREFERRED KNOWLEDGE, SKILLS, OR ABILITIES:\\nHands-on Talend work experience (anyone with this skill will have an advantage over other candidates)\\nUnderstanding of data science and visualization technologies (Hadoop, Spark, Databricks)\\nExperience working on a cloud environment, preferably, Microsoft Azure\\nCloud Data Warehouse solutions (Snowflake, Azure DW)\\nNoSQL databases and modeling (Cassandra, HBase, MongoDB)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AWS Data Engineer</td>\n",
       "      <td>Atlanta, GA 30303</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>30303</td>\n",
       "      <td>None Found</td>\n",
       "      <td>At least 5 years of Consulting or client service delivery experience on Amazon AWS (AWS)At least 5 years of experience in developing data ingestion, data processing and analytical pipelines for big data, relational databases, NoSQL and data warehouse solutionsExtensive experience providing practical direction within the AWS Native and HadoopExperience with private and public cloud architectures, pros/cons, and migration considerations.Minimum of 5 years of hands-on experience in AWS and Big Data technologies such as Java, Node.js, C##, Python, SQL, EC2, S3, Lambda, Spark/SparkSQL, Hive/MR, Pig, Oozie and streaming technologies such as Kafka, Kinesis, NiFI etc.Extensive hands-on experience implementing data migration and data processing using AWS services: VPC/SG, EC2, S3, AutoScaling, CloudFormation, LakeFormation, DMS, Kinesis, Kafka, Nifi, CDC processing Redshift, Snowflake, RDS, Aurora, Neptune, DynamoDB, Hive, NoSQL, Cloudtrail, CloudWatch, Docker, Lambda, Spark,Glue, Sage Maker, AI/ML, API GW, etc.5+ years of hands on experience in programming languages such as Java, c#, node.js, python, pyspark, spark, SQL, Unix shell/Perl scripting etc.Minimum of 5 years of RDBMS experienceExperience in using Hadoop File Formats and compression techniquesExperience working with DevOps tools such as GitLabs, Jenkins, CodeBuild, CoePipeline CodeDeploy, etc.Bachelors or higher degree in Computer Science or a related discipline.</td>\n",
       "      <td>DevOps on an AWS platform. Multi-cloud experience a plus.Experience developing and deploying ETL solutions on AWS using tools like Talend, Informatica, MatillionStrong in Java, C##, Spark, PySpark, Unix shell/Perl scriptingIoT, event-driven, microservices, containers/Kubernetes in the cloud</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Proven ability to build, manage and foster a team-oriented environment Proven ability to work creatively and analytically in a problem-solving environment Desire to work in an information systems environment Excellent communication (written and oral) and interpersonal skills Excellent leadership and management skills</td>\n",
       "      <td>Are you ready to step up to the New and take your technology expertise to the next level?\\n\\nJoin Accenture and help transform leading organizations and communities around the world. The sheer scale of our capabilities and client engagements, in conjunction with the way we collaborate, operate and deliver value, provides an unparalleled opportunity to grow and advance. Choose Accenture and make delivering innovative work part of your extraordinary career.\\n\\nPeople in our Client Delivery &amp; Operations career track drive delivery and capability excellence through the design, development and/ or delivery of a solution, service, capability or offering. They grow into delivery-focused roles, and can progress within their current role, laterally or upward. We partner with our clients to help transform their data into an ‘Appreciating Business Asset.’\\n\\nAs part of our Data Business Group, you will lead technology innovation for our clients through robust delivery of world-class solutions. You will build better software better! There will never be a typical day and that’s why people love it here. The opportunities to make a difference within exciting client initiatives are unlimited in the ever-changing technology landscape. You will be part of a highly collaborative and growing network of technology and data experts, who are taking on today’s biggest, most complex business challenges using the latest data and analytics technologies. We will nurture your talent in an inclusive culture that values diversity. You will have an opportunity to work in roles such as Data Scientist, Data Engineer, or Chief Data Officer covering all aspects of Data including Data Management, Data Governance, Data Intelligence, Knowledge Graphs, and IoT. Come grow your career in Technology at Accenture!\\n\\nThe Amazon AWS Data Engineer is responsible for delivering Data On Cloud projects for Amazon AWS based deals. The ideal candidate would be responsible for developing and delivering AWS cloud solutions to meet today’s high demand in areas such as AIML, IoT, advanced analytics, open source, enterprise collaboration, microservices, serverless, etc. The AWS Data Engineer is a highly performant engineer responsible for delivering Cloud based Big Data and Analytical Solutions at our clients. Responsibilities include building data on cloud solutions at customers, leading Business and IT stakeholders through designing a robust, secure and optimized AWS solutions and ability to be hands-on delivering the target solution. This role will work with customers and leading internal engineering teams in delivering big data soltuions on cloud. Using Amazon AWS public cloud technologies, our AWS Data Engineer professionals implement state of the art, scalable, high performance Data On Cloud solutions that meet the need of today’s corporate and emerging digital applications.\\n\\nRole &amp; Responsibilities:\\nProvide subject matter expertise and hands on delivery of data capture, curation and consumption pipelines on AWS and HadoopAbility to build cloud data solutions and provide domain perspective on storage, big data platform services, serverless architectures, hadoop ecosystem, RDBMS, DW/DM, NoSQL databases and security.Participate in deep architectural discussions to build confidence and ensure customer success when building new solutions and migrating existing data applications on the AWS platform.\\n- Build full technology stack of services required including PaaS (Platform as-a-service), IaaS (Infrastructure as-a-service), SaaS (software as-a-service), operations, management and automation.Apply Accenture methodology, Accenture reusable assets, and previous work experience to delivery consistently high-quality work.Stay educated on new and emerging technologies/patterns/methodologies and market offerings that may be of interest to our clients.Understand the strategic direction set by senior management as it relates to team goals.Use considerable judgment to define solution and seeks guidance on complex problems.Primary upward interaction is with direct supervisor. May interact with peers and/or management levels at a client and/or within Accenture. Establish methods and procedures\\non new assignments with guidance.Manage small teams of delivery engineers successfully delivering work efforts (if in an independent contributor role) at a client or within Accenture.Able to travel up to 100% (M-TH)\\n\\nBasic QualificationsAt least 5 years of Consulting or client service delivery experience on Amazon AWS (AWS)At least 5 years of experience in developing data ingestion, data processing and analytical pipelines for big data, relational databases, NoSQL and data warehouse solutionsExtensive experience providing practical direction within the AWS Native and HadoopExperience with private and public cloud architectures, pros/cons, and migration considerations.Minimum of 5 years of hands-on experience in AWS and Big Data technologies such as Java, Node.js, C##, Python, SQL, EC2, S3, Lambda, Spark/SparkSQL, Hive/MR, Pig, Oozie and streaming technologies such as Kafka, Kinesis, NiFI etc.Extensive hands-on experience implementing data migration and data processing using AWS services: VPC/SG, EC2, S3, AutoScaling, CloudFormation, LakeFormation, DMS, Kinesis, Kafka, Nifi, CDC processing Redshift, Snowflake, RDS, Aurora, Neptune, DynamoDB, Hive, NoSQL, Cloudtrail, CloudWatch, Docker, Lambda, Spark,Glue, Sage Maker, AI/ML, API GW, etc.5+ years of hands on experience in programming languages such as Java, c#, node.js, python, pyspark, spark, SQL, Unix shell/Perl scripting etc.Minimum of 5 years of RDBMS experienceExperience in using Hadoop File Formats and compression techniquesExperience working with DevOps tools such as GitLabs, Jenkins, CodeBuild, CoePipeline CodeDeploy, etc.Bachelors or higher degree in Computer Science or a related discipline.\\n\\nCandidate Must Have Completed The Following Certifications\\n§ Certified AWS Developer - Associate\\n§ Certified AWS DevOps – Professional (Nice to have)\\n§ Certified AWS Big Data Specialty (Nice to have)\\n\\nNice-to-Have Skills/Qualifications:DevOps on an AWS platform. Multi-cloud experience a plus.Experience developing and deploying ETL solutions on AWS using tools like Talend, Informatica, MatillionStrong in Java, C##, Spark, PySpark, Unix shell/Perl scriptingIoT, event-driven, microservices, containers/Kubernetes in the cloud\\nExperience in Apache Maven a plusUnderstanding and implementation of Data Lake architecturesUnderstanding NoSQL technologies such as MongoDB, Cassandra, Hbase is a plusUnderstanding Solr, Elasticsearch is a plus\\n\\nProfessional Skill Requirements Proven ability to build, manage and foster a team-oriented environment Proven ability to work creatively and analytically in a problem-solving environment Desire to work in an information systems environment Excellent communication (written and oral) and interpersonal skills Excellent leadership and management skills\\n\\nAll of our professionals receive comprehensive training covering business acumen, technical and professional skills development. You'll also have opportunities to hone your functional skills and expertise in an area of specialization. We offer a variety of formal and informal training programs at every level to help you acquire and build specialized skills faster. Learning takes place both on the job and through formal training conducted online, in the classroom, or in collaboration with teammates. The sheer variety of work we do, and the experience it offers, provide an unbeatable platform from which to build a career.\\n\\nApplicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status).\\n\\nCandidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.\\n\\nAccenture is a Federal Contractor and an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities.\\n\\nEqual Employment Opportunity\\n\\nAll employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.\\n\\nJob candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.\\n\\nAccenture is committed to providing veteran employment opportunities to our service men and women.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Big Data Engineer</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nYou will design and create multi-tenant systems capable of loading and transforming a large volume of structured and semi-structured fast moving data\\nBuild robust and scalable data infrastructure (both batch processing and real-time) to support needs from internal and external users\\nBuild Data Pipelines\\nRun ETL into Hadoop/Elastic Search</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Location: San Jose, CA or Atlanta, GA\\nFor over 10 years, Zscaler has been disrupting and transforming the security industry. Our 100% purpose built cloud platform delivers the entire gateway security stack as a service through 150 global data centers to securely connect users to their applications, regardless of device, location, or network in over 185 countries protecting over 3,500 companies and 100 Million threats detected a day.\\nWe work in a fast paced, dynamic and make it happen culture. Our people are some of the brightest and passionate in the industry that thrive on being the first to solve problems. We are always looking to hire highly passionate, collaborative and humble people that want to make a difference.\\nAs a Big Data Engineer, you will work on building the next generation of Zscaler's security analytics platform. You will play a crucial role in building a platform to collect and ingest several billion (and growing) log events from Zscaler's globally distributed security infrastructure and provide actionable insights to customers and Zscaler's security researchers.\\nResponsibilities:\\nYou will design and create multi-tenant systems capable of loading and transforming a large volume of structured and semi-structured fast moving data\\nBuild robust and scalable data infrastructure (both batch processing and real-time) to support needs from internal and external users\\nBuild Data Pipelines\\nRun ETL into Hadoop/Elastic Search\\nRequired:\\n3+ years of experience in Python or Java development a must (Strong Scala would skills would be acceptable as well)\\n3+ years experience in application big data development (Spark, Kafka, Storm, Kinesis, &amp; building data pipelines)\\nAbility to troubleshoot and find complex performance issues with queries on the Spark platform (Spark SQL)\\nFamiliarity with implementing services following REST model\\nExcellent interpersonal, technical and communication skills\\nAbility to learn, evaluate and adopt new technologies\\nBachelor's Degree in computer science or equivalent experience\\nHighly Desirable:\\nExperience working with data processing infrastructure\\nExperience with data serialization techniques and data stores for persisting events\\nWhat You Can Expect From Us:\\nAn environment where you will be working on cutting edge technologies and architectures\\nA fun, passionate and collaborative workplace\\nCompetitive salary and benefits, including equity\\nThe pace and excitement of working for a Silicon Valley Unicorn\\nWhy Zscaler?\\nPeople who excel at Zscaler are smart, motivated and share our values. Ask yourself: Do you want to team with the best talent in the industry? Do you want to work on disruptive technology? Do you thrive in a fluid work environment? Do you appreciate a company culture that enables individual and group success and celebrates achievement?\\n\\nIf you said yes, we’d love to talk to you about joining our award-winning team!\\nLearn more at zscaler.com or follow us on Twitter @zscaler. Additional information about Zscaler (NASDAQ : ZS ) is available at http://www.zscaler.com. All qualified applicants will receive consideration for employment without regard to race, sex, color, religion, sexual orientation, gender identity, national origin, protected veteran status, or on the basis of disability.\\n#LI-JM1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>FraudScope - the rapidly growing company that is tackling the problem of healthcare, fraud, waste and abuse - is looking for a full-time Data Engineer to work in their office located at Midtown Atlanta.\\nWe are seeking a talented data engineer with experience in data analytics, building large reservoirs of data, and performing efficient queries. We have built a web-based application that is supported by a large dataset of healthcare data, on which we must frequently perform large queries very efficiently and return results in real time to the user. The role of the data engineer is to bridge the data scientist with the developers and the ingestion of data. Specifically, one of the major tasks is to build and execute new data pipelines on the cloud (AWS).\\nRequired technical skills:\\n\\nRelational database (PostgreSQL)\\nCloud experience (AWS S3, Aurora, EC2)\\nPython\\nLinux\\n\\nBeneficial technical skills:\\nApache Spark, Hadoop\\nAWS Glue, Athena, IAM, KMS\\nProven experience processing billions of records and terabytes of data\\nTable partitioning with PostgreSQL\\nShell scripting (e.g., bash)\\n\\nOther Requirements/Preferences:\\nExperience with healthcare data, particularly medical claims\\nBachelor degree in Computer Science, Engineering or related field - At least 2 years of experience in the software industry\\nAuthorization to work in the USA\\nPosition in Midtown - Atlanta, GA (no remote)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Advanced Data Engineer</td>\n",
       "      <td>Atlanta, GA 30309</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>30309</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Strong analytical and critical thinking skills\\nAutonomous personality. We’ll help guide you, but we won’t micromanage you. We expect integrity and results. Your work and deliverables will speak for themselves\\nStrong written and verbal communication skills\\nEnjoy challenging and thought-provoking work and have a strong desire to learn and progress\\nAbility to manage multiple tasks and requests\\nMust demonstrate a positive, team-focused attitude\\nAbility to react positively under pressure to meet tight deadlines\\nYou listen to the input of your team members and take diverse perspectives into account to approach challenges from multiple angles\\nStructured, disciplined approach to work, with attention to detail\\nFlexible – able to meet changing requirements and priorities\\nMaintenance of up-to-date knowledge in the appropriate technical areas\\nAble to work in a global, multicultural environment</td>\n",
       "      <td>Build robust data pipelines on public Cloud using AWS Kinesis, Kafka, Lambda or other technologies\\nResponsible to collect, process, and compute business metrics from activity &amp; persisted data using Python/Spark\\nProcess, cleanse, and verify the integrity of data used for analysis; optimize data for consumption\\nBuild scalable OLAP backend storage for data in PB scale\\nDevelop data set processes for data discovery, modeling, mining, and archival</td>\n",
       "      <td>\\nBachelor’s or Master's Degree of Statistics, Computer Science or other similar advanced degrees from a top tier educational institution preferred</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Invesco is one of the world's leading global investment managers, entrusted with managing $1.2 trillion* in assets on behalf of clients worldwide. We are the 6th largest US retail asset manager and the 13th largest investment manager globally, and our more than 8,000 employees worldwide are dedicated to delivering an investment experience that helps people get more out of life. We are purely focused on managing a comprehensive range of active, passive and alternative investment capabilities, which we draw on to provide customized solutions aligned to client needs, our most important benchmark. (*As of May 31, 2019)\\n\\nJob Purpose (Job Summary):\\n\\nWe’re seeking an Advanced Data Engineer to join a fast-paced agile development team building-out enterprise grade data platforms that support Client Experience, Regulatory, and investment teams. You’ll be a part of a dynamic, collaborative team that wants to hear your input because you know the leading methods, tools, and theories in data engineering. The focus of this role will be to source data sets, both internal and external, that support our business clients. You’ll be working alongside our data science and machine learning teams leveraging the Invesco enterprise data lake architecture. Candidates will be expected to ingest, curate, and provide access to structured and unstructured data sets.\\n\\nKey Responsibilities / Duties:\\nBuild robust data pipelines on public Cloud using AWS Kinesis, Kafka, Lambda or other technologies\\nResponsible to collect, process, and compute business metrics from activity &amp; persisted data using Python/Spark\\nProcess, cleanse, and verify the integrity of data used for analysis; optimize data for consumption\\nBuild scalable OLAP backend storage for data in PB scale\\nDevelop data set processes for data discovery, modeling, mining, and archival\\nWork Experience / Knowledge:\\n2+ years of experience focused in big data engineering\\n2+ years of experience with ETL/SQL design build and tuning\\nExperience with data services using Amazon Web Services (AWS), Azure, and / or Google Cloud\\nExpertise in at least one of the following areas:\\nExperience with parallel computing, batch processing, and stream processing using tools such as Kinesis or Kafka\\nExperience with data processing technologies such as Hadoop, Spark, Hive / Pig, and Java / MapReduce\\nExperience with data warehousing and columnar databases such as Redshift as well as NoSQL databases such as AWS S3, MongoDB, Cassandra, HBase, DynamoDB\\nExperience with programming languages such as Java, Python or Scala\\nExperience with micro-services based architecture and design/build of RESTful API’s is a plus\\nExperience operationalizing data sourcing/loading including automating/scheduling data ingestion\\nFamiliar with Agile software development (Scrum is a plus)\\nDevOps knowledge is a plus\\nSkills / Other Personal Attributes Required:\\nStrong analytical and critical thinking skills\\nAutonomous personality. We’ll help guide you, but we won’t micromanage you. We expect integrity and results. Your work and deliverables will speak for themselves\\nStrong written and verbal communication skills\\nEnjoy challenging and thought-provoking work and have a strong desire to learn and progress\\nAbility to manage multiple tasks and requests\\nMust demonstrate a positive, team-focused attitude\\nAbility to react positively under pressure to meet tight deadlines\\nYou listen to the input of your team members and take diverse perspectives into account to approach challenges from multiple angles\\nStructured, disciplined approach to work, with attention to detail\\nFlexible – able to meet changing requirements and priorities\\nMaintenance of up-to-date knowledge in the appropriate technical areas\\nAble to work in a global, multicultural environment\\nFormal Education: (minimum requirement to perform job duties)\\nBachelor’s or Master's Degree of Statistics, Computer Science or other similar advanced degrees from a top tier educational institution preferred\\nWorking Conditions:\\nNormal office environment with little exposure to noise, dust and temperatures\\nThe ability to lift, carry or otherwise move objects of up to 10 pounds is also necessary\\nNormally works a regular schedule of hours, however hours may vary depending upon the project or assignment\\nHours may include evenings and/or weekends and may include 24 hour a day on call support by pager and/or cell phone\\nAble and willing to travel both domestically and internationally. Frequency and duration to be determined by manager. Estimate: 10-15%\\nFLSA (US Only): Nonexempt\\n\\nThe above information on this description has been designed to indicate the general nature and level of work performed by employees within this role. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications required of employees assigned to this job. The job holder may be required to perform other duties as deemed appropriate by their manager from time to time.\\n\\nInvesco's culture of inclusivity and its commitment to diversity in the workplace are demonstrated through our people practices. We are proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, creed, color, religion, sex, gender, gender identity, sexual orientation, marital status, national origin, citizenship status, disability, age, or veteran status. Our equal opportunity employment efforts comply with all applicable U.S. state and federal laws governing non-discrimination in employment.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Big Data Engineer</td>\n",
       "      <td>Atlanta, GA 30309</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>30309</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Strong analytical and critical thinking skills\\nAutonomous personality. We’ll help guide you, but we won’t micromanage you. We expect integrity and results. Your work and deliverables will speak for themselves\\nStrong written and verbal communication skills\\nEnjoy challenging and thought-provoking work and have a strong desire to learn and progress\\nAbility to manage multiple tasks and requests\\nMust demonstrate a positive, team-focused attitude\\nAbility to react positively under pressure to meet tight deadlines\\nYou listen to the input of your team members and take diverse perspectives into account to approach challenges from multiple angles\\nStructured, disciplined approach to work, with attention to detail\\nFlexible – able to meet changing requirements and priorities\\nMaintenance of up-to-date knowledge in the appropriate technical areas\\nAble to work in a global, multicultural environment</td>\n",
       "      <td>Build robust data pipelines on public Cloud using AWS Kinesis, Kafka, Lambda or other technologies\\nResponsible to collect, process, and compute business metrics from activity &amp; persisted data using Python/Spark\\nProcess, cleanse, and verify the integrity of data used for analysis; optimize data for consumption\\nBuild scalable OLAP backend storage for data in PB scale\\nDevelop data set processes for data discovery, modeling, mining, and archival</td>\n",
       "      <td>\\nBachelor’s or master’s degree of Statistics, Computer Science or other similar advanced degrees from a top tier educational institution preferred</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Invesco is one of the world’s leading global investment managers, entrusted with managing $1.2 trillion* in assets on behalf of clients worldwide. We are the 6th largest US retail asset manager and the 13th largest investment manager globally, and our more than 8,000 employees worldwide are dedicated to delivering an investment experience that helps people get more out of life. We are purely focused on managing a comprehensive range of active, passive and alternative investment capabilities, which we draw on to provide customized solutions aligned to client needs, our most important benchmark. (*As of May 31,2019)\\n\\nJob Purpose (Job Summary):\\n\\nWe’re seeking a Senior Data Engineer to join a fast-paced agile development team building-out enterprise grade data platforms that support Client Experience, Regulatory, and investment teams. You’ll be a part of a dynamic, collaborative team that wants to hear your input because you know the leading methods, tools, and theories in data engineering. The focus of this role will be to source data sets, both internal and external, that support our business clients. You’ll be working alongside our data science and machine learning teams leveraging the Invesco enterprise data lake architecture. Candidates will be expected to ingest, curate, and provide access to structured and unstructured data sets.\\n\\nKey Responsibilities / Duties:\\nBuild robust data pipelines on public Cloud using AWS Kinesis, Kafka, Lambda or other technologies\\nResponsible to collect, process, and compute business metrics from activity &amp; persisted data using Python/Spark\\nProcess, cleanse, and verify the integrity of data used for analysis; optimize data for consumption\\nBuild scalable OLAP backend storage for data in PB scale\\nDevelop data set processes for data discovery, modeling, mining, and archival\\nWork Experience / Knowledge:\\n3+ years of experience focused in big data engineering with 6+ years overall working experience\\n3+ years of experience with ETL/SQL including fundamental and optimization query techniques, normal forms, and processing semi-structured data such as CSV, XML, XPath, XQuery\\n3+ years of experience with data services using Amazon Web Services (AWS), Azure, and / or Google Cloud\\nExpertise in at least one of the following areas:\\nExperience with parallel computing, batch processing, and stream processing using tools such as Kinesis or Kafka\\nExperience with data processing technologies such as Hadoop, Spark, Hive / Pig, and Java / MapReduce\\nExperience with data warehousing and columnar databases such as Redshift as well as NoSQL databases such as AWS S3, MongoDB, Cassandra, HBase, DynamoDB\\n3-5 years of experience with programming languages such as Java, Python or Scala\\nExperience with micro-services-based architecture and design/build of RESTful API’s is a plus\\nExperience operationalizing data sourcing/loading including automating/scheduling data ingestion\\nFamiliar with Agile software development (Scrum is a plus)\\nExpertise in building out DevOps pipelines is a plus\\nSkills / Other Personal Attributes Required:\\nStrong analytical and critical thinking skills\\nAutonomous personality. We’ll help guide you, but we won’t micromanage you. We expect integrity and results. Your work and deliverables will speak for themselves\\nStrong written and verbal communication skills\\nEnjoy challenging and thought-provoking work and have a strong desire to learn and progress\\nAbility to manage multiple tasks and requests\\nMust demonstrate a positive, team-focused attitude\\nAbility to react positively under pressure to meet tight deadlines\\nYou listen to the input of your team members and take diverse perspectives into account to approach challenges from multiple angles\\nStructured, disciplined approach to work, with attention to detail\\nFlexible – able to meet changing requirements and priorities\\nMaintenance of up-to-date knowledge in the appropriate technical areas\\nAble to work in a global, multicultural environment\\nFormal Education: (minimum requirement to perform job duties)\\nBachelor’s or master’s degree of Statistics, Computer Science or other similar advanced degrees from a top tier educational institution preferred\\nWorking Conditions:\\nNormal office environment with little exposure to noise, dust and temperatures\\nThe ability to lift, carry or otherwise move objects of up to 10 pounds is also necessary\\nNormally works a regular schedule of hours, however hours may vary depending upon the project or assignment\\nHours may include evenings and/or weekends and may include 24 hour a day on call support by pager and/or cell phone\\nAble and willing to travel both domestically and internationally. Frequency and duration to be determined by manager. Estimate: 10-15%\\nFLSA (US Only): Exempt\\n\\nThe above information on this description has been designed to indicate the general nature and level of work performed by employees within this role. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications required of employees assigned to this job. The job holder may be required to perform other duties as deemed appropriate by their manager from time to time.\\n\\nInvesco's culture of inclusivity and its commitment to diversity in the workplace are demonstrated through our people practices. We are proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, creed, color, religion, sex, gender, gender identity, sexual orientation, marital status, national origin, citizenship status, disability, age, or veteran status. Our equal opportunity employment efforts comply with all applicable U.S. state and federal laws governing non-discrimination in employment.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lead Big Data Engineer</td>\n",
       "      <td>Atlanta, GA 30308</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>30308</td>\n",
       "      <td>None Found</td>\n",
       "      <td>M.S. in Computer Science, Informatics, Mathematics, Electronic/Electrical Engineering or other relevant field with an emphasis on data analytics.Experience with big data technologies such as Hadoop, Apache Spark, NoSQL databases.Strong computer science grounding, with knowledge of data structures, algorithms and computer architectures.Proficiency developing in one or more languages such as C++, Python or Java.Self-starting, requiring minimal supervision with strong problem-solving skills.Excellent communication and teamwork skills.</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Keysight launched a Software Design Center in Atlanta to create a new software platform for electronic product design and test. The new center is located in Atlanta’s growing Midtown district and features an open environment to foster collaboration and agile software development. We are seeking a lead developer to build upon a solid working knowledge of big data technologies such as MapReduce, Apache Spark and NoSQL databases on both structured and unstructured data. The focus of this position will be implementation of scalable computing technologies for data analytics. Along with a team of researchers and developers, you will help define, investigate, develop and implement, state-of-the-art informatics, data analysis and data visualization technology.\\nJob Qualifications\\nREQUIRED QUALIFICATIONS:M.S. in Computer Science, Informatics, Mathematics, Electronic/Electrical Engineering or other relevant field with an emphasis on data analytics.Experience with big data technologies such as Hadoop, Apache Spark, NoSQL databases.Strong computer science grounding, with knowledge of data structures, algorithms and computer architectures.Proficiency developing in one or more languages such as C++, Python or Java.Self-starting, requiring minimal supervision with strong problem-solving skills.Excellent communication and teamwork skills.\\n\\nDESIRED QUALIFICATIONS:Hands-on experience with Cloud environments, such as AWS, Google Cloud, or AzureExperience with Cloudera\\nJob Function\\nR&amp;D\\n___________________________________________________________________________________\\nPrivacy Statement\\n***Keysight is an Equal Opportunity Employer.***\\nKeysight Technologies Inc. is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability or any other protected categories under all applicable laws.\\n\\nCandidates can be considered to work from the following locations:\\nAmericas : United States : Georgia : Atlanta\\nJob ID : 391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Alpharetta, GA</td>\n",
       "      <td>Alpharetta</td>\n",
       "      <td>GA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Alpharetta, GA.\\nFull time\\n$90,000 - $110,000 / year\\n40h / week\\n2+ years experience\\nMaster or Bachelor\\nJob Requirements\\n1. Responsible for evaluating, developing, maintaining and testing big data solutions for advanced analytics projects\\n2. The role would involve big data pre-processing &amp; reporting workflows including collecting, parsing, managing, analyzing and visualizing large sets of data to turn information into business insights\\n3. Responsible for developing, coding, testing and debugging solution related to our Data solutions\\n4. Develop, enhance and maintain the data pipeline ingestion, transformation, storage, analysis and visualization using combination of open source and paid technology tools\\n5. Automating data solutions for reporting KPI, trends, etc.\\n\\nPreferred Qualifications\\n\\n1. Understanding of data flows, data architecture, ETL and processing of structured and unstructured data\\n2. Possess strong computer science fundamentals: data structures, algorithms, programming languages, distributed systems, and information retrieval\\n3. Familiar with data mining concepts\\n4. Strong Programming Skills in Python / Java / Scala /Node.js\\n5. Hands on experience working at least one Relational and/or NoSQL Databases\\n6. Knowledge on SQL Queries and Data Modelling\\n7. Hands on experience working in ETL Use cases either in On-premise or Cloud\\n8. Experience in any Cloud Platform (AWS, Azure, GCP, Alibaba)\\n9. Knowledge in one or more AWS Services like Kinesis, EC2, EMR, Hive Integration, Athena, Firehose, Lambda, S3, Glue Crawler, Redshift, RDS is a plus\\n10. Good Communication Skills and Self Driven - should be able to deliver the projects with minimum instructions from Client\\n11. Experience in Spark &amp; Big Data is big plus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Engineer (Business Intelligence)</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>The Pindrop engineering team solves tough problems and invents new ways to battle fraud using big data and audio science in the cloud. Pindrop creates innovative products to solve global problems, and we are looking for an expert Data Engineer to join the Business Intelligence engineering team as we continue to develop ways to fight fraud and improve security in voice channels.\\n\\nIn this role, you will be working cross-functionally with business intelligence operations, research, analytics, and engineering teams to design and implement our Data platform. You will participate in designing, implementing and scaling our Datalake and data pipelines that transform billions of records into actionable insights.\\n\\n--------------------\\nwhat you'll do\\n--------------------\\n\\n\\nWork with a growing team to design, develop, test, deploy, maintain and improve brand new data services\\nRefactor existing systems and architect new solutions\\nDevelop new and efficient ways to ingest, store and process our billions of records\\nWork with our research department to build data pipelines that transform raw semi-structured events into structured data, consumable by machine learning pipelines and algorithms\\nWork with our backend software engineers to build efficient and scalable reporting solutions that tap into our datastores\\nDeliver production ready code from start to finish -- designed, implemented, tested and deployed\\nReview code to maintain quality with an eye towards performance, scale, and security\\nWork with multiple teams to implement company wide solutions\\n\\n-----------\\nwho you are\\n-----------\\n\\n\\nData Engineer with strong software engineering skills\\nStrong experience with relational databases and document stores (SQL + NoSQL)\\nExperience with multiple programming languages, such as Python, Java, and Go\\nExperience with Big Data technologies such as Spark or Hadoop a big plus\\nLinux experience\\nKnowledge of Docker and container orchestration frameworks such as Kubernetes ideal\\nExperience developing with AWS managed services such as S3, ElastiCache and DynamoDB\\nAbility to deal with ambiguity in a fast-paced dynamic environment\\nProven track record of providing stable, secure code in environments that change and improve rapidly\\nBS in CS or EE or relevant technical discipline\\n\\n-------------\\nwhat we offer\\n-------------\\n\\nAs a part of Pindrop, you'll have a direct impact on our growing list of products and thus the future of security in the voice driven economy. We hire great people and take care of them. Here's a snapshot of benefits we offer:\\n\\n\\nRecognized top employer\\nAJC Top Workplaces 2017 ( http://topworkplaces.com/publication/ajc/pindrop-security/ )\\n51 Startups to Bet Your Career On ( http://www.businessinsider.com/51-enterprise-startups-to-bet-your-career-on-in-2018-2017-11/#pindrop-security-for-the-next-big-thing-in-computing-26 )\\n50 Startups That Will Boom in 2018 ( http://www.businessinsider.com/50-startups-to-boom-in-2018-according-to-vcs-2017-11?IR=T/#pindrop-stopping-voice-fraudsters-3 )\\nHealth plans and 401k\\nContinued education budget\\nFlex schedules\\nBest in class tools\\nPaid commuter options\\nFun outings to celebrate our accomplishments as a team\\nAll the good karma you can rack up for fighting bad guys (our conference rooms are named after the ones we've busted)\\n\\n----------\\nwho we are\\n----------\\n\\nPindrop is a company founded on research and continues to innovate new ideas to market. Our solutions are leading the way to the future of voice by establishing the standard for security, identity, and trust. Pindrop products secure the future of voice, making technology more human from the call center to IoT devices.\\n\\n---------------\\nwhat we live by\\n---------------\\n\\nPindrop is driven by our DEPTH values. These are reflected in our goals and the base of our team's peer awards.\\n\\nAct with Deliberate urgency.\\nCreate Evangelical customers.\\nPassionate about the fight.\\nPlaying for the Team.\\nMake Hard easy.\\n\\nPindrop is an Equal Opportunity Employer ( https://www.eeoc.gov/employers/upload/poster_screen_reader_optimized.pdf ).\\n\\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status; and will not be discriminated against on the basis of disability.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Big Data Engineer</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Our data platform enables analytics, experimentation, machine learning models, streaming, reporting infrastructure and systems metrics which powers and drives innovation at UserTesting. Our team of data engineers and scientists is focused on creating a competitive advantage for UserTesting and our customers through novel data infrastructure, metrics, insights and data services. We are a small but rapidly growing team that builds and leverages state-of-the-art analytics systems, especially around video and Natural Language Processing (NLP).\\n\\nAs a Big Data Engineer, you’ll design, develop &amp; tune data products, applications and integrations on large scale data platforms with an emphasis on performance, reliability and scalability and most of all quality. You’ll support our Machine Learning efforts by building large-scale distributed infrastructure for rapid experimentation, training, and inference. You are passionate about applying cutting-edge machine learning to real-world problems and building the required frameworks and tools to do so.\\n\\nYou will play a key role in the evolution of our Data Platform, duties include:\\n\\n\\nWork closely with product and design to discover and build solutions that help our customers build great user experiences\\nCollaborate with engineers who are both remote and co-located in our Mountain View, San Francisco, and Atlanta offices\\nWork effectively within a team environment, to regularly solicit and act on feedback, focus on root causes, and continually strive to improve\\nEnhance our customer-facing platform, tester panel distribution systems, video playback tools, and mobile device recording capabilities\\nAdvocate and lead-by-example best practices for code quality in architecture and design, maintainability, performance, and scalability\\nLead on promoting just-right solutions to build for the future while also avoiding costly premature optimizations\\n\\nRequirements\\n\\nAt least 5 years of software development experience.\\nAt least 3 years of experience of using Big Data systems.\\nStrong in one or more languages (Python/Ruby/Scala/Java/C++)\\nStrong experience on a professional software development team building highly scalable, distributed systems in the cloud\\nExperience in REST API design and implementation\\nExperience with messaging, queuing, and workflow systems, especially Kafka or Amazon Kinesis\\nExperience with non-relational, NoSQL databases and various data-storage systems, especially: Cassandra, ElasticSearch/Solr, Neo4j, etc.\\n\\nPreferred Qualifications\\n\\nExperience working with Machine Learning, especially NLP\\nExperience with software development on top of Deep Learning Frameworks, especially Tensorflow/Keras\\nData engineering knowledge including ETL, DataWarehouse, Data Visualization, etc.\\nData modeling experience with columnar data formats\\nExperience integrating with CI tools programmatically\\nExperience with Docker, registries and container deployment services (e.g., AWS ECS, Kubernetes).\\n\\nAdditional Information\\nBesides a great work environment and the opportunity to change the world, we offer competitive salary, benefits, plenty of perks, as well as equity participation.\\n\\nUserTesting is an Equal Opportunity Employer and participant in the U.S. Federal E-Verify program. Women, minorities, individuals with disabilities and protected veterans are encouraged to apply. We welcome people of different backgrounds, experiences, abilities and perspectives. UserTesting will consider qualified applicants with criminal histories in a manner consistent with the\\nSan Francisco Fair Chance Ordinance.\\n[http://sfgsa.org/modules/showdocument.aspx?documentid=11600]\\n\\nLearn more about what it is like to work at UserTesting at :\\nhttps://www.usertesting.com/about-us/jobs\\n[https://www.usertesting.com/about-us/jobs]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Azure Data Engineer</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>About Avanade\\n\\nAvanade leads in providing innovative digital services, business solutions and design-led experiences for its clients, delivered through the power of people and the Microsoft ecosystem. Our professionals combine technology, business and industry expertise to build and deploy solutions to realize results for clients and their customers. Avanade has 34,000 digitally connected people across 24 countries, bringing clients the best thinking through a collaborative culture that honors diversity and reflects the communities in which we operate. Majority owned by Accenture, Avanade was founded in 2000 by Accenture LLP and Microsoft Corporation. Learn more at www.avanade.com\\n\\nWhy Avanade?\\n\\n14-time winner of Microsoft Partner of the Year\\n24,000+ certifications in Microsoft technology\\n90+ Microsoft partner awards\\n17 Gold Competencies\\n3,500 analytics professionals worldwide\\n1,000 data engineers\\nImplemented analytics systems for more than 550 clients\\n400 AI practitioners\\n300 cognitive service experts\\n\\nHow We Support You:\\nWe believe in gender equity and an inclusive community. We offer a comprehensive benefits package: generous vacation allowance disability coverage, retirement plans, paid maternity and paternity leave, life insurance, hotel and travel discounts, extended benefits to cover items that support your well-being, health, dental and vision insurance, professional development and paid Microsoft certification opportunities.\\n\\nRole Overview:\\nAs an Azure Data Engineer you will collect, aggregate, store, and reconcile data in support of Client business decisions. You will help design and build data pipelines, data streams, reporting tools, information dashboards, data service APIs, data generators and other end-user information portals and insight tools. You will be a critical part of the data supply chain, ensuring that business partners can access and manipulate data for routine and ad hoc analysis to drive business outcomes using Advanced Analytics.\\n\\nKey Role Responsibilities:\\nDay-to-day, you will:\\nTranslate business requirements to technical solutions using strong business insight.\\nAnalyzes current business practices, processes and procedures as well as identifying future business opportunities for demonstrating Microsoft Azure Data &amp; Analytics PaaS Services.\\nSupport the planning and implementation of data design services, providing sizing and configuration assistance and performing needs assessments.\\nDelivery of architectures for transformations and modernizations of enterprise data solutions using Azure cloud data technologies.\\nDesign and Build Modern Data Pipelines and Data Streams.\\nDesign and Build Data Service APIs.\\nDevelop and maintain data warehouse schematics, layouts, architectures and relational/non-relational databases for data access and Advanced Analytics.\\nExpose data to end users using Power BI, Azure API Apps or other modern visualization platform or experience.\\nImplement effective metrics and monitoring processes.\\nAble to travel approximately 80%\\n\\nKey Role Skill &amp; Capability Requirements:\\nYour technical/non-technical skills include:\\nDemonstrable experience of turning business use cases and requirements to technical solutions.\\nExperience in business processing mapping of data and analytics solutions.\\nAbility to conduct data profiling, cataloging, and mapping for technical design and construction of technical data flows.\\nThe ability to apply such methods to take on business problems using one or more Azure Data and Analytics services in combination with building data pipelines, data streams, and system integration.\\nT-SQL is required.\\nKnowledge of Azure Data Factory, Azure Data Lake, Azure SQL DW, and Azure SQL, Azure App Service is required.\\nExperience preparing data for Data Science and Machine Learning.\\nKnowledge of Lambda and Kappa architecture patterns.\\nKnowledge of Master Data Management (MDM) and Data Quality tools and processes.\\nStrong collaboration ethic and experience working with remote teams.\\nKnowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals.\\nWorking experience with Visual Studio, PowerShell Scripting, and ARM templates.\\nExperience with Git/TFS/VSTS is a requirement.\\n\\nPreferred Certifications:\\nMCSA\\n\\nPreferred Education Background:\\nYou likely possess a Bachelor's degree in Computer Science, Information Technology, Business, or another relevant field. An equivalent combination of education and experience will also suffice.\\n\\nPreferred Years of Work Experience:\\nYou likely have about 3-5+ years of relevant professional experience.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>ThoughtWorks is a global software consultancy, made up of around 4,500 passionate technologists across 15 countries. We specialize in strategy, portfolio management, and product design, combined with digital engineering excellence.\\n\\nAs a Senior Data Engineer, here's what we'll be looking for you to bring:\\nHands-on Engineering Leadership\\nProven track record of Innovation and expertise in Data Engineering\\nTenure in coding, architecting and delivering complex projects\\nDeep understanding and application of modern data processing technology stacks. For example Spark, Kafka, Hadoop, ecosystem technologies, and others\\nDeep understanding of NoSQL technologies including column family, graph, document, and key-value data storage technologies\\nDeep understanding of relational database technologies and database development techniques\\nUnderstanding of how to architect solutions for data science and analytics\\nData management for reporting and BI experience is a plus\\nUnderstanding of “Agility”, including core values, guiding principles, and key agile practices\\nUnderstanding of the theory and application of Continuous Integration/Delivery\\nPassion for software craftmanship\\nA rich breadth of industry experience and background working across different organizations, ranging in size, from start-ups to large corporations..\\nStrong stakeholder management and interaction experience at different levels\\nAny experience building and leading an offshore/outsourcing function would be highly beneficial.\\nThere's no typical day or engagement for our Senior Engineers. Here’s what you’ll do:\\n\\nBe the SME. Develop Big Data architectural approach to meet key business objectives and provide end to end development solution\\nYou might spend a few weeks with a new client on a deep technical review or a complete organizational review, helping them to understand the potential that Big Data has to solve their most pressing problems.\\nOn other projects, you might be acting as the architect, leading the design of technical solutions, or perhaps overseeing a program inception to build a new product.\\nIt could be much more about getting stuck into a delivery project where you're equally happy coding and tech leading the team to implement the solution.\\nWhatever your role, the team always look to draw on your experience when things get tough and you often handle the difficult client conversations allowing the team to continue delivering without undue pressure.\\nYou have great relationships with our new business team and work collaboratively to support pre-sales, meet prospective clients and ultimately influence and shape our portfolio of work.\\nYou recognize that building your network with a client is absolutely key to enable you to perform in your role. You'll be drawing on all of your passion for technology, hands-on experience and knowledge of latest Big Data and Engineering best practices to help you gain the respect and credibility of those around you.\\nRegardless of what you do at ThoughtWorks, you’ll always have the opportunity to:\\n\\nThink through hard problems, and work with a team to make them reality.\\nLearn something new every day.\\nWork in a dynamic, collaborative, transparent, non-hierarchal, and ego-free culture where your talent is valued over a role title\\nTravel the world.\\nSpeak at conferences.\\nWrite blogs and books.\\nDevelop your career outside of the confinements of a traditional career path by focusing on what you’re passionate about rather than a predetermined one-size-fits-all plan\\nBe part of a company with Social and Economic Justice at the heart of its mission.\\n\\nA few important things to know:\\nProjects are almost exclusively on customer site, so candidates should be flexible and open to travel.\\n\\nCandidates must possess work authorization that does not require H-1B visa sponsorship by ThoughtWorks or dependent EAD.\\n\\nNot quite ready to apply? Or maybe this isn’t the right role for you? That’s OK, you can stay in touch with AccessThoughtWorks, our learning community (click \"contact me about recruitment opportunities\" to hear about jobs in the future).\\n\\nIt is the policy of ThoughtWorks, Inc. to provide a work environment free of discrimination. The Company will take affirmative action to ensure applicants and ThoughtWorks employees are treated without regard to race, color, religion, sex, national origin, ethnic origin, veteran status, family status, disability, sexual orientation, gender expression or gender identity. This also includes individuals who are perceived to have any of the aforementioned attributes. ThoughtWorks will adhere to all federal, state, and municipal laws and regulations governing employment.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Senior Engineer - Data &amp; Analytics</td>\n",
       "      <td>Atlanta, GA 30326</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>30326</td>\n",
       "      <td>None Found</td>\n",
       "      <td>3+ years of related work experience in Data Engineering or Data Warehousing</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Work as part of a team to develop Cloud Data and Analytics solutions</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>About Slalom Build\\nSlalom Build is a highly-scalable, high-velocity Build as a Service firm. We work with clients to close the distance between dream and reality, imagined possibility and technical realization.\\n\\nWe do this by blending design, product engineering, analytics, and automation to build the modern technology products of tomorrow.\\n\\nNearly 1000 builders strong in seven Build Centers across North America, Slalom Build leverages a foundation of innovation inherited from Slalom Consulting. We’re intensely proud to partner with future-focused clients committed to disrupting their industries.\\n\\nAbout Slalom\\nFounded in 2001 and headquartered in Seattle, WA, Slalom has organically grown to over 6,000 employees. We were named one of Fortune’s 100 Best Companies to Work For in 2017 and are regularly recognized by our employees as a best place to work. You can find us in 27 cities across the U.S., U.K., and Canada.\\n\\nJob Title: Senior Data Engineer\\nAs a Senior Data Engineer for Slalom Build, you’ll work in small teams to deliver innovative solutions on Amazon Web Services, Azure, and Google Cloud using core cloud data warehouse tools, Hadoop, Spark, Event Stream platforms, and other Big Data related technologies. In addition to building the next generation of data platforms, you’ll be working with some of the most forward-thinking organizations in data and analytics.\\n\\nResponsibilities:Work as part of a team to develop Cloud Data and Analytics solutionsParticipate in development of cloud data warehouses and business intelligence solutionsData wrangling of heterogeneous data and explore and discover new insightsGain hands-on experience with new data platforms and programming languages (e.g. Python, Hive, Spark)Willingness to travel up to 50%, at peak times of projects\\n\\nQualifications:3+ years of related work experience in Data Engineering or Data WarehousingHands-on experience with leading commercial Cloud platforms, including AWS, Azure, and GoogleProven experience with data warehousing, data ingestion, and data profilingProficient in SQLStrong aptitude for learning new technologies and analytics techniquesHighly self-motivated and able to work independently as well as in a team environmentUnderstanding of agile project approaches and methodologiesProficient in a source code control system, such as GitProficient in the Linux shell, including utilities such as SSH\\n\\nPreferred Experience:Familiarity with implementing analytics solutions with one or more Hadoop distributions (Cloudera, Hortonworks, MapR, HDInsight, EMR)Failiarity with streaming data ingestionProficient in Python and/or JavaConsulting experienceFamiliarity or strong desire to learn quantitative analysis techniques (e.g., predictive modeling, machine learning, segmentation, optimization, clustering, regression)\\n\\nSlalom is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AI Model Development Lead for Virtual Channels (Analytic Manager 5)</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\n8+ years of experience in analytics, modeling, or a combination of both\\n6+ years of management experience; or 6+ years of leadership experience in an advanced quantitative analytics function\\nA Master's degree or higher\\n5 + years of experience using quantitative machine learning techniques</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Overview:\\nWells Fargo technology teams drive innovation to create a more powerful and fulfilling financial experience for our customers and team members. You will join more than 24,000 team members supporting 95 billion transactions annually in 10 countries. Our career opportunities span the technology spectrum: advanced analytics, big data, information security, application development, cloud enablement, project management and more.\\n\\nSUCCESS PROFILE\\nCheck out the top traits we're looking for and see if you have the right mix. Additional related traits listed below.\\n\\nAnalytical\\nDetail-oriented\\nInsightful\\nInventive\\nProblem Solver\\nCurious\\nBenefits\\nWells Fargo wants to help you get more out of life and take care of things outside the office to make life a little easier. We provide:\\n\\nMedical, Dental and Vision\\nEmployer Matching 401(k)\\nTuition Reimbursment\\nMaternity and Paternity Leave\\nPaid Time Off\\nResponsibilties\\nJob Description\\nAt Wells Fargo, we want to satisfy our customers’ financial needs and help them succeed financially. We’re looking for talented people who will put our customers at the center of everything we do. Join our diverse and inclusive team where you’ll feel valued and inspired to contribute your unique skills and experience.\\nHelp us build a better Wells Fargo. It all begins with outstanding talent. It all begins with you.\\nEnterprise Finance drives financial management for the company and maintains and enhances risk and financial controls. Key functions within Enterprise Finance include finance and accounting; Treasury; corporate development, mergers, and acquisitions; Data Management and Insights, the Customer Remediation Center of Excellence, Enterprise Shared Services, Business Process Management, and Corporate Strategy. Enterprise Finance informs shareholders, regulators, taxing authorities, team members, and leaders of the company’s financial performance through earnings releases, investor meetings and conferences, and meetings with regulators and credit rating agencies, following appropriate reporting guidelines. They also maintain and enhance risk and financial controls and lead many of the company’s shared services functions including corporate properties, security, and global services.\\nAs part of the newly formed AI Model Development COE in Enterprise Analytics and Data Science (EADS), which focuses on building, implementing, and monitoring AI models for the enterprise, the AI model development team for personalization, Virtual Channels, and virtual channels is looking for an experienced AI leader to manage the development of AI models for Virtual Channels.\\n\\nThis leader will be responsible for building and managing a team of data scientists to design, develop, and implement AI models focused on Virtual Channels’ AI priorities. Partnering with Wells Fargo AI technology team, Wells Fargo AI business solution team, and Virtual Channels executives, you and your team will deliver and deploy AI models on the Well Fargo AI open source platform to scale these solutions and embed them in our operational processes.\\n\\nKEY RESPONSIBILITIES INCLUDE:\\nBuild and grow a team of data scientists responsible for AI model development in support of Virtual Channels\\nDesign, develop, and deploy AI models using state of the art AI techniques available in the open stack and/or vendor solutions\\nPartner with Virtual Channels executives to frame the problem, manage the model development process, and business relationship\\nManage a portfolio of the data science projects including the following responsibilities:\\nHelp finalize project scope working with business partners\\nOn-going touch-base with business partners and governance stakeholders\\nDefine priorities in partnership with the business partners during on-going development\\nWork with AI technology and production teams to operationalize models\\nWill be called upon to review vendor models and solutions and/or models developed outside of EADS\\nDivisional Information:\\nData Management and Insights (DMI) is transforming the way that Wells Fargo uses and manages data. Our work enables Wells Fargo to empower and inform our team members, deliver exceptional experiences for our customers, and meet the elevated expectations of our regulators. The team is responsible for designing the future data environment, defining data governance and oversight, and partnering with technology to operate the data infrastructure for the company. This team also provides next generation analytic insights to drive business strategies and help meet our commitment to satisfy our customers’ financial needs.\\nAs a Team Member Manager, you are expected to achieve success by leading yourself, your team, and the business. Specifically you will:\\nLead your team with integrity and create an environment where your team members feel included, valued, and supported to do work that energizes them.\\nAccomplish management responsibilities which include sourcing and hiring talented team members, providing ongoing coaching and feedback, recognizing and developing team members, identifying and managing risks, and completing daily management tasks.\\n\\nRequired Qualifications\\n\\n8+ years of experience in analytics, modeling, or a combination of both\\n6+ years of management experience; or 6+ years of leadership experience in an advanced quantitative analytics function\\nA Master's degree or higher\\n5 + years of experience using quantitative machine learning techniques\\n\\n\\nDesired Qualifications\\n\\nStrong analytical skills with high attention to detail and accuracy\\nAbility to work and influence successfully within a matrix environment and build effective business partnerships with all levels of team members\\nMeeting facilitation experience in leading discussions that result in consensus and commitment\\n\\n\\nOther Desired Qualifications\\n4+ years managing or directing data scientist/ statistician/ data engineer teams\\nHands on experience with deep learning toolkits such as Tensorflow, Keras, PyTorch, Dynet\\nDetail oriented. Experience with model governance requirements. Able to de-mystify AI models to make them transparent and explainable\\nExperience with agile project management methodologies for data science\\nExperience with Big Data or Hadoop tools such as Spark, Hive, Kafka and Map\\n\\nStreet Address\\nNC-Charlotte: 401 S Tryon St - Charlotte, NC\\nMN-Minneapolis: 600 S 4th St - Minneapolis, MN\\nNC-Charlotte: 11625 N Community House Road - Charlotte, NC\\nSC-Fort Mill: 3480 State View Blvd - Fort Mill, SC\\nTX-Addison: 5080 Spectrum Dr - Addison, TX\\nTX-DAL-Downtown Dallas: 1445 Ross Ave - Dallas, TX\\nTX-Irving: 5000 Riverside Drive - Irving, TX\\nAZ-Tempe: 1150 W Washington St - Tempe, AZ\\nIA-Des Moines: 6200 Park Ave - Des Moines, IA\\nIA-Des Moines: 800 Walnut St - Des Moines, IA\\nGA-Atlanta: 3579 Atlanta Ave - Atlanta, GA\\n\\n\\nDisclaimer\\n\\nAll offers for employment with Wells Fargo are contingent upon the candidate having successfully completed a criminal background check. Wells Fargo will consider qualified candidates with criminal histories in a manner consistent with the requirements of applicable local, state and Federal law, including Section 19 of the Federal Deposit Insurance Act.\\n\\nRelevant military experience is considered for veterans and transitioning service men and women.\\n\\nWells Fargo is an Affirmative Action and Equal Opportunity Employer, Minority/Female/Disabled/Veteran/Gender Identity/Sexual Orientation.\\n\\nENT FINANCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Senior Big Data Engineer</td>\n",
       "      <td>Alpharetta, GA</td>\n",
       "      <td>Alpharetta</td>\n",
       "      <td>GA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nA bachelor's degree or related field with at least 3 – 8 years of experience with Big Data or Hadoop tools such as Spark, Hive, Kafka and MapReduce, Spark, R, Python\\nExperience working within a Linux computing environment, and use of command line tools including knowledge of shell/Python scripting for automating common tasks\\nExperience in AI/ML on big data platforms preferred:\\nSlid applied statistics skills, such as identifying distributions, statistical testing, regression, etc.\\nPrficiency querying both structured and unstructured data\\nExperience with Pythn and Deep Learning packages (Keras, Tensorflow, mxnet) and NLP packages (nltk, spacy) is a plus\\nExperience deplying models in production environments\\nStrong experience in System Integration, Application Development or Data-Warehouse projects, across technologies used in the enterprise space\\nHands-on experience with Apache Spark and its components (Streaming, SQL, MLLib) is a strong advantage\\nExcellent written and oral communication skills; must be able to effectively articulate technical concepts to non-technical audiences\\nSoftware development experience using:\\nDatabase prgramming using any flavor of SQL\\nExpertise in relatinal and dimensional modelling</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nUnderstand problems from a client's point of view, build and execute solid analytics work plans, gather and organize large and complex data sets, perform relevant analyses (data exploration and statistical modeling), manage priorities and deadlines, foster teamwork in interactions, develop client relationships with client counterparts, and communicate hypotheses and findings in a structured way\\nPartner with business teams in identifying business requirements and developing advanced analytical solutions to complex problems by utilizing statistical models and machine learning techniques and algorithms</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Company Overview\\nFractal Analytics is a strategic AI partner to Fortune 500 companies with a vision to power every human decision in the enterprise. Fractal is building a world where individual choices, freedom, and diversity are the greatest assets. An ecosystem where human imagination is at the heart of every decision. Where no possibility is written off, only challenged to get better. We believe that a true Fractalite is the one who empowers imagination with intelligence.\\nWe are seeking for a strong candidate with advanced analytics experience to fill an exciting Big Data Engineer position, in Alpharetta, GA. In this role, you will be a valuable expert and will help design and build analytics methodologies, solutions, and products to deliver value to our clients in collaboration with cross-functional teams. As an exceptional candidate, you will show an analytical curiosity.\\nResponsibilities\\nUnderstand problems from a client's point of view, build and execute solid analytics work plans, gather and organize large and complex data sets, perform relevant analyses (data exploration and statistical modeling), manage priorities and deadlines, foster teamwork in interactions, develop client relationships with client counterparts, and communicate hypotheses and findings in a structured way\\nPartner with business teams in identifying business requirements and developing advanced analytical solutions to complex problems by utilizing statistical models and machine learning techniques and algorithms\\nQualifications\\nA bachelor's degree or related field with at least 3 – 8 years of experience with Big Data or Hadoop tools such as Spark, Hive, Kafka and MapReduce, Spark, R, Python\\nExperience working within a Linux computing environment, and use of command line tools including knowledge of shell/Python scripting for automating common tasks\\nExperience in AI/ML on big data platforms preferred:\\nSlid applied statistics skills, such as identifying distributions, statistical testing, regression, etc.\\nPrficiency querying both structured and unstructured data\\nExperience with Pythn and Deep Learning packages (Keras, Tensorflow, mxnet) and NLP packages (nltk, spacy) is a plus\\nExperience deplying models in production environments\\nStrong experience in System Integration, Application Development or Data-Warehouse projects, across technologies used in the enterprise space\\nHands-on experience with Apache Spark and its components (Streaming, SQL, MLLib) is a strong advantage\\nExcellent written and oral communication skills; must be able to effectively articulate technical concepts to non-technical audiences\\nSoftware development experience using:\\nDatabase prgramming using any flavor of SQL\\nExpertise in relatinal and dimensional modelling\\nNice to Have:\\nOperating knowledge of cloud computing platforms (AWS, especially EMR, EC2, S3, SWF services and the AWS CLI)\\nExperience building recommendation engines (both offline and online validation metrics)\\nz8yMgRjHjP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sr. Data Engineer</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Qualifications: 7 – 10 (3 years min relevant experience in the role) years experience, Bachelor’s Degree.Must have experience in Software Engineering Techniques, Software Engineering Architecture, Software Engineering Lifecycle and Data Management.Should be proficient in Business Analysis, Business Knowledge, Software Engineering Leadership, Architecture Knowledge and Technical Solution Design.</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Must Have qualifications: Top tier consultant firm experience 8-10 years building products and architecting solutions. Experience advising clients on Data Modernization initiatives. Ability to deal with structured, semi-structured, unstructured and streaming data. Ability to lead proofs-of-concepts and then effectively transition and scale those concepts into production at scale through, engineering, deployment and commercialization. Serve as an expert; envision and integrate emerging data technologies, anticipate new trends to solve complex business and technical problems. Experience in sales, pre-sales functions, leading pursuits, proposal development, and statement of works. Ability to work in the United States without visa sponsorship now or in the future\\n\\nTECHNICAL REQUIREMENTS:\\n Experience designing, developing, optimizing and troubleshooting complex data-intensive applications using Spark, HDFS, Kafka, MapReduce, MongoDB and other big data related technologies. Must know PySpark, Python and SQL; comfortable with Java and/or Scala. Comfortable designing and implementing data warehouse and pipelines—such as ETL, data integration, and streaming—to support teams focused in Analytics. Experienced in AWS or/and Azure Cloud Platform. Ability to engineer for performance, scalability, latency, &amp; reliability. DevOps and automation experience highly desired\\nCandidates should be flexible / willing to work across this delivery landscape which includes and not limited to Agile Applications Development, Support and Deployment.\\nApplicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Capgemini.\\n\\nQualifications\\n\\nResponsible for programming and software development using various programming languages and related tools and frameworks, reviewing code written by other programmers, requirement gathering, bug fixing, testing, documenting and implementing software systems. Experienced programmers are also responsible for interpreting architecture and design, code reviews, mentoring, guiding and monitoring programmers, ensuring adherence to programming and documentation policies, software development, testing and release.\\n\\nRequired Skills and Experience:\\n\\nYou assign, coordinate, and review work and activities of programming personnel. Collaborate with computer manufacturers and other users to develop new programming methods. Supervise, train, mentor junior level programmers in programming and program coding. Represent team in project meetings. Work with business and functional analysts, and software &amp; solution architects in ensuring that programs and systems function as intended Supervise, mentor and manage large teams of programmers in one or more projects. Represent project teams in project/program meetings or in meetings with sponsor.\\nQualifications: 7 – 10 (3 years min relevant experience in the role) years experience, Bachelor’s Degree.Must have experience in Software Engineering Techniques, Software Engineering Architecture, Software Engineering Lifecycle and Data Management.Should be proficient in Business Analysis, Business Knowledge, Software Engineering Leadership, Architecture Knowledge and Technical Solution Design.\\n\\nCapgemini is an Equal Opportunity Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.\\nThis is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.\\n\\nClick the following link for more information on your rights as an Applicant - http://www.capgemini.com/resources/equal-employment-opportunity-is-the-law\\n\\n\\nAbout Capgemini\\n\\nA global leader in consulting, technology services and digital transformation, Capgemini is at the forefront of innovation to address the entire breadth of clients’ opportunities in the evolving world of cloud, digital and platforms. Building on its strong 50 year heritage and deep industry-specific expertise, Capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations. Capgemini is driven by the conviction that the business value of technology comes from and through people. It is a multicultural company of 200,000 team members in more than 40 countries. The Group reported 2018 global revenues of EUR 13.2 billion.\\n\\nVisit us at www.capgemini.com. People matter, results count.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Senior Big Data Data Engineer</td>\n",
       "      <td>Alpharetta, GA 30022</td>\n",
       "      <td>Alpharetta</td>\n",
       "      <td>GA</td>\n",
       "      <td>30022</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>What you’ll be doing...\\nLooking for a Senior Data Engineer to work with a small team responsible for building, deploying, and supporting a Big Data solution that will enable operations for a large enterprise environment. Must be able to design, build and maintain Enterprise Level Data Pipe-Lines utilizing the tools available within Big Data Eco-System. As a Senior Big Data Engineer - You will work on Advanced Analytics using Big Data technologies such as Hadoop and Data Warehousing.\\nBuild analytical solutions to enable Data Scientist by manipulating large data sets and integrating diverse data sources.\\nPerform ad-hoc analysis and develop reproducible analytical approaches to meet business requirements.\\nPerform exploratory and targeted data analyses using descriptive statistics and other methods.\\nUse complex algorithms to develop systems &amp; applications that deliver business functions or architectural components.\\nTypical duties will include the following:\\nWork closely with the data scientists, and database and systems administrators to create data solutions.\\nFollow best practices on design and implementation to aid in company-wide data governance.\\nImprove existing data pipelines by simplifying and increasing performance.\\nDesign, build, and deploy new data pipelines within Big Data Eco-Systems.\\nDocuments new/existing pipelines, Data Sets and Data Sets.\\nAbides by department development standards and SOP's.\\nAttends all department meetings.\\nAll other duties as assigned.\\nKeeps updated on latest technologies relevant to position’s duties.\\nHas great knowledge of commonly used software concepts and design.\\nGreat knowledge of the development lifecycle.\\nKeeps management updated on projects and assigned work.\\nWhat we’re looking for...\\nYou will need to have:\\nBachelor’s degree or four or more years of work experience.\\nSix or more years of relevant work experience.\\nEven Better If You Have:\\nA Degree.\\nExperience of designing, building, and deploying production-level data pipelines using tools from Hadoop stack (HDFS, Hive, Spark, HBase, Kafka, NiFi, Oozie, Splunk etc).\\nExperience with various noSQL databases (Hive, MongoDB, Couchbase, Cassandra, and Neo4j).\\nExperience with analytic or feature engineer programming (python or scala or java).\\nExperience implementing open source frameworks &amp; exposure to various open source &amp; package software architectures (AngularJS, ReactJS, Node, Elasticsearch, Spark, Scala, Splunk, Apigee, and Jenkins etc.).\\nExperience troubleshooting JVM-related issues.\\nExperience with SQL databases and Change Data Capture.\\nExperience and strategies to deal with mutable data in Hadoop.\\nExperience with Stream sets.\\nExperience of Agile and DevOps methodologies.\\nExperiencewithjudgment to plan and accomplish goals.\\nWorks under general supervision.\\nExperience in full development life cycle and significant experience in delivering applications and architecture services.\\nExperience in data visualization tools like Kibana, Grafana, Tableau and associated architectures.\\nExperience evaluating and implementing cutting-edge digital technologies.\\nExperience with Cloud technologies (AWS, GCP, PCF, Docker, Kubernetes and application migration.\\nWhen you join Verizon...\\nYou’ll have the power to go beyond – doing the work that’s transforming how people, businesses and things connect with each other. Not only do we provide the fastest and most reliable network for our customers, but we were first to 5G - a quantum leap in connectivity. Our connected solutions are making communities stronger and enabling energy efficiency. Here, you’ll have the ability to make an impact and create positive change. Whether you think in code, words, pictures or numbers, join our team of the best and brightest. We offer great pay, amazing benefits and opportunity to learn and grow in every role. Together we’ll go far.\\nEqual Employment Opportunity\\nWe're proud to be an equal opportunity employer- and celebrate our employees' differences,including race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, and Veteran status. Different makes us better.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Lead Data Engineer</td>\n",
       "      <td>Atlanta, GA 30309</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>30309</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Previous management experience and successfully leading a team of direct reports\\nProven track record of effectively leading and managing employees, managing performance, setting goals for team/individuals and provide mentoring.\\nStrong Tableau, Adobe Analytics other BI solution\\nExpert Oracle and Vertica skillsets\\nExperience using JIRA and Agile Project Management software\\nExperience using GitHub, Bit Bucket, or other code repository solution\\nStrong written, verbal communication and presentation skills\\nAbility to explain complex technical issues in a way that non-technical people may understand\\nAble to work in a global, multicultural environment\\nSelf-motivated. Capable of working with little or no supervision\\nAbility to react positively under pressure to meet tight deadlines\\nAble to work independently or as a team player\\nEnjoy challenging and thought provoking work and have a strong desire to learn and progress</td>\n",
       "      <td>Work with development teams and other project leaders/stakeholders to provide technical solutions that enable business capabilities\\nSupports the data science community by enabling data availability in environments that provide advanced analytical capabilities\\nMaintains a broad understanding of implementation, integration, and inter-connectivity issues with emerging technologies to define data strategies\\nAssist in the decision-making process related to the selection of software architecture solutions\\nImplement architectures to handle web-scale data and its organization\\nExecute strategies that inform data design and architecture partnering with enterprise standard\\nBuild robust data pipelines on public Cloud using AWS Kinesis, Kafka, Lambda or other technologies\\nAssist in creating documents that ensure consistency in development across the online organization. Implements and improves core software infrastructure\\nDeep expertise in SQL language, Python, Hadoop ecosystem and/or Spark ecosystem. Strong experience with writing complex programs, implementing architectures, and enabling automation in these environments\\nDevelop and maintain business reporting, ensuring reliability and performance, delivery of performance management tools (such as control charts and scorecards), readiness and adoption of data w/in the organization\\nConsolidate, standardize and control changes to capacity management data and metric definitions, ownership, accountability and taxonomy to ensure alignment in understanding\\nServe as strong advocate to improve analytical capability across the organization\\nCommunicate with various business areas and to gather and prioritize their business requirements\\nSupport various reporting and BI solutions (Tableau, Power BI, Salesforce Einstein)\\nManage application and data integration platforms (Informatica, Talend)\\nManage the full life cycle of development/reporting/integration projects: planning, design, develop, testing and rollout\\nManage solution providers, define sourcing approach and manage the providers\\nCreate and manage data, applications and technology architecture documentation and design artifacts\\nWork across teams to deliver meaningful reference architectures that outline architecture principles and best practices for technology advancement\\nGain adoption of architecture processes, standards and procedures</td>\n",
       "      <td>\\nBS in Computer Science, Applied Mathematics, Physics, Statistics or area of study related to data sciences and data mining or relevant experience</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Invesco is one of the world’s leading global investment managers, entrusted with managing $1.2 trillion* in assets on behalf of clients worldwide. We are the 6th largest US retail asset manager and the 13th largest investment manager globally, and our more than 8,000 employees worldwide are dedicated to delivering an investment experience that helps people get more out of life. We are purely focused on managing a comprehensive range of active, passive and alternative investment capabilities, which we draw on to provide customized solutions aligned to client needs, our most important benchmark. (*As of May 31,2019)\\n\\nJob Purpose (Job Summary):\\n\\nAs a Team Lead at Invesco, you would align business outcomes to technology goals and objectives. You will be responsible for managing decision sciences and advanced analytics initiatives, data integration/engineering. Interacts with Data Scientists, Business Owners, Business Data Analysts, Data Modelers, Architects, and Application Developers, to design, build and manage large-scale batch and real-time data pipelines utilizing various data analytics processing frameworks in support of Data Science practice. The position requires building strong technical hands-on-skills and experiences as well as establishing close business relationships across the enterprise. Working closely with marketing and sales stakeholders, you will establish and drive long term advance analytics roadmap manage increasing demands for advance analytics in Sales and Marketing. You will help steer the strategic technology direction, define target state architecture, technology roadmaps and mentor others. A successful candidate must have a demonstrable background with experience in development of high performance, distributed computing tasks using Big Data technologies such as Hadoop (platform level), NoSQL, text mining and other distributed environment technologies based on the needs of the organization. Responsible for analyzing, designing, programing, debugging and modifying software enhancements and/or new products used in distributed, large scale analytics solutions. Strong visualization skills and experience with BI tools (ex. Tableau)\\n\\nKey Responsibilities / Duties:\\nWork with development teams and other project leaders/stakeholders to provide technical solutions that enable business capabilities\\nSupports the data science community by enabling data availability in environments that provide advanced analytical capabilities\\nMaintains a broad understanding of implementation, integration, and inter-connectivity issues with emerging technologies to define data strategies\\nAssist in the decision-making process related to the selection of software architecture solutions\\nImplement architectures to handle web-scale data and its organization\\nExecute strategies that inform data design and architecture partnering with enterprise standard\\nBuild robust data pipelines on public Cloud using AWS Kinesis, Kafka, Lambda or other technologies\\nAssist in creating documents that ensure consistency in development across the online organization. Implements and improves core software infrastructure\\nDeep expertise in SQL language, Python, Hadoop ecosystem and/or Spark ecosystem. Strong experience with writing complex programs, implementing architectures, and enabling automation in these environments\\nDevelop and maintain business reporting, ensuring reliability and performance, delivery of performance management tools (such as control charts and scorecards), readiness and adoption of data w/in the organization\\nConsolidate, standardize and control changes to capacity management data and metric definitions, ownership, accountability and taxonomy to ensure alignment in understanding\\nServe as strong advocate to improve analytical capability across the organization\\nCommunicate with various business areas and to gather and prioritize their business requirements\\nSupport various reporting and BI solutions (Tableau, Power BI, Salesforce Einstein)\\nManage application and data integration platforms (Informatica, Talend)\\nManage the full life cycle of development/reporting/integration projects: planning, design, develop, testing and rollout\\nManage solution providers, define sourcing approach and manage the providers\\nCreate and manage data, applications and technology architecture documentation and design artifacts\\nWork across teams to deliver meaningful reference architectures that outline architecture principles and best practices for technology advancement\\nGain adoption of architecture processes, standards and procedures\\nWork Experience / Knowledge:\\n7+ years of experience in data modeling, data warehousing, and big data architectures\\n5+ years of experience in a data engineering role\\nProficient in application/software architecture (Definition, Business Process Modeling, etc.)\\nDeep expertise in (at least one) SQL language, Python, Hadoop ecosystem and/or Spark ecosystem. Strong experience with writing complex programs, implementing architectures, and enabling automation in these environments\\nThe role will be responsible for providing innovative operational solutions and best practices\\nAdvanced knowledge in SQL/Hive, Spark, NoSQL, (Java/Python is a plus)\\nStrong programming skills and ability to utilize a variety of software/languages/tools; e.g., Spark, R, Python, Scala, Java, Hive, SQL, SAS, Tableau, etc.\\nExperience with microservice development, Docker, Kubernetes\\nDevelop software to run on cloud native big data infrastructure built on AWS using Spark, Lambda, S3, and other cloud native services\\nDesigns and develops complex and large-scale data structures and pipelines to organize, collect and standardize data to generate insight\\n3+ years of experience in data integration platforms (Informatica, Talend)\\nStrong analytics and reporting skills – hands on experience in BI Tools like Tableau, Power BI, Salesforce Einstein\\nHands on experience in self-service data preparation tool like Alteryx\\nExperience using GitHub, Bit Bucket, or other code repository solution\\nDevOps experience is a plus\\nSkills / Other Personal Attributes Required:\\nPrevious management experience and successfully leading a team of direct reports\\nProven track record of effectively leading and managing employees, managing performance, setting goals for team/individuals and provide mentoring.\\nStrong Tableau, Adobe Analytics other BI solution\\nExpert Oracle and Vertica skillsets\\nExperience using JIRA and Agile Project Management software\\nExperience using GitHub, Bit Bucket, or other code repository solution\\nStrong written, verbal communication and presentation skills\\nAbility to explain complex technical issues in a way that non-technical people may understand\\nAble to work in a global, multicultural environment\\nSelf-motivated. Capable of working with little or no supervision\\nAbility to react positively under pressure to meet tight deadlines\\nAble to work independently or as a team player\\nEnjoy challenging and thought provoking work and have a strong desire to learn and progress\\nFormal Education: (minimum requirement to perform job duties)\\nBS in Computer Science, Applied Mathematics, Physics, Statistics or area of study related to data sciences and data mining or relevant experience\\nFLSA (US Only): Exempt\\n\\nThe above information on this description has been designed to indicate the general nature and level of work performed by employees within this role. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications required of employees assigned to this job. The job holder may be required to perform other duties as deemed appropriate by their manager from time to time.\\n\\nInvesco's culture of inclusivity and its commitment to diversity in the workplace are demonstrated through our people practices. We are proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, creed, color, religion, sex, gender, gender identity, sexual orientation, marital status, national origin, citizenship status, disability, age, or veteran status. Our equal opportunity employment efforts comply with all applicable U.S. state and federal laws governing non-discrimination in employment.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Senior Digital Lead Data Engineer</td>\n",
       "      <td>Atlanta, GA 30309</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>30309</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Exceptional interpersonal skills, including teamwork, facilitation, and negotiation.\\nCommunicates IT requirements and guidelines to vendor partners.\\nApplies multiple technical solutions to business problems.\\nQuickly comprehends the functions and capabilities of new technology.\\nExcellent written and oral communications skills.</td>\n",
       "      <td>Design and work with Agile teams to implement highly scalable Enterprise approaches for metadata, taxonomy, tagging, folder structures providing the lightweight controls to ensure sustainable data quality and efficiencies\\nDefines non-functional requirements including data cleansing and validation\\nMentors and coaches other members of the agile and\\or Run team\\nInterfaces with the Product Owner and Technology partners at the Program level to define and estimate features for agile teams\\nWorks within the SAFe Agile framework and employs ITIL best practices\\nClient-facing, senior strategic support\\nContent assessment. Providing content revision/creation recommendations that help the business and its customers achieve their goals (based on brand documentation, competitive assessments, audience segmentation, SEO data, and site metrics)\\nGenerating and/or overseeing an inventory of relevant client content assets\\nCreating and/or reviewing site structure and nomenclature for the most intuitive presentation of content, usually partnering with UX\\nCreating taxonomy and tagging strategies\\nEnsuring content is structured properly for any relevant backend systems including CMS, DAM, eCommerce and/or PIM\\nContributing to technical system evaluations (such as CMS, DAM, and/or PIM) from a content perspective in terms of requirements\\nEstablishing and/or maintaining editorial standards and accuracy/quality of content\\nOverseeing content migration and creating or reviewing associated documentation\\nContributing to definition and management of, as well as periodic updates to, content governance and workflow (including content creation, content entry, publication, and decommission) as well as localization strategies\\nResponsible for management of, as well as periodic updates to, personalization and content tagging strategies for the site\\nAssists in production support and maintenance of applications as needed</td>\n",
       "      <td>\\nBachelor's degree in English, Library Science, Journalism, Technical Writing, Marketing or equivalent military experience preferred</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Invesco is one of the world's leading global investment managers, entrusted with managing $1.2 trillion* in assets on behalf of clients worldwide. We are the 6th largest US retail asset manager and the 13th largest investment manager globally, and our more than 8,000 employees worldwide are dedicated to delivering an investment experience that helps people get more out of life. We are purely focused on managing a comprehensive range of active, passive and alternative investment capabilities, which we draw on to provide customized solutions aligned to client needs, our most important benchmark. (*As of May 31,2019)\\n\\nAbout Invesco Technology\\nAt Invesco Technology, we are strategic problem solvers. Our mission is to create world-class technology solutions to enable global operations, lead in the innovative use of data and emerging technologies to redefine the investment experience, and help our clients “get more out of life.\" This mission is fueled by our high-performing teams, which thrive on collaboration, operate on shared trust, and leverage diversity of thought to deliver valuable results every day to Invesco, clients, and partners.\\n\\nWe wholeheartedly believe that our success is driven by our people. That is why we invest heavily in our top talent, providing opportunities for continuous learning and professional development. Our employees are encouraged and supported in taking advantage of development opportunities tied to their goals and are recognized for employing new skills to make an impact beyond the scope of their daily roles.\\n\\nTo continue building our high-performing, OneTech Team, we are seeking candidates who champion innovation, operate effectively in an agile environment, challenge the status quo and are empowered to take risks.\\n\\nJob Purpose (Job Summary):\\n\\nJoin us in realizing Invesco's Digital Transformation! We are on a journey to reimagine what is into what could be. Think of us as like a tribe of digital activists who focus disruptive innovation who believe that digital operations in Investment Management can be done better. We have MASSIVE aspirations however we are focused on four goals:\\nStreamline content capture across the enterprise and create a one source of truth\\nFully exploit the tremendous re-use potential through seamless accessibility to content\\nProvide Invesco with a highly scalable and dynamic platform that enables rapid growth\\nTo shake-up the norm by developing new digital operating models to create a \"new world order\"\\nOur vision is simple. To create strategic advantage by being the best at digital operations. We are highly motivated, not your usual financial services stereotype, and thrive within an industry resistant to change. As a team we respect and trust each other and celebrate our successes AND failures. Welcome to the new world order!\\nRight now, we are transforming the way we operate and to that note, we are looking for a super-strong and super-passionate Digital Lead Data Engineer. In our digital transformation, data is key. In this role, you will build technical solutions to help improve the scalability and performance of our data stores and our overall systems. As a Lead Engineer, you will focus on efforts that will provide increased flexibility and accessibility to our data, such as our cloud-based data lake and digital pipeline initiatives.\\nThe Digital Lead Data Engineer acts as a senior level technical and functional expert, collaborating with business and Tech stakeholders at all levels to identify architectural solution options and map value streams. This position is responsible for using data engineering practices and techniques to deliver measurable business outcomes in a large-scale, complex organization.\\n\\nKey Responsibilities / Duties:\\nDesign and work with Agile teams to implement highly scalable Enterprise approaches for metadata, taxonomy, tagging, folder structures providing the lightweight controls to ensure sustainable data quality and efficiencies\\nDefines non-functional requirements including data cleansing and validation\\nMentors and coaches other members of the agile and\\or Run team\\nInterfaces with the Product Owner and Technology partners at the Program level to define and estimate features for agile teams\\nWorks within the SAFe Agile framework and employs ITIL best practices\\nClient-facing, senior strategic support\\nContent assessment. Providing content revision/creation recommendations that help the business and its customers achieve their goals (based on brand documentation, competitive assessments, audience segmentation, SEO data, and site metrics)\\nGenerating and/or overseeing an inventory of relevant client content assets\\nCreating and/or reviewing site structure and nomenclature for the most intuitive presentation of content, usually partnering with UX\\nCreating taxonomy and tagging strategies\\nEnsuring content is structured properly for any relevant backend systems including CMS, DAM, eCommerce and/or PIM\\nContributing to technical system evaluations (such as CMS, DAM, and/or PIM) from a content perspective in terms of requirements\\nEstablishing and/or maintaining editorial standards and accuracy/quality of content\\nOverseeing content migration and creating or reviewing associated documentation\\nContributing to definition and management of, as well as periodic updates to, content governance and workflow (including content creation, content entry, publication, and decommission) as well as localization strategies\\nResponsible for management of, as well as periodic updates to, personalization and content tagging strategies for the site\\nAssists in production support and maintenance of applications as needed\\n\\nWork Experience / Knowledge:\\nMinimum 8+ years' experience in digital content strategy or similar\\nAgency or consulting experience a plus\\nProven track record of Innovation and expertise in Data Engineering\\nUnderstanding of agile development methods including: core values, guiding principles, and key agile practices\\nProven ability to get stuff done, driven to see your team succeed.\\n\\nSkills / Other Personal Attributes Required:\\nExceptional interpersonal skills, including teamwork, facilitation, and negotiation.\\nCommunicates IT requirements and guidelines to vendor partners.\\nApplies multiple technical solutions to business problems.\\nQuickly comprehends the functions and capabilities of new technology.\\nExcellent written and oral communications skills.\\n\\nFormal Education: (minimum requirement to perform job duties)\\nBachelor's degree in English, Library Science, Journalism, Technical Writing, Marketing or equivalent military experience preferred\\n\\nWorking Conditions:\\nAn entrepreneurial working environment. If you can make a case for a project that helps achieve our goals or fits within our vision, we would encourage and pave the way for you to deliver it\\nA team that supports and collaborates with you\\nA fun environment that is not your typical Financial Services way-of-working\\nChallenges that will not only positively impact our organization and clients, however will also be a first in our industry\\nA competitive salary\\nTraining to further your career and development. We want you to stay progressive and relevant and therefore we will invest in you to do just that!\\n\\nFLSA (US Only): Exempt\\n\\nThe above information on this description has been designed to indicate the general nature and level of work performed by employees within this role. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications required of employees assigned to this job. The job holder may be required to perform other duties as deemed appropriate by their manager from time to time.\\n\\nInvesco's culture of inclusivity and its commitment to diversity in the workplace are demonstrated through our people practices. We are proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, creed, color, religion, sex, gender, gender identity, sexual orientation, marital status, national origin, citizenship status, disability, age, or veteran status. Our equal opportunity employment efforts comply with all applicable U.S. state and federal laws governing non-discrimination in employment.\\n\\n#Ll-SD1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Technology Spring 2020 Intern</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Opportunity Overview\\nAbout Us\\n\\nWarnerMedia is a leading media and entertainment company that creates and distributes premium and popular content from a diverse array of talented storytellers and journalists to global audiences through its consumer brands including: HBO, Warner Bros., TNT, TBS, CNN, DC Entertainment, New Line, Cartoon Network, Adult Swim, TCM, truTV and others.\\n\\nSee what it’s like to work at WarnerMedia! Discover more about the program and follow us on Instagram, Twitter and Facebook.\\n\\nWe are looking for a Big Data Engineer Intern interested in data engineering and analytics using large structured, semi-structured, and unstructured datasets. You will be part of a talented team of engineers that are tasked with making sense of the vast resource of data in the Warner Media infrastructure. In addition, as an intern, you will gain practical experience and gain new skills as a result of working in our world class media organization.\\n\\nThe Day-to-Day\\n\\nBig Data engineering at Warner Media involves one or more of the following:\\nDesigning, implementing, and improving data models, data pipelines, and metadata extractors\\nAnalyzing AWS Cloudwatch or other logs, for example, to optimize resource utilization\\nImplementing statistical measurement for A/B testing\\nThe Essentials\\nStudents enrolled in a program for computer science, information technology, analytics, math, statistics, or a related field\\nSolid grasp of programming languages (particularly Python), various operating systems (Linux, Mac, Windows), and some familiarity with public cloud platforms\\nDemonstrated ability to conduct independent research utilizing large data sets\\nStrong analytical and quantitative skills, along with curiosity, creativity, and ability to communicate\\nPassion for seeing projects through from initial conception to eventual application\\nEmpirical, detail-oriented mindset\\nSense of ownership of her/his work, working well both independently and within a small collaborative team\\nWhat’s so great about this internship?\\nAn opportunity to work with a great team that is passionate about the same thing you are!\\nNetworking opportunities to meet people that you’d like to know!\\nA speaker series that introduces you to cool executives and what they do for the best brands!\\nInternship dates are January 21, 2020 – May 8, 2020. All interns are expected to work 20 hours per week and paid competitively based on location (relocation is not provided). Participation in the internship program is reserved for students who are currently enrolled or within 6 months post-graduation. Most positions are targeted to upperclassmen and graduate students. Candidates must be qualified and available to work at the time the application is submitted. Full-time employment is not guaranteed at the end of the program.\\n\\nWarnerMedia and its subsidiaries are Equal Opportunity Employers and E-Verify users. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability, or protected veteran status.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Data Engineer (Scala, NoSQL) Corp to Corp is also fine</td>\n",
       "      <td>Alpharetta, GA</td>\n",
       "      <td>Alpharetta</td>\n",
       "      <td>GA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Job Description\\n\\nTitle : Data Engineer\\nLocation : Alpharetta, GA\\nNature of employment : Full time, Permanent position or Contract (Corp-Corp or W2) is also fine\\nJob Description:\\n6 years overall work experience\\nExpert in Scala coding.\\nExperience in designing the middle ware integration flows\\nExpert in security implementation in middle ware integration\\nExperience implementing RESTful webservices in Scala\\nExperience with NoSQL and SQL databases\\nProficiency with HTML5, CSS3, JavaScript\\nFamiliarity with modern web development frameworks, libraries and tools\\nExcellent analytical and problem solving skills\\nExcellent oral and written communication skills\\nData Transformation\\nPreparation Develop ETL scripts to harmonize, filter, aggregate, &amp; correlate data\\n\\nQualifications\\n\\nScala, NoSQL, SQL, HTML5, CSS3, JavaScript, ETL\\nAdditional Information\\n\\nAll your information will be kept confidential according to EEO guidelines.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Data Engineer - Java / Python &amp; Spark</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Qualifications: 3-7 years (2 years min relevant experience in the role) experience; Bachelor’s degreeShould be proficient in Software Engineering Techniques, Software Engineering Architecture, Software Engineering Life cycle and Data Management.Should have progressing skills on Business Analysis, Business Knowledge, Software Engineering Leadership, Architecture Knowledge and Technical Solution Design.</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Data Engineer\\nJava/Python + Spark\\nOverall experience of around 5-8 years with Data integration, data migration\\nJob description:\\nGood understanding of ETL/ELT concepts\\nHands on working experience with one of the programming languages (Java, Python)\\nExperience working with big data tools and technologies (Spark, Kafka)\\nShould be able to interpret business requirements, understand design and identify mechanism to test\\nResource should know how to figure out what should be tested, with a focus on data quality\\nExperience with data reconciliation, testing to ensure quality of migrated data.\\nUnderstanding of Cloud Architecture\\nExperience with NoSQL databases (Cassandra, Couchbase)\\nUnderstanding of Cloud Data Warehouse solutions (AWS)\\nResource must be comfortable working in an Agile environment\\n\\n\\nCandidates should be flexible / willing to work across this delivery landscape which includes and not limited to Agile Applications Development, Support and Deployment.\\n\\nApplicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Capgemini.\\n\\nQualifications\\n\\nResponsible for programming and software development using various programming languages and related tools and frameworks, reviewing code written by other programmers, requirement gathering, bug fixing, testing, documenting and implementing software systems. Experienced programmers are also responsible for interpreting architecture and design, code reviews, mentoring, guiding and monitoring programmers, ensuring adherence to programming and documentation policies, software development, testing and release.\\nRequired Skills and Experience:\\nWrite software programs using specific programming languages/platforms such as Java or MS .NET, and related tools, platform and environment. Write, update, and maintain computer programs or software packages to handle specific jobs, such as tracking inventory, storing or retrieving data, or controlling other equipment. Consult with managerial, engineering, and technical personnel to clarify program intent, identify problems, and suggest changes. Perform or direct revision, repair, or expansion of existing programs to increase operating efficiency or adapt to new requirements. Write, analyze, review, and rewrite programs, using workflow chart and diagram, and applying knowledge of computer capabilities, subject matter, and symbolic logic. Write or contribute to instructions or manuals to guide end users. Correct errors by making appropriate changes and then rechecking the program to ensure that the desired results are produced. Conduct trial runs of programs and software applications to be sure they will produce the desired information and that the instructions are correct. Compile and write documentation of program development and subsequent revisions, inserting comments in the coded instructions so others can understand the program. Investigate whether networks, workstations, the central processing unit of the system, and/or peripheral equipment are responding to a program's instructions. Prepare detailed workflow charts and diagrams that describe input, output, and logical operation, and convert them into a series of instructions coded in a computer language. Perform systems analysis and programming tasks to maintain and control the use of computer systems software as a systems programmer. Consult with and assist computer operators or system analysts to define and resolve problems in running computer programs. Perform unit testing Assist in system and user testing Fix errors and bugs that are identified in the course of testing.\\nQualifications: 3-7 years (2 years min relevant experience in the role) experience; Bachelor’s degreeShould be proficient in Software Engineering Techniques, Software Engineering Architecture, Software Engineering Life cycle and Data Management.Should have progressing skills on Business Analysis, Business Knowledge, Software Engineering Leadership, Architecture Knowledge and Technical Solution Design.\\n\\nCapgemini is an Equal Opportunity Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.\\n\\nThis is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.\\nClick the following link for more information on your rights as an Applicant - http://www.capgemini.com/resources/equal-employment-opportunity-is-the-law\\n\\nAbout Capgemini\\nA global leader in consulting, technology services and digital transformation, Capgemini is at the forefront of innovation to address the entire breadth of clients’ opportunities in the evolving world of cloud, digital and platforms. Building on its strong 50 year heritage and deep industry-specific expertise, Capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations. Capgemini is driven by the conviction that the business value of technology comes from and through people. It is a multicultural company of 200,000 team members in more than 40 countries. The Group reported 2018 global revenues of EUR 13.2 billion.\\n\\nVisit us at www.capgemini.com. People matter, results count.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Atlanta, GA 30340</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>30340</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Monthly employee social functionsOn premises gymDaily afternoon yoga stretchingFriendly</td>\n",
       "      <td>Monthly employee social functionsOn premises gymDaily afternoon yoga stretchingFriendly</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Job Description\\n\\nAccountabilities in this Role:\\nØ Develop, construct, test and maintain architectures\\nØ Data acquisition / verifies it meets business and data privacy regulations\\nØ Deploy sophisticated analytics programs, machine learning and statistical methods\\nØ Acts as primary backup for ERP (Syspro) Administration\\nØ Ownership / support of company intranet (SharePoint) along with workflows\\nØ Web Master (Website Development) / Website Support (back-end)\\n\\nQualifications\\n\\nTechnical Skills:\\nØ Understanding of object-oriented design, client-server architecture and relational database design\\nØ Knowledge of .NET Framework and ability to work with C#, ASP.NET, WCF, MVC and ADO.NET\\nØ Experience using T-SQL with the ability to write SQL queries and stored procedures\\nØ Knowledge of client-side technologies such as JavaScript, jQuery, HTML5 and CSS\\nØ Experience with Microsoft Visual Studio and SQL Server Management Studio\\nØ Experience using Team Foundation Server for source control and build management\\nØ SharePoint development experience with SharePoint 2010 / 2013\\nØ Experience with SharePoint Solutions (SharePoint Server 2013, InfoPath, Forms Services, Excel Services, Search, Workflows, Content Management, Metadata, Business Data Catalog and Web Services)\\nØ SharePoint experience including SharePoint workflows, effective use of the data view web part (DVWP), content query web part, data form web part, navigation customization, and some branding customization\\nØ Web development experience (HTML, CSS, XSL, XSLT, JavaScript, AngularJS).\\nØ Experience with SharePoint templates (site templates, list templates, master page customization)\\nØ Strong experience in a scripting language such as PowerShell\\nØ ERP system support and implementation in the finance, manufacturing and logistics arena. SYSPRO experience\\nØ Database architecture and design; optimize T-SQL code and stored procedures\\nØ SQL Server Reporting services (SSRS) to write reports not possible using SYSPRO report writer\\nØ Use Automate software to print journals and distribution reports from all SYSPRO modules then post in the GL\\nØ SYSPRO application administration with MS SQL Server administration and development\\nØ Working knowledge of Storage (SAN) platforms, specifically HP.\\nØ Understanding of Windows 2012 R2 Microsoft Hyper-V technology\\nAdditional Preferred Qualifications:\\nØ Bachelor’s degree in a computer/accounting/finance or related field.\\nØ Understands accounting, purchasing, manufacturing and distribution methodologies through an ERP system. The company uses SYSPRO.\\nØ Self-starter and requires minimal supervision, but works well in a group.\\nØ Ability to interpret what non-computer science personnel need and then develop the ideas to solve the situation.\\nAdditional Information\\n\\nThe Rewards:\\n\\nØ Fantastic, casual working environmentMonthly employee social functionsOn premises gymDaily afternoon yoga stretchingFriendly\\nØ Comprehensive benefit package401(k) with company matchExtremely competitive health insurance planVacation and Personal DaysCompany paid holidays\\n\\nAll qualified applicants will receive consideration for employment without regard to race, color, gender identity or expression, age, religion, intellectual disability, mental disability, physical disability, including but not limited to blindness, unless it is shown that such disability prevents performance of the work involved, medical condition, handicap, national origin, ancestry, sexual orientation, marital status, domestic partnership status, parental status, military status, veteran or military discharge status, source of income or housing status or any other status protected by applicable law.\\nGF Health Products, Inc. is a drug free workplace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Big Data Engineer</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Qualification: 3-7 years (2 years min relevant experience in the role) experience, Bachelor’s DegreeCertification: Should have or seeking SE Level 1Should have progressing knowledge in Business Analysis, Business Knowledge, Software Engineering, Testing, Data Management, Architecture Knowledge and Technical Solution Design</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>The big data Senior Technical person (4 to 10 years of experience) responsible for managing the full life-cycle of a Hadoop solution\\n\\nThis includes creating the requirements analysis, the platform selection, design of the technical architecture, design of the application design and development, testing, and deployment of the proposed solution\\n\\nAnalytical and problem solving skills, applied to big data domain\\n\\nGood communication skill\\n\\nWorked on Hadoop, Hive, Spark, Scala, Kafka, NiFi, Scoop, Oozie\\n\\n\\nCandidates should be flexible / willing to work across this delivery landscape which includes and not limited to Agile Applications Development, Support and Deployment.\\nApplicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Capgemini.\\nQualifications\\nSoftware Engineers perform requirements analysis. They then design, develop or maintain the physical application (components) or the application environment, based on the Software Architecture (models and principles). Activities include coding, integrating, implementing, installing or changing frameworks and standard components, or technical and functional application management. A Software Engineer also develops languages, methods, frameworks and tools, and/or undertakes activities in support of server-based databases in development, test and production environments.\\nRequired Skills and Experience:\\nYou are an experienced Software Engineer. You have received training and mastered at least one technology environment. You are good at elaborating technology areas and have an ability to position them within the scope of an overall project. You are a member of at least one community.\\nQualification: 3-7 years (2 years min relevant experience in the role) experience, Bachelor’s DegreeCertification: Should have or seeking SE Level 1Should have progressing knowledge in Business Analysis, Business Knowledge, Software Engineering, Testing, Data Management, Architecture Knowledge and Technical Solution Design\\n\\nCapgemini is an Equal Opportunity Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.\\nThis is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.\\nClick the following link for more information on your rights as an Applicant - http://www.capgemini.com/resources/equal-employment-opportunity-is-the-law\\nAbout Capgemini\\nA global leader in consulting, technology services and digital transformation, Capgemini is at the forefront of innovation to address the entire breadth of clients’ opportunities in the evolving world of cloud, digital and platforms. Building on its strong 50 year heritage and deep industry-specific expertise, Capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations. Capgemini is driven by the conviction that the business value of technology comes from and through people. It is a multicultural company of 200,000 team members in more than 40 countries. The Group reported 2018 global revenues of EUR 13.2 billion.\\nVisit us at www.capgemini.com. People matter, results count.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Lead Data Engineer</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>You are curious, persistent, logical and clever a true techie at heart. You enjoy living by the code of your craft and developing elegant solutions for complex problems. If this sounds like you, this could be the perfect opportunity to join EPAM as a Lead Data Enigneer. Scroll down to learn more about the position’s responsibilities and requirements.\\nWhat You’ll Do\\nArchitecture design of holistic Cloud data ecosystem with a focus on Google Cloud Platform capabilities and features\\nArchitecture design of Production, Staging/QA, and Development infrastructures running is 24/7 environments\\nRobust and consistent Cloud Strategy design aligned with business objectives\\nProvide guidelines for data migration approaches and techniques including ingest, store, process, analyze and explore/visualize data\\nAssistance with data migration and transformation\\nEvangelize Cloud computing expertise internally and externally to drive Cloud Adoption\\nWhat You Have\\nA degree in an associated field and/or other advanced certification along with significant experience\\nIn-depth cloud professional, competent of quickly establishing connections and credibility in how to address the business needs via design and operate cloud-based solutions\\nExperience in Agile or PMI methodology managed projects\\nExperience in enterprise applications, and big data solutions\\nExperience in platform and cloud migrations, including migration factory\\nIn-depth experience with databases and tools analysis\\nIn-depth experience with ETL tools\\nProcesses design and development for the data modeling, mining, and analysis\\nExtensive experience in methodologies and processes for large-scale databases management on-premises and cloud environment\\nIn-depth understanding and knowledge of distributed version control systems like Git\\nStrong understanding of concepts and experience with StackDriver and other cloud-based monitoring tools including application level and logging\\nNice to have\\nGoogle Cloud Certified Professional Data Engineer\\nExperience Creating automated tooling for cloud platforms\\nExperience with architecting and handling large datasets, structured and semi-structured data formats\\nExperience with streaming processing\\nExperience with messaging platforms\\nExperience with performance testing and tuning\\nExperience with GCP based security hardening including IAM, ACL, firewall rules, data traffic encryption\\nWhat We Offer\\nMedical, Dental and Vision Insurance (Subsidized)\\nHealth Savings Account\\nFlexible Spending Accounts (Healthcare, Dependent Care, Commuter)\\nShort-Term and Long-Term Disability (Company Provided)\\nLife and AD&amp;D Insurance (Company Provided)\\nEmployee Assistance Program\\nUnlimited access to LinkedIn learning solutions\\nMatched 401(k) Retirement Savings Plan\\nPaid Time Off\\nLegal Plan and Identity Theft Protection\\nAccident Insurance\\nEmployee Discounts\\nPet Insurance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>AnswerRocket is a leader in AI-powered analytics disrupting the traditional BI and analytics market. Named a Cool Vendor by Gartner, AnswerRocket is changing the way that Fortune 500 and mid-size clients make decisions everyday. Our self-service analytics platform combines machine learning with natural language generation to enable business leaders to make better, faster decisions.\\n\\nWe’re looking for a passionate Data Engineer to join our growing team. This is a great role for a Data Scientist who wants to transition into Data Engineering. You will be an experienced data wrangler who enjoys optimizing our data capabilities and building them from the ground up. You will be a key owner and thought leader in bringing our infrastructure to the next level!\\n\\nWhat You’ll Do\\n\\n\\nIngest, process, and analyze end-to-end data\\nDesign data warehouses on platforms such as AWS Redshift, Azure SQL Data Warehouse, Snowflake, and other high performance platforms\\nDesign custom ETL processes based on customer needs and their existing data sources\\nOptimize data warehouses for performance\\nContribute to the core design of data architecture, data models and schemas, and implementation plans\\nSupport regular ad-hoc data querying and analysis to better understand customer behaviors\\nCollaborate with teams across the organization to design, build and improve AnswerRocket’s AI tool and to address and predict data performance bottlenecks\\n\\nWhy We’ll Love You\\n\\n\\nBS or MS in Computer Science, Engineering, Mathematics or a related technical discipline\\nAt least 2 years of professional experience in data analysis including SQL, database modeling and design\\nA background in Data Science with an understanding of the principles of machine learning and high-availability datastores\\nProficient, or some type of experience, in the following: Python, Java, Javascript, MySQL, Amazon Redshift, and NLP pipelines\\nExperience with BI and data visualization tools\\nExcellent communication skills, particularly translating between technical and non-technical stakeholders\\nWe are unable to sponsor visas at this time - can only accept applications from US Citizens and Permanent Greencard holders.\\n\\nWhy You’ll Love Us\\n\\n\\nPremium health, dental &amp; vision coverage for Rocketeers and their families\\n401K and long-term disability insurance\\nFlexible PTO and paid parental leave to sustain energy and creativity\\nFlex Scheduling\\nWeekly chef-prepared lunches\\nFully stocked kitchen with bottomless snacks and coffee\\nEasy access to public transit including MARTA\\nComplimentary onsite gym\\nTeam outings and activities to build community\\nCasual dress all-day, everyday\\nStable startup with a fun culture and approachable leadership\\n\\nAbout AnswerRocket\\n\\nWe’re honored to have been named a Best Place to Work in Atlanta! Founded by successful technology entrepreneurs in 2013, our offices are located in metro Atlanta and include a fun work environment with the dynamic vibe of growth. Customers love what we are doing, and Gartner has recently named us a Cool Vendor in analytics.\\n\\nOur team consists of smart and creative people who are motivated by clear goals to deliver “a ha” moments to our customers. We are breaking away from tired, traditional software and are committed to delivering high quality, well-engineered solutions that fit into modern enterprises. AnswerRocket offers the opportunity to grow immensely, both personally and professionally, as we leverage the latest technology to change how companies use big data.\\n\\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, protected veteran status, or any other legally protected basis, in accordance with applicable law. We are an Equal Opportunity Employer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Senior Technical Analyst – AWS Data Engineer</td>\n",
       "      <td>Atlanta, GA 30326</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>30326</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Job Description:\\nCarter's, Inc. is the largest branded marketer in North America of apparel exclusively for babies and young children. The Company owns the Carter's and OshKosh B'gosh brands, two of the most recognized brands in the marketplace. These brands are sold in leading department stores, national chains, and specialty retailers domestically and internationally. They are also sold through more than 1,000 Company-operated stores in the United States, Canada, and Mexico and online at www.carters.com, www.oshkoshbgosh.com, and www.cartersoshkosh.ca. The Company's Just One You and Genuine Kids brands are available at Target, its Child of Mine brand is available at Walmart, and its Simple Joys brand is available on Amazon. The Company also owns Skip Hop, a global lifestyle brand for families with young children. Carter's is headquartered in Atlanta, Georgia. Additional information may be found at www.carters.com.\\nThis position will be responsible for the day to day activities and new project initiatives related to our AWS datalake that complements our Retail Merchandising and Planning systems. We have several initiatives to improve our decision support capabilities by enabling advanced analytics on our AWS datalake platform and this position will play a leading role in helping architect and implement these initiatives. Once implemented, this role will lead the effort to support and grow these capabilities alongside the business.\\nProject and Initiative Delivery - 50%\\nUtilize extensive knowledge of the AWS platform and related programming languages to contribute to the implementation of new capabilities on the AWS datalake platform\\nPlay a major role in architecting the solutions and developing the required technical components\\nProactively drive and facilitate conversations about data needs with stakeholders across the company\\nUnderstand, unify and integrate data from internal and third-party data sources using industry best practices for scalability, quality, simplicity, and maintainability\\nBuild and maintain data pipelines and ETL process\\nDesign, develop, maintain and enhance data collection procedures and analytic systems\\nSupport Daily Operations - 50%:\\nPartner with internal business and external vendors to support daily operations, problem solve and gather business and technical requirements, and implement changes\\nCreate, build, and maintain partnerships with all levels of the organization, ensuring collaboration in system changes and enhancements\\nOwnership of end-to-end data and analytical solutions including internal and third-party systems and software components\\nProvide occasional support on weekends when needed\\nRequired Experience:\\nMinimum of 5 years of work experience in system support, software implementation or IT consulting\\nMinimum of 4 years of experience architecting data analytics solutions on AWS\\nMinimum of 4 years of experience with various programming languages (Python, Java, Javascript, GLU, R, SQL, Shell scripting) required\\nMinimum of 3 years of experience managing ETL with data warehouses (AWS Redshift, Google BigQuery, etc)\\nExperience working with both structured and unstructured data. Experience building and optimizing data pipelines and big data sets\\nWork experience in Retail or CPG preferred\\nSkilled in preparing and/or presenting reports and data; Identifying trends through analysis\\nCritical Thinking with a drive for process improvement\\nStrong verbal, written and presentation communication skills\\nProficient with Microsoft Excel, Word, and Powerpoint\\nBachelors degree in an appropriate Science or Math field (MIS or CIS preferred)\\nCarters is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity, sexual orientation, national origin, genetics, disability, age, veteran status, or any other status protected by federal, state, or local law.\\nVisit https://carters.submit4jobs.com/ today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Atlanta, GA 30308</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>30308</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>8+ years of hands-on software development and database experience\\n\\n5+ years programming Python/R or equivalent data science scripting languages\\n\\n6+ years programming with Java/Scala\\n\\n4+ years developing with Hadoop, Hive/MapReduce/HDFS\\n\\n3+ years of experience with Stream Processing Frameworks such as Kafka/Spark\\n\\n5+ years of experience with Linux/Unix\\n\\n5+ years of experience with SQL\\n\\n4+ years of experience with Cassandra or equivalent NoSQL Databases\\n\\n2+ years of experience with Cloud Engineering and Deployment, Containers and Orchestration\\n\\n2+ years developing with Spring Framework: Core, Integration, MVC and SpringBoot\\n\\nStrong understanding of database design, development and data modeling\\n\\nExposure to Amazon Web Services, such as S3, Dynamo\\n\\nExperience working in an Agile/DevOps environment\\n\\nThorough knowledge of data partitioning, archival, and retention strategies\\n\\nWorking knowledge of network/transport protocols: TCP/UDP, HTTP, FTP, MQ\\n\\nExperience with Java/J2EE, Integration frameworks, JavaFX, and building API's for both external and internal consumption\\n\\nStrong written and verbal skills for communicating technical information to a technical and non-technical community\\n\\nAbility to work in a dynamic multi-team environment as well as independently\\n\\nMust be a self-driven, individual contributor, aware of Agile scrum methodology to participate in project activities\\n\\nMust have excellent communication and presentation skills in English and be equally comfortable in a deep dive technical workshop\\n\\nAbility to work with geographically dispersed teams yet deliver value\\n\\nShould have an active GitHub profile\\n\\nAuthorized to work in USA\\n\\nOther Good to have skills\\n\\nExperience working in Agile development process and deep understanding of various phases of the Software Development Life Cycle\\nExperience working in Agile development process and deep understanding of various phases of the Software Development Life Cycle\\nExperience using Source Code and Version Control systems\\nSelf-starter and a Team player who works with minimal supervision and the ability to work in a team of diverse skill sets\\nAbility to comprehend customer requests and provide the correct solution\\nDesire to resolve issues and dive into potential issues\\nWriting white papers, blogging and participation in Big Data related events and conferences are a definitive plus\\nIndividual contributor with excellent analytical skills and ability to think out of box\\nTravel: As part of project, willing to travel occasionally within US with prior notice.\\n\\nLocation: Atlanta\\n\\nAcademic Qualification\\n\\nBachelor’s degree in Computer Science or similar, advanced degree preferred with outstanding record of academic achievement\\n\\nOur culture\\n\\nWe thrive for authority. This can only be achieved by working with the best people, offering them the most challenging projects and create a continuous learning environment.\\n\\nAll this is in place so you can accelerate your career.\\n\\nWhat can you expect?\\n\\nInspiring working environment\\nThe most challenging assignments\\nTrust\\nFreedom to accelerate\\nMuch more!\\n\\nAbout Us\\n\\nXebia is a Dutch headquartered IT company which specializes in Continuous Delivery &amp; DevOps, Full Stack Agile Development, Agile Consulting &amp; Transformation, Big Data/Data Science, Mobile, Cloudification and Data Centre Automation. With core software development offices in Netherlands (Amsterdam, Hilversum), India (Delhi NCR, Bangalore, Pune), France (Paris) and U.S.(Boston, Atlanta) we employ over 1100 people worldwide!\\n\\nAtlanta is our software development hub and we are looking for smart, consultative, hands-on software developers to be a part of our exclusive team.\\n\\nXebia explores and creates new frontiers in IT. We provide innovative products and services and strive to stay one step ahead of our customers’ needs. We turn new technology trends into business advantages. As mainstream front-runners, we create new IT solutions and build the future with our customers.\\n\\nPassion for in depth technology &amp; software craftsmanship in combination with Lean, Agile and Scrum practices are Xebia's driving factors and competitive edge. True knowledge workers find Xebia to be an inspiring place to work where they are challenged by peers.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Based in our Atlanta office, we are looking for savvy Data Engineers to join our growing team of analytics experts. You will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up.\\n\\nThe Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company's data architecture to support our next generation of products and data initiatives.\\n\\nResponsibilities\\n\\n\\nCreate and maintain optimal data pipeline architecture,\\nAssemble large, complex data sets that meet functional / non-functional business requirements.\\nIdentify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.\\nBuild the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS 'big data' technologies.\\nBuild analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.\\nWork with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.\\nKeep our data separated and secure across national boundaries through multiple data centers and AWS regions.\\nCreate data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.\\nWork with data and analytics experts to strive for greater functionality in our data systems.\\n\\nQualifications\\n\\n\\nAdvanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.\\nExperience building and optimizing 'big data' data pipelines, architectures and data sets.\\nExperience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.\\nStrong analytic skills related to working with unstructured datasets.\\nBuild processes supporting data transformation, data structures, metadata, dependency and workload management.\\nA successful history of manipulating, processing and extracting value from large disconnected datasets.\\nWorking knowledge of message queuing, stream processing, and highly scalable 'big data' data stores.\\nStrong project management and organizational skills.\\nExperience supporting and working with cross-functional teams in a dynamic environment.\\nWe are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience using the following software/tools:\\nExperience with big data tools: Hadoop, Spark, Kafka, etc.\\nExperience with relational SQL and NoSQL databases, including Postgres and Cassandra.\\nExperience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.\\nExperience with AWS cloud services: EC2, EMR, RDS, Redshift\\nExperience with stream-processing systems: Storm, Spark-Streaming, etc.\\nExperience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Lead Data Engineer</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>ThoughtWorks is a global software consultancy, made up of around 4,500 passionate technologists across 15 countries. We specialize in strategy, portfolio management and product design, combined with digital engineering excellence.\\n\\nAs a Lead Data Engineer, here's what we'll be looking for you to bring:\\n\\nHands-on Engineering Leadership\\nProven track record of Innovation and expertise in Data Engineering\\nTenure in coding, architecting and delivering complex projects\\nDeep understanding and application of modern data processing technology stacks. For example Spark, Hadoop ecosystem technologies, and others\\nDeep understanding of streaming data architectures and technologies for real-time and low-latency data processing\\nDeep understanding of NoSQL technologies including column family, graph, document, and key-value data storage technologies\\nUnderstanding of how to architect solutions for data science and analytics such as productionizing machine learning models and collaborating with data scientists\\nUnderstanding of agile development methods including: core values, guiding principles, and key agile practices\\nUnderstanding of the theory and application of Continuous Integration/Delivery\\nPassion for software craftsmanship\\nA rich breadth of industry experience and background working across different organizations, ranging in size, from start-ups to large corporations..\\nStrong stakeholder management and interaction experience at different levels\\n\\n\\nThere's no typical day or engagement for our Senior Data Engineers. Here’s what you’ll do:\\n\\nBe the SME. Develop modern data architectural approaches to meet key business objectives and provide end to end data solutions\\nYou might spend a few weeks with a new client on a deep technical review or a complete organizational review, helping them to understand the potential that data brings to solve their most pressing problems.\\nOn other projects, you might be acting as the architect, leading the design of technical solutions, or perhaps overseeing a program inception to build a new product.\\nIt could be much more about getting stuck into a delivery project where you're equally happy coding and tech leading the team to implement the solution.\\nWhatever your role, the team always look to draw on your experience when things get tough and you often handle the difficult client conversations allowing the team to continue delivering without undue pressure.\\nYou have great relationships with our new business team and work collaboratively to support pre-sales, meet prospective clients and ultimately influence and shape our portfolio of work.\\nYou recognize that building your network with a client is absolutely key to enable you to perform in your role. You'll be drawing on all of your passion for technology, hands-on experience and knowledge of latest Big Data and Engineering best practices to help you gain the respect and credibility of those around you.\\n\\n\\nA few important things to know:\\nProjects are almost exclusively on customer site, so candidates should be flexible and open to extensive travel.\\n\\nCandidates must possess work authorization that does not require H-1B visa sponsorship by ThoughtWorks or dependent EAD.\\n\\nNot quite ready to apply? Or maybe this isn’t the right role for you? That’s OK, you can stay in touch with AccessThoughtWorks, our learning community (click \"contact me about recruitment opportunities\" to hear about jobs in the future).\\n\\nIt is the policy of ThoughtWorks, Inc. to provide a work environment free of discrimination. The Company will take affirmative action to ensure applicants and ThoughtWorks employees are treated without regard to race, color, religion, sex, national origin, ethnic origin, veteran status, family status, disability, sexual orientation, gender expression or gender identity. This also includes individuals who are perceived to have any of the aforementioned attributes. ThoughtWorks will adhere to all federal, state, and municipal laws and regulations governing employment.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Data Analyst III - Data Engineer</td>\n",
       "      <td>Atlanta, GA 30328</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>30328</td>\n",
       "      <td>None Found</td>\n",
       "      <td>5 or more years of experience required in related field (developing and implementing analytical solutions in Finance, Marketing, Sales or Operations). 3 or more years of experience required if candidate possesses a related advanced degree. Requires strong skills in SQL writing and query optimization. Requires experience building data workflows, manipulation of large data sets, or developing data pipelines in analytical tools such as Informatica, Alteryx, Tableau Prep, SQL, SSIS, etc. Requires strong skills and experience with reporting and data visualization in analytical tools such as Tableau, Prep, SQL, etc. Requires effective proficiency in teamwork, communication, presentation, and time management to work effectively with teams throughout organization, including strong verbal and written communication. Experience manipulating large datasets and the ability to extrapolate conclusions from the data. Demonstrated problem solving and analytical thinking skills. Excellent interpersonal, leadership, presentation, and collaborative skills to work effectively with teams throughout organization. BS/BA degree in related discipline</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Cox Communications is the largest private telecom company in America, and we proudly serve six million homes and businesses across 18 states. At Cox, we are committed to creating meaningful moments of human connection, not only with our products and services, but also with our career opportunities. Come connect with us, and lets build a better future together.\\n\\nRole Summary\\n\\nLooking for a Senior Data Analyst to join an enterprise reporting and analytics team supporting Cox Communications Enterprise Finance and Accounting as well as our business partners. This person should be comfortable in a data engineering role building data pipelines and ETL processes, have enough business acumen to understand context and intent, and apply these concepts to data solutions. This role will assist in data strategy and design, and develop data-sets for the Finance BI ecosystem to support reporting, analysis &amp; analytical modeling.\\n\\nRecognized as a Subject Matter Expert (SME) and authority on issues related to Business Intelligence applications reporting, analysis, and metrics. This person will exercise an inquisitive mindset to transform business questions into actionable data exploration exercises and data sets using data analysis, modeling, automation, and optimization techniques. Operates with considerable latitude for independent judgment. Provides influence and expertise to cross-functional teams and other stakeholders on ideas and solutions that impact corporate results.\\n\\nPrimary Responsibilities and Essential Functions\\n Supports and/or leads discussions with multidisciplinary teams to collect functional business requirements, scoping analytical projects, manage expectations and deadlines, and translate needs into technical specifications. Supports technical development of solutions to expedite delivery of new datasets, process automation, production of complex models and analyses, including gap assessments, and works to deliver strategies. Serves as an organizational consultant on matters relating to data and databases by providing expertise to assist users in meeting their needs. Initiates the identification of actionable insights and contribute to the development of business recommendations through effective presentations and communication of results. Develops processes and solutions to speed up / expedite the development of datasets, report automation, production of dashboards, complex models, and analyses. Extract and manipulate data from a variety of cloud and on-premise based systems for reporting and analytical purposes, including: Oracle databases, Essbase and data cubes, Tableau, SQL Server, and various data sources as needed. Report automation and self-service dashboard solutions using combination of tools such as SQL, Tableau, Prep, Alteryx, Informatica and Python. Develops automated processes that preserve data integrity by managing the alignment of data availability and integration processes. Expertise in creating and optimizing Tableau Datasets and Visualizations. Identifies, researches, and resolves discrepancies in an analytical procedure or cross-functional methods. Establish and maintain design and development best practices including keeping written procedures to document data processes and ensure best data governance practices are maintained. Liaises with CCI Technology/EDS partners for both data-sourcing needs and for “promotion” of data-sets into the enterprise BI layer when/as-needed. Leads data collection, cleansing, and validation. Conducts day-to-day activities with minimum supervision.\\n\\nQualifications:\\nSkills and Qualifications\\n\\nMinimum\\n 5 or more years of experience required in related field (developing and implementing analytical solutions in Finance, Marketing, Sales or Operations). 3 or more years of experience required if candidate possesses a related advanced degree. Requires strong skills in SQL writing and query optimization. Requires experience building data workflows, manipulation of large data sets, or developing data pipelines in analytical tools such as Informatica, Alteryx, Tableau Prep, SQL, SSIS, etc. Requires strong skills and experience with reporting and data visualization in analytical tools such as Tableau, Prep, SQL, etc. Requires effective proficiency in teamwork, communication, presentation, and time management to work effectively with teams throughout organization, including strong verbal and written communication. Experience manipulating large datasets and the ability to extrapolate conclusions from the data. Demonstrated problem solving and analytical thinking skills. Excellent interpersonal, leadership, presentation, and collaborative skills to work effectively with teams throughout organization. BS/BA degree in related discipline\\n\\nPreferred\\n Master's degree in a related discipline preferred Working knowledge of Tableau and/or visual analytics software tools and best practices Working knowledge of Alteryx and/or data transformation tools and best practices 3 or more years using Tableau for analysis, visualization &amp; dashboard development 3 or more years of experience in database administration and SQL, including SQL tuning/performance optimization 2 or more years of experience in Data Warehousing, ETL Development, Data Management tools such as SSIS, Informatica, Datastage, etc 1 or more years of experience using Oracle Essbase or integration with data cubes 2 or more years of experience using Alteryx for data preparation &amp; modeling 1 or more years of experience in OBIEE report and RPD development 1 or more years of experience in Java, Python or other programming or scripting languages Knowledge of Big Data querying tools, such as Pig, Hive, and Impala Experience within telecom, consumer package goods, retail, financial services, or consulting industries Operational analytics including application for Call Center, Technical Support, Collections, and Customer Experience Analytics\\n#LI-355\\n\\nAbout Cox Communications\\nCox Communications is committed to creating meaningful moments of human connection through broadband applications and services. The largest private telecom company in America, we proudly serve six million homes and businesses across 18 states. We're dedicated to empowering others to build a better future and celebrate diverse products, people, suppliers, communities and the characteristics that makes each one unique. Cox Communications is the largest division of Cox Enterprises, a family-owned business founded in 1898 by Governor James M. Cox.\\nCox is an Equal Employment Opportunity employer - All qualified applicants/employees will receive consideration for employment without regard to that individual's age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law.\\nStatement to ALL Third-Party Agencies and Similar Organizations: Cox accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Cox employees, Cox hiring manager, or send to any Cox facility. Cox is not responsible for any fees or charges associated with unsolicited resumes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Lead Big Data Engineer</td>\n",
       "      <td>Atlanta, GA 30319</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>30319</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>In some organizations Data Analytics, Data Science, Business Intelligence, and Big Data sit with different teams. We are looking for a Lead Big Data Engineer to work globally across all these areas to help support our core business function: creating the best beverage brands in the world. We care less about your knowledge of a particular technology and care more about your passion and aptitude for utilizing the right tool for the right job, even if that tool hasn't been created yet.\\nThis individual will work as a Lead Engineer coaching, mentoring, doing code review, and sharing best practices with both a team of internal and external engineering resources. He/She will also work as an individual contributor to engineer leading edge analytics solutions and platforms for big data, data science, and business intelligence reporting needs. This role will be responsible for ensuring code is well designed, efficient, and uses best software development practices to build and enhance our big data systems for scale.\\nTravel: 0-25%\\nRequired:\\n5+ years of experience working with data (analytics, science, big data, business intelligence, etc.)\\nAbility to interact and influence senior Leaders\\nExperience designing, developing and implementing traditional and emerging BI and big data information systems from end-to-end\\nBackground in data modeling and/or data mining\\nExperience leveraging cloud platforms (AWS or Azure)\\nExtensive knowledge of database management systems, online analytical processing (OLAP) and ETL (extract, transform, load) frameworks\\nExperience with NoSQL databases (Azure Cosmos DB, Document DB, Mongo DB, etc.)\\nExperience with one or more of these: PySpark, Python, Scala, Spark, Hadoop\\nExperience with one or more of the following Agile development methods: Extreme Programming (XP), Scrum, Crystal, Dynamic Systems Development Method (DSDM), Lean Development, and/or Feature-Driven Development (FDD)\\nDev/Ops experience and/or training in Dev/Ops methods and tools such as Jira, GitHub, Docker, Kubernetes, Bamboo, BitBucket\\nProven abilities to take initiative and be innovative\\nPassionate, creative and forward thinking individual\\nPreferred:\\nBachelor’s degree or higher in Computer Science or related field\\nAzure Data Factory or Informatica\\nAzure SQL DB\\nKey responsibilities:\\nCollaborate with different Corporate Technical (Supply Chain) Process owners to determine and meet their reporting and analytics needs\\nDesign and build MVP traditional BI solutions and big data solutions leveraging the data lake based on business requirements or user stories, architectural requirements, and established coding standards\\nCollaborate closely and cohesively with Technical Data Intelligence counterparts to maintain the intelligence framework, tools, datasets and standards\\nManage the process for connecting key technical data sources, explore and implement artificial intelligence technologies and drive data automation to unlock value and productivity for the Global Technical function\\nDesign and build MVP traditional BI solutions and big data solutions leveraging the data lake based on business requirements or user stories, architectural requirements, and established coding standards\\nConnect key technical data sources, explore and implement artificial intelligence technologies and drive data automation to unlock value and productivity for the Global Technical function\\nMaintain and support data analytics platforms (e.g. MS Azure BI / Analytics Platforms &amp; Tools) under Dev/Ops model\\n\\nOur Growth Culture:\\nOne of the reasons our company continues to thrive after 130+ years is having a company culture that supports and rewards behaviors that lead to growth. Our “Growth Behaviors,” as we call them, are ways of being and working that help to make us successful. Think about how you can bring this to life in your next role at Coca-Cola.\\n\\nCurious\\nKeep seeking, never settle. Staying curious about what is outside, and two steps ahead inspires us to challenge the status quo. Having the courage to look and leap is the way we grow. Because asking “what if?” pushes us to the next level as people and as a company.\\n\\nEmpowered\\nMake it happen. True empowerment is the result of taking responsibility. This means giving yourself permission to see it, say it and do it, and owning the outcomes. Because we move forward faster when we all take action.\\n\\nVersion 1.0, 2.0, 3.0\\nPush for progress, not perfection. There are very few overnight successes. Greatness is borne of many little victories (and failures). Share v 1.0, test it, and make it better. Then create the next version. Because the moment we think something is perfect, it will be obsolete.\\n\\nInclusive\\nInclude, value and trust each other. We are smart alone but together we are genius. This means being inclusive, giving the benefit of the doubt and being responsible for each other. Because, for our company to thrive for the next 100+ years, smart isn’t enough. We need genius.\\n\\nWe are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity and/or expression, status as a veteran, and basis of disability or any other federal, state or local protected class.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Duluth, GA 30097</td>\n",
       "      <td>Duluth</td>\n",
       "      <td>GA</td>\n",
       "      <td>30097</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nTechnology certifications such as Amazon Certified Solutions Architect\\nProficiency in programming in Spark, R and/or ML packages\\nExposure to applications developed to support manufacturing quality\\nExperience with MS Dynamics CRM, MicroStrategy BI tools, SAP ERP\\nConsulting experience</td>\n",
       "      <td>\\nDrive design and development of internal data pipeline architecture to service BI and Analytics capabilities\\nWork with key stakeholders including Product, Sales, Quality Engineering and Marketing to assist with data-related technical needs and support their data infrastructure needs.\\nEnsure operational resilience, stability, and scalability of our enterprise data platform by conduct continuous hardening activates that increase uptime, data quality and reduce cost\\nEnsure tight data platform security during data transport and while at rest\\nBuild hybrid cloud/prem data platform to enable self-service Business Intelligence and Analytics functions\\nConduct data profiling and analysis of complex data sets to discover how to meet functional / non-functional requirements\\nInstitute data quality monitoring and alerting platform operations\\nBuild analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics\\nDrive solutions for meta data and data lineage management\\nDrive innovation by recommending and driving adoption of new technologies that provide competitive data advantages for enterprise\\nContributes to agile team alignment and is committed to constant improvement efforts by participating in team ceremonies sprint planning, stand-ups, backlog grooming and retrospectives\\nEnsure technical delivery of detailed feature/story level solutions that satisfies the IT roadmap’s acceptance criteria\\nMaintains professional and technical knowledge by attending educational workshops; reviewing professional publications; establishing personal networks; participating in professional societies</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>The Data Engineer will be responsible for expanding and optimizing our data capabilities for Data Warehousing, Master Data, Data Services as well as Business Intelligence. The ideal candidate is an experienced data wrangler who enjoys optimizing data systems and can build them from the ground up. He/she must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. The ideal candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.\\nResponsibilities\\nDrive design and development of internal data pipeline architecture to service BI and Analytics capabilities\\nWork with key stakeholders including Product, Sales, Quality Engineering and Marketing to assist with data-related technical needs and support their data infrastructure needs.\\nEnsure operational resilience, stability, and scalability of our enterprise data platform by conduct continuous hardening activates that increase uptime, data quality and reduce cost\\nEnsure tight data platform security during data transport and while at rest\\nBuild hybrid cloud/prem data platform to enable self-service Business Intelligence and Analytics functions\\nConduct data profiling and analysis of complex data sets to discover how to meet functional / non-functional requirements\\nInstitute data quality monitoring and alerting platform operations\\nBuild analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics\\nDrive solutions for meta data and data lineage management\\nDrive innovation by recommending and driving adoption of new technologies that provide competitive data advantages for enterprise\\nContributes to agile team alignment and is committed to constant improvement efforts by participating in team ceremonies sprint planning, stand-ups, backlog grooming and retrospectives\\nEnsure technical delivery of detailed feature/story level solutions that satisfies the IT roadmap’s acceptance criteria\\nMaintains professional and technical knowledge by attending educational workshops; reviewing professional publications; establishing personal networks; participating in professional societies\\nMinimum Work Experience\\n8+ years of proven experience in the design, development and deployment of end-to-end data pipeline solutions including data processing (Batch, Micro-Batch, Streaming), data preparation (ETL, ELT), data modeling (STAR, OLAP, MPP)\\n5+ year of Business Intelligence Development and Administration\\nExperience of building data solutions for back office applications that source data from CRM and ERP applications\\nAdvanced experience working with SQL Server databases\\nStrong grasp of master data management, data quality monitoring and metadata management\\nProficiency in data centric shell scripting, ETL, Python, and/or .NET Programming skills\\nA comfortable and confident communicator with technical staff but also able to speak with customers concisely to translate technical concepts into business terminology and impacts\\nExposure to continuous integration implementations that utilize DevOps style tools (such as Jenkins, Chef, Docker, Terraform, etc.)\\nProven team player with the ability to multi-task in a fast-paced dynamic agile work environment\\nHas previously supported a metrics-driven data culture to drive accountability and transparency\\nPassionate problem solver and motivated self-starter including ability to analyze situation and recommend sound solutions and implementation strategies\\nAdditional Desired Skills:\\nTechnology certifications such as Amazon Certified Solutions Architect\\nProficiency in programming in Spark, R and/or ML packages\\nExposure to applications developed to support manufacturing quality\\nExperience with MS Dynamics CRM, MicroStrategy BI tools, SAP ERP\\nConsulting experience\\nEducation: Bachelor’s degree in Computer Science, Information Systems, or combination of education and experience.\\nLocation: Duluth, Georgia\\nEqual Opportunity Employer/Protected Veterans/Individuals with Disabilities\\nThe contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Lead Data Engineer, Assessment Analytics &amp; Visualization</td>\n",
       "      <td>Atlanta, GA 30309</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>30309</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Previous management experience and successfully leading a team of direct reports\\nProven track record of effectively leading and managing employees, managing performance, setting goals for team/individuals and provide mentoring.\\nStrong Tableau, Adobe Analytics other BI solution\\nExpert Oracle and Vertica skillsets\\nExperience using JIRA and Agile Project Management software\\nExperience using GitHub, Bit Bucket, or other code repository solution\\nStrong written, verbal communication and presentation skills\\nAbility to explain complex technical issues in a way that non-technical people may understand\\nAble to work in a global, multicultural environment\\nSelf-motivated. Capable of working with little or no supervision\\nAbility to react positively under pressure to meet tight deadlines\\nAble to work independently or as a team player\\nEnjoy challenging and thought provoking work and have a strong desire to learn and progress</td>\n",
       "      <td>Work with development teams and other project leaders/stakeholders to provide technical solutions that enable business capabilities\\nSupports the data science community by enabling data availability in environments that provide advanced analytical capabilities\\nMaintains a broad understanding of implementation, integration, and inter-connectivity issues with emerging technologies to define data strategies\\nAssist in the decision-making process related to the selection of software architecture solutions\\nImplement architectures to handle web-scale data and its organization\\nExecute strategies that inform data design and architecture partnering with enterprise standard\\nBuild robust data pipelines on public Cloud using AWS Kinesis, Kafka, Lambda or other technologies\\nAssist in creating documents that ensure consistency in development across the online organization. Implements and improves core software infrastructure\\nDeep expertise in SQL language, Python, Hadoop ecosystem and/or Spark ecosystem. Strong experience with writing complex programs, implementing architectures, and enabling automation in these environments\\nDevelop and maintain business reporting, ensuring reliability and performance, delivery of performance management tools (such as control charts and scorecards), readiness and adoption of data w/in the organization\\nConsolidate, standardize and control changes to capacity management data and metric definitions, ownership, accountability and taxonomy to ensure alignment in understanding\\nServe as strong advocate to improve analytical capability across the organization\\nCommunicate with various business areas and to gather and prioritize their business requirements\\nSupport various reporting and BI solutions (Tableau, Power BI, Salesforce Einstein)\\nManage application and data integration platforms (Informatica, Talend)\\nManage the full life cycle of development/reporting/integration projects: planning, design, develop, testing and rollout\\nManage solution providers, define sourcing approach and manage the providers\\nCreate and manage data, applications and technology architecture documentation and design artifacts\\nWork across teams to deliver meaningful reference architectures that outline architecture principles and best practices for technology advancement\\nGain adoption of architecture processes, standards and procedures</td>\n",
       "      <td>\\nBS in Computer Science, Applied Mathematics, Physics, Statistics or area of study related to data sciences and data mining or relevant experience</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Invesco is one of the world’s leading global investment managers, entrusted with managing $1.2 trillion* in assets on behalf of clients worldwide. We are the 6th largest US retail asset manager and the 13th largest investment manager globally, and our more than 8,000 employees worldwide are dedicated to delivering an investment experience that helps people get more out of life. We are purely focused on managing a comprehensive range of active, passive and alternative investment capabilities, which we draw on to provide customized solutions aligned to client needs, our most important benchmark. (*As of May 31,2019)\\n\\nJob Purpose (Job Summary):\\n\\nAs a Team Lead at Invesco, you would align business outcomes to technology goals and objectives. You will be responsible for managing decision sciences and advanced analytics initiatives, data integration/engineering. Interacts with Data Scientists, Business Owners, Business Data Analysts, Data Modelers, Architects, and Application Developers, to design, build and manage large-scale batch and real-time data pipelines utilizing various data analytics processing frameworks in support of Data Science practice. The position requires building strong technical hands-on-skills and experiences as well as establishing close business relationships across the enterprise. Working closely with marketing and sales stakeholders, you will establish and drive long term advance analytics roadmap manage increasing demands for advance analytics in Sales and Marketing. You will help steer the strategic technology direction, define target state architecture, technology roadmaps and mentor others. A successful candidate must have a demonstrable background with experience in development of high performance, distributed computing tasks using Big Data technologies such as Hadoop (platform level), NoSQL, text mining and other distributed environment technologies based on the needs of the organization. Responsible for analyzing, designing, programing, debugging and modifying software enhancements and/or new products used in distributed, large scale analytics solutions. Strong visualization skills and experience with BI tools (ex. Tableau)\\n\\nKey Responsibilities / Duties:\\nWork with development teams and other project leaders/stakeholders to provide technical solutions that enable business capabilities\\nSupports the data science community by enabling data availability in environments that provide advanced analytical capabilities\\nMaintains a broad understanding of implementation, integration, and inter-connectivity issues with emerging technologies to define data strategies\\nAssist in the decision-making process related to the selection of software architecture solutions\\nImplement architectures to handle web-scale data and its organization\\nExecute strategies that inform data design and architecture partnering with enterprise standard\\nBuild robust data pipelines on public Cloud using AWS Kinesis, Kafka, Lambda or other technologies\\nAssist in creating documents that ensure consistency in development across the online organization. Implements and improves core software infrastructure\\nDeep expertise in SQL language, Python, Hadoop ecosystem and/or Spark ecosystem. Strong experience with writing complex programs, implementing architectures, and enabling automation in these environments\\nDevelop and maintain business reporting, ensuring reliability and performance, delivery of performance management tools (such as control charts and scorecards), readiness and adoption of data w/in the organization\\nConsolidate, standardize and control changes to capacity management data and metric definitions, ownership, accountability and taxonomy to ensure alignment in understanding\\nServe as strong advocate to improve analytical capability across the organization\\nCommunicate with various business areas and to gather and prioritize their business requirements\\nSupport various reporting and BI solutions (Tableau, Power BI, Salesforce Einstein)\\nManage application and data integration platforms (Informatica, Talend)\\nManage the full life cycle of development/reporting/integration projects: planning, design, develop, testing and rollout\\nManage solution providers, define sourcing approach and manage the providers\\nCreate and manage data, applications and technology architecture documentation and design artifacts\\nWork across teams to deliver meaningful reference architectures that outline architecture principles and best practices for technology advancement\\nGain adoption of architecture processes, standards and procedures\\nWork Experience / Knowledge:\\n7+ years of experience in data modeling, data warehousing, and big data architectures\\n5+ years of experience in a data engineering role\\nProficient in application/software architecture (Definition, Business Process Modeling, etc.)\\nDeep expertise in (at least one) SQL language, Python, Hadoop ecosystem and/or Spark ecosystem. Strong experience with writing complex programs, implementing architectures, and enabling automation in these environments\\nThe role will be responsible for providing innovative operational solutions and best practices\\nAdvanced knowledge in SQL/Hive, Spark, NoSQL, (Java/Python is a plus)\\nStrong programming skills and ability to utilize a variety of software/languages/tools; e.g., Spark, R, Python, Scala, Java, Hive, SQL, SAS, Tableau, etc.\\nExperience with microservice development, Docker, Kubernetes\\nDevelop software to run on cloud native big data infrastructure built on AWS using Spark, Lambda, S3, and other cloud native services\\nDesigns and develops complex and large-scale data structures and pipelines to organize, collect and standardize data to generate insight\\n3+ years of experience in data integration platforms (Informatica, Talend)\\nStrong analytics and reporting skills – hands on experience in BI Tools like Tableau, Power BI, Salesforce Einstein\\nHands on experience in self-service data preparation tool like Alteryx\\nExperience using GitHub, Bit Bucket, or other code repository solution\\nDevOps experience is a plus\\nSkills / Other Personal Attributes Required:\\nPrevious management experience and successfully leading a team of direct reports\\nProven track record of effectively leading and managing employees, managing performance, setting goals for team/individuals and provide mentoring.\\nStrong Tableau, Adobe Analytics other BI solution\\nExpert Oracle and Vertica skillsets\\nExperience using JIRA and Agile Project Management software\\nExperience using GitHub, Bit Bucket, or other code repository solution\\nStrong written, verbal communication and presentation skills\\nAbility to explain complex technical issues in a way that non-technical people may understand\\nAble to work in a global, multicultural environment\\nSelf-motivated. Capable of working with little or no supervision\\nAbility to react positively under pressure to meet tight deadlines\\nAble to work independently or as a team player\\nEnjoy challenging and thought provoking work and have a strong desire to learn and progress\\nFormal Education: (minimum requirement to perform job duties)\\nBS in Computer Science, Applied Mathematics, Physics, Statistics or area of study related to data sciences and data mining or relevant experience\\nFLSA (US Only): Exempt\\n\\nThe above information on this description has been designed to indicate the general nature and level of work performed by employees within this role. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications required of employees assigned to this job. The job holder may be required to perform other duties as deemed appropriate by their manager from time to time.\\n\\nInvesco's culture of inclusivity and its commitment to diversity in the workplace are demonstrated through our people practices. We are proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, creed, color, religion, sex, gender, gender identity, sexual orientation, marital status, national origin, citizenship status, disability, age, or veteran status. Our equal opportunity employment efforts comply with all applicable U.S. state and federal laws governing non-discrimination in employment.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nYou are passionate about making a difference in the world and the impact technology can have in helping people get better faster\\nYou drive results effectively through cross functional teams\\nYou are flexible and adaptive and can adjust quickly in the face of changing situations and challenges\\nYou are disciplined and able to manage multiple responsibilities simultaneously\\nYou are a strong team player who is happy to share knowledge and mentor others to grow their skills\\nYou work effectively with minimal supervision and can be relied on to deliver on commitments effectively\\n</td>\n",
       "      <td>\\nCreate data ingestion pipelines and manage and maintain master data specification documents which reflect necessary data elements. Cleanse, analyze, and maintain incoming client data. Develop features relevant to healthcare use cases/vectors.\\nGenerate data visualizations and presentations, including the design of interactive and intuitive dashboards.\\nParticipate in process adherence and continuance through automation of workflow schedules and cyclic support to ensure stable production environment.\\n</td>\n",
       "      <td>\\nBachelor's degree in Information Technology/Computer Engineering\\n3+ years of experience in development and deployment of Big Data technologies with a focus on Data Engineering (SQL, AWS/Azure Cloud platform tools, Data handling, Shell Scripting, Airflow, Python, etc.)\\nExpertise in cloud platforms (AWS, Azure)\\nExperience in data interchange standards like EDI and HL7 is a plus\\nFamiliarity in Agile delivery framework\\nAwareness of Artificial Intelligence; data science concepts a plus\\nExperience working in healthcare setting preferred\\n</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Company Summary:\\nHeadquartered in Atlanta, Ga, Jvion is the leader in Artificial Intelligence (AI)-enabled prescriptive analytics that helps healthcare organizations lower rates of preventable harm and reduce costs. Charting the future with our proprietary solution, Jvion is partnering with healthcare organizations to empower clinicians with AI that more effectively identifies at risk patients, the factors driving that risk, and the interventions that will lead to better outcomes. As the leader in healthcare AI, Jvion is making healthcare data meaningful, bringing leading edge technology to the front lines of care, tackling socioeconomic barriers to health and ultimately improving patients' lives.\\n\\nPosition Summary:\\nAs a key member of Jvion's technology team, the Data Engineer is responsible for managing, optimizing, analyzing, overseeing, and monitoring data retrieval, storage, and distribution. This individual will prepare the \"big data\" infrastructure to be analyzed by the Jvion Machine. The Data Engineer participates as a member of technical professionals in the development, delivery and support of cutting-edge Artificial Intelligence, cloud-based prescriptive solutions to healthcare clients that deliver high levels of customer satisfaction.\\n\\nResponsibilities and Essential Functions:\\n\\nCreate data ingestion pipelines and manage and maintain master data specification documents which reflect necessary data elements. Cleanse, analyze, and maintain incoming client data. Develop features relevant to healthcare use cases/vectors.\\nGenerate data visualizations and presentations, including the design of interactive and intuitive dashboards.\\nParticipate in process adherence and continuance through automation of workflow schedules and cyclic support to ensure stable production environment.\\n\\nExperience/Education:\\n\\nBachelor's degree in Information Technology/Computer Engineering\\n3+ years of experience in development and deployment of Big Data technologies with a focus on Data Engineering (SQL, AWS/Azure Cloud platform tools, Data handling, Shell Scripting, Airflow, Python, etc.)\\nExpertise in cloud platforms (AWS, Azure)\\nExperience in data interchange standards like EDI and HL7 is a plus\\nFamiliarity in Agile delivery framework\\nAwareness of Artificial Intelligence; data science concepts a plus\\nExperience working in healthcare setting preferred\\n\\nWork Skills / Personal Characteristics:\\n\\nYou are passionate about making a difference in the world and the impact technology can have in helping people get better faster\\nYou drive results effectively through cross functional teams\\nYou are flexible and adaptive and can adjust quickly in the face of changing situations and challenges\\nYou are disciplined and able to manage multiple responsibilities simultaneously\\nYou are a strong team player who is happy to share knowledge and mentor others to grow their skills\\nYou work effectively with minimal supervision and can be relied on to deliver on commitments effectively\\n\\nJvion is proud to be an Equal Employment Opportunity employer. We do not discriminate based upon race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nYou are passionate about making a difference in the world and the impact technology can have in helping people get better faster\\nYou drive results effectively through cross functional teams\\nYou are flexible and adaptive and can adjust quickly in the face of changing situations and challenges\\nYou are disciplined and able to manage multiple responsibilities simultaneously\\nYou are a strong team player who is happy to share knowledge and mentor others to grow their skills\\nYou work effectively with minimal supervision and can be relied on to deliver on commitments effectively\\n</td>\n",
       "      <td>\\nDesign and create data ingestion pipelines and manage and maintain master data specification documents which reflect necessary data elements. Cleanse, analyze, and maintain incoming client data. Design and develop features relevant to healthcare use cases/vectors.\\nLead in generating data visualizations and presentations, including the design of interactive and intuitive dashboards.\\nLead process adherence and continuance through automation of workflow schedules and cyclic support to ensure stable production environment.\\n</td>\n",
       "      <td>\\nBachelor's degree in Information Technology/Computer Engineering\\n5+ years of experience in development and deployment of Big Data technologies with a focus on Data Engineering (SQL, AWS/Azure Cloud platform tools, Data handling, Shell Scripting, Airflow, Python, etc.)\\nExpertise in cloud platforms (AWS, Azure)\\nExperience in data interchange standards like EDI and HL7 is a plus\\nFamiliarity in Agile delivery framework\\nAwareness of Artificial Intelligence; data science concepts a plus\\nExperience working in healthcare setting preferred\\n</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Company Summary:\\nHeadquartered in Atlanta, GA, Jvion is the leader in Artificial Intelligence (AI)-enabled prescriptive analytics that helps healthcare organizations lower rates of preventable harm and reduce costs. Charting the future with our proprietary solution, Jvion is partnering with healthcare organizations to empower clinicians with AI that more effectively identifies at risk patients, the factors driving that risk, and the interventions that will lead to better outcomes. As the leader in healthcare AI, Jvion is making healthcare data meaningful, bringing leading edge technology to the front lines of care, tackling socioeconomic barriers to health and ultimately improving patients' lives.\\n\\nPosition Summary:\\nAs a key member of Jvion's technology team, the Senior Data Engineer is responsible for managing, optimizing, analyzing, overseeing, and monitoring data retrieval, storage, and distribution. This individual will prepare the \"big data\" infrastructure to be analyzed by the Jvion Machine. The Senior Data Engineer participates as a member of technical professionals in the development, delivery and support of cutting-edge Artificial Intelligence, cloud-based prescriptive solutions to healthcare clients that deliver high levels of customer satisfaction.\\n\\nResponsibilities and Essential Functions:\\n\\nDesign and create data ingestion pipelines and manage and maintain master data specification documents which reflect necessary data elements. Cleanse, analyze, and maintain incoming client data. Design and develop features relevant to healthcare use cases/vectors.\\nLead in generating data visualizations and presentations, including the design of interactive and intuitive dashboards.\\nLead process adherence and continuance through automation of workflow schedules and cyclic support to ensure stable production environment.\\n\\nExperience/Education:\\n\\nBachelor's degree in Information Technology/Computer Engineering\\n5+ years of experience in development and deployment of Big Data technologies with a focus on Data Engineering (SQL, AWS/Azure Cloud platform tools, Data handling, Shell Scripting, Airflow, Python, etc.)\\nExpertise in cloud platforms (AWS, Azure)\\nExperience in data interchange standards like EDI and HL7 is a plus\\nFamiliarity in Agile delivery framework\\nAwareness of Artificial Intelligence; data science concepts a plus\\nExperience working in healthcare setting preferred\\n\\nWork Skills / Personal Characteristics:\\n\\nYou are passionate about making a difference in the world and the impact technology can have in helping people get better faster\\nYou drive results effectively through cross functional teams\\nYou are flexible and adaptive and can adjust quickly in the face of changing situations and challenges\\nYou are disciplined and able to manage multiple responsibilities simultaneously\\nYou are a strong team player who is happy to share knowledge and mentor others to grow their skills\\nYou work effectively with minimal supervision and can be relied on to deliver on commitments effectively\\n\\nJvion is proud to be an Equal Employment Opportunity employer. We do not discriminate based upon race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Alpharetta, GA 30009</td>\n",
       "      <td>Alpharetta</td>\n",
       "      <td>GA</td>\n",
       "      <td>30009</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Your responsibilities\\nthyssenkrupp Elevator Corporation is seeking a Sr. Data Engineer to be responsible for data engineering activities related to business’ information systems, data integration and data warehousing solutions. The candidate must demonstrate strong computer skills and a deep passion for analytics, possess an ability to perform complex data analyses and development with large data volumes, and have expert level knowledge in SQL, data warehousing and ETL. The role of the Senior Data Engineer is responsible for building and maintaining optimized and highly available data solutions that facilitate deeper analysis for reporting and analytics to tkE’s corporate and field organizations in North America. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. • Develop new applications and features within an agile delivery team providing data and data services to the enterprise, other engineering teams, analysts, product, management/executives, and other business teams• Build high performing and scalable data systems to support multiple internal and 3rd party data pipelines • Build and maintain reliable and scalable ETL on data platforms that support critical business functions and analytics’ functions of the organization• Implement new technologies and practices where appropriate to provide the best in class solutions • Responsible for architecture/design and risk analysis/mitigation on a micro level • Develop and maintain solutions on chosen technology landscape (Microsoft Azure, SQL Server, SSIS, Azure Data Factory) • Work with business teams to create technical requirements and deliver within time and scope • Work with IT Operations and Prod Support to ensure solutions are releasable, maintainable, and scalable • Work with Risk &amp; Compliance to ensure necessary logging/security is in place to comply with audits• Ability to design data architecture by studying the solution concept, strategy, and target audience by envisioning architectural scheme, data structure and features, functionality, and user-interface design.• Execute on new development activities and ensures they are consistent and well-integrated with the established ecosystem data architecture• Creates ecosystem models (e.g. conceptual, logical, canonical) that are required for supporting services within the enterprise data• Driven self-starter, with ability to perform research and issue analysis duties with little supervision\\nYour profile\\nRequired Qualifications:• Bachelor’s degree (B.A. / B.S.) in Information Technology or Computer Science or related field or the equivalent combination of education and experience• 5+ years of data engineering, ETL, and data warehousing experiences in Microsoft Azure, MS SQL Server and SSIS, Azure Data Factory (Must have in-depth knowledge of SQL Server and SSIS). • Extensive experience working in a Agile Environment• Extensive experience working in a Data &amp; Analytics Environment• Proficient knowledge of optimization, concurrency, scale-up vs scale-out • Must have demonstrated experience in building and maintaining reliable and scalable ETL on data platforms• Experience working with varied forms of data infrastructure inclusive of databases such as Azure SQL Database, Azure SQL Datawarehouse, SAP HANA, SAP BW, Azure Data Factory, Hadoop, Spark and column-oriented databases such as Redshift, MySQL, or Oracle• System integration experience, including interface design, and familiarity with web-oriented architecture techniques• Data modeling and information classification expertise at an enterprise level Nice to Have Qualifications: • Familiarity with data science concepts leveraging tools such as Databricks or Cloudera• Experience with Master Data Management, Metadata Management, Data Integration, Data Migration, Data Governance design and implementation techniques leveraging data management tools such as SAP MDG, Informatica or Talend is a plus• Streaming experience and knowledge of bottleneck/queue theory is a plus• Ability to calibrate Machine Learning (ML) models and experience with Artificial Intelligence (AI) preferred• Knowledge of predictive and analytic dashboards and reporting strongly preferred• Experience with designing and implementing self-service models preferred• Hands-on experience with implementing data and analytics management programs is preferred\\nOur offer to you\\nSafety at work and Healthcare\\nSafety at work &amp; Healthcare: Highest standards in occupational safety and health, comprehensive programs and measures for safety at work and preventive healthcare with comprehensive coverage and flexible options.\\nSecurity for the future\\nFinancial security for your individual retirement plan.\\nCollaboration\\nRespect, recognition and appreciation of the contribution of everyone. Regular team - and social events.\\nContinuing development\\nTraining and continuing developement options. Help to grow alongside with us, in personality and profession.\\nCompensation and benefits\\nWe offer a lot: Fair working conditions and a reasonable, competitive compensation are the foundation for many more attractive benefits.\\nDiversity\\nOpen, tolerant and constructive work environment with a team consistent of diverse views and backgrounds.\\nWe work together closely and respect each other, for over 200 years. If that is just as important to you as it is to us, apply now!\\n\\nTo learn more about thyssenkrupp in North America, please visit our website:\\nhttps://www.thyssenkrupp-north-america.com\\nthyssenkrupp Elevator Corp. is an equal opportunity employer. Applicants will receive consideration for employment without regard to age, sex, race, color, religion, national origin, genetics, disability, gender identity, marital status, sexual orientation, veteran status or any other protected characteristic required by applicable law.\\n\\nApplicants with disabilities who require reasonable accommodation in connection with the application process are encouraged to contact us directly at 1-844-427-5461.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Metavance Developer</td>\n",
       "      <td>Atlanta, GA 30319</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>30319</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>8 or more years experience writing code using languages such as (and not limited to) COBOL, PL/1, Java, C, C++, C#, VB.Net.\\nAdvanced ability to work with Web-development tools for new applications.\\nAdvanced understanding of RDBMS databases such SQL Server and Oracle.\\nAdvanced understanding of modern software design and development methodologies.\\nExperience on multiple full release project life cycles.\\nAdvanced understanding of modern SCM (software configuration management).\\nAdvanced understanding of testing tools and unit test and integration test scripting, and testing methodologies\\nAdvanced experience using an Integrated Development Environment (e.g., Eclipse, Visual Studio) and development of tool add-ins.\\nStrong understanding of basic Database Administration. Able to define quality and security standards.\\nGood verbal and written communication and negotiation skills.\\nGeneral project management/team leader skills.\\nAbility to work effectively in a globally dispersed team and with clients and vendors.\\nDemonstrated technical leadership skills.</td>\n",
       "      <td>Participates as a member of and leads development teams.\\nDesigns units for others.\\nCompletes development to implement complex components.\\nDesigns solutions for others to develop.\\nParticipates in cross-functional teams.\\nLeads design activities May provide mentoring and guidance to developers.\\nDesigns, prepares and executes unit tests.\\nRepresents team to clients.\\nDemonstrates technical leadership, and exerts influence outside of immediate team.\\nDevelops innovative team solutions to complex problems.\\nContributes to strategic direction for teams.\\nApplies in-depth or broad technical knowledge to provide maintenance solutions across one or more technology areas (e.g. Web-site Development).\\nApplies company and 3rd party technologies to complex software solutions of moderate complexity. Independently implements end- user or enterprise solutions of significant complexity.\\nIntegrates technical expertise and business understanding to create superior solutions for clients.\\nConsults with team members and other organizations, clients and vendors on complex issues.</td>\n",
       "      <td>Typically a technical Bachelor's degree or equivalent experience and a minimum of 8 years of related experience or a Master's degree and a minimum of 8 years of experience.</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Job Description:\\nApplies specialized knowledge to conceptualize, design, develop, unit-test, configure, and implement portions of new or enhanced (upgrades or conversions) business and technical software solutions through application of appropriate standard software development life cycle methodologies and processes. Interacts with the Client and project roles (e.g., Project Manager, Business Analyst, Data Engineer) as required, to gain an understanding of the business environment, technical context, and organizational strategic direction. Defines scope, plans, and deliverables for assigned components. Understands and uses appropriate tools to analyze, identify, and resolve business and or technical problems. Applies metrics to monitor performance and measure key project parameters. Prepares system documentation. Conforms to security and quality standards. Stays current on emerging tools, techniques, and technologies.\\nResponsibilities:\\nParticipates as a member of and leads development teams.\\nDesigns units for others.\\nCompletes development to implement complex components.\\nDesigns solutions for others to develop.\\nParticipates in cross-functional teams.\\nLeads design activities May provide mentoring and guidance to developers.\\nDesigns, prepares and executes unit tests.\\nRepresents team to clients.\\nDemonstrates technical leadership, and exerts influence outside of immediate team.\\nDevelops innovative team solutions to complex problems.\\nContributes to strategic direction for teams.\\nApplies in-depth or broad technical knowledge to provide maintenance solutions across one or more technology areas (e.g. Web-site Development).\\nApplies company and 3rd party technologies to complex software solutions of moderate complexity. Independently implements end- user or enterprise solutions of significant complexity.\\nIntegrates technical expertise and business understanding to create superior solutions for clients.\\nConsults with team members and other organizations, clients and vendors on complex issues.\\nEducation and Experience Required:\\nTypically a technical Bachelor's degree or equivalent experience and a minimum of 8 years of related experience or a Master's degree and a minimum of 8 years of experience.\\nKnowledge and Skills:\\n8 or more years experience writing code using languages such as (and not limited to) COBOL, PL/1, Java, C, C++, C#, VB.Net.\\nAdvanced ability to work with Web-development tools for new applications.\\nAdvanced understanding of RDBMS databases such SQL Server and Oracle.\\nAdvanced understanding of modern software design and development methodologies.\\nExperience on multiple full release project life cycles.\\nAdvanced understanding of modern SCM (software configuration management).\\nAdvanced understanding of testing tools and unit test and integration test scripting, and testing methodologies\\nAdvanced experience using an Integrated Development Environment (e.g., Eclipse, Visual Studio) and development of tool add-ins.\\nStrong understanding of basic Database Administration. Able to define quality and security standards.\\nGood verbal and written communication and negotiation skills.\\nGeneral project management/team leader skills.\\nAbility to work effectively in a globally dispersed team and with clients and vendors.\\nDemonstrated technical leadership skills.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Lead Data Engineer - Buckhead - 8491</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nDegree in Computer Science, Engineering, Mathematics, Statistics or related quantitative field\\n5+ years’ experience in RDBMS systems, data warehousing, advanced SQL Server Analytical development, and sophisticated data analysis\\nExpertise with Azure Cloud Technologies (Data Factory, PowerShell, Data Lake and Data Lake Analytics)\\nExtensive experience with Data Modeling and ETL tools, Business Intelligence platforms, API Integration, and Object-Oriented Programming (OOP)\\nAbility to thrive in a cross-functional environment utilizing modern technologies (Python, Git, Jenkins, Octopus Deploy, Tensorflow, Domo, ArcGIS, E/R Studio, RedGate DLM Automation and other tools)\\nExperience with messaging/event processing tooling and frameworks such as Azure Event Hub, Kafka, Kinesis\\nWorking knowledge of Azure HDInsight + Spark, Azure Databricks, Azure Stream Analytics</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>At Cortland, you map the story of your success. We don't adhere to the status quo, we love outside industry perspective, and we thrive on exploring possibilities and reimagining solutions. As an innovative leader in multifamily, our high performance continues to drive exponential growth – and we invite you to join us on our journey towards real estate excellence. With tools and guidance to sharpen your skills, you can forge your own career path, love what you do, and let it show.\\nKey Responsibilites\\nCollaborate to architect and implement end-to-end cloud infrastructure (analytics, compute, databases, DevOps, identity, integration, management, networking, security, and storage)\\nLeverage technologies such as the Azure BI Stack, BI and GIS visualization platforms, and modern developer tools to execute innovative solutions that facilitate data-driven analysis, automation, and data science\\nApply dimensional data modeling to solve business problems\\nAnalyze, develop, and maintain data pipelines from internal and external sources, utilizing Python and Azure Data Factory\\nProfile and analyze data in designing scalable solutions\\nApply and build automated test-driven development, continuous integration/delivery, and version control best practices\\nPreferred Qualifications\\nDegree in Computer Science, Engineering, Mathematics, Statistics or related quantitative field\\n5+ years’ experience in RDBMS systems, data warehousing, advanced SQL Server Analytical development, and sophisticated data analysis\\nExpertise with Azure Cloud Technologies (Data Factory, PowerShell, Data Lake and Data Lake Analytics)\\nExtensive experience with Data Modeling and ETL tools, Business Intelligence platforms, API Integration, and Object-Oriented Programming (OOP)\\nAbility to thrive in a cross-functional environment utilizing modern technologies (Python, Git, Jenkins, Octopus Deploy, Tensorflow, Domo, ArcGIS, E/R Studio, RedGate DLM Automation and other tools)\\nExperience with messaging/event processing tooling and frameworks such as Azure Event Hub, Kafka, Kinesis\\nWorking knowledge of Azure HDInsight + Spark, Azure Databricks, Azure Stream Analytics\\nAt Cortland, we create, reimagine, and manage apartment communities for residents nationwide. Headquartered in Atlanta, GA, we have communities and regional offices all over the country, as well as overseas. From product design and procurement to general contracting and property management, we do it all – to make sure our communities are the perfect setting for living life to its fullest.\\n\\nOur success is fueled by our belief in a better life – where hospitality is always a given, each detail is worth a second thought, and every open door is a new opportunity to go beyond expectations. We come to work every day to create possibilities for people – possibilities that translate into superior living spaces and experiences designed to inspire our residents, associates, and investors to live a better life focused on what matters most to them.\\n\\nCortland is an equal opportunity employer, and we’re proud to support and celebrate diversity in the workplace. We are committed to equal consideration for all qualified applicants regardless of race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, disability, protected veteran status, genetic information, or any other characteristic protected by applicable law. If you have a disability and need an accommodation or assistance with the application process and/or using our website, please email talentresources@cortland.com or call 404.965.3988.\\n\\nCortland is a drug-free workplace.\\n\\nCortland participates in e-verify to verify the employment status of all persons hired to work in the United States.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Job Description\\n\\nData Engineers work in our Data &amp; Analytics practice area at CapTech. Our DE consultants deliver Data, Pipeline, and Integration and solutions and services to our clients across many industries in support of crucial and diverse data strategies. Our consultants work to bridge the ever-evolving gap between value and technology for our clients. Through our core values of intellectual curiosity, enthusiasm, flexibility, servant leadership, and serving as trusted advisors, CapTech seeks to maintain the premier workplace and destination for technology consultants.\\nSpecific responsibilities for the Data Engineer position include:\\nDevelop data solutions using data storage, integration, and pipeline platforms such as HDFS, Spark, Hive, Impala, Cassandra, Informatica, Ab Initio, SQL Server, Oracle, Python, and Kafka\\nDesign/develop data models and consolidate data into them of various types/formats from various sources\\nOptimize data solutions for the right mix of performance, reliability, and maintainability\\nCollaborate with Quality Assurance resources and systems administrators to debug code and ensure the timely delivery of products\\nPrepare documentation conveying design and support information\\nConvey complex technical information in a clear, concise manner to all levels of stakeholders, including executives, business users, IT, application developers, and customers\\nParticipate in requirements gathering sessions with business and technical staff\\nFully understand clients’ business philosophies and IT Strategies. Recommend process improvements to increase efficiency and reliability of data solutions\\n\\nQualifications\\n\\nSpecific qualifications for the Data Engineer, Analytics position include:\\nBachelor's Degree in Computer Science, MIS, or equivalent combination of education and experience preferred.\\nStrong SQL and Python skills\\nExperience optimizing data solutions for strong performance\\nDevelopment experience with Hadoop and related platforms\\nDevelopment experience with database platforms (Redshift, Snowflake, MS or Azure SQL, Teradata, Oracle, etc.)\\nDevelopment experience building ETL graphs using the Ab Initio GDE, EME and Co-Operating system\\nPreferred - development experience with programming languages\\nPreferred - development experience with Unix tools and shell scripts preferred\\nMinimum of 5 years’ experience designing, developing, and testing software aligned with defined requirements\\nExperience with version control (Git, TFS, JIRA, etc.) and test driven development\\nExposure to Business Intelligence tools such as Tableau, Power BI, Qlik, Domo, Birst, Business Objects, SSRS, Cognos, MicroStrategy, etc.\\nAdditional Information\\n\\nWe offer challenging and impactful jobs with professional career paths. All CapTechers can keep their hands-on technology no matter what position they hold. Our employees find their work exciting and rewarding in a culture filled with opportunities to have fun along the way.\\nAt CapTech we offer a competitive and comprehensive benefits package including, but not limited to:\\nCompetitive salary with performance-based bonus opportunities\\nSingle and Family Health Insurance plans, including Dental coverage\\nShort-Term and Long-Term disability\\nMatching 401(k)\\nCompetitive Paid Time Off\\nTraining and Certification opportunities eligible for expense reimbursement\\nTeam building and social activities\\nMentor program to help you develop your career\\nCapTech is an equal opportunity employer committed to fostering a culture of equality, inclusion and fairness — each foundational to our core values. We strive to create a diverse environment where each employee is encouraged to bring their unique ideas, backgrounds and experiences to the workplace.\\nCandidates must be eligible to work in the U.S. for any employer directly (we are not open to contract or “corp to corp” agreements). At this time, CapTech cannot transfer nor sponsor a work visa for this position. Applicants must be authorized to work directly for any employer in the United States without visa sponsorship.\\nCapTech is a Drug-Free work place.\\nCandidates must have the ability to work at CapTech’s client locations.\\nAll positions include the possibility of travel.\\nCapTech has not contracted/does not contract with any outside vendors in its recruitment process. If you are interested in this position, please apply to CapTech directly.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Data Engineer w/ Snowflake</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Qualifications: 3-7 years (2 years min relevant experience in the role) experience; Bachelor’s degreeShould be proficient in Software Engineering Techniques, Software Engineering Architecture, Software Engineering Lifecycle and Data Management.Should have progressing skills on Business Analysis, Business Knowledge, Software Engineering Leadership, Architecture Knowledge and Technical Solution Design.</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>The Snowflake Developer will be responsible for designing and implementing Snowflake data warehouse infrastructure and pipelines.\\nStrong experience and comfort with relational database concepts (Databases, Schemas, Tabular/Semi-structured Data, Primary/Foreign keys, etc).At least 2 years of experience in data warehouse build projects including data loading, processing and transformationExpert-level Python and SQL (Scala and Java are a plus). At least 2 years of experience is requiredExperience and comfort with ETL/ELT concepts and frameworks and data modelling.Knowledge and hands on experience with Snowflake, familiarity with Snowflake's features and use cases is a plus.Exposure to either AWS or Azure cloud environments in a production settingHands on experience with Apache Airflow is a plus.\\n\\n\\nCandidates should be flexible / willing to work across this delivery landscape which includes and not limited to Agile Applications Development, Support and Deployment.\\nApplicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Capgemini.\\n\\nQualifications\\n\\nResponsible for programming and software development using various programming languages and related tools and frameworks, reviewing code written by other programmers, requirement gathering, bug fixing, testing, documenting and implementing software systems. Experienced programmers are also responsible for interpreting architecture and design, code reviews, mentoring, guiding and monitoring programmers, ensuring adherence to programming and documentation policies, software development, testing and release.\\nRequired Skills and Experience:\\nWrite software programs using specific programming languages/platforms such as Java or MS .NET, and related tools, platform and environment. Write, update, and maintain computer programs or software packages to handle specific jobs, such as tracking inventory, storing or retrieving data, or controlling other equipment. Consult with managerial, engineering, and technical personnel to clarify program intent, identify problems, and suggest changes. Perform or direct revision, repair, or expansion of existing programs to increase operating efficiency or adapt to new requirements. Write, analyze, review, and rewrite programs, using workflow chart and diagram, and applying knowledge of computer capabilities, subject matter, and symbolic logic. Write or contribute to instructions or manuals to guide end users. Correct errors by making appropriate changes and then rechecking the program to ensure that the desired results are produced. Conduct trial runs of programs and software applications to be sure they will produce the desired information and that the instructions are correct. Compile and write documentation of program development and subsequent revisions, inserting comments in the coded instructions so others can understand the program. Investigate whether networks, workstations, the central processing unit of the system, and/or peripheral equipment are responding to a program's instructions. Prepare detailed workflow charts and diagrams that describe input, output, and logical operation, and convert them into a series of instructions coded in a computer language. Perform systems analysis and programming tasks to maintain and control the use of computer systems software as a systems programmer. Consult with and assist computer operators or system analysts to define and resolve problems in running computer programs. Perform unit testing Assist in system and user testing Fix errors and bugs that are identified in the course of testing.\\nQualifications: 3-7 years (2 years min relevant experience in the role) experience; Bachelor’s degreeShould be proficient in Software Engineering Techniques, Software Engineering Architecture, Software Engineering Lifecycle and Data Management.Should have progressing skills on Business Analysis, Business Knowledge, Software Engineering Leadership, Architecture Knowledge and Technical Solution Design.\\n\\nCapgemini is an Equal Opportunity Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.\\n\\nThis is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.\\nClick the following link for more information on your rights as an Applicant - http://www.capgemini.com/resources/equal-employment-opportunity-is-the-law\\n\\nAbout Capgemini\\nA global leader in consulting, technology services and digital transformation, Capgemini is at the forefront of innovation to address the entire breadth of clients’ opportunities in the evolving world of cloud, digital and platforms. Building on its strong 50 year heritage and deep industry-specific expertise, Capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations. Capgemini is driven by the conviction that the business value of technology comes from and through people. It is a multicultural company of 200,000 team members in more than 40 countries. The Group reported 2018 global revenues of EUR 13.2 billion.\\n\\nVisit us at www.capgemini.com. People matter, results count.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Requisition Number: 75000\\nOur Insight Digital Innovation team is searching for an experienced, passionate and professional Data Engineer to join our team.\\nWhat our Data Engineer’s Do:\\nTranslate business requirements to technical solutions leveraging strong business acumen.\\nAnalyzes current business practices, processes and procedures as well as identifying future business opportunities for leveraging Microsoft Azure Data &amp; Analytics PaaS Services.\\nSupport the planning and implementation of data design services, providing sizing and configuration assistance and performing needs assessments.\\nDelivery of architectures for transformations and modernizations of enterprise data solutions using Azure cloud data technologies.\\nDesign and Build Modern Data Pipelines and Data Streams.\\nDesign and Build Data Service APIs.\\nDevelop and maintain data warehouse schematics, layouts, architectures and relational/non-relational databases for data access and Advanced Analytics.\\nExpose data to end users using PowerBI, Azure API Apps or any other modern visualization platform or experience.\\nImplement effective metrics and monitoring processes.\\nWhat We Look For at Insight:\\nDemonstrated experience of turning business use cases and requirements to technical solutions.\\nExperience in business processing mapping of data and analytics solutions.\\nAbility to conduct data profiling, cataloging, and mapping for technical design and construction of technical data flows.\\nThe ability to apply such methods to solve business problems using one or more Azure Data and Analytics services in combination with building data pipelines, data streams, and system integration.\\nKnowledge of Azure Data Factory, Azure Data Lake, Azure SQL DW, and Azure SQL, Azure App Service is required.\\nAzure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics is a plus.\\nExperience preparing data for Data Science and Machine Learning.\\nDemonstrated experience preparing data and building data pipelines for AI Use Cases (text, voice, image, etc.…) is a plus.\\nDesigning and building Data Pipelines using streams of IOT data is a plus.\\nWhat can Insight offer?\\nClient Facing Opportunities\\nLocal Travel\\nFlex Hours\\nRemote Work\\nNo Formal Dress Code\\nLeadership from great Mentors\\nUnlimited Vacation\\nPay for Training\\nStartup Atmosphere\\n…and tons of other great Perks!\\nWe have created a team-oriented environment with quality people, career advancement opportunities, great work/life balance and an excellent compensation and benefits package. Our people appreciate that they represent a brand that is invested in growing local relationships while working globally and doing what is right for our co-workers and clients. We are high on supporting each other and hiring/developing the best technical professionals in the industry.\\nInsight is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, sexual orientation or any other characteristic protected by law.\\nThe position described above provides a summary of some the job duties required and what it would be like to work at Insight. For a comprehensive list of physical demands and work environment for this position, click here.\\nToday, every business is a technology business. Insight Enterprises, Inc. empowers organizations of all sizes with Insight Intelligent Technology Solutions™ and services to maximize the business value of IT. As a Fortune 500-ranked global provider of digital innovation, cloud/data center transformation, connected workforce, and supply chain optimization solutions and services, we help clients successfully manage their IT today while transforming for tomorrow. From IT strategy and design to implementation and management, our 6,800 employees help clients innovate and optimize their operations to run smarter. Discover more at insight.com.\\n\\nFounded in 1988 in Tempe, Arizona\\n7,400+ teammates in 19 countries providing Intelligent Technology Solutions for organizations across the globe\\n$7.1 billion in revenue in 2018\\nRanked #417 on the 2018 Fortune 500, #12 on the 2018 CRN Solution Provider 500\\n2018 Dell EMC Server Partner of the Year, 2018 Intel Retail Solution Partner of the Year, 2018 Microsoft Worldwide Artificial Intelligence Partner of the Year\\nRanked #23 on the 2019 Fortune 50 Best Workplaces in Technology and #5 on the Phoenix Business Journal 2018 list of Best Places to Work (Extra Large Business)\\nSignatory of the United Nations (UN) Global Compact and Affiliate Member of the Responsible Business Alliance\\n\\nToday's talent leads tomorrow's success. Learn about careers at Insight: jobs.insight.com.\\n\\nInsight is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, sexual orientation or any other characteristic protected by law.\\n\\nPosting Notes: Atlanta || Georgia (US-GA) || United States (US) || None || None || US - Atlanta, GA ||</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Atlanta, GA 30326</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>30326</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nBS or MS degree in Computer Science or a related technical experience\\n3+ years of experience in custom or structured ETL design, implementation, maintenance and support\\n3+ years of experience with one or more programming language: Python, Scala, Java, R, etc.\\n3+ years of experience with SQL, data definition, and data manipulation\\n3+ years of experience designing, implementing and maintaining SSIS packages\\n3+ years of experience managing ETL with data warehouses (AWS Redshift, Google BigQuery, etc)\\nStrong experience working with both structured and unstructured data\\nExperience building and optimizing data pipelines and big data sets\\nFluency running automated jobs to manipulate and store data from APIs via Google Compute Engine, Google App Engine, Google Cloud Storage, EC2, AWS Lambda, S3, etc.\\nExperience with Spark\\nExperience with container applications like Docker\\nExpertise creating and managing dashboards in data visualization platforms such as Tableau, Microsoft PowerBI, Google Data Studio, SSRS, etc.\\nExcellent written and oral communication skills including facilitation, project management, and working with others in team communicate data-driven insights</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nProactively drive and facilitate conversations about data needs with stakeholders across the company\\nBuild and maintain data pipelines and ETL process\\nDesign, develop, maintain and enhance data collection procedures and analytic systems\\nUnderstand, unify and integrate data from internal and third-party data sources using industry best practices for scalability, quality, simplicity, and maintainability</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nBS or MS degree in Computer Science or a related technical experience\\n3+ years of experience in custom or structured ETL design, implementation, maintenance and support\\n3+ years of experience with one or more programming language: Python, Scala, Java, R, etc.\\n3+ years of experience with SQL, data definition, and data manipulation\\n3+ years of experience designing, implementing and maintaining SSIS packages\\n3+ years of experience managing ETL with data warehouses (AWS Redshift, Google BigQuery, etc)\\nStrong experience working with both structured and unstructured data\\nExperience building and optimizing data pipelines and big data sets\\nFluency running automated jobs to manipulate and store data from APIs via Google Compute Engine, Google App Engine, Google Cloud Storage, EC2, AWS Lambda, S3, etc.\\nExperience with Spark\\nExperience with container applications like Docker\\nExpertise creating and managing dashboards in data visualization platforms such as Tableau, Microsoft PowerBI, Google Data Studio, SSRS, etc.\\nExcellent written and oral communication skills including facilitation, project management, and working with others in team communicate data-driven insights</td>\n",
       "      <td>Data Engineer\\n\\nJob Description\\n\\nCoStar Group is currently looking for a Data Engineer to join our Atlanta-based Apartments Network team. This exciting opportunity contributes to the growth of CoStar’s apartment rental brands including Apartments.com, ForRent.com, ApartmentFinder.com, ApartmentHomeLiving.com, Apartamentos.com, Cozy.co, WestsideRentals.com, AFTER55.com, ForRentUniversity.com, and CorporateHousing.com.\\nThe ideal candidate is ambitious, a self-starter, loves challenges and thrives in a fast-paced, dynamic environment. This excellent problem solver takes pride in being best in class at leveraging their technical depth and breadth to design, build and support data solutions. This candidate is never satisfied with the status quo and is strong communicator who can actively engage in conversations about data needs and opportunities.\\nResponsibilities:\\nProactively drive and facilitate conversations about data needs with stakeholders across the company\\nBuild and maintain data pipelines and ETL process\\nDesign, develop, maintain and enhance data collection procedures and analytic systems\\nUnderstand, unify and integrate data from internal and third-party data sources using industry best practices for scalability, quality, simplicity, and maintainability\\nDesigning appropriate indexes for new tables, and analyze existing indexes for improvement\\nConduct performance analysis and optimize systems to ensure products provide optimal performance\\nOwnership of end-to-end data and analytical solutions including internal and third-party systems and software components\\nDesign, build and manage the deployment of various big data applications\\nDrive self-service analytics initiatives\\nRequirements and Qualifications:\\nBS or MS degree in Computer Science or a related technical experience\\n3+ years of experience in custom or structured ETL design, implementation, maintenance and support\\n3+ years of experience with one or more programming language: Python, Scala, Java, R, etc.\\n3+ years of experience with SQL, data definition, and data manipulation\\n3+ years of experience designing, implementing and maintaining SSIS packages\\n3+ years of experience managing ETL with data warehouses (AWS Redshift, Google BigQuery, etc)\\nStrong experience working with both structured and unstructured data\\nExperience building and optimizing data pipelines and big data sets\\nFluency running automated jobs to manipulate and store data from APIs via Google Compute Engine, Google App Engine, Google Cloud Storage, EC2, AWS Lambda, S3, etc.\\nExperience with Spark\\nExperience with container applications like Docker\\nExpertise creating and managing dashboards in data visualization platforms such as Tableau, Microsoft PowerBI, Google Data Studio, SSRS, etc.\\nExcellent written and oral communication skills including facilitation, project management, and working with others in team communicate data-driven insights\\nNice to Have\\nExperience with workflow management tools like Airflow\\nUnderstanding of supervised and unsupervised machine learning techniques and algorithms, such as k-NN, K-Means, Naive Bayes, SVM, Decision Forests, Neural Networks, etc.\\nExperience developing recommendation engines using different techniques like collaborative filtering, content-based filtering, deep learning-based approaches, etc.\\nWhat We Offer\\nYou work hard to connect with our customers and communities every day. As part of your total rewards package, CoStar is committed to offering you valuable health, wellness and financial benefits to support you and your family, both now and in the future. At CoStar, we help our clients succeed by providing the most cutting-edge, reliable information and tools in the business. And we want our employees to succeed too. We strive to hire the best talent and reward you with top-notch, market-leading pay, benefits and career opportunities. As an example of our commitment to excellence, CoStar ranks in the 90th percentile of employers who offer competitive and affordable medical plans.\\nJoin the CoStar Team\\nJoin the team that creates CoStar’s winning technology. If you’re an engineer you have an incredible opportunity at CoStar – named one of Forbes’ Most Innovative Growth Companies for four consecutive years. We’re always looking for talent to help build the tools and analytics that harvest our big data and power our research operations and shape the marketplaces that serve tens of millions of people each month. Our culture of innovation and excellence attracts and encourages the best and brightest in a broad range of disciplines, which makes CoStar a fun and supportive place to work.\\nCompany Overview:\\nCoStar Group, Inc. (NASDAQ: CSGP) is the leading provider of commercial real estate information, analytics and online marketplaces. Founded in 1987, CoStar conducts expansive, ongoing research to produce and maintain the largest and most comprehensive database of commercial real estate information. Our suite of online services enables clients to analyze, interpret and gain unmatched insight on commercial property values, market conditions and current availabilities. LoopNet is the most heavily trafficked commercial real estate marketplace online with approximately 5 million monthly unique visitors per month. Realla is the UK's most comprehensive commercial property digital marketplace. Apartments.com, ApartmentFinder.com, ForRent.com, ApartmentHomeLiving.com, Westside Rentals, AFTER55.com, CorporateHousing.com, ForRentUniversity.com, Cozy and Apartamentos.com form the premier online apartment resource for renters seeking great apartment homes and provide property managers and owners a proven platform for marketing their properties. CoStar Group's websites attracted an average of approximately 45 million unique monthly visitors in aggregate in the third quarter of 2018. Headquartered in Washington, DC, CoStar maintains offices throughout the U.S. and in Europe and Canada with a staff of over 3,600 worldwide, including the industry's largest professional research organization.LI-AM2\\n\\nCoStar Group is an Equal Employment Opportunity Employer; we maintain a drug-free workplace and perform pre-employment substance abuse testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Data Engineer, Decision Sciences</td>\n",
       "      <td>Atlanta, GA 30309</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>30309</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Strong Tableau, Adobe Analytics other BI solution\\nExpert Oracle and Vertica skillsets\\nExperience using JIRA and Agile Project Management software\\nExperience using GitHub, Bit Bucket, or other code repository solution\\nStrong written, verbal communication and presentation skills\\nAbility to explain complex technical issues in a way that non-technical people may understand\\nAble to work in a global, multicultural environment\\nSelf-motivated. Capable of working with little or no supervision\\nAbility to react positively under pressure to meet tight deadlines\\nAble to work independently or as a team player\\nEnjoy challenging and thought provoking work and have a strong desire to learn and progress</td>\n",
       "      <td>Work with development teams and other project leaders/stakeholders to provide technical solutions that enable business capabilities\\nServe as a key driver on various new technology initiatives and programs on behalf of IT organization, including big data, machine learning and AI\\nSupports the data science community by enabling data availability in environments that provide advanced analytical capabilities\\nMaintains a broad understanding of implementation, integration, and inter-connectivity issues with emerging technologies to define data strategies\\nAssist in the decision-making process related to the selection of software architecture solutions\\nBuild robust data pipelines on public Cloud using AWS Kinesis, Kafka, Lambda or other technologies\\nAssist in creating documents that ensure consistency in development across the online organization. Implements and improves core software infrastructure\\nDeep expertise in SQL language, Python, Hadoop ecosystem and/or Spark ecosystem. Strong experience with writing complex programs, implementing architectures, and enabling automation in these environments\\nDevelop and maintain business reporting, ensuring reliability and performance, delivery of performance management tools (such as control charts and scorecards), readiness and adoption of data w/in the organization\\nConsolidate, standardize and control changes to capacity management data and metric definitions, ownership, accountability and taxonomy to ensure alignment in understanding\\nServe as strong advocate to improve analytical capability across the organization\\nSupport various reporting and BI solutions (Tableau, Power BI, Salesforce Einstein)\\nManage application and data integration platforms (Informatica, Talend)\\nCreate and manage data, applications and technology architecture documentation and design artifacts\\nWork across teams to deliver meaningful reference architectures that outline architecture principles and best practices for technology advancement\\nGain adoption of architecture processes, standards and procedures</td>\n",
       "      <td>\\nBS in Computer Science, Applied Mathematics, Physics, Statistics or area of study related to data sciences and data mining or relevant experience</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Invesco is one of the world’s leading global investment managers, entrusted with managing $1.2 trillion* in assets on behalf of clients worldwide. We are the 6th largest US retail asset manager and the 13th largest investment manager globally, and our more than 8,000 employees worldwide are dedicated to delivering an investment experience that helps people get more out of life. We are purely focused on managing a comprehensive range of active, passive and alternative investment capabilities, which we draw on to provide customized solutions aligned to client needs, our most important benchmark. (*As of May 31,2019)\\n\\nJob Purpose (Job Summary):\\n\\nAs a Data Engineer at Invesco, you would align business outcomes to technology goals and objectives. You will be responsible for managing decision sciences and advanced analytics initiatives, data integration/engineering. Interacts with Data Scientists, Business Owners, Business Data Analysts, Data Modelers, Architects, and Application Developers, to design, build and manage large-scale batch and real-time data pipelines utilizing various data analytics processing frameworks in support of Data Science practice. The position requires building strong technical hands-on-skills and experiences as well as establishing close business relationships across the enterprise. Working closely with marketing and sales stakeholders, you will execute long term advance analytics roadmap manage increasing demands for advance analytics in Sales and Marketing. A successful candidate must have a demonstrable background with experience in development of high performance, distributed computing tasks using Big Data technologies such as Hadoop (platform level), NoSQL, text mining and other distributed environment technologies based on the needs of the organization. Responsible for analyzing, designing, programing, debugging and modifying software enhancements and/or new products used in distributed, large scale analytics solutions. Strong visualization skills and experience with BI tools (ex. Tableau)\\n\\nKey Responsibilities / Duties:\\nWork with development teams and other project leaders/stakeholders to provide technical solutions that enable business capabilities\\nServe as a key driver on various new technology initiatives and programs on behalf of IT organization, including big data, machine learning and AI\\nSupports the data science community by enabling data availability in environments that provide advanced analytical capabilities\\nMaintains a broad understanding of implementation, integration, and inter-connectivity issues with emerging technologies to define data strategies\\nAssist in the decision-making process related to the selection of software architecture solutions\\nBuild robust data pipelines on public Cloud using AWS Kinesis, Kafka, Lambda or other technologies\\nAssist in creating documents that ensure consistency in development across the online organization. Implements and improves core software infrastructure\\nDeep expertise in SQL language, Python, Hadoop ecosystem and/or Spark ecosystem. Strong experience with writing complex programs, implementing architectures, and enabling automation in these environments\\nDevelop and maintain business reporting, ensuring reliability and performance, delivery of performance management tools (such as control charts and scorecards), readiness and adoption of data w/in the organization\\nConsolidate, standardize and control changes to capacity management data and metric definitions, ownership, accountability and taxonomy to ensure alignment in understanding\\nServe as strong advocate to improve analytical capability across the organization\\nSupport various reporting and BI solutions (Tableau, Power BI, Salesforce Einstein)\\nManage application and data integration platforms (Informatica, Talend)\\nCreate and manage data, applications and technology architecture documentation and design artifacts\\nWork across teams to deliver meaningful reference architectures that outline architecture principles and best practices for technology advancement\\nGain adoption of architecture processes, standards and procedures\\nWork Experience / Knowledge:\\n2+ years of experience in data modeling, data warehousing, and big data architectures\\n2+ years of experience in a data engineering role\\nProficient in application/software architecture (Definition, Business Process Modeling, etc.)\\nDeep expertise in (at least one) SQL language, Python, Hadoop ecosystem and/or Spark ecosystem. Strong experience with writing complex programs, implementing architectures, and enabling automation in these environments\\nThe role will be responsible for providing innovative operational solutions and best practices\\nAdvanced knowledge in SQL/Hive, Spark, NoSQL, (Java/Python is a plus)\\nStrong programming skills and ability to utilize a variety of software/languages/tools; e.g., Spark, R, Python, Scala, Java, Hive, SQL, SAS, Tableau, etc.\\nExperience with microservice development, Docker, Kubernetes\\nDevelop software to run on cloud native big data infrastructure built on AWS using Spark, Lambda, S3, and other cloud native services\\nDesigns and develops complex and large-scale data structures and pipelines to organize, collect and standardize data to generate insight\\n2+ years of experience in data integration platforms (Informatica, Talend)\\nStrong analytics and reporting skills – hands on experience in BI Tools like Tableau, Power BI, Salesforce Einstein\\nExperience using JIRA and Agile Project Management software\\nExperience using GitHub, Bit Bucket, or other code repository solution\\nDevOps experience is a plus\\nSkills / Other Personal Attributes Required:\\nStrong Tableau, Adobe Analytics other BI solution\\nExpert Oracle and Vertica skillsets\\nExperience using JIRA and Agile Project Management software\\nExperience using GitHub, Bit Bucket, or other code repository solution\\nStrong written, verbal communication and presentation skills\\nAbility to explain complex technical issues in a way that non-technical people may understand\\nAble to work in a global, multicultural environment\\nSelf-motivated. Capable of working with little or no supervision\\nAbility to react positively under pressure to meet tight deadlines\\nAble to work independently or as a team player\\nEnjoy challenging and thought provoking work and have a strong desire to learn and progress\\nFormal Education: (minimum requirement to perform job duties)\\nBS in Computer Science, Applied Mathematics, Physics, Statistics or area of study related to data sciences and data mining or relevant experience\\nFLSA (US Only): Nonexempt\\n\\nThe above information on this description has been designed to indicate the general nature and level of work performed by employees within this role. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications required of employees assigned to this job. The job holder may be required to perform other duties as deemed appropriate by their manager from time to time.\\n\\nInvesco's culture of inclusivity and its commitment to diversity in the workplace are demonstrated through our people practices. We are proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, creed, color, religion, sex, gender, gender identity, sexual orientation, marital status, national origin, citizenship status, disability, age, or veteran status. Our equal opportunity employment efforts comply with all applicable U.S. state and federal laws governing non-discrimination in employment.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Atlanta, GA 30303</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>30303</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Challengers Wanted.\\nSee how we're embracing the challenges of tomorrow!\\n\\nAre you interested in working with an excellent team of Data-focused professionals focused on opportunities to enable and enhance BI and Analytics capabilities? Here at Koch Business Solutions (KBS), we place a high value on innovation and thinking creatively in a real way. KBS serves as a technology arm to various Koch Industries companies, and the Data Services team provides real-world solutions that deliver data across systems and to end-user BI and Analytics users. If you're excited about a shift to cloud-based BI and Analytics platforms, guess what…so are we! If you have a passion for productionizing the tribal knowledge that exists in the minds of business subject matter experts, and then backing that knowledge up with real data to help business make the best decisions possible through self-service analytics and dashboards, this could be the place for you. Come grow with us!\\nA Day In The Life Typically Includes:\\nTeam collaboration in development and maintenance of scalable data warehouse architecture that supports business/technical requirements\\nParticipation in all phases of SDLC related to data delivery: Logical and physical data modeling\\nETL development/management\\nMultidimensional Cube and Tabular model development\\nPlatform to platform data integrations\\nIdentifying data quality issues and supporting data governance initiatives by participating in necessary activities including data profiling, data mining, and clean up\\nPerforming support and troubleshooting tasks for Data Services products and platforms\\nTasks include: Performing work on service requests, incidents, and run and maintain activities\\nProviding estimates for development work needed to support break-fix, new projects, and enhancements\\nProviding after hours support for mission critical applications and platforms when needed\\nWhat You Will Need:\\n\\nBasic Qualifications:\\n2+ years of experience in applied data warehousing methodology, analysis, and development\\n2+ years of experience developing ETL packages, including scheduling and automation\\n2+ years of SQL coding and tuning experience\\nProven experience transforming business requirements to technical solutions\\nWhat Will Put You Ahead?\\n\\nPreferred Qualifications:\\nExperience with both Multi-Dimensional and Tabular Analysis Services development\\nBachelor's Degree in Computer Science, Information Systems, Math or other related field\\nExperience with AWS Cloud data platforms\\nWorking knowledge of data platforms such as: Redshift, Glue, Matillion, Snowflake, Tableau, Alteryx and Power BI\\nUnderstanding of and experience in ETL performance tuning\\nExperience working in agile development environment\\nSolid understanding of SDLC\\nExperience using Source Control systems\\nThis role is not eligible for visa sponsorship.\\nLearn more about us\\n\\nSalary and benefits commensurate with experience.\\nEqual Opportunity Employer.\\n\\nExcept where prohibited by state law, all offers of employment are conditioned upon successfully passing a drug test.\\n\\nThis employer uses E-Verify. Please visit the following website for additional information: www.kochcareers.com/doc/Everify.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Data Architect</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nAuthority in everything data related. Know exactly how data is collected, analyzed, and delivered. Also familiar with both the technical and user-facing sides of databases.\\n5+ years work experience as a Data Architect or Data Engineer or similar role\\nIn-depth understanding of database structure principles used for analytics such as star schemas and SCD\\nExpertise in database performance optimization\\nExpertise in building processes supporting data transformation, data structures, metadata, dependency and workload management.\\nA successful history of manipulating, processing and extracting value from large disconnected datasets.\\nExperience using the following software/tools:\\nExpertise in Redshift, Snowflake, or similar cloud databases\\nExperience with object-oriented/object function scripting languages\\nExperience with ETL tools: Alooma, Matillion, Fivetran, Talend, etc.\\nExperience with big data tools: Hadoop, Spark, Kafka, etc.\\nExperience with relational SQL and NoSQL databases, including Postgres and Cassandra.\\nExperience with data pipeline and workflow management tools: Airflow, Data Factory, etc.\\nExperience with stream-processing systems: Storm, Spark-Streaming, etc.\\nFamiliarity with data visualization tools (e.g. Tableau, Looker, Power BI)\\nDemonstrated analytical skills\\nProblem-solving attitude\\nB.S. in Computer Science, Information Systems or another quantitative field</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Your Opportunity\\nWe are looking for a Data Architect to run and evolve our data practice within the Go-To-Market Data &amp; Analytics Team. We use data to (i) define and measure performance and productivity metrics across Go-To-Market Functions (ii) identify and monitor leading indicators and predictive models, and (iii) deliver insights to Go-To-Market teams to ultimately improve core business processes and outcomes. The team partners with Executives and their teams within Sales, Marketing, Pre-and-Post Technical Sales, Customer Success, and Alliances &amp; Channels. We also partner on multi-functional projects with Product and G&amp;A.\\n\\nWho You Are:\\nA creative and forward-thinking data professional\\nAn experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up\\nYou thrive in a fast-paced growth environment\\nResults and Team oriented\\nWhat You'll Do\\nDesign, develop and build database design and architecture to power Go-To-Market analytics products\\nBuild, optimize and maintain conceptual and logical database models\\nDesign data pipeline architecture and ensure successful creation of the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and other technologies.\\nIdentify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.\\nCreate data monitoring models for each product and work with business and analytics teams to create models ahead of new releases\\nExamine and identify database structural necessities by evaluating operations, applications, and programming.\\nMonitor the system performance by performing regular tests, fixing performance issues, and integrating new features.\\nWork with business partners to assist with data-related technical issues and support their data infrastructure needs\\nRecommend solutions to improve new and existing database systems.\\nEducate staff members through training and individual support.\\nYour Qualifications\\nAuthority in everything data related. Know exactly how data is collected, analyzed, and delivered. Also familiar with both the technical and user-facing sides of databases.\\n5+ years work experience as a Data Architect or Data Engineer or similar role\\nIn-depth understanding of database structure principles used for analytics such as star schemas and SCD\\nExpertise in database performance optimization\\nExpertise in building processes supporting data transformation, data structures, metadata, dependency and workload management.\\nA successful history of manipulating, processing and extracting value from large disconnected datasets.\\nExperience using the following software/tools:\\nExpertise in Redshift, Snowflake, or similar cloud databases\\nExperience with object-oriented/object function scripting languages\\nExperience with ETL tools: Alooma, Matillion, Fivetran, Talend, etc.\\nExperience with big data tools: Hadoop, Spark, Kafka, etc.\\nExperience with relational SQL and NoSQL databases, including Postgres and Cassandra.\\nExperience with data pipeline and workflow management tools: Airflow, Data Factory, etc.\\nExperience with stream-processing systems: Storm, Spark-Streaming, etc.\\nFamiliarity with data visualization tools (e.g. Tableau, Looker, Power BI)\\nDemonstrated analytical skills\\nProblem-solving attitude\\nB.S. in Computer Science, Information Systems or another quantitative field\\nPlease note that visa sponsorship is not available for this position.\\nOur Office\\nOur office is in the tech-rich urban center of San Francisco, with easy commute access and a plethora of good eats. We provide competitive compensation, equity and big-company benefits (medical, dental, etc.)—all while maintaining the energy, agility, and fun of a start-up.\\nAbout Us\\nNew Relic (NYSE: NEWR) is the industry’s largest and most comprehensive cloud-based instrumentation platform built to create more perfect software. The world’s best software and DevOps teams rely on New Relic to move faster, make better decisions and create best-in-class digital experiences. If you run software, you need to run New Relic. We’re proudly trusted by more than 50% of the Fortune 100.\\nFounded in 2008, we’re a global company focused on building a culture where all employees feel a deep sense of belonging, where every ‘Relic’ can bring their whole self to work and feel supported and empowered to thrive. We’re consistently recognized as a distinguished employer and are committed to building world-class products and an award winning culture. For more information, visit newrelic.com.\\nOur Hiring Process\\nIn compliance with applicable law, all persons hired will be required to verify identity and eligibility to work and to complete employment eligibility verification. Note: Our stewardship of the data of thousands of customers’ means that a criminal background check is required to join New Relic.\\nWe will consider qualified applicants with arrest and conviction records based on individual circumstances and in accordance with applicable law including, but not limited to, the San Francisco Fair Chance Ordinance.\\nHeadhunters and recruitment agencies may not submit resumes/CVs through this website or directly to managers. New Relic does not accept unsolicited headhunter and agency resumes, and will not pay fees to any third-party agency or company that does not have a signed agreement with New Relic.\\nNew Relic is an equal opportunity employer. We eagerly seek applicants of diverse background and hire without regard to race, color, gender identity, religion, national origin, ancestry, citizenship, physical abilities (or disability), age, sexual orientation, veteran status, or any other characteristic protected by law.\\n\\nInterested in the details of our privacy policy? Read more here: https://newrelic.com/termsandconditions/applicant-privacy-policy\\n\\n#LI-SP2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Google Data Engineer</td>\n",
       "      <td>Atlanta, GA 30303</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>30303</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Minimum of 3 years previous Consulting or client service delivery experience on Google GCP\\n</td>\n",
       "      <td>DevOps on an GCP platform. Multi-cloud experience a plus.</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Proven ability to build, manage and foster a team-oriented environment\\nProven ability to work creatively and analytically in a problem-solving environment\\nDesire to work in an information systems environment\\nExcellent communication (written and oral) and interpersonal skills\\nExcellent leadership and management skills</td>\n",
       "      <td>Are you ready to step up to the New and take your technology expertise to the next level?\\nJoin Accenture and help transform leading organizations and communities around the world. The sheer scale of our capabilities and client engagements, in conjunction with the way we collaborate, operate and deliver value, provides an unparalleled opportunity to grow and advance. Choose Accenture and make delivering innovative work part of your extraordinary career.\\nPeople in our Client Delivery &amp; Operations career track drive delivery and capability excellence through the design, development and/ or delivery of a solution, service, capability or offering. They grow into delivery-focused roles, and can progress within their current role, laterally or upward. We partner with our clients to help transform their data into an ‘Appreciating Business Asset.’\\n\\nAs part of our Data Business Group, you will lead technology innovation for our clients through robust delivery of world-class solutions. You will build better software better! There will never be a typical day and that’s why people love it here. The opportunities to make a difference within exciting client initiatives are unlimited in the ever-changing technology landscape. You will be part of a highly collaborative and growing network of technology and data experts, who are taking on today’s biggest, most complex business challenges using the latest data and analytics technologies. We will nurture your talent in an inclusive culture that values diversity. You will have an opportunity to work in roles such as Data Scientist, Data Engineer, or Chief Data Officer covering all aspects of Data including Data Management, Data Governance, Data Intelligence, Knowledge Graphs, and IoT. Come grow your career in Technology at Accenture!\\n\\nThe Google GCP Data Engineer is responsible for delivering Data On Cloud projects for Google GCP based deals. The ideal candidate would be responsible for developing and delivering GCP cloud solutions to meet today’s high demand in areas such as AI/ML, IoT, advanced analytics, open source, enterprise collaboration, microservices, serverless, etc. The GCP Data Engineer is a highly performant engineer responsible for delivering Cloud based Big Data and Analytical Solutions for our clients. Responsibilities include building data on cloud solutions for customers, leading Business and IT stakeholders through designing a robust, secure and optimized GCP solutions and ability to be hands-on delivering the target solution. This role will work with customers and leading internal engineering teams in delivering big data solutions on cloud. Using Google GCP cloud technologies, our GCP Data Engineer professionals implement state of the art, scalable, high performance Data On Cloud solutions that meet the need of today’s corporate and emerging digital applications.\\n\\nRole &amp; Responsibilities:\\nProvide subject matter expertise and hands on delivery of data capture, curation and consumption pipelines on GCP and HadoopAbility to build cloud data solutions and provide domain perspective on storage, big data platform services, serverless architectures, hadoop ecosystem, RDBMS, DW/DM, NoSQL databases and security (Cloud IAM, Data Loss Prevention API, etc)Participate in deep architectural discussions to build confidence and ensure customer success when building new solutions and migrating existing data applications on the GCP platform.\\n- Build full technology stack of services required including PaaS (Platform as-a-service), IaaS (Infrastructure as-a-service), SaaS (software as-a-service), operations, management and automation.Apply Accenture methodology, Accenture reusable assets, and previous work experience to delivery consistently high-quality work.Stay educated on new and emerging technologies/patterns/methodologies and market offerings that may be of interest to our clients.Understand the strategic direction set by senior management as it relates to team goals.Use considerable judgment to define solution and seeks guidance on complex problems.Primary upward interaction is with direct supervisor. May interact with peers and/or management levels at a client and/or within Accenture. Establish methods and procedures\\non new assignments with guidance.\\nManage small teams of delivery engineers successfully delivering work efforts (if in an independent contributor role) at a client or within Accenture.\\nExtensive travel may be required\\n\\nBasic Qualifications\\nMinimum of 3 years previous Consulting or client service delivery experience on Google GCP\\nMinimum of 3 years of RDBMS experience\\nMinimum pf 3 years of experience in developing data ingestion, data processing and analytical pipelines for big data, relational databases, NoSQL, data lake and data warehouse solutionsMinimum of 3 years of hands-on experience in GCP and Big Data technologies such as Java, Node.js, C##, Python, PySpark, Spark/SparkSQL, Hadoop, Hive, Pig, Oozie and streaming technologies such as Kafka, Stream Ingestion API, Unix shell/Perl scripting etc.\\nExtensive experience providing practical direction with the GCP Native and Hadoop ecosystem\\nExperience with private and public cloud architectures, pros/cons, and migration considerations.\\nExtensive hands-on experience implementing data migration and data processing using GCP services etc:\\nData Ingestion : Cloud Pub/Sub, Data Transfer Service, Cloud IoT Core\\nData Storage : Cloud Spanner, Cloud Storage, Cloud Datastore, Cloud SQL, Cloud Bigtable, Cloud Memorystore\\nStreaming Data Pipeline : Cloud Dataflow, Cloud Dataproc, Cloud Dataprep, Apache Beam\\nData Warehousing &amp; Data Lake : BigQuery, Cloud Storage\\nAdvanced Analytics : Cloud ML engine, Google Data Studio, Google Datalab, Tensorflow &amp; Sheets\\nExperience working with DevOps tools such as GitLabs, Jenkins, CodeBuild, CoePipeline CodeDeploy, etc.\\nBachelors or higher degree in Computer Science or a related discipline.\\nAble to trval 100% M-TH\\n\\nCandidate Must Have Completed The Following Certifications\\nCertified GCP Developer - Associate\\nCertified GCP DevOps – Professional (Nice to have)\\nCertified GCP Big Data Specialty (Nice to have)\\n\\nNice-to-Have Skills/Qualifications:\\nDevOps on an GCP platform. Multi-cloud experience a plus.\\nExperience developing and deploying ETL solutions on GCP using tools like Talend, Informatica, Matillion\\nIoT, event-driven, microservices, containers/Kubernetes in the cloud\\nExperience in Apache Maven a plus\\nUnderstanding and implementation of Data Lake architecturesUnderstanding NoSQL technologies such as MongoDB, Cassandra, Hbase is a plusUnderstanding Solr, Elasticsearch is a plus\\n\\n\\nProfessional Skill Requirements\\nProven ability to build, manage and foster a team-oriented environment\\nProven ability to work creatively and analytically in a problem-solving environment\\nDesire to work in an information systems environment\\nExcellent communication (written and oral) and interpersonal skills\\nExcellent leadership and management skills\\n\\nAll of our professionals receive comprehensive training covering business acumen, technical and professional skills development. You'll also have opportunities to hone your functional skills and expertise in an area of specialization. We offer a variety of formal and informal training programs at every level to help you acquire and build specialized skills faster. Learning takes place both on the job and through formal training conducted online, in the classroom, or in collaboration with teammates. The sheer variety of work we do, and the experience it offers, provide an unbeatable platform from which to build a career.\\n\\nApplicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status).\\n\\nCandidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.\\n\\nAccenture is a Federal Contractor and an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities.\\n\\nEqual Employment Opportunity\\n\\nAll employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.\\n\\nJob candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.\\n\\nAccenture is committed to providing veteran employment opportunities to our service men and women.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Senior Cloud Solutions Architect</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nMastery in at least one of the following domain areas:\\nInfrastructure Modernization: migrating n-tiered workloads from on-prem and other clouds to GCP with near-zero-downtime (includes full spectrum of lift and shift to complete re-platforming scenarios), or building hybrid-cloud solutions based on Anthos and containerization technologies, such as Docker, Kubernetes, and Istio\\nApplication Development: building custom web and mobile applications on top of the GCP stack\\nData Engineering: data warehouse modernization (including technical architectures, star/snowflake schema designs, infrastructure components, ETL/ELT pipelines and reporting/analytic tools), OLTP/OLAP data migrations, or backup, restore and disaster recovery solutions.\\nExperience providing oversight and direction of cloud projects\\nExperience leading technical design sessions, architecting and documenting technical solutions that are aligned with client business objectives, and identifying gaps between the client's current and desired end states\\nExperience strategizing, designing, architecting and leading the deployment of scalable solutions on GCP\\nExperience across multiple cloud platforms: GCP, AWS, Azure\\nExperience with container engines: Kubernetes, Docker, AWS Elastic Container Service\\nExperience with automation technologies including Terraform, Google Cloud Deployment Manager, AWS Cloud Formation or Microsoft Azure Automation\\nExperience working with engineering and sales teams to elicit customer requirements\\nAbility to communicate across business units and the ability to interface with and communicate complex technical concepts to a broad range of internal and external stakeholders\\nTime management skills with the ability to manage multiple streams and lead less experienced architects\\nExperience as a technical consultant or another customer-facing technical role\\n</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Join SADA as a Sr. Cloud Solutions Architect!\\n\\nYour Mission\\n\\nAs a Sr. Cloud Solutions Architect at SADA, you will work collaboratively with other architects and engineers to design, prototype and lead the deployment of scalable Google Cloud Platform (GCP) architectures. You will work with engineering teams, customers and sales teams to qualify potential engagements, craft robust architectural proposals, and deliver Statements of Work (SOWs) that engineering teams can successfully execute. You’re also hands-on, able to conduct experiments and build functioning prototypes that prove out ideas and build confidence in the solutions you advocate.\\n\\nYou will be a recognized expert within SADA and will develop a reputation with customers as well as the Google Cloud sales and professional services organizations for the quality of your work. You will demonstrate repeated delivery of project architectures that other engineers and architects demur to you for lack of expertise. You will also lead early-stage opportunity technical qualification calls, as well as lead client-facing technical discussions.\\n\\nPathway to Success\\n\\n#BeAChangeAgent: You are a rainmaker! You are way out in front of our delivery organization, meeting with the spectrum of corporate and enterprise customers that need our consultative services. You have your finger on the pulse of their technical needs and take pride in helping them solve their real-world problems on GCP.\\n\\nYou will be measured quarterly by a combination of (a) the volume of signed SOWs that you shepherd through the sales funnel, and (b) the level of customer satisfaction measured at the end of each engagement.\\n\\nAs you continue to execute successfully, we will build a customized development plan together that leads you through the solution architecture or management growth tracks.\\n\\nExpectations\\n\\nRequired Travel - 30% travel to customer sites, conferences, and other related events.\\nCustomer Facing - You will interact with customers on a regular basis, sometimes daily, other times weekly/bi-weekly. Common touchpoints occur when qualifying potential opportunities, at project kickoff, throughout the engagement as progress is communicated, and at project close. You can expect to interact with a range of customer stakeholders, including engineers, technical project managers, and executives\\nTraining - Ongoing with first-week orientation at HQ followed by a 90-day onboarding schedule. Details of the timeline can be shared.\\n\\nJob Requirements\\n\\nRequired Credentials:\\n\\nGoogle Professional Cloud Architect Certified\\n\\n[https://cloud.google.com/certification/cloud-architect] and/or Google\\nProfessional Data Engineer Certified\\n[https://cloud.google.com/certification/data-engineer], or able to complete one of the above within the first 45 days of employment.\\n\\nRequired Qualifications:\\n\\nMastery in at least one of the following domain areas:\\nInfrastructure Modernization: migrating n-tiered workloads from on-prem and other clouds to GCP with near-zero-downtime (includes full spectrum of lift and shift to complete re-platforming scenarios), or building hybrid-cloud solutions based on Anthos and containerization technologies, such as Docker, Kubernetes, and Istio\\nApplication Development: building custom web and mobile applications on top of the GCP stack\\nData Engineering: data warehouse modernization (including technical architectures, star/snowflake schema designs, infrastructure components, ETL/ELT pipelines and reporting/analytic tools), OLTP/OLAP data migrations, or backup, restore and disaster recovery solutions.\\nExperience providing oversight and direction of cloud projects\\nExperience leading technical design sessions, architecting and documenting technical solutions that are aligned with client business objectives, and identifying gaps between the client's current and desired end states\\nExperience strategizing, designing, architecting and leading the deployment of scalable solutions on GCP\\nExperience across multiple cloud platforms: GCP, AWS, Azure\\nExperience with container engines: Kubernetes, Docker, AWS Elastic Container Service\\nExperience with automation technologies including Terraform, Google Cloud Deployment Manager, AWS Cloud Formation or Microsoft Azure Automation\\nExperience working with engineering and sales teams to elicit customer requirements\\nAbility to communicate across business units and the ability to interface with and communicate complex technical concepts to a broad range of internal and external stakeholders\\nTime management skills with the ability to manage multiple streams and lead less experienced architects\\nExperience as a technical consultant or another customer-facing technical role\\n\\nUseful Qualifications:\\n\\nHands-on experience designing and recommending elegant solutions that drive business outcomes\\nExperience building, designing and migrating complex cloud architectures\\nStrong aptitude for learning new technologies and techniques with a willingness and capability to skill up the team\\nAbility to lead an in-depth client meeting/workshop across a broad range of topics including discovery, cloud compliance, and security\\nDeep understanding of best practices, design patterns, reference and compliance architectures with an uncanny ability to build and recommend these as needed\\nKnowledge and understanding of industry trends, new technologies and the ability to apply these to customer architectures to drive outcomes\\nHighly self-motivated and able to work independently as well as in a team environment\\n\\nAbout SADA\\n\\nValues: We built our core values\\n[https://sadasystems.com/about/company-overview/] on themes that internally compel us to deliver our best to our partners, our customers and to each other. Ensuring a diverse and inclusive workplace where we learn from each other is core to SADA’s values. We welcome people of different backgrounds, experiences, abilities and perspectives. We are an equal opportunity employer.\\n\\n1. Make them rave\\n2. Be data driven\\n3. Be one step ahead\\n4. Be a change agent\\n5. Do the right thing\\n\\nWork with the best : SADA has been the largest partner in North America for GCP since 2016 and recently announced, at Google NEXT, as the\\n2018 Global Partner of the Year\\n[https://sadasystems.com/blog/google-cloud/gcp/sada-wins-2018-google-cloud-partner-award/]. SADA has also been awarded\\nBest Place to Work\\n[https://sadasystems.com/blog/news/sada-systems-best-places-work-2019/] by Inc. as well as LA Business Journal!\\n\\nBenefits : Unlimited PTO\\n[https://sadasystems.com/blog/news/blogannouncementsblogannouncementsunlimited-pto-yes-unlimited-why-sada-is-the-best-place-to-work/], competitive and attractive compensation, performance-based bonuses, paid holidays, rich medical, dental, vision plans, life, short and long-term disability insurance, 401K with match,\\nprofessional development reimbursement program\\n[https://sadasystems.com/blog/news/blogannouncementsprofessional-development-how-we-do-it-why-it-matters/] as well as Google Certified training programs.\\n\\nBusiness Performance: SADA has been named to the INC 5000 Fastest Growing Private Companies list for 12 years in a row garnering Honoree status. CRN has also named SADA on the Top 500 Global Solutions Providers for the past 5 years. The overall culture continues to evolve with engineering at its core: 3200+ projects completed, 3000+ customers served, 10K+ workloads and 25M+ users migrated to the cloud.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Senior Big Data Engineer- Java/Scala/Python</td>\n",
       "      <td>Atlanta, GA 30327</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>30327</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nBachelors/Master/PHD in computer science, engineering, information technology, or related degree and/or equivalent work experience\\n4+ years of Java development experience in large scale enterprise development for Undergraduates\\n2+ years of Java development experience in large scale enterprise development for Masters or PHD\\nKnowledge of multiple threading development and performance tuning\\nKnowledge of implementing efficient logic using collections and data structures\\nKnowledge of one or more Big Data Technologies like Elastic Search, Spark, Kafka, Map-Reduce, HDFS and Hive\\nKnowledge in Design Patterns, OOP/OOD, Software Architecture\\nKnowledge of how to assess the performance of data solutions, how to diagnose performance problems, and tools used to monitor and tune performance.\\nExcellent communication skills with both Technical and Business audience</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Travelport are the only true travel commerce platform in the world. We are specialist solution providers and are committed to building leading technology that makes the experience of buying and managing travel continually better for the global travel and tourism industry. Come and be part of our mission to make sure that every trip is powered by Travelport…\\nRole &amp; Team\\nYou will come on board at a truly exciting time, and as a member of the Big Data Team, you will play a pivotal and crucial part in finding unrivaled and creative ways to use the massive amount of data that we generate.\\nTravelport’s Big Data Engineers are tasked with designing and implementing big data solutions with terabytes and petabytes daily transaction volume. Travelport employees enjoy a collaborative environment and have many opportunities to learn from and share knowledge with other Travelport developers, architects, and business architects.\\nMain Accountabilities:\\nLead, design, develop, document, and test big data solutions.\\nInstall and integrate various technologies in the big data echo system\\nConfigure and troubleshoot issues in big data framework\\nAid in the implementation of and implementing analytical models\\nDeliver solutions for using an Agile Development model\\nCreate quality deliverables to communicate technical solutions to appropriate audiences.\\nUnderstand issues, problem solving and design/architect solutions\\nBuild and collaborate with business and technical teams to deliver software\\nLearn continuously, leveraging training resources and self-directed training, sharing knowledge and skills with others.\\nProvide mentoring and leadership to more junior resources.\\nPassion for technology and willingness to learn is required\\nHave ability to work in a fast paced and dynamic work environment and be able to produce efficient and robust solution\\nHigh energy, confidence, and agility to drive a team\\nCandid and direct communication\\nA creative thinker who can bring in new ideas and innovations to the company.\\nRequired Qualifications:\\nBachelors/Master/PHD in computer science, engineering, information technology, or related degree and/or equivalent work experience\\n4+ years of Java development experience in large scale enterprise development for Undergraduates\\n2+ years of Java development experience in large scale enterprise development for Masters or PHD\\nKnowledge of multiple threading development and performance tuning\\nKnowledge of implementing efficient logic using collections and data structures\\nKnowledge of one or more Big Data Technologies like Elastic Search, Spark, Kafka, Map-Reduce, HDFS and Hive\\nKnowledge in Design Patterns, OOP/OOD, Software Architecture\\nKnowledge of how to assess the performance of data solutions, how to diagnose performance problems, and tools used to monitor and tune performance.\\nExcellent communication skills with both Technical and Business audience\\nPreferred Qualifications:\\nStrong programming skills in standard programming and/or algorithms\\n1+ years of Scala or Python programming\\n1+ years of development experience in the field of big data on Large Scale environment (e.g. Hadoop, MongoDB, Couch Base, Cassandra)\\n1+ years of Spark Based Technologies (e.g. Spark Dataframes, Spark Streaming and Spark SQL)\\nKnowledge of Big Data querying tools (e.g. Spark, Pig, Hive, and Impala)\\nAid in the modeling and implementation of machine learning and deep learning solutions\\nReal time analytics using stream processing frameworks such like Spark / Storm\\nExperience in the following: C, C++, Perl, or PHP\\nKnowledge of designing and developing reusable components\\nExperience in web frontend development (e.g. Javascript, Jquery, AngularJS, ReactJS)\\nIf this sounds like you, we’d love for you to get in touch.\\nWhat’s in it for you...\\nYou will receive a competitive salary &amp; benefits package accompanied by the opportunity to work in a fast-paced, dynamic and progressive organisation that cares about its people and promotes innovation.\\nWe are an equal opportunity employer and value diversity at our company. We do not discriminate based on race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Peachtree Corners, GA</td>\n",
       "      <td>Peachtree Corners</td>\n",
       "      <td>GA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Development and implementation of Master Data Web services/APIs as part of the Crawford Master Data Services Framework\\nResponsible for developing solutions in the Informatica MDM platform (also Salesforce and/or Mulesoft) by converting business requirements into quality technical solutions\\nAssist with the development and enforcement architecture standards\\nServe as an expert developer, proficient in configuring, staging, loading, matching and merging processes and overseeing and promoting quality development standards\\nCapture and rationalize key business requirements data definitions for attributes in conceptual and logical models\\nPerforming data extraction from legacy systems to map/load data into Informatica MDM performing validation routines and reviewing that all data was appropriately loaded\\nEngage with business partners to understand functional requirements to design best possible global solutions\\nAnalyze business and data requirements and help define the best solution keeping our long term goal in mind of reducing data redundancy\\nProvide business and technical input in project activities and decision making processes\\nPerforms analysis of cross-functional and complex business requirements.\\nFollow project management methodologies and ensure the timely delivery of project deliverables\\nUnderstand, influence and provide feedback on technical solution in support of end-to-end data, processes and assets\\nFlexibility and ability to work in a global and multi-cultural environment. Team members are in multiple geographies, resulting in time constraints due to time zones differences</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Bachelor's/Master’s degree or equivalent in Information Technology, Computer Science, Engineering or related field.\\n1 – 3 years prior experience\\nCertified Data Management Professional (CDMP) preferred\\nSome experienced in extracting and loading large data volumes to-and-from platforms such a Microsoft Azure and Amazon Web Services (AWS)\\nHands on experience working on UI development and configuration\\nMust have a minimum of exposure to tools such as and not limited to Java, C,C++, C#,VB, Sql Server/Oracle.\\nExperience with analysis and business intelligence tools (Tableau, Cognos, etc.)\\nBasic understanding of databases (RDBMSs) and database scripting.\\nHave some performance tuning and SQL query skills\\nSome experience with 3rd party package software (Oracle, Informatica, SAP)\\nSome knowledge and experience in software development life cycle (SDLC), software development methodologies and standards</td>\n",
       "      <td>Excellence In Everything We Touch\\nPosition Summary\\nTranslating business requirements into callable data services, which may focus on issues such as reducing redundancy of data within the Crawford environment and improving the way in which it moves from one system to another. Will contribute technical and business knowledge expertise to design, develop, and implement integrated IT / business solutions focused primarily around the linkage to/from the Master Data Management (MDM) platform. Contributions will be on both next-generation and legacy solutions.\\nResponsibilities\\nDevelopment and implementation of Master Data Web services/APIs as part of the Crawford Master Data Services Framework\\nResponsible for developing solutions in the Informatica MDM platform (also Salesforce and/or Mulesoft) by converting business requirements into quality technical solutions\\nAssist with the development and enforcement architecture standards\\nServe as an expert developer, proficient in configuring, staging, loading, matching and merging processes and overseeing and promoting quality development standards\\nCapture and rationalize key business requirements data definitions for attributes in conceptual and logical models\\nPerforming data extraction from legacy systems to map/load data into Informatica MDM performing validation routines and reviewing that all data was appropriately loaded\\nEngage with business partners to understand functional requirements to design best possible global solutions\\nAnalyze business and data requirements and help define the best solution keeping our long term goal in mind of reducing data redundancy\\nProvide business and technical input in project activities and decision making processes\\nPerforms analysis of cross-functional and complex business requirements.\\nFollow project management methodologies and ensure the timely delivery of project deliverables\\nUnderstand, influence and provide feedback on technical solution in support of end-to-end data, processes and assets\\nFlexibility and ability to work in a global and multi-cultural environment. Team members are in multiple geographies, resulting in time constraints due to time zones differences\\nRequirements\\nBachelor's/Master’s degree or equivalent in Information Technology, Computer Science, Engineering or related field.\\n1 – 3 years prior experience\\nCertified Data Management Professional (CDMP) preferred\\nSome experienced in extracting and loading large data volumes to-and-from platforms such a Microsoft Azure and Amazon Web Services (AWS)\\nHands on experience working on UI development and configuration\\nMust have a minimum of exposure to tools such as and not limited to Java, C,C++, C#,VB, Sql Server/Oracle.\\nExperience with analysis and business intelligence tools (Tableau, Cognos, etc.)\\nBasic understanding of databases (RDBMSs) and database scripting.\\nHave some performance tuning and SQL query skills\\nSome experience with 3rd party package software (Oracle, Informatica, SAP)\\nSome knowledge and experience in software development life cycle (SDLC), software development methodologies and standards\\nAbout Us\\nPeople taking care of people. It’s that simple. At Crawford &amp; Company, we treat our clients’ policyholders like our own, helping to restore and enhance lives, businesses and communities at all points of the claims management process. Combining a legacy of nearly 80 years of unmatched experience with global capabilities and industry-leading technology, Crawford is at the forefront of change, while also staying firmly rooted to our commitment to putting people first.\\nWe are guided by our collective value system: RESTORE.\\nAt Crawford, we:\\nRespect our culture of integrity and ethical behavior, while embracing the unique talents of the individual and encouraging an ownership mentality among everyone.\\nAre Empowered to advance the company mission and take ownership of our individual career progression.\\nPromote Sustainability through a corporate culture in which employees are good stewards of their communities.\\nEmphasize Training and an environment where employees continually seek and share knowledge and are engaged and satisfied with their work.\\nAre One Crawford, embracing a global mindset that’s inclusive, agile, mission-focused, and customer-focused.\\nGive Recognition, participating in an environment where people are rewarded for jobs well done.\\nEmbody an Entrepreneurial Spirit, sharing a passion to succeed, innovate, and outpace our competitors.\\nWe believe in leading by example – at work and in our communities. We hail from more than 70 countries and speak dozens of languages, reflecting the global fabric of the audience we serve. Though our reach is vast, we proudly operate as One Crawford: united in mission, vision and values. Learn more at www.crawfordandcompany.com.\\nIn addition to a competitive salary, Crawford offers you:\\nCareer advancement potential locally, nationally and internationally. Crawford &amp; Company has more than 700 locations in 70 countries\\nOn-going training opportunities through every stage of your career\\nStrong benefits package including matching 401k; health, dental, and life insurance; employee stock purchase plans; tuition reimbursement and so much more.\\nCrawford &amp; Company participates in E-Verify and is an Equal Opportunity Employer. M/F/D/V Crawford &amp; Company is not accepting unsolicited assistance from search firms for this employment opportunity. All resumes submitted by search firms to any employee at Crawford via-email, the Internet or in any form and/or method without a valid written Statement of Work in place for this position from Crawford HR/Recruitment will be deemed the sole property of Crawford. No fee will be paid in the event the candidate is hired by Crawford as a result of the referral or through other means.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Do you enjoy helping business teams make good decisions with data? The work you do will be instrumental in developing the Clutch platform especially around building technology and products that makes it possible for us to create, launch and manage mobility service offerings. This is a technical role with strong software engineering experience.\\n\\nWhat You'll Do\\n\\nLead the technical efforts to build the Data Warehouse at Clutch leveraging mainly Open source and Cloud technologies\\nArchitect data pipelines and ETL jobs to injest data from different sources into a queryable format for Analytics and Business Intelligence\\nDeliver gold standard dashboards providing key metrics to both internal and external customers\\nDefine and implement architecture to enable outflow of data to our customers\\nMust Haves\\n\\n2-5 years experience working with data\\nStrong programming skills in Python or other high level languages like Java\\nStrong SQL query writing skills including ability to address query performance issues\\nExperience identifying the right tools and designing a data warehouse from scratch\\nExperience communicating with business users and helping them articulate requirements\\nNice to Haves\\n\\nDelivering software working in an Agile environment\\nExposure to machine learning algorithms and data science\\nFamiliarity with NoSQL databases and Big Data technologies\\nExperience with best in class commercial BI tools\\nBS in Computer Science or equivalent Analytics background\\nAbout Clutch\\nClutch Technologies is the leader in subscription and mobility services software to the automotive industry. Utilizing Clutch’s end-to-end platform, automotive dealers, OEM’s, car rental companies and fleet operators can increase asset utilization, offer new revenue streams and deliver innovative consumer experiences. Clutch, a Cox Automotive company, is recognized as a pioneer in the subscription category and has been chosen, trusted and recommended by more than 45 signed dealers and manufacturers across the U.S. and Canada.\\n\\nIf you'd like to be considered for the position write to the email below with the job title as the subject.\\nengineeringjobs@driveclutch.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>AI Model Development Lead For Marketing (Analytics Manager 5)</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\n8+ years of experience in analytics, modeling, or a combination of both\\n6+ years of management experience; or 6+ years of leadership experience in an advanced quantitative analytics function\\nA Master's degree or higher\\n5 + years of experience using quantitative machine learning techniques\\n4+ years of experience working with digital data science including analyzing cookie-level data</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Overview:\\nWells Fargo technology teams drive innovation to create a more powerful and fulfilling financial experience for our customers and team members. You will join more than 24,000 team members supporting 95 billion transactions annually in 10 countries. Our career opportunities span the technology spectrum: advanced analytics, big data, information security, application development, cloud enablement, project management and more.\\n\\nSUCCESS PROFILE\\nCheck out the top traits we're looking for and see if you have the right mix. Additional related traits listed below.\\n\\nAnalytical\\nDetail-oriented\\nInsightful\\nInventive\\nProblem Solver\\nCurious\\nBenefits\\nWells Fargo wants to help you get more out of life and take care of things outside the office to make life a little easier. We provide:\\n\\nMedical, Dental and Vision\\nEmployer Matching 401(k)\\nTuition Reimbursment\\nMaternity and Paternity Leave\\nPaid Time Off\\nResponsibilties\\nJob Description\\nAt Wells Fargo, we want to satisfy our customers’ financial needs and help them succeed financially. We’re looking for talented people who will put our customers at the center of everything we do. Join our diverse and inclusive team where you’ll feel valued and inspired to contribute your unique skills and experience.\\nHelp us build a better Wells Fargo. It all begins with outstanding talent. It all begins with you.\\nEnterprise Finance drives financial management for the company and maintains and enhances risk and financial controls. Key functions within Enterprise Finance include finance and accounting; Treasury; corporate development, mergers, and acquisitions; Data Management and Insights, the Customer Remediation Center of Excellence, Enterprise Shared Services, Business Process Management, and Corporate Strategy. Enterprise Finance informs shareholders, regulators, taxing authorities, team members, and leaders of the company’s financial performance through earnings releases, investor meetings and conferences, and meetings with regulators and credit rating agencies, following appropriate reporting guidelines. They also maintain and enhance risk and financial controls and lead many of the company’s shared services functions including corporate properties, security, and global services.\\nAs part of the newly formed AI Model Development COE in Enterprise Analytics and Data Science (EADS), which focuses on building, implementing, and monitoring AI models for the enterprise, the AI model development team for personalization, marketing, and virtual channels is looking for an experienced AI leader to manage the development of AI models for marketing.\\n\\nThis leader will be responsible for building and managing a team of data scientists to design, develop, and implement AI models focused on marketing’s AI priorities. Partnering with Wells Fargo AI technology team, Wells Fargo AI business solution team, and marketing executives, you and your team will deliver and deploy AI models on the Well Fargo AI open source platform to scale these solutions and embed them in our operational processes.\\nKEY RESPONSIBILITIES INCLUDE:\\nBuild and grow a team of data scientists responsible for AI model development in support of marketing\\nDesign, develop, and deploy AI models using state of the art AI techniques available in the open stack and/or vendor solutions\\nPartner with marketing executives to frame the problem, manage the model development process, and business relationship\\nManage a portfolio of the data science projects including the following responsibilities:\\nHelp finalize project scope working with business partners\\nOn-going touch-base with business partners and governance stakeholders\\nDefine priorities in partnership with the business partners during on-going development\\nWork with AI technology and production teams to operationalize models\\nMay be called upon to review vendor models and solutions and/or models developed outside of EADS\\nDivisional Information:\\nData Management and Insights (DMI) is transforming the way that Wells Fargo uses and manages data. Our work enables Wells Fargo to empower and inform our team members, deliver exceptional experiences for our customers, and meet the elevated expectations of our regulators. The team is responsible for designing the future data environment, defining data governance and oversight, and partnering with technology to operate the data infrastructure for the company. This team also provides next generation analytic insights to drive business strategies and help meet our commitment to satisfy our customers’ financial needs.\\nAs a Team Member Manager, you are expected to achieve success by leading yourself, your team, and the business. Specifically you will:\\nLead your team with integrity and create an environment where your team members feel included, valued, and supported to do work that energizes them.\\nAccomplish management responsibilities which include sourcing and hiring talented team members, providing ongoing coaching and feedback, recognizing and developing team members, identifying and managing risks, and completing daily management tasks.\\n\\nRequired Qualifications\\n\\n8+ years of experience in analytics, modeling, or a combination of both\\n6+ years of management experience; or 6+ years of leadership experience in an advanced quantitative analytics function\\nA Master's degree or higher\\n5 + years of experience using quantitative machine learning techniques\\n4+ years of experience working with digital data science including analyzing cookie-level data\\n\\n\\nDesired Qualifications\\n\\nStrong analytical skills with high attention to detail and accuracy\\nAbility to work and influence successfully within a matrix environment and build effective business partnerships with all levels of team members\\nMeeting facilitation experience in leading discussions that result in consensus and commitment\\n\\n\\nOther Desired Qualifications\\nData science experience in the ad tech space (DMPs, DSPs, Google and/or Adobe Cloud, digital attribution)\\n4+ years managing or directing data scientist/ statistician/ data engineer teams\\nHands on experience with deep learning toolkits such as Tensorflow, Keras, PyTorch, Dynet\\nDetail oriented. Experience with model governance requirements. Able to de-mystify AI models to make them transparent and explainable\\nExperience with agile project management methodologies for data science\\n\\nDisclaimer\\n\\nAll offers for employment with Wells Fargo are contingent upon the candidate having successfully completed a criminal background check. Wells Fargo will consider qualified candidates with criminal histories in a manner consistent with the requirements of applicable local, state and Federal law, including Section 19 of the Federal Deposit Insurance Act.\\n\\nRelevant military experience is considered for veterans and transitioning service men and women.\\n\\nWells Fargo is an Affirmative Action and Equal Opportunity Employer, Minority/Female/Disabled/Veteran/Gender Identity/Sexual Orientation.\\n\\nENT FINANCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Duluth, GA 30095</td>\n",
       "      <td>Duluth</td>\n",
       "      <td>GA</td>\n",
       "      <td>30095</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nTechnology certifications such as Amazon Certified Solutions Architect\\nProficiency in programming in Spark, R and/or ML packages\\nExposure to applications developed to support manufacturing quality\\nExperience with MS Dynamics CRM, MicroStrategy BI tools, SAP ERP\\nConsulting experience\\n</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>If you have these 7 bullet points we are interested in talking to you, please read the entire JD as well.\\n\\n\\nSSIS\\nETL\\nData analysis and profiling\\nData Model\\nPowerBI\\nReporting\\nData Warehouse.\\n\\nHere is the complete Job Description.\\n\\nJob Details\\n\\nDescription\\n\\nThe Data Engineer will be responsible for expanding and optimizing our data capabilities for Data Warehousing, Master Data, Data Services as well as Business Intelligence. The ideal candidate is an experienced data wrangler who enjoys optimizing data systems and can build them from the ground up. He/she must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. The ideal candidate will be excited by the prospect of optimizing or even re-designing our companys data architecture to support our next generation of products and data initiatives.\\n\\nResponsibilities\\n\\n\\nDrive design and development of internal data pipeline architecture to service BI and Analytics capabilities\\nWork with key stakeholders including Product, Sales, Quality Engineering and Marketing to assist with data-related technical needs and support their data infrastructure needs.\\nEnsure operational resilience, stability, and scalability of our enterprise data platform by conduct continuous hardening activates that increase uptime, data quality and reduce cost\\nEnsure tight data platform security during data transport and while at rest\\nBuild hybrid cloud/prem data platform to enable self-service Business Intelligence and Analytics functions\\nConduct data profiling and analysis of complex data sets to discover how to meet functional / non-functional requirements\\nInstitute data quality monitoring and alerting platform operations\\nBuild analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics\\nDrive solutions for meta data and data lineage management\\nDrive innovation by recommending and driving adoption of new technologies that provide competitive data advantages for enterprise\\nContributes to agile team alignment and is committed to constant improvement efforts by participating in team ceremonies sprint planning, stand-ups, backlog grooming and retrospectives\\nEnsure technical delivery of detailed feature/story level solutions that satisfies the IT roadmaps acceptance criteria\\nMaintains professional and technical knowledge by attending educational workshops; reviewing professional publications; establishing personal networks; participating in professional societies\\n\\nMinimum Work Experience\\n\\n\\n8+ years of proven experience in the design, development and deployment of end-to-end data pipeline solutions including data processing (Batch, Micro-Batch, Streaming), data preparation (ETL, ELT), data modeling (STAR, OLAP, MPP)\\n5+ year of Business Intelligence Development and Administration\\nExperience of building data solutions for back office applications that source data from CRM and ERP applications\\nAdvanced experience working with SQL Server databases\\nStrong grasp of master data management, data quality monitoring and metadata management\\nProficiency in data centric shell scripting, ETL, Python, and/or .NET Programming skills\\nA comfortable and confident communicator with technical staff but also able to speak with customers concisely to translate technical concepts into business terminology and impacts\\nExposure to continuous integration implementations that utilize DevOps style tools (such as Jenkins, Chef, Docker, Terraform, etc.)\\nProven team player with the ability to multi-task in a fast-paced dynamic agile work environment\\nHas previously supported a metrics-driven data culture to drive accountability and transparency\\nPassionate problem solver and motivated self-starter including ability to analyze situation and recommend sound solutions and implementation strategies\\n\\nAdditional Desired Skills:\\n\\nTechnology certifications such as Amazon Certified Solutions Architect\\nProficiency in programming in Spark, R and/or ML packages\\nExposure to applications developed to support manufacturing quality\\nExperience with MS Dynamics CRM, MicroStrategy BI tools, SAP ERP\\nConsulting experience\\n\\nEducation: Bachelors degree in Computer Science, Information Systems, or combination of education and experience.\\n\\nLocation: Duluth, Georgia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Who is Georgia-Pacific?Watch to find out!\\nData Engineer\\nAtlanta, GA or Green Bay, WI\\nGeorgia-Pacific is a known industry leader with roughly 200 facilities and 35,000 world-class employees who strive for excellence, challenge the status quo, and create value.\\nGP makes products that are part of your everyday life. We are one of the world’s leading producers of tissue, pulp, paper, packaging, building products, and related chemicals. If you are self-driven with a commitment to safety, manufacturing excellence, and product quality, we’re looking for people like you.\\nGeorgia-Pacific (GP) is seeking several motivated and inquisitive individuals with skills in data engineering to help start-up and run a brand-new centralized support center\\nA Day In The Life Typically Includes:\\nGeorgia-Pacific is looking for a Data Engineer on its Data Historian team in Atlanta, GA who will work closely with a highly leveraged team of system experts that provide project resources and troubleshooting support for data collection and process visualizations systems. Duties include:\\nWorking with Manufacturing Big Data, Machine Learning Models, AWS, Data Visualization, and Edge devices\\nStream / Transfer data from manufacturing equipment to Data Lake and Data Historian tools residing in AWS\\nDesign and maintain a technical environment that enables development of Machine Learning and other Analytical Models\\nDeployment and monitoring of Analytical Models to AWS, Edge Server, Edge Gateways devices for 40+ manufacturing sites\\nDevelop data visualization for analytical models in PI Vision, Tableau, custom web page\\nDaily collaboration with Data Scientist, Manufacturing Equipment SMEs, Remote Support Engineers, and IT peers\\nPosition reports thru Information Technology\\n\\nWhat You Will Need:\\nBasic Qualifications:\\nBachelor's Degree in IT, Engineering, or Data Science\\nProven ability to collaboratively work with peers and internal customers\\nExperience in programming in at least one object-oriented programming language such as Java, C#, C++, or Python\\nKnowledge of software engineering best practices and software project lifecycles\\nExperience with data integration ETL techniques and frameworks\\nAbility and desire to learn new technologies\\nAbility to create and maintain clearly written technical, user, and system documentation\\n\\nWhat Will Put You Ahead?\\nPreferred Qualifications:\\nExperience with Python, Amazon Web Services, OSIsoft PI Data Historian software, Tableau, SAS, Dataiku\\nExperience in deploying Analytical models to the Cloud and Edge environments\\nExperience working in multi-site manufacturing environment\\nUnderstanding of the Purdue model, IT/OT network segmentation, and PLC/DCS communication\\nWant to learn more about Georgia-Pacific?\\nSalary and benefits commensurate with experience.\\nWe are an equal opportunity employer. Minority/Female/Disabled/Veteran\\nExcept where prohibited by state law, all offers of employment are conditioned upon successfully passing a drug test.\\n\\nThis employer uses E-Verify. Please visit the following website for additional information: www.kochcareers.com/doc/Everify.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Atlanta, GA 30309</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>30309</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Previous management experience and successfully leading a team of direct reports\\nProven track record of effectively leading and managing employees, managing performance, setting goals for team/individuals and provide mentoring.\\nStrong Tableau, Adobe Analytics other BI solution\\nExpert Oracle and Vertica skillsets\\nExperience using JIRA and Agile Project Management software\\nExperience using GitHub, Bit Bucket, or other code repository solution\\nStrong written, verbal communication and presentation skills\\nAbility to explain complex technical issues in a way that non-technical people may understand\\nAble to work in a global, multicultural environment\\nSelf-motivated. Capable of working with little or no supervision\\nAbility to react positively under pressure to meet tight deadlines\\nAble to work independently or as a team player\\nEnjoy challenging and thought provoking work and have a strong desire to learn and progress</td>\n",
       "      <td>Work with development teams and other project leaders/stakeholders to provide technical solutions that enable business capabilities\\nSupports the data science community by enabling data availability in environments that provide advanced analytical capabilities\\nMaintains a broad understanding of implementation, integration, and inter-connectivity issues with emerging technologies to define data strategies\\nAssist in the decision-making process related to the selection of software architecture solutions\\nImplement architectures to handle web-scale data and its organization\\nExecute strategies that inform data design and architecture partnering with enterprise standard\\nBuild robust data pipelines on public Cloud using AWS Kinesis, Kafka, Lambda or other technologies\\nAssist in creating documents that ensure consistency in development across the online organization. Implements and improves core software infrastructure\\nDeep expertise in SQL language, Python, Hadoop ecosystem and/or Spark ecosystem. Strong experience with writing complex programs, implementing architectures, and enabling automation in these environments\\nDevelop and maintain business reporting, ensuring reliability and performance, delivery of performance management tools (such as control charts and scorecards), readiness and adoption of data w/in the organization\\nConsolidate, standardize and control changes to capacity management data and metric definitions, ownership, accountability and taxonomy to ensure alignment in understanding\\nServe as strong advocate to improve analytical capability across the organization\\nCommunicate with various business areas and to gather and prioritize their business requirements\\nSupport various reporting and BI solutions (Tableau, Power BI, Salesforce Einstein)\\nManage application and data integration platforms (Informatica, Talend)\\nManage the full life cycle of development/reporting/integration projects: planning, design, develop, testing and rollout\\nManage solution providers, define sourcing approach and manage the providers\\nCreate and manage data, applications and technology architecture documentation and design artifacts\\nWork across teams to deliver meaningful reference architectures that outline architecture principles and best practices for technology advancement\\nGain adoption of architecture processes, standards and procedures</td>\n",
       "      <td>\\nBS in Computer Science, Applied Mathematics, Physics, Statistics or area of study related to data sciences and data mining or relevant experience</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Invesco is one of the world’s leading global investment managers, entrusted with managing $1.2 trillion* in assets on behalf of clients worldwide. We are the 6th largest US retail asset manager and the 13th largest investment manager globally, and our more than 8,000 employees worldwide are dedicated to delivering an investment experience that helps people get more out of life. We are purely focused on managing a comprehensive range of active, passive and alternative investment capabilities, which we draw on to provide customized solutions aligned to client needs, our most important benchmark. (*As of May 31,2019)\\n\\nJob Purpose (Job Summary):\\n\\nAs a Senior Data Engineer at Invesco, you would align business outcomes to technology goals and objectives. You will be responsible for managing decision sciences and advanced analytics initiatives, data integration/engineering. Interacts with Data Scientists, Business Owners, Business Data Analysts, Data Modelers, Architects, and Application Developers, to design, build and manage large-scale batch and real-time data pipelines utilizing various data analytics processing frameworks in support of Data Science practice. The position requires building strong technical hands-on-skills and experiences as well as establishing close business relationships across the enterprise. Working closely with marketing and sales stakeholders, you will establish and drive long term advance analytics roadmap manage increasing demands for advance analytics in Sales and Marketing. You will help steer the strategic technology direction, define target state architecture, technology roadmaps and mentor others. A successful candidate must have a demonstrable background with experience in development of high performance, distributed computing tasks using Big Data technologies such as Hadoop (platform level), NoSQL, text mining and other distributed environment technologies based on the needs of the organization. Responsible for analyzing, designing, programing, debugging and modifying software enhancements and/or new products used in distributed, large scale analytics solutions. Strong visualization skills and experience with BI tools (ex. Tableau)\\n\\nKey Responsibilities / Duties:\\nWork with development teams and other project leaders/stakeholders to provide technical solutions that enable business capabilities\\nSupports the data science community by enabling data availability in environments that provide advanced analytical capabilities\\nMaintains a broad understanding of implementation, integration, and inter-connectivity issues with emerging technologies to define data strategies\\nAssist in the decision-making process related to the selection of software architecture solutions\\nImplement architectures to handle web-scale data and its organization\\nExecute strategies that inform data design and architecture partnering with enterprise standard\\nBuild robust data pipelines on public Cloud using AWS Kinesis, Kafka, Lambda or other technologies\\nAssist in creating documents that ensure consistency in development across the online organization. Implements and improves core software infrastructure\\nDeep expertise in SQL language, Python, Hadoop ecosystem and/or Spark ecosystem. Strong experience with writing complex programs, implementing architectures, and enabling automation in these environments\\nDevelop and maintain business reporting, ensuring reliability and performance, delivery of performance management tools (such as control charts and scorecards), readiness and adoption of data w/in the organization\\nConsolidate, standardize and control changes to capacity management data and metric definitions, ownership, accountability and taxonomy to ensure alignment in understanding\\nServe as strong advocate to improve analytical capability across the organization\\nCommunicate with various business areas and to gather and prioritize their business requirements\\nSupport various reporting and BI solutions (Tableau, Power BI, Salesforce Einstein)\\nManage application and data integration platforms (Informatica, Talend)\\nManage the full life cycle of development/reporting/integration projects: planning, design, develop, testing and rollout\\nManage solution providers, define sourcing approach and manage the providers\\nCreate and manage data, applications and technology architecture documentation and design artifacts\\nWork across teams to deliver meaningful reference architectures that outline architecture principles and best practices for technology advancement\\nGain adoption of architecture processes, standards and procedures\\nWork Experience / Knowledge:\\n5+ years of experience in data modeling, data warehousing, and big data architectures\\n3+ years of experience in a data engineering role\\nProficient in application/software architecture (Definition, Business Process Modeling, etc.)\\nStrong analytics and reporting skills – hands on experience in BI Tools like Tableau, Power BI, Salesforce Einstein\\nDeep expertise in (at least one) SQL language, Python, Hadoop ecosystem and/or Spark ecosystem. Strong experience with writing complex programs, implementing architectures, and enabling automation in these environments\\nThe role will be responsible for providing innovative operational solutions and best practices\\nAdvanced knowledge in SQL/Hive, Spark, NoSQL, (Java/Python is a plus\\nStrong programming skills and ability to utilize a variety of software/languages/tools; e.g., Spark, R, Python, Scala, Java, Hive, SQL, SAS, Tableau, etc.\\nExperience with microservice development, Docker, Kubernetes\\nDevelop software to run on cloud native big data infrastructure built on AWS using Spark, Lambda, S3, and other cloud native services\\nDesigns and develops complex and large-scale data structures and pipelines to organize, collect and standardize data to generate insight\\n3+ years of experience in data integration platforms (Informatica, Talend)\\nHands on experience in self-service data preparation tool like Alteryx\\nExperience using GitHub, Bit Bucket, or other code repository solution\\nDevOps experience is a plus\\nSkills / Other Personal Attributes Required:\\nPrevious management experience and successfully leading a team of direct reports\\nProven track record of effectively leading and managing employees, managing performance, setting goals for team/individuals and provide mentoring.\\nStrong Tableau, Adobe Analytics other BI solution\\nExpert Oracle and Vertica skillsets\\nExperience using JIRA and Agile Project Management software\\nExperience using GitHub, Bit Bucket, or other code repository solution\\nStrong written, verbal communication and presentation skills\\nAbility to explain complex technical issues in a way that non-technical people may understand\\nAble to work in a global, multicultural environment\\nSelf-motivated. Capable of working with little or no supervision\\nAbility to react positively under pressure to meet tight deadlines\\nAble to work independently or as a team player\\nEnjoy challenging and thought provoking work and have a strong desire to learn and progress\\nFormal Education: (minimum requirement to perform job duties)\\nBS in Computer Science, Applied Mathematics, Physics, Statistics or area of study related to data sciences and data mining or relevant experience\\nFLSA (US Only): Exempt\\n\\nThe above information on this description has been designed to indicate the general nature and level of work performed by employees within this role. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications required of employees assigned to this job. The job holder may be required to perform other duties as deemed appropriate by their manager from time to time.\\n\\nInvesco's culture of inclusivity and its commitment to diversity in the workplace are demonstrated through our people practices. We are proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, creed, color, religion, sex, gender, gender identity, sexual orientation, marital status, national origin, citizenship status, disability, age, or veteran status. Our equal opportunity employment efforts comply with all applicable U.S. state and federal laws governing non-discrimination in employment.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Senior Data Engineer - Governance</td>\n",
       "      <td>Alpharetta, GA 30009</td>\n",
       "      <td>Alpharetta</td>\n",
       "      <td>GA</td>\n",
       "      <td>30009</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Your responsibilities\\nthyssenkrupp Elevator Corporation is seeking a Sr. Data Engineer - Governance in Alpharetta, GA. The Sr. Data Engineer to be responsible for data engineering activities and aiding in building the business’ information systems, data governance, data management, data integration and data warehouse for key business areas including but not limited to Manufacturing, Engineering, Spare Parts and Supply Chain. The role of the Senior Data Engineer is responsible for building and maintaining optimized and highly available data that facilitate deeper analysis, quality data, metadata and reporting for the various systems and Analytics groups which supports relevant tkE. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. RESPONSIBILITIES:\\nPartner with Data Owners and Data Stewards to design solutions that align to data governance and data management principles and best practices\\nDesign data models for key program processes and data entities and ensure integration of logical data model into the enterprise conceptual data model and physical data models\\nBuild and maintain reliable and scalable ETL on data platforms that support critical business functions and analytics’ functions of the organization\\nEnsures regulatory issues are considered surrounding data assets (such as consumer privacy laws, data retention policies\\nRecognize and resolve conflicts between models, ensuring that data models are consistent with the enterprise model (e.g., entity names, relationships and definitions).\\nPartner with Quality Teams on Six Sigma methodology to ensure data and processes are properly aligned and efficient\\nCreates the principles, models, designs and systems that strengthen the network effect of sharing such data across the enterprise\\nPlans data architecture and design by studying the solution concept, strategy, and target audience and by envisioning architectural scheme, data structure and features, functionality, and user-interface design.\\nImplements a discipline and approach to managing data assets and converting the principles of the architecture into a technology solution\\nRequired to draft reports and prepare presentations for senior leadership. These reports and presentation must be clear, concise, unambiguous, engaging and convincing, which will demand exceptional communication skills\\nLeads the design of the data architecture, across multiple data domains and sub-domains.\\nCoordinates new development activities and ensures they are consistent and well-integrated with the established ecosystem data architecture\\nCreates ecosystem models (e.g. conceptual, logical, canonical) that are required for supporting services within the enterprise data\\nReviews and approves data model designs with a focus on those areas influencing interoperability, analytics including compliance with the portfolio information model\\nYour profile\\nQUALIFICATIONS:\\nBachelor’s degree (B.A. / B.S.) in Information Technology or Computer Science or related field or the equivalent combination of education and experience\\nMust have had at least 5 years of working experience working in a data engineering department, preferably as a Data Engineer in a fast-paced environment and complex business setting\\nBusiness domain, data/content and process understanding of Manufacturing, Engineering, Spare Parts and Supply Chain\\nSystem integration experience, including interface design, and familiarity with web-oriented architecture techniques\\nData modeling and information classification expertise at an enterprise level\\nExperience with Master Data Management, Metadata Management, Data Integration, Data Migration, Data Governance design and implementation techniques leveraging data management tools such as SAP MDG, Informatica or Talend\\nExperience with distributed management and analytics in cloud and hybrid environments with an understanding of a variety of data access and analytics approaches such as micro-services and event-based architectures\\nPREFERRED QUALIFICATIONS:\\nExperience with designing and implementing self-service models\\nHands-on experience with implementing data and analytics management programs\\nOur offer to you\\nSafety at work and Healthcare\\nSafety at work &amp; Healthcare: Highest standards in occupational safety and health, comprehensive programs and measures for safety at work and preventive healthcare with comprehensive coverage and flexible options.\\nSecurity for the future\\nFinancial security for your individual retirement plan.\\nCollaboration\\nRespect, recognition and appreciation of the contribution of everyone. Regular team - and social events.\\nContinuing development\\nTraining and continuing developement options. Help to grow alongside with us, in personality and profession.\\nCompensation and benefits\\nWe offer a lot: Fair working conditions and a reasonable, competitive compensation are the foundation for many more attractive benefits.\\nDiversity\\nOpen, tolerant and constructive work environment with a team consistent of diverse views and backgrounds.\\nWe work together closely and respect each other, for over 200 years. If that is just as important to you as it is to us, apply now!\\n\\nTo learn more about thyssenkrupp in North America, please visit our website:\\nhttps://www.thyssenkrupp-north-america.com\\nthyssenkrupp Elevator Corp. is an equal opportunity employer. Applicants will receive consideration for employment without regard to age, sex, race, color, religion, national origin, genetics, disability, gender identity, marital status, sexual orientation, veteran status or any other protected characteristic required by applicable law.\\n\\nApplicants with disabilities who require reasonable accommodation in connection with the application process are encouraged to contact us directly at 1-844-427-5461.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Kennesaw, GA 30144</td>\n",
       "      <td>Kennesaw</td>\n",
       "      <td>GA</td>\n",
       "      <td>30144</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Experience with JavaScript/Java/ Python or Jitterbit and other developer languages.\\nExperience with Data Analytics.\\nExperience with Web Services and APIs.\\nExperience in the development of batch and real-time data integration and data consolidation processes.\\nExperience with machine learning, AI, and data lakes.\\nProficiency in TSQL/PLSQL query-writing, stored procedure development, and views.\\nStrong analytical skills with ability for problem-solving.\\nUnderstands the importance of data provenance and the ability to demonstrate it to clients.\\nDetail oriented, organized, self-motivated.\\n\\n</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Develop strategy for new multi-platform data integration and analytics.\\nDevelop strategy for new multi-platform-sourced data lake.\\nContribute to API strategy to facilitate application connectivity and analytics.\\nContribute to the maintenance and evolution of best practices.\\nContribute to process documentation.\\nPerform multiple proofs of concept (POCs).\\nContribute to implementation plan for decided-upon solution(s).\\n\\n</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Riskonnect is the leading integrated risk management software solution provider that empowers organizations to anticipate, manage and respond in real-time to strategic and operational risks across the extended enterprise. Riskonnect is the only provider ranked in the leadership and visionary quadrants by world renowned industry analysts - Gartner, Forrester and Advisen RMIS Review. We employ more than 500 risk professionals in the Americas, EMEA and Asia Pacific and serve over 900 customers across 6 continents. The combination of innovative risk technology, a customer success mindset, and employee-first belief makes Riskonnect a sought after place to work.\\nResponsibilities:\\nDevelop strategy for new multi-platform data integration and analytics.\\nDevelop strategy for new multi-platform-sourced data lake.\\nContribute to API strategy to facilitate application connectivity and analytics.\\nContribute to the maintenance and evolution of best practices.\\nContribute to process documentation.\\nPerform multiple proofs of concept (POCs).\\nContribute to implementation plan for decided-upon solution(s).\\n\\nRequired Qualifications:\\nExperience with JavaScript/Java/ Python or Jitterbit and other developer languages.\\nExperience with Data Analytics.\\nExperience with Web Services and APIs.\\nExperience in the development of batch and real-time data integration and data consolidation processes.\\nExperience with machine learning, AI, and data lakes.\\nProficiency in TSQL/PLSQL query-writing, stored procedure development, and views.\\nStrong analytical skills with ability for problem-solving.\\nUnderstands the importance of data provenance and the ability to demonstrate it to clients.\\nDetail oriented, organized, self-motivated.\\n\\nPreferred Qualifications:\\nExperience with Salesforce.\\nExperience in the Risk Management, Healthcare, Financial, and/or Insurance industries is recommended.\\nExperience with Financial data sets, involving financial validation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Google Cloud Architect</td>\n",
       "      <td>Alpharetta, GA 30005</td>\n",
       "      <td>Alpharetta</td>\n",
       "      <td>GA</td>\n",
       "      <td>30005</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Job Description\\n\\nMerkle is looking for experienced Google Cloud professional to be part of its Cloud practice. You will be working on industry leading Google Cloud Platform (GCP) to design, develop, and implement next generation Marketing solutions leveraging Cloud native and Commercial/Open Source Big Data technologies.\\nKey Responsibilities\\nAs a Senior Google Cloud Architect, you will\\nBe the force behind shaping the future of our Cloud strategy practice by leading innovation efforts and developing Intellectual Property\\nBe client facing in advising them on GCP optimized architectures for data management, help develop roadmaps for on-prem to Cloud migration efforts\\nBe hands-on in developing prototypes and conducting Proof of Concepts\\nAct as a trusted advisor to client on all things GCP\\nLead team members on project involving data migration and implementation of new solutions on cloud platforms\\nParticipate in crafting customer facing proposal responses\\nParticipate in technical interactions with client’s executives and senior management\\nMentor client/Merkle resources on GCP and its services\\nEvaluate and analyze new commercial/open-source services/technologies offered by public Cloud providers, and Big Data technology vendors\\nInterface with Cloud/Technology provider’s Product Managers, and Engineers\\nDevelop reference architectures and design pattern library for typical Cloud based Marketing solutions implementations\\nParticipate in creating new services capabilities, productized solution offerings and document implementation handbooks\\nAdvise on Cloud project set up, security and role based access implementation, and network optimizations\\nMerkle is looking for experienced Google Cloud professional to be part of its Cloud practice. You will be working on industry leading Google Cloud Platform (GCP) to design, develop, and implement next generation Marketing solutions leveraging Cloud native and Commercial/Open Source Big Data technologies.\\nKey Responsibilities\\nAs a Senior Google Cloud Architect, you will\\nBe the force behind shaping the future of our Cloud strategy practice by leading innovation efforts and developing Intellectual Property\\nBe client facing in advising them on GCP optimized architectures for data management, help develop roadmaps for on-prem to Cloud migration efforts\\nBe hands-on in developing prototypes and conducting Proof of Concepts\\nAct as a trusted advisor to client on all things GCP\\nLead team members on project involving data migration and implementation of new solutions on cloud platforms\\nParticipate in crafting customer facing proposal responses\\nParticipate in technical interactions with client’s executives and senior management\\nMentor client/Merkle resources on GCP and its services\\nEvaluate and analyze new commercial/open-source services/technologies offered by public Cloud providers, and Big Data technology vendors\\nInterface with Cloud/Technology provider’s Product Managers, and Engineers\\nDevelop reference architectures and design pattern library for typical Cloud based Marketing solutions implementations\\nParticipate in creating new services capabilities, productized solution offerings and document implementation handbooks\\nAdvise on Cloud project set up, security and role based access implementation, and network optimizations\\n\\nQualifications\\n\\nKey Skills and Experience\\nBe hands-on\\nUnderstanding of Google cloud computing technologies, business drivers, and emerging computing trends\\nCertified Google Cloud Data Engineer\\nMinimum 10 years experience in data warehouse/data engineering with strong hands-on experience in ETL\\nProven track record of building technical and business relationships with senior executives\\nProven track record of driving decisions collaboratively, resolving conflicts and ensuring follow up\\nProblem-solving mentality leveraging internal and/or external resources, where and when needed, to do what’s right for the customer\\nExceptional verbal and written communication\\nAbility to coordinate across geographically dispersed team members and consolidate status for stakeholders\\nAbility to connect technology with measurable business value\\nDemonstrated technical thought leadership in customer facing situations\\n\\nRequirements:\\nCertified Google Cloud Data Engineer\\n5+ years of technical management and though leadership role delivering success in complex data analytics environment, managing various stakeholders relationships to get consensus on solution\\n5+ year’s design and/or implementation of highly distributed applications\\n2+ years’ experience in “migrating” on premise workloads to one or more industry leading public cloud(s)\\nDemonstrated experience of designing and building Big Data solutions on GCP stack leveraging BigQuery, Dataproc, Dataflow, BigTable, Data Prep, etc.\\n5+ years experience using Python for building data pipelines\\nTechnical architectural and development experience on Massively Parallel Processing technologies, such as Hadoop, Spark, Teradata, Netezza, Hadoop\\nTechnical architectural and development experience on one or more Data Integration technologies, such as Ab Initio, Talend, Pentaho, Informatica, Data Stage, Map Reduce\\nTechnical architectural experience on Data Visualization technologies, such as Tableau, Qlik, etc.\\nTechnical architectural experience on data modeling, designing data structures for business reporting\\nDeep understanding of Advanced Analytics, such as predictive, prescriptive, etc.\\nWorking knowledge of cloud components: Software design and development, Systems Operations / Management, Database architecture, Virtualization, IP Networking, Storage, IT Security\\nTechnical prowess and passion-especially for public Cloud, modern Application design practices and principles. Certifications on Cloud Platform preferred.\\nOversight experience on major transformation projects and successful transitions to operations support teams\\nPresentation skills with a high degree of comfort to both large and small audiences\\nAdditional Information\\n\\nMerkle fosters adiverse environment that encourages original thinking about our business andempowers us to communicate with a global world of customers. We embracedifferences of opinion and diversity of thought as they help us challenge andrefine our solutions. Merkle, as a best-in-class marketing agency, welcomes bigideas, and believes they can come from anywhere.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Azure Data Engineer</td>\n",
       "      <td>Atlanta, GA 30303</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>30303</td>\n",
       "      <td>None Found</td>\n",
       "      <td>At least 5 years of consulting or client service delivery experience on Azure\\n</td>\n",
       "      <td>DevOps on an Azure platform</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Proven ability to build, manage and foster a team-oriented environment\\n</td>\n",
       "      <td>Are you ready to step up to the New and take your technology expertise to the next level?\\n Join Accenture and help transform leading organizations and communities around the world. The sheer scale of our capabilities and client engagements, in conjunction with the way we collaborate, operate and deliver value, provides an unparalleled opportunity to grow and advance. Choose Accenture and make delivering innovative work part of your extraordinary career.\\n People in our Client Delivery &amp; Operations career track drive delivery and capability excellence through the design, development and/ or delivery of a solution, service, capability or offering. They grow into delivery-focused roles, and can progress within their current role, laterally or upward. We partner with our clients to help transform their data into an ‘Appreciating Business Asset.’\\n\\nAs part of our Data Business Group, you will lead technology innovation for our clients through robust delivery of world-class solutions. You will build better software better! There will never be a typical day and that’s why people love it here. The opportunities to make a difference within exciting client initiatives are unlimited in the ever-changing technology landscape. You will be part of a highly collaborative and growing network of technology and data experts, who are taking on today’s biggest, most complex business challenges using the latest data and analytics technologies. We will nurture your talent in an inclusive culture that values diversity. You will have an opportunity to work in roles such as Data Scientist, Data Engineer, or Chief Data Officer covering all aspects of Data including Data Management, Data Governance, Data Intelligence, Knowledge Graphs, and IoT. Come grow your career in Technology at Accenture!\\n\\nThe Azure Technical Architect Delivery is responsible for delivering Data On Cloud projects for Azure based deals. The ideal candidate would also be responsible for developing and delivering Azure cloud solutions to meet todays high demand in areas such as AIML, IoT, advanced analytics, open source, enterprise collaboration, microservices, serverless, etc. The Azure Data Engineer is a highly performant engineer responsible for delivering Cloud based Big Data and Analytical Solutions at our clients. Responsibilities include evangelizing data on cloud solutions with customers, leading Business and IT stakeholders through designing a robust, secure and optimized Azure architectures and ability to be hands-on delivering the target solution. This role will work with customers and leading internal engineering teams in delivering big data soltuions on cloud. Using Azure public cloud technologies, our Data Engineer professionals implement state of the art, scalable, high performance Data On Cloud solutions that meet the need of todays corporate and emerging digital applications\\n\\n Role &amp; Responsibilities:Provide subject matter expertise and hands on delivery of data capture, curation and consumption pipelines on Azure and HadoopAbility to build cloud data solutions and provide domain perspective on storage, big data platform services, serverless architectures, hadoop ecosystem, vendor products, RDBMS, DW/DM, NoSQL databases and security.Participate in deep architectural discussions to build confidence and ensure customer success when building new solutions and migrating existing data applications on the Azure platform.Conduct full technical discovery, identifying pain points, business and technical requirements, “as is” and “to be” scenarios.\\n- Build full technology stack of services required including PaaS (Platform as-a-service), IaaS (Infrastructure as-a-service), SaaS (software as-a-service), operations, management and automation.Apply Accenture methodology, Accenture reusable assets, and previous work experience to delivery consistently high-quality work.Stay educated on new and emerging technologies/patterns/methodologies and market offerings that may be of interest to our clients.Adapt to existing methods and procedures to create possible alternative solutions to moderately complex problems.Understand the strategic direction set by senior management as it relates to team goals.Use considerable judgment to define solution and seeks guidance on complex problems.Primary upward interaction is with direct supervisor. May interact with peers and/or management levels at a client and/or within Accenture. Establish methods and procedures\\non new assignments with guidance.\\nManage small teams of deliver engineers successfully delivering work efforts\\n\\n (if in an independent contributor role) at a client or within Accenture.\\nExtensive travel may be required\\n\\nBasic Qualifications\\nAt least 5 years of consulting or client service delivery experience on Azure\\nAt least 5 years of experience in developing data ingestion, data processing and analytical pipelines for big data, relational databases, NoSQL and data warehouse solutions\\nExtensive experience providing practical direction within the Azure Native and HadoopMinimum of 5 years of hands-on experience in Azure and Big Data technologies such as Powershell, C#, Java, Node.js, Python, SQL, ADLS/Blob, Spark/SparkSQL, Hive/MR, Pig, Oozie and streaming technologies such as Kafka, EventHub, NiFI etc.\\nExtensive hands-on experience implementing data migration and data processing using Azure services: Networking, Windows/Linux virtual machines, Container, Storage, ELB, AutoScaling, Azure Functions, Serverless Architecture, ARM Templates, Azure SQL DB/DW, Data Factory, Azure Stream Analytics, Azure Analysis Service, HDInsight, Databricks Azure Data Catalog, Cosmo Db, ML Studio, AI/ML, etc.\\n Cloud migration methodologies and processes including tools like Azure Data Factory, Event Hub, etc.\\n5+ years of hands on experience in programming languages such as Java, c#, node.js, python, pyspark, spark, SQL, Unix shell/Perl scripting etc.\\nMinimum of 5 years of RDBMS experience\\nExperience in using Hadoop File Formats and compression techniquesExperience working with Developer tools such as Visual Studio, GitLabs, Jenkins, etc.\\nExperience with private and public cloud architectures, pros/cons, and migration considerations.\\nBachelors or higher degree in Computer Science or a related discipline.\\n\\nCandidate Must Have Completed The Following Certifications\\nMCSA Cloud Platform (Azure) Training &amp; Certification\\nMCSE Cloud Platform &amp; Infratsructiure Training &amp; Certification\\nMCSD Azure Solutions Architect Training &amp; Certification\\n\\nNice-to-Have Skills/Qualifications:\\nDevOps on an Azure platform\\nExperience developing and deploying ETL solutions on Azure\\nIoT, event-driven, microservices, containers/Kubernetes in the cloud\\nFamiliarity with the technology stack available in the industry for metadata management: Data Governance, Data Quality, MDM, Lineage, Data Catalog etc.\\nFamiliarity with the Technology stack available in the industry for data management, data ingestion, capture, processing and curation: Kafka, StreamSets, Attunity, GoldenGate, Map Reduce, Hadoop, Hive, Hbase, Cassandra, Spark, Flume, Hive, Impala, etc.\\n- Multi-cloud experience a plus - Azure, AWS, Google\\n\\nProfessional Skill Requirements\\n Proven ability to build, manage and foster a team-oriented environment\\n Proven ability to work creatively and analytically in a problem-solving environment\\n Desire to work in an information systems environment\\n Excellent communication (written and oral) and interpersonal skills\\n Excellent leadership and management skills\\n Excellent organizational, multi-tasking, and time-management skills\\n Proven ability to work independently\\n\\nAll of our professionals receive comprehensive training covering business acumen, technical and professional skills development. You'll also have opportunities to hone your functional skills and expertise in an area of specialization. We offer a variety of formal and informal training programs at every level to help you acquire and build specialized skills faster. Learning takes place both on the job and through formal training conducted online, in the classroom, or in collaboration with teammates. The sheer variety of work we do, and the experience it offers, provide an unbeatable platform from which to build a career.\\n\\nApplicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status).\\n\\nCandidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.\\n\\nAccenture is a Federal Contractor and an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities.\\n\\nEqual Employment Opportunity\\n\\nAll employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.\\n\\nJob candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.\\n\\nAccenture is committed to providing veteran employment opportunities to our service men and women.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title              Location  \\\n",
       "0   Cloud Data Engineer, Google Professional Services  Atlanta, GA            \n",
       "1   Sr. Data Engineer                                  Atlanta, GA 30328      \n",
       "2   AWS Data Engineer                                  Atlanta, GA 30303      \n",
       "3   Senior Big Data Engineer                           Atlanta, GA            \n",
       "4   Data Engineer                                      Atlanta, GA            \n",
       "..            ...                                              ...            \n",
       "56  Senior Data Engineer                               Atlanta, GA 30309      \n",
       "57  Senior Data Engineer - Governance                  Alpharetta, GA 30009   \n",
       "58  Data Engineer                                      Kennesaw, GA 30144     \n",
       "59  Google Cloud Architect                             Alpharetta, GA 30005   \n",
       "60  Azure Data Engineer                                Atlanta, GA 30303      \n",
       "\n",
       "          City State         Zip     Country  \\\n",
       "0   Atlanta     GA    None Found  None Found   \n",
       "1   Atlanta     GA    30328       None Found   \n",
       "2   Atlanta     GA    30303       None Found   \n",
       "3   Atlanta     GA    None Found  None Found   \n",
       "4   Atlanta     GA    None Found  None Found   \n",
       "..      ...     ..           ...         ...   \n",
       "56  Atlanta     GA    30309       None Found   \n",
       "57  Alpharetta  GA    30009       None Found   \n",
       "58  Kennesaw    GA    30144       None Found   \n",
       "59  Alpharetta  GA    30005       None Found   \n",
       "60  Atlanta     GA    30303       None Found   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Qualifications  \\\n",
       "0   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "1   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "2   At least 5 years of Consulting or client service delivery experience on Amazon AWS (AWS)At least 5 years of experience in developing data ingestion, data processing and analytical pipelines for big data, relational databases, NoSQL and data warehouse solutionsExtensive experience providing practical direction within the AWS Native and HadoopExperience with private and public cloud architectures, pros/cons, and migration considerations.Minimum of 5 years of hands-on experience in AWS and Big Data technologies such as Java, Node.js, C##, Python, SQL, EC2, S3, Lambda, Spark/SparkSQL, Hive/MR, Pig, Oozie and streaming technologies such as Kafka, Kinesis, NiFI etc.Extensive hands-on experience implementing data migration and data processing using AWS services: VPC/SG, EC2, S3, AutoScaling, CloudFormation, LakeFormation, DMS, Kinesis, Kafka, Nifi, CDC processing Redshift, Snowflake, RDS, Aurora, Neptune, DynamoDB, Hive, NoSQL, Cloudtrail, CloudWatch, Docker, Lambda, Spark,Glue, Sage Maker, AI/ML, API GW, etc.5+ years of hands on experience in programming languages such as Java, c#, node.js, python, pyspark, spark, SQL, Unix shell/Perl scripting etc.Minimum of 5 years of RDBMS experienceExperience in using Hadoop File Formats and compression techniquesExperience working with DevOps tools such as GitLabs, Jenkins, CodeBuild, CoePipeline CodeDeploy, etc.Bachelors or higher degree in Computer Science or a related discipline.   \n",
       "3   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "4   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "..         ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "56  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "57  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "58  Experience with JavaScript/Java/ Python or Jitterbit and other developer languages.\\nExperience with Data Analytics.\\nExperience with Web Services and APIs.\\nExperience in the development of batch and real-time data integration and data consolidation processes.\\nExperience with machine learning, AI, and data lakes.\\nProficiency in TSQL/PLSQL query-writing, stored procedure development, and views.\\nStrong analytical skills with ability for problem-solving.\\nUnderstands the importance of data provenance and the ability to demonstrate it to clients.\\nDetail oriented, organized, self-motivated.\\n\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "59  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "60  At least 5 years of consulting or client service delivery experience on Azure\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Skills  \\\n",
       "0   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "1   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "2   DevOps on an AWS platform. Multi-cloud experience a plus.Experience developing and deploying ETL solutions on AWS using tools like Talend, Informatica, MatillionStrong in Java, C##, Spark, PySpark, Unix shell/Perl scriptingIoT, event-driven, microservices, containers/Kubernetes in the cloud                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "3   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "4   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "..         ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "56  Previous management experience and successfully leading a team of direct reports\\nProven track record of effectively leading and managing employees, managing performance, setting goals for team/individuals and provide mentoring.\\nStrong Tableau, Adobe Analytics other BI solution\\nExpert Oracle and Vertica skillsets\\nExperience using JIRA and Agile Project Management software\\nExperience using GitHub, Bit Bucket, or other code repository solution\\nStrong written, verbal communication and presentation skills\\nAbility to explain complex technical issues in a way that non-technical people may understand\\nAble to work in a global, multicultural environment\\nSelf-motivated. Capable of working with little or no supervision\\nAbility to react positively under pressure to meet tight deadlines\\nAble to work independently or as a team player\\nEnjoy challenging and thought provoking work and have a strong desire to learn and progress   \n",
       "57  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "58  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "59  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "60  DevOps on an Azure platform                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Responsibilities  \\\n",
       "0   \\nAct as a trusted technical advisor to customers and solve complex Big Data challenges.\\nCreate and deliver best practices recommendations, tutorials, blog articles, sample code, and technical presentations adapting to different levels of key business and technical stakeholders.\\nTravel up to 30% of the time.\\nCommunicate effectively via video conferencing for meetings, technical reviews and onsite delivery activities.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "1   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "2   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "3   \\nYou will design and create multi-tenant systems capable of loading and transforming a large volume of structured and semi-structured fast moving data\\nBuild robust and scalable data infrastructure (both batch processing and real-time) to support needs from internal and external users\\nBuild Data Pipelines\\nRun ETL into Hadoop/Elastic Search                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "4   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "..         ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "56  Work with development teams and other project leaders/stakeholders to provide technical solutions that enable business capabilities\\nSupports the data science community by enabling data availability in environments that provide advanced analytical capabilities\\nMaintains a broad understanding of implementation, integration, and inter-connectivity issues with emerging technologies to define data strategies\\nAssist in the decision-making process related to the selection of software architecture solutions\\nImplement architectures to handle web-scale data and its organization\\nExecute strategies that inform data design and architecture partnering with enterprise standard\\nBuild robust data pipelines on public Cloud using AWS Kinesis, Kafka, Lambda or other technologies\\nAssist in creating documents that ensure consistency in development across the online organization. Implements and improves core software infrastructure\\nDeep expertise in SQL language, Python, Hadoop ecosystem and/or Spark ecosystem. Strong experience with writing complex programs, implementing architectures, and enabling automation in these environments\\nDevelop and maintain business reporting, ensuring reliability and performance, delivery of performance management tools (such as control charts and scorecards), readiness and adoption of data w/in the organization\\nConsolidate, standardize and control changes to capacity management data and metric definitions, ownership, accountability and taxonomy to ensure alignment in understanding\\nServe as strong advocate to improve analytical capability across the organization\\nCommunicate with various business areas and to gather and prioritize their business requirements\\nSupport various reporting and BI solutions (Tableau, Power BI, Salesforce Einstein)\\nManage application and data integration platforms (Informatica, Talend)\\nManage the full life cycle of development/reporting/integration projects: planning, design, develop, testing and rollout\\nManage solution providers, define sourcing approach and manage the providers\\nCreate and manage data, applications and technology architecture documentation and design artifacts\\nWork across teams to deliver meaningful reference architectures that outline architecture principles and best practices for technology advancement\\nGain adoption of architecture processes, standards and procedures   \n",
       "57  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "58  Develop strategy for new multi-platform data integration and analytics.\\nDevelop strategy for new multi-platform-sourced data lake.\\nContribute to API strategy to facilitate application connectivity and analytics.\\nContribute to the maintenance and evolution of best practices.\\nContribute to process documentation.\\nPerform multiple proofs of concept (POCs).\\nContribute to implementation plan for decided-upon solution(s).\\n\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "59  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "60  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "\n",
       "                                                                                                                                              Education  \\\n",
       "0   None Found                                                                                                                                            \n",
       "1   None Found                                                                                                                                            \n",
       "2   None Found                                                                                                                                            \n",
       "3   None Found                                                                                                                                            \n",
       "4   None Found                                                                                                                                            \n",
       "..         ...                                                                                                                                            \n",
       "56  \\nBS in Computer Science, Applied Mathematics, Physics, Statistics or area of study related to data sciences and data mining or relevant experience   \n",
       "57  None Found                                                                                                                                            \n",
       "58  None Found                                                                                                                                            \n",
       "59  None Found                                                                                                                                            \n",
       "60  None Found                                                                                                                                            \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                        Requirement  \\\n",
       "0   None Found                                                                                                                                                                                                                                                                                                                        \n",
       "1   None Found                                                                                                                                                                                                                                                                                                                        \n",
       "2    Proven ability to build, manage and foster a team-oriented environment Proven ability to work creatively and analytically in a problem-solving environment Desire to work in an information systems environment Excellent communication (written and oral) and interpersonal skills Excellent leadership and management skills   \n",
       "3   None Found                                                                                                                                                                                                                                                                                                                        \n",
       "4   None Found                                                                                                                                                                                                                                                                                                                        \n",
       "..         ...                                                                                                                                                                                                                                                                                                                        \n",
       "56  None Found                                                                                                                                                                                                                                                                                                                        \n",
       "57  None Found                                                                                                                                                                                                                                                                                                                        \n",
       "58  None Found                                                                                                                                                                                                                                                                                                                        \n",
       "59  None Found                                                                                                                                                                                                                                                                                                                        \n",
       "60   Proven ability to build, manage and foster a team-oriented environment\\n                                                                                                                                                                                                                                                         \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        FullDescriptions  \n",
       "0   Note: By applying to this position your application is automatically submitted to the following locations: Chicago, IL, USA; Atlanta, GA, USA\\nMinimum qualifications:\\n\\nBA/BS degree in Computer Science, Mathematics or related technical field, or equivalent practical experience.\\nExperience with data processing software (such as Hadoop, Spark, Pig, Hive) and with data processing algorithms (MapReduce, Flume).\\nExperience in writing software in one or more languages such as Java, C++, Python, Go and/or JavaScript.\\nExperience managing internal or client-facing projects to completion; experience troubleshooting clients' technical issues; experience working with engineering teams, sales, services, and customers.\\n\\nPreferred qualifications:\\nExperience working data warehouses, including data warehouse technical architectures, infrastructure components, ETL/ELT and reporting/analytic tools and environments.\\nExperience in technical consulting.\\nExperience working with big data, information retrieval, data mining or machine learning as well as experience in building multi-tier high availability applications with modern web technologies (such as NoSQL, MongoDB, SparkML, Tensorflow).\\nExperience architecting, developing software, or internet scale production-grade Big Data solutions in virtualized environments.\\nAbout the job\\nAs a Cloud Data Engineer, you'll guide customers on how to ingest, store, process, analyze and explore/visualize data on the Google Cloud Platform. You will work on data migrations and transformational projects, and with customers to design large-scale data processing systems, develop data pipelines optimized for scaling, and troubleshoot potential platform challenges.\\nIn this role you are the Google Engineer working with Google's most strategic Cloud customers. Together with the team you will support customer implementation of Google Cloud products through: architecture guidance, best practices, data migration, capacity planning, implementation, troubleshooting, monitoring and much more.\\nThe Google Cloud Platform team helps customers transform and evolve their business through the use of Google’s global network, web-scale data centers and software infrastructure. As part of an entrepreneurial team in this rapidly growing business, you will help shape the future of businesses of all sizes use technology to connect with customers, employees and partners.\\nResponsibilities\\nAct as a trusted technical advisor to customers and solve complex Big Data challenges.\\nCreate and deliver best practices recommendations, tutorials, blog articles, sample code, and technical presentations adapting to different levels of key business and technical stakeholders.\\nTravel up to 30% of the time.\\nCommunicate effectively via video conferencing for meetings, technical reviews and onsite delivery activities.\\nAt Google, we don’t just accept difference—we celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "1   We are looking for a Data Engineer for the Enterprise Data Organization to build and manage data pipeline (Data ingest, data transformation, data distribution, quality rules, data storage etc.) for Azure cloud based data platform. The candidate will require to possess strong technical, analytical, programming and critical thinking skills. Ideal candidate will have familiarity with data transformation, data modeling, Master data management, and Meta data management.\\n\\nKEY RESPONSIBILITIES:\\n\\nDesign, develop and maintain reliable automated data solutions based on the identification, collection and evaluation of business requirements. Including but not limited to data models, database objects, stored procedures and views.\\nDeveloping new and enhancing existing data processing (Data Ingest, Data Transformation, Data Store, Data Management, Data Quality ) components\\nEngage with IT teams such as DBAs, Security, Storage and Networking when their involvement is required to meet the project needs.\\nSupport and troubleshoot the data environment (including periodically on call)\\nDocument technical artifacts for developed solutions\\nMaintains professional and technical knowledge by attending educational workshops; reviewing professional publications; establishing personal networks; benchmarking state-of-the-art practices; participating in professional societies.\\nEDUCATION QUALIFICATIONS:\\n\\nBS in either Information Systems, Finance/Mathematics, or Computer Science or similar field\\nEXPERIENCE QUALIFICATION:\\n\\n10+ Years\\nREQUIRED KNOWLEDGE, SKILLS or ABILITIES:\\n\\nGood interpersonal skills; comfort and competence in dealing with different teams within the organization. Requires an ability to interface with multiple constituent groups and build sustainable relationships.\\nStrong and effective communication skills (verbal and written).\\nStrong analytical, problem solving skills.\\nExperience of working in a matrix organization, self-driven. A go getter and a problem solver.\\nAbility to prioritize, work to deadlines, work under pressure. Results oriented, flexible, adaptable.\\nWork well independently, and be a team player.\\nVersatile, creative temperament, ability to think out-of-the box while defining sound and practical solutions. Ability to master new skills.\\nProactive approach to problem solving with effective influencing skills.\\nTECHNICAL SKILLS:\\n\\nFamiliar with Agile practices and methodologies\\n5+ years professional data engineering experience focused on batch and real time data pipelines using Spark, PySpark, Python, SQL, Java\\n8+ Years of hands-on design and development experience in data space : data processing / data transformation using ETL tools, data warehouse (data modeling, programming), RDBMS\\nExposure in Microsoft technologies like SSIS, SQL Server, SSRS\\nExperience with a DevOps model utilizing a CI/CD tool\\nPREFERRED KNOWLEDGE, SKILLS, OR ABILITIES:\\nHands-on Talend work experience (anyone with this skill will have an advantage over other candidates)\\nUnderstanding of data science and visualization technologies (Hadoop, Spark, Databricks)\\nExperience working on a cloud environment, preferably, Microsoft Azure\\nCloud Data Warehouse solutions (Snowflake, Azure DW)\\nNoSQL databases and modeling (Cassandra, HBase, MongoDB)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "2   Are you ready to step up to the New and take your technology expertise to the next level?\\n\\nJoin Accenture and help transform leading organizations and communities around the world. The sheer scale of our capabilities and client engagements, in conjunction with the way we collaborate, operate and deliver value, provides an unparalleled opportunity to grow and advance. Choose Accenture and make delivering innovative work part of your extraordinary career.\\n\\nPeople in our Client Delivery & Operations career track drive delivery and capability excellence through the design, development and/ or delivery of a solution, service, capability or offering. They grow into delivery-focused roles, and can progress within their current role, laterally or upward. We partner with our clients to help transform their data into an ‘Appreciating Business Asset.’\\n\\nAs part of our Data Business Group, you will lead technology innovation for our clients through robust delivery of world-class solutions. You will build better software better! There will never be a typical day and that’s why people love it here. The opportunities to make a difference within exciting client initiatives are unlimited in the ever-changing technology landscape. You will be part of a highly collaborative and growing network of technology and data experts, who are taking on today’s biggest, most complex business challenges using the latest data and analytics technologies. We will nurture your talent in an inclusive culture that values diversity. You will have an opportunity to work in roles such as Data Scientist, Data Engineer, or Chief Data Officer covering all aspects of Data including Data Management, Data Governance, Data Intelligence, Knowledge Graphs, and IoT. Come grow your career in Technology at Accenture!\\n\\nThe Amazon AWS Data Engineer is responsible for delivering Data On Cloud projects for Amazon AWS based deals. The ideal candidate would be responsible for developing and delivering AWS cloud solutions to meet today’s high demand in areas such as AIML, IoT, advanced analytics, open source, enterprise collaboration, microservices, serverless, etc. The AWS Data Engineer is a highly performant engineer responsible for delivering Cloud based Big Data and Analytical Solutions at our clients. Responsibilities include building data on cloud solutions at customers, leading Business and IT stakeholders through designing a robust, secure and optimized AWS solutions and ability to be hands-on delivering the target solution. This role will work with customers and leading internal engineering teams in delivering big data soltuions on cloud. Using Amazon AWS public cloud technologies, our AWS Data Engineer professionals implement state of the art, scalable, high performance Data On Cloud solutions that meet the need of today’s corporate and emerging digital applications.\\n\\nRole & Responsibilities:\\nProvide subject matter expertise and hands on delivery of data capture, curation and consumption pipelines on AWS and HadoopAbility to build cloud data solutions and provide domain perspective on storage, big data platform services, serverless architectures, hadoop ecosystem, RDBMS, DW/DM, NoSQL databases and security.Participate in deep architectural discussions to build confidence and ensure customer success when building new solutions and migrating existing data applications on the AWS platform.\\n- Build full technology stack of services required including PaaS (Platform as-a-service), IaaS (Infrastructure as-a-service), SaaS (software as-a-service), operations, management and automation.Apply Accenture methodology, Accenture reusable assets, and previous work experience to delivery consistently high-quality work.Stay educated on new and emerging technologies/patterns/methodologies and market offerings that may be of interest to our clients.Understand the strategic direction set by senior management as it relates to team goals.Use considerable judgment to define solution and seeks guidance on complex problems.Primary upward interaction is with direct supervisor. May interact with peers and/or management levels at a client and/or within Accenture. Establish methods and procedures\\non new assignments with guidance.Manage small teams of delivery engineers successfully delivering work efforts (if in an independent contributor role) at a client or within Accenture.Able to travel up to 100% (M-TH)\\n\\nBasic QualificationsAt least 5 years of Consulting or client service delivery experience on Amazon AWS (AWS)At least 5 years of experience in developing data ingestion, data processing and analytical pipelines for big data, relational databases, NoSQL and data warehouse solutionsExtensive experience providing practical direction within the AWS Native and HadoopExperience with private and public cloud architectures, pros/cons, and migration considerations.Minimum of 5 years of hands-on experience in AWS and Big Data technologies such as Java, Node.js, C##, Python, SQL, EC2, S3, Lambda, Spark/SparkSQL, Hive/MR, Pig, Oozie and streaming technologies such as Kafka, Kinesis, NiFI etc.Extensive hands-on experience implementing data migration and data processing using AWS services: VPC/SG, EC2, S3, AutoScaling, CloudFormation, LakeFormation, DMS, Kinesis, Kafka, Nifi, CDC processing Redshift, Snowflake, RDS, Aurora, Neptune, DynamoDB, Hive, NoSQL, Cloudtrail, CloudWatch, Docker, Lambda, Spark,Glue, Sage Maker, AI/ML, API GW, etc.5+ years of hands on experience in programming languages such as Java, c#, node.js, python, pyspark, spark, SQL, Unix shell/Perl scripting etc.Minimum of 5 years of RDBMS experienceExperience in using Hadoop File Formats and compression techniquesExperience working with DevOps tools such as GitLabs, Jenkins, CodeBuild, CoePipeline CodeDeploy, etc.Bachelors or higher degree in Computer Science or a related discipline.\\n\\nCandidate Must Have Completed The Following Certifications\\n§ Certified AWS Developer - Associate\\n§ Certified AWS DevOps – Professional (Nice to have)\\n§ Certified AWS Big Data Specialty (Nice to have)\\n\\nNice-to-Have Skills/Qualifications:DevOps on an AWS platform. Multi-cloud experience a plus.Experience developing and deploying ETL solutions on AWS using tools like Talend, Informatica, MatillionStrong in Java, C##, Spark, PySpark, Unix shell/Perl scriptingIoT, event-driven, microservices, containers/Kubernetes in the cloud\\nExperience in Apache Maven a plusUnderstanding and implementation of Data Lake architecturesUnderstanding NoSQL technologies such as MongoDB, Cassandra, Hbase is a plusUnderstanding Solr, Elasticsearch is a plus\\n\\nProfessional Skill Requirements Proven ability to build, manage and foster a team-oriented environment Proven ability to work creatively and analytically in a problem-solving environment Desire to work in an information systems environment Excellent communication (written and oral) and interpersonal skills Excellent leadership and management skills\\n\\nAll of our professionals receive comprehensive training covering business acumen, technical and professional skills development. You'll also have opportunities to hone your functional skills and expertise in an area of specialization. We offer a variety of formal and informal training programs at every level to help you acquire and build specialized skills faster. Learning takes place both on the job and through formal training conducted online, in the classroom, or in collaboration with teammates. The sheer variety of work we do, and the experience it offers, provide an unbeatable platform from which to build a career.\\n\\nApplicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status).\\n\\nCandidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.\\n\\nAccenture is a Federal Contractor and an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities.\\n\\nEqual Employment Opportunity\\n\\nAll employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.\\n\\nJob candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.\\n\\nAccenture is committed to providing veteran employment opportunities to our service men and women.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "3   Location: San Jose, CA or Atlanta, GA\\nFor over 10 years, Zscaler has been disrupting and transforming the security industry. Our 100% purpose built cloud platform delivers the entire gateway security stack as a service through 150 global data centers to securely connect users to their applications, regardless of device, location, or network in over 185 countries protecting over 3,500 companies and 100 Million threats detected a day.\\nWe work in a fast paced, dynamic and make it happen culture. Our people are some of the brightest and passionate in the industry that thrive on being the first to solve problems. We are always looking to hire highly passionate, collaborative and humble people that want to make a difference.\\nAs a Big Data Engineer, you will work on building the next generation of Zscaler's security analytics platform. You will play a crucial role in building a platform to collect and ingest several billion (and growing) log events from Zscaler's globally distributed security infrastructure and provide actionable insights to customers and Zscaler's security researchers.\\nResponsibilities:\\nYou will design and create multi-tenant systems capable of loading and transforming a large volume of structured and semi-structured fast moving data\\nBuild robust and scalable data infrastructure (both batch processing and real-time) to support needs from internal and external users\\nBuild Data Pipelines\\nRun ETL into Hadoop/Elastic Search\\nRequired:\\n3+ years of experience in Python or Java development a must (Strong Scala would skills would be acceptable as well)\\n3+ years experience in application big data development (Spark, Kafka, Storm, Kinesis, & building data pipelines)\\nAbility to troubleshoot and find complex performance issues with queries on the Spark platform (Spark SQL)\\nFamiliarity with implementing services following REST model\\nExcellent interpersonal, technical and communication skills\\nAbility to learn, evaluate and adopt new technologies\\nBachelor's Degree in computer science or equivalent experience\\nHighly Desirable:\\nExperience working with data processing infrastructure\\nExperience with data serialization techniques and data stores for persisting events\\nWhat You Can Expect From Us:\\nAn environment where you will be working on cutting edge technologies and architectures\\nA fun, passionate and collaborative workplace\\nCompetitive salary and benefits, including equity\\nThe pace and excitement of working for a Silicon Valley Unicorn\\nWhy Zscaler?\\nPeople who excel at Zscaler are smart, motivated and share our values. Ask yourself: Do you want to team with the best talent in the industry? Do you want to work on disruptive technology? Do you thrive in a fluid work environment? Do you appreciate a company culture that enables individual and group success and celebrates achievement?\\n\\nIf you said yes, we’d love to talk to you about joining our award-winning team!\\nLearn more at zscaler.com or follow us on Twitter @zscaler. Additional information about Zscaler (NASDAQ : ZS ) is available at http://www.zscaler.com. All qualified applicants will receive consideration for employment without regard to race, sex, color, religion, sexual orientation, gender identity, national origin, protected veteran status, or on the basis of disability.\\n#LI-JM1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "4   FraudScope - the rapidly growing company that is tackling the problem of healthcare, fraud, waste and abuse - is looking for a full-time Data Engineer to work in their office located at Midtown Atlanta.\\nWe are seeking a talented data engineer with experience in data analytics, building large reservoirs of data, and performing efficient queries. We have built a web-based application that is supported by a large dataset of healthcare data, on which we must frequently perform large queries very efficiently and return results in real time to the user. The role of the data engineer is to bridge the data scientist with the developers and the ingestion of data. Specifically, one of the major tasks is to build and execute new data pipelines on the cloud (AWS).\\nRequired technical skills:\\n\\nRelational database (PostgreSQL)\\nCloud experience (AWS S3, Aurora, EC2)\\nPython\\nLinux\\n\\nBeneficial technical skills:\\nApache Spark, Hadoop\\nAWS Glue, Athena, IAM, KMS\\nProven experience processing billions of records and terabytes of data\\nTable partitioning with PostgreSQL\\nShell scripting (e.g., bash)\\n\\nOther Requirements/Preferences:\\nExperience with healthcare data, particularly medical claims\\nBachelor degree in Computer Science, Engineering or related field - At least 2 years of experience in the software industry\\nAuthorization to work in the USA\\nPosition in Midtown - Atlanta, GA (no remote)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "56  Invesco is one of the world’s leading global investment managers, entrusted with managing $1.2 trillion* in assets on behalf of clients worldwide. We are the 6th largest US retail asset manager and the 13th largest investment manager globally, and our more than 8,000 employees worldwide are dedicated to delivering an investment experience that helps people get more out of life. We are purely focused on managing a comprehensive range of active, passive and alternative investment capabilities, which we draw on to provide customized solutions aligned to client needs, our most important benchmark. (*As of May 31,2019)\\n\\nJob Purpose (Job Summary):\\n\\nAs a Senior Data Engineer at Invesco, you would align business outcomes to technology goals and objectives. You will be responsible for managing decision sciences and advanced analytics initiatives, data integration/engineering. Interacts with Data Scientists, Business Owners, Business Data Analysts, Data Modelers, Architects, and Application Developers, to design, build and manage large-scale batch and real-time data pipelines utilizing various data analytics processing frameworks in support of Data Science practice. The position requires building strong technical hands-on-skills and experiences as well as establishing close business relationships across the enterprise. Working closely with marketing and sales stakeholders, you will establish and drive long term advance analytics roadmap manage increasing demands for advance analytics in Sales and Marketing. You will help steer the strategic technology direction, define target state architecture, technology roadmaps and mentor others. A successful candidate must have a demonstrable background with experience in development of high performance, distributed computing tasks using Big Data technologies such as Hadoop (platform level), NoSQL, text mining and other distributed environment technologies based on the needs of the organization. Responsible for analyzing, designing, programing, debugging and modifying software enhancements and/or new products used in distributed, large scale analytics solutions. Strong visualization skills and experience with BI tools (ex. Tableau)\\n\\nKey Responsibilities / Duties:\\nWork with development teams and other project leaders/stakeholders to provide technical solutions that enable business capabilities\\nSupports the data science community by enabling data availability in environments that provide advanced analytical capabilities\\nMaintains a broad understanding of implementation, integration, and inter-connectivity issues with emerging technologies to define data strategies\\nAssist in the decision-making process related to the selection of software architecture solutions\\nImplement architectures to handle web-scale data and its organization\\nExecute strategies that inform data design and architecture partnering with enterprise standard\\nBuild robust data pipelines on public Cloud using AWS Kinesis, Kafka, Lambda or other technologies\\nAssist in creating documents that ensure consistency in development across the online organization. Implements and improves core software infrastructure\\nDeep expertise in SQL language, Python, Hadoop ecosystem and/or Spark ecosystem. Strong experience with writing complex programs, implementing architectures, and enabling automation in these environments\\nDevelop and maintain business reporting, ensuring reliability and performance, delivery of performance management tools (such as control charts and scorecards), readiness and adoption of data w/in the organization\\nConsolidate, standardize and control changes to capacity management data and metric definitions, ownership, accountability and taxonomy to ensure alignment in understanding\\nServe as strong advocate to improve analytical capability across the organization\\nCommunicate with various business areas and to gather and prioritize their business requirements\\nSupport various reporting and BI solutions (Tableau, Power BI, Salesforce Einstein)\\nManage application and data integration platforms (Informatica, Talend)\\nManage the full life cycle of development/reporting/integration projects: planning, design, develop, testing and rollout\\nManage solution providers, define sourcing approach and manage the providers\\nCreate and manage data, applications and technology architecture documentation and design artifacts\\nWork across teams to deliver meaningful reference architectures that outline architecture principles and best practices for technology advancement\\nGain adoption of architecture processes, standards and procedures\\nWork Experience / Knowledge:\\n5+ years of experience in data modeling, data warehousing, and big data architectures\\n3+ years of experience in a data engineering role\\nProficient in application/software architecture (Definition, Business Process Modeling, etc.)\\nStrong analytics and reporting skills – hands on experience in BI Tools like Tableau, Power BI, Salesforce Einstein\\nDeep expertise in (at least one) SQL language, Python, Hadoop ecosystem and/or Spark ecosystem. Strong experience with writing complex programs, implementing architectures, and enabling automation in these environments\\nThe role will be responsible for providing innovative operational solutions and best practices\\nAdvanced knowledge in SQL/Hive, Spark, NoSQL, (Java/Python is a plus\\nStrong programming skills and ability to utilize a variety of software/languages/tools; e.g., Spark, R, Python, Scala, Java, Hive, SQL, SAS, Tableau, etc.\\nExperience with microservice development, Docker, Kubernetes\\nDevelop software to run on cloud native big data infrastructure built on AWS using Spark, Lambda, S3, and other cloud native services\\nDesigns and develops complex and large-scale data structures and pipelines to organize, collect and standardize data to generate insight\\n3+ years of experience in data integration platforms (Informatica, Talend)\\nHands on experience in self-service data preparation tool like Alteryx\\nExperience using GitHub, Bit Bucket, or other code repository solution\\nDevOps experience is a plus\\nSkills / Other Personal Attributes Required:\\nPrevious management experience and successfully leading a team of direct reports\\nProven track record of effectively leading and managing employees, managing performance, setting goals for team/individuals and provide mentoring.\\nStrong Tableau, Adobe Analytics other BI solution\\nExpert Oracle and Vertica skillsets\\nExperience using JIRA and Agile Project Management software\\nExperience using GitHub, Bit Bucket, or other code repository solution\\nStrong written, verbal communication and presentation skills\\nAbility to explain complex technical issues in a way that non-technical people may understand\\nAble to work in a global, multicultural environment\\nSelf-motivated. Capable of working with little or no supervision\\nAbility to react positively under pressure to meet tight deadlines\\nAble to work independently or as a team player\\nEnjoy challenging and thought provoking work and have a strong desire to learn and progress\\nFormal Education: (minimum requirement to perform job duties)\\nBS in Computer Science, Applied Mathematics, Physics, Statistics or area of study related to data sciences and data mining or relevant experience\\nFLSA (US Only): Exempt\\n\\nThe above information on this description has been designed to indicate the general nature and level of work performed by employees within this role. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications required of employees assigned to this job. The job holder may be required to perform other duties as deemed appropriate by their manager from time to time.\\n\\nInvesco's culture of inclusivity and its commitment to diversity in the workplace are demonstrated through our people practices. We are proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, creed, color, religion, sex, gender, gender identity, sexual orientation, marital status, national origin, citizenship status, disability, age, or veteran status. Our equal opportunity employment efforts comply with all applicable U.S. state and federal laws governing non-discrimination in employment.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "57  Your responsibilities\\nthyssenkrupp Elevator Corporation is seeking a Sr. Data Engineer - Governance in Alpharetta, GA. The Sr. Data Engineer to be responsible for data engineering activities and aiding in building the business’ information systems, data governance, data management, data integration and data warehouse for key business areas including but not limited to Manufacturing, Engineering, Spare Parts and Supply Chain. The role of the Senior Data Engineer is responsible for building and maintaining optimized and highly available data that facilitate deeper analysis, quality data, metadata and reporting for the various systems and Analytics groups which supports relevant tkE. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. RESPONSIBILITIES:\\nPartner with Data Owners and Data Stewards to design solutions that align to data governance and data management principles and best practices\\nDesign data models for key program processes and data entities and ensure integration of logical data model into the enterprise conceptual data model and physical data models\\nBuild and maintain reliable and scalable ETL on data platforms that support critical business functions and analytics’ functions of the organization\\nEnsures regulatory issues are considered surrounding data assets (such as consumer privacy laws, data retention policies\\nRecognize and resolve conflicts between models, ensuring that data models are consistent with the enterprise model (e.g., entity names, relationships and definitions).\\nPartner with Quality Teams on Six Sigma methodology to ensure data and processes are properly aligned and efficient\\nCreates the principles, models, designs and systems that strengthen the network effect of sharing such data across the enterprise\\nPlans data architecture and design by studying the solution concept, strategy, and target audience and by envisioning architectural scheme, data structure and features, functionality, and user-interface design.\\nImplements a discipline and approach to managing data assets and converting the principles of the architecture into a technology solution\\nRequired to draft reports and prepare presentations for senior leadership. These reports and presentation must be clear, concise, unambiguous, engaging and convincing, which will demand exceptional communication skills\\nLeads the design of the data architecture, across multiple data domains and sub-domains.\\nCoordinates new development activities and ensures they are consistent and well-integrated with the established ecosystem data architecture\\nCreates ecosystem models (e.g. conceptual, logical, canonical) that are required for supporting services within the enterprise data\\nReviews and approves data model designs with a focus on those areas influencing interoperability, analytics including compliance with the portfolio information model\\nYour profile\\nQUALIFICATIONS:\\nBachelor’s degree (B.A. / B.S.) in Information Technology or Computer Science or related field or the equivalent combination of education and experience\\nMust have had at least 5 years of working experience working in a data engineering department, preferably as a Data Engineer in a fast-paced environment and complex business setting\\nBusiness domain, data/content and process understanding of Manufacturing, Engineering, Spare Parts and Supply Chain\\nSystem integration experience, including interface design, and familiarity with web-oriented architecture techniques\\nData modeling and information classification expertise at an enterprise level\\nExperience with Master Data Management, Metadata Management, Data Integration, Data Migration, Data Governance design and implementation techniques leveraging data management tools such as SAP MDG, Informatica or Talend\\nExperience with distributed management and analytics in cloud and hybrid environments with an understanding of a variety of data access and analytics approaches such as micro-services and event-based architectures\\nPREFERRED QUALIFICATIONS:\\nExperience with designing and implementing self-service models\\nHands-on experience with implementing data and analytics management programs\\nOur offer to you\\nSafety at work and Healthcare\\nSafety at work & Healthcare: Highest standards in occupational safety and health, comprehensive programs and measures for safety at work and preventive healthcare with comprehensive coverage and flexible options.\\nSecurity for the future\\nFinancial security for your individual retirement plan.\\nCollaboration\\nRespect, recognition and appreciation of the contribution of everyone. Regular team - and social events.\\nContinuing development\\nTraining and continuing developement options. Help to grow alongside with us, in personality and profession.\\nCompensation and benefits\\nWe offer a lot: Fair working conditions and a reasonable, competitive compensation are the foundation for many more attractive benefits.\\nDiversity\\nOpen, tolerant and constructive work environment with a team consistent of diverse views and backgrounds.\\nWe work together closely and respect each other, for over 200 years. If that is just as important to you as it is to us, apply now!\\n\\nTo learn more about thyssenkrupp in North America, please visit our website:\\nhttps://www.thyssenkrupp-north-america.com\\nthyssenkrupp Elevator Corp. is an equal opportunity employer. Applicants will receive consideration for employment without regard to age, sex, race, color, religion, national origin, genetics, disability, gender identity, marital status, sexual orientation, veteran status or any other protected characteristic required by applicable law.\\n\\nApplicants with disabilities who require reasonable accommodation in connection with the application process are encouraged to contact us directly at 1-844-427-5461.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "58  Riskonnect is the leading integrated risk management software solution provider that empowers organizations to anticipate, manage and respond in real-time to strategic and operational risks across the extended enterprise. Riskonnect is the only provider ranked in the leadership and visionary quadrants by world renowned industry analysts - Gartner, Forrester and Advisen RMIS Review. We employ more than 500 risk professionals in the Americas, EMEA and Asia Pacific and serve over 900 customers across 6 continents. The combination of innovative risk technology, a customer success mindset, and employee-first belief makes Riskonnect a sought after place to work.\\nResponsibilities:\\nDevelop strategy for new multi-platform data integration and analytics.\\nDevelop strategy for new multi-platform-sourced data lake.\\nContribute to API strategy to facilitate application connectivity and analytics.\\nContribute to the maintenance and evolution of best practices.\\nContribute to process documentation.\\nPerform multiple proofs of concept (POCs).\\nContribute to implementation plan for decided-upon solution(s).\\n\\nRequired Qualifications:\\nExperience with JavaScript/Java/ Python or Jitterbit and other developer languages.\\nExperience with Data Analytics.\\nExperience with Web Services and APIs.\\nExperience in the development of batch and real-time data integration and data consolidation processes.\\nExperience with machine learning, AI, and data lakes.\\nProficiency in TSQL/PLSQL query-writing, stored procedure development, and views.\\nStrong analytical skills with ability for problem-solving.\\nUnderstands the importance of data provenance and the ability to demonstrate it to clients.\\nDetail oriented, organized, self-motivated.\\n\\nPreferred Qualifications:\\nExperience with Salesforce.\\nExperience in the Risk Management, Healthcare, Financial, and/or Insurance industries is recommended.\\nExperience with Financial data sets, involving financial validation.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "59  Job Description\\n\\nMerkle is looking for experienced Google Cloud professional to be part of its Cloud practice. You will be working on industry leading Google Cloud Platform (GCP) to design, develop, and implement next generation Marketing solutions leveraging Cloud native and Commercial/Open Source Big Data technologies.\\nKey Responsibilities\\nAs a Senior Google Cloud Architect, you will\\nBe the force behind shaping the future of our Cloud strategy practice by leading innovation efforts and developing Intellectual Property\\nBe client facing in advising them on GCP optimized architectures for data management, help develop roadmaps for on-prem to Cloud migration efforts\\nBe hands-on in developing prototypes and conducting Proof of Concepts\\nAct as a trusted advisor to client on all things GCP\\nLead team members on project involving data migration and implementation of new solutions on cloud platforms\\nParticipate in crafting customer facing proposal responses\\nParticipate in technical interactions with client’s executives and senior management\\nMentor client/Merkle resources on GCP and its services\\nEvaluate and analyze new commercial/open-source services/technologies offered by public Cloud providers, and Big Data technology vendors\\nInterface with Cloud/Technology provider’s Product Managers, and Engineers\\nDevelop reference architectures and design pattern library for typical Cloud based Marketing solutions implementations\\nParticipate in creating new services capabilities, productized solution offerings and document implementation handbooks\\nAdvise on Cloud project set up, security and role based access implementation, and network optimizations\\nMerkle is looking for experienced Google Cloud professional to be part of its Cloud practice. You will be working on industry leading Google Cloud Platform (GCP) to design, develop, and implement next generation Marketing solutions leveraging Cloud native and Commercial/Open Source Big Data technologies.\\nKey Responsibilities\\nAs a Senior Google Cloud Architect, you will\\nBe the force behind shaping the future of our Cloud strategy practice by leading innovation efforts and developing Intellectual Property\\nBe client facing in advising them on GCP optimized architectures for data management, help develop roadmaps for on-prem to Cloud migration efforts\\nBe hands-on in developing prototypes and conducting Proof of Concepts\\nAct as a trusted advisor to client on all things GCP\\nLead team members on project involving data migration and implementation of new solutions on cloud platforms\\nParticipate in crafting customer facing proposal responses\\nParticipate in technical interactions with client’s executives and senior management\\nMentor client/Merkle resources on GCP and its services\\nEvaluate and analyze new commercial/open-source services/technologies offered by public Cloud providers, and Big Data technology vendors\\nInterface with Cloud/Technology provider’s Product Managers, and Engineers\\nDevelop reference architectures and design pattern library for typical Cloud based Marketing solutions implementations\\nParticipate in creating new services capabilities, productized solution offerings and document implementation handbooks\\nAdvise on Cloud project set up, security and role based access implementation, and network optimizations\\n\\nQualifications\\n\\nKey Skills and Experience\\nBe hands-on\\nUnderstanding of Google cloud computing technologies, business drivers, and emerging computing trends\\nCertified Google Cloud Data Engineer\\nMinimum 10 years experience in data warehouse/data engineering with strong hands-on experience in ETL\\nProven track record of building technical and business relationships with senior executives\\nProven track record of driving decisions collaboratively, resolving conflicts and ensuring follow up\\nProblem-solving mentality leveraging internal and/or external resources, where and when needed, to do what’s right for the customer\\nExceptional verbal and written communication\\nAbility to coordinate across geographically dispersed team members and consolidate status for stakeholders\\nAbility to connect technology with measurable business value\\nDemonstrated technical thought leadership in customer facing situations\\n\\nRequirements:\\nCertified Google Cloud Data Engineer\\n5+ years of technical management and though leadership role delivering success in complex data analytics environment, managing various stakeholders relationships to get consensus on solution\\n5+ year’s design and/or implementation of highly distributed applications\\n2+ years’ experience in “migrating” on premise workloads to one or more industry leading public cloud(s)\\nDemonstrated experience of designing and building Big Data solutions on GCP stack leveraging BigQuery, Dataproc, Dataflow, BigTable, Data Prep, etc.\\n5+ years experience using Python for building data pipelines\\nTechnical architectural and development experience on Massively Parallel Processing technologies, such as Hadoop, Spark, Teradata, Netezza, Hadoop\\nTechnical architectural and development experience on one or more Data Integration technologies, such as Ab Initio, Talend, Pentaho, Informatica, Data Stage, Map Reduce\\nTechnical architectural experience on Data Visualization technologies, such as Tableau, Qlik, etc.\\nTechnical architectural experience on data modeling, designing data structures for business reporting\\nDeep understanding of Advanced Analytics, such as predictive, prescriptive, etc.\\nWorking knowledge of cloud components: Software design and development, Systems Operations / Management, Database architecture, Virtualization, IP Networking, Storage, IT Security\\nTechnical prowess and passion-especially for public Cloud, modern Application design practices and principles. Certifications on Cloud Platform preferred.\\nOversight experience on major transformation projects and successful transitions to operations support teams\\nPresentation skills with a high degree of comfort to both large and small audiences\\nAdditional Information\\n\\nMerkle fosters adiverse environment that encourages original thinking about our business andempowers us to communicate with a global world of customers. We embracedifferences of opinion and diversity of thought as they help us challenge andrefine our solutions. Merkle, as a best-in-class marketing agency, welcomes bigideas, and believes they can come from anywhere.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "60  Are you ready to step up to the New and take your technology expertise to the next level?\\n Join Accenture and help transform leading organizations and communities around the world. The sheer scale of our capabilities and client engagements, in conjunction with the way we collaborate, operate and deliver value, provides an unparalleled opportunity to grow and advance. Choose Accenture and make delivering innovative work part of your extraordinary career.\\n People in our Client Delivery & Operations career track drive delivery and capability excellence through the design, development and/ or delivery of a solution, service, capability or offering. They grow into delivery-focused roles, and can progress within their current role, laterally or upward. We partner with our clients to help transform their data into an ‘Appreciating Business Asset.’\\n\\nAs part of our Data Business Group, you will lead technology innovation for our clients through robust delivery of world-class solutions. You will build better software better! There will never be a typical day and that’s why people love it here. The opportunities to make a difference within exciting client initiatives are unlimited in the ever-changing technology landscape. You will be part of a highly collaborative and growing network of technology and data experts, who are taking on today’s biggest, most complex business challenges using the latest data and analytics technologies. We will nurture your talent in an inclusive culture that values diversity. You will have an opportunity to work in roles such as Data Scientist, Data Engineer, or Chief Data Officer covering all aspects of Data including Data Management, Data Governance, Data Intelligence, Knowledge Graphs, and IoT. Come grow your career in Technology at Accenture!\\n\\nThe Azure Technical Architect Delivery is responsible for delivering Data On Cloud projects for Azure based deals. The ideal candidate would also be responsible for developing and delivering Azure cloud solutions to meet todays high demand in areas such as AIML, IoT, advanced analytics, open source, enterprise collaboration, microservices, serverless, etc. The Azure Data Engineer is a highly performant engineer responsible for delivering Cloud based Big Data and Analytical Solutions at our clients. Responsibilities include evangelizing data on cloud solutions with customers, leading Business and IT stakeholders through designing a robust, secure and optimized Azure architectures and ability to be hands-on delivering the target solution. This role will work with customers and leading internal engineering teams in delivering big data soltuions on cloud. Using Azure public cloud technologies, our Data Engineer professionals implement state of the art, scalable, high performance Data On Cloud solutions that meet the need of todays corporate and emerging digital applications\\n\\n Role & Responsibilities:Provide subject matter expertise and hands on delivery of data capture, curation and consumption pipelines on Azure and HadoopAbility to build cloud data solutions and provide domain perspective on storage, big data platform services, serverless architectures, hadoop ecosystem, vendor products, RDBMS, DW/DM, NoSQL databases and security.Participate in deep architectural discussions to build confidence and ensure customer success when building new solutions and migrating existing data applications on the Azure platform.Conduct full technical discovery, identifying pain points, business and technical requirements, “as is” and “to be” scenarios.\\n- Build full technology stack of services required including PaaS (Platform as-a-service), IaaS (Infrastructure as-a-service), SaaS (software as-a-service), operations, management and automation.Apply Accenture methodology, Accenture reusable assets, and previous work experience to delivery consistently high-quality work.Stay educated on new and emerging technologies/patterns/methodologies and market offerings that may be of interest to our clients.Adapt to existing methods and procedures to create possible alternative solutions to moderately complex problems.Understand the strategic direction set by senior management as it relates to team goals.Use considerable judgment to define solution and seeks guidance on complex problems.Primary upward interaction is with direct supervisor. May interact with peers and/or management levels at a client and/or within Accenture. Establish methods and procedures\\non new assignments with guidance.\\nManage small teams of deliver engineers successfully delivering work efforts\\n\\n (if in an independent contributor role) at a client or within Accenture.\\nExtensive travel may be required\\n\\nBasic Qualifications\\nAt least 5 years of consulting or client service delivery experience on Azure\\nAt least 5 years of experience in developing data ingestion, data processing and analytical pipelines for big data, relational databases, NoSQL and data warehouse solutions\\nExtensive experience providing practical direction within the Azure Native and HadoopMinimum of 5 years of hands-on experience in Azure and Big Data technologies such as Powershell, C#, Java, Node.js, Python, SQL, ADLS/Blob, Spark/SparkSQL, Hive/MR, Pig, Oozie and streaming technologies such as Kafka, EventHub, NiFI etc.\\nExtensive hands-on experience implementing data migration and data processing using Azure services: Networking, Windows/Linux virtual machines, Container, Storage, ELB, AutoScaling, Azure Functions, Serverless Architecture, ARM Templates, Azure SQL DB/DW, Data Factory, Azure Stream Analytics, Azure Analysis Service, HDInsight, Databricks Azure Data Catalog, Cosmo Db, ML Studio, AI/ML, etc.\\n Cloud migration methodologies and processes including tools like Azure Data Factory, Event Hub, etc.\\n5+ years of hands on experience in programming languages such as Java, c#, node.js, python, pyspark, spark, SQL, Unix shell/Perl scripting etc.\\nMinimum of 5 years of RDBMS experience\\nExperience in using Hadoop File Formats and compression techniquesExperience working with Developer tools such as Visual Studio, GitLabs, Jenkins, etc.\\nExperience with private and public cloud architectures, pros/cons, and migration considerations.\\nBachelors or higher degree in Computer Science or a related discipline.\\n\\nCandidate Must Have Completed The Following Certifications\\nMCSA Cloud Platform (Azure) Training & Certification\\nMCSE Cloud Platform & Infratsructiure Training & Certification\\nMCSD Azure Solutions Architect Training & Certification\\n\\nNice-to-Have Skills/Qualifications:\\nDevOps on an Azure platform\\nExperience developing and deploying ETL solutions on Azure\\nIoT, event-driven, microservices, containers/Kubernetes in the cloud\\nFamiliarity with the technology stack available in the industry for metadata management: Data Governance, Data Quality, MDM, Lineage, Data Catalog etc.\\nFamiliarity with the Technology stack available in the industry for data management, data ingestion, capture, processing and curation: Kafka, StreamSets, Attunity, GoldenGate, Map Reduce, Hadoop, Hive, Hbase, Cassandra, Spark, Flume, Hive, Impala, etc.\\n- Multi-cloud experience a plus - Azure, AWS, Google\\n\\nProfessional Skill Requirements\\n Proven ability to build, manage and foster a team-oriented environment\\n Proven ability to work creatively and analytically in a problem-solving environment\\n Desire to work in an information systems environment\\n Excellent communication (written and oral) and interpersonal skills\\n Excellent leadership and management skills\\n Excellent organizational, multi-tasking, and time-management skills\\n Proven ability to work independently\\n\\nAll of our professionals receive comprehensive training covering business acumen, technical and professional skills development. You'll also have opportunities to hone your functional skills and expertise in an area of specialization. We offer a variety of formal and informal training programs at every level to help you acquire and build specialized skills faster. Learning takes place both on the job and through formal training conducted online, in the classroom, or in collaboration with teammates. The sheer variety of work we do, and the experience it offers, provide an unbeatable platform from which to build a career.\\n\\nApplicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status).\\n\\nCandidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.\\n\\nAccenture is a Federal Contractor and an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities.\\n\\nEqual Employment Opportunity\\n\\nAll employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.\\n\\nJob candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.\\n\\nAccenture is committed to providing veteran employment opportunities to our service men and women.  \n",
       "\n",
       "[61 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Descriptions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Descriptions_df.to_csv('Descriptions_df_DE_Atlanta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
