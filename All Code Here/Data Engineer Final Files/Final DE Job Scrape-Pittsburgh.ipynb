{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "import pandas as pd\n",
    "import requests\n",
    "from requests import get\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pulling all links off of the search pages (up to 3000) and putting them in a dataframe to scrape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_template=\"http://www.indeed.com/jobs?q=%22Data+Engineer%22&l=Pittsburgh%2C+PA&start={}\"\n",
    "max_results=250\n",
    "Linkdf=[]\n",
    "\n",
    "for start in range(0, max_results, 7):\n",
    "    url=url_template.format(start)\n",
    "    html=requests.get(url)\n",
    "    soup=BeautifulSoup(html.content,'html.parser', from_encoding=\"utf-8\")\n",
    "    \n",
    "    #for each in soup.find_all(a_=\"href\"):\n",
    "    page_links=soup.find_all('a',{'href':re.compile(\"/rc/\")})\n",
    "    for items in page_links:\n",
    "        Linkdf.append(items['href'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity Check\n",
    "len(Linkdf)\n",
    "#print(Linkdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This code allows the code to display the full website instead of truncating\n",
    "pd.set_option('display.max_colwidth',-1)\n",
    "\n",
    "#Moving it to a data frame\n",
    "data = {'links':Linkdf}\n",
    "df = pd.DataFrame(data, columns=['links'])\n",
    "\n",
    "#append indeed.com to the front of each\n",
    "df['Web'] = 'https://www.indeed.com'\n",
    "df['URL'] = df.Web.str.cat(df.links)\n",
    "\n",
    "#pull out just a list of the websites.\n",
    "websites=list(df['URL'])\n",
    "\n",
    "#Sanity Check\n",
    "#print(websites)\n",
    "len(websites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "websites1=set(websites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(websites1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looping through websites...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Title=[]\n",
    "Descriptions=[]\n",
    "Location=[]\n",
    "FullDescriptions=[]\n",
    "\n",
    "for url in websites1:\n",
    "    response=get(url)\n",
    "    soup=BeautifulSoup(response.text,'html.parser')\n",
    "    \n",
    "    description_containers= soup.find(class_='jobsearch-jobDescriptionText')\n",
    "    title_containers=soup.find('h3')\n",
    "    try:\n",
    "        location_containers=soup.find('',{'class':'jobsearch-CompanyInfoWithoutHeaderImage'}).find_all('div')[-1]\n",
    "    except:\n",
    "        location_containers='None Found'\n",
    "    \n",
    "    job_descriptions=str(description_containers)\n",
    "    job_title=str(title_containers.text)\n",
    "    try:\n",
    "        locations=str(location_containers.text)\n",
    "    except AttributeError:\n",
    "        locations = 'None Found'\n",
    "    try:\n",
    "        full_descriptions = str(description_containers.text)\n",
    "    except AttributeError:\n",
    "        full_descriptions= 'None Found'\n",
    "    \n",
    "    Descriptions.append(job_descriptions)\n",
    "    Title.append(job_title)\n",
    "    Location.append(locations)\n",
    "    FullDescriptions.append(full_descriptions)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting what we want from the Descriptions Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'Location' left in for sanity check. Should be removed once code is confirmed to work\n",
    "Descriptions_df = pd.DataFrame(columns = ['Title', 'Location','City', 'State', 'Zip', 'Country', 'Qualifications', 'Skills', 'Responsibilities', 'Education', 'Requirement', 'FullDescriptions'])\n",
    "Country = ['US', 'USA', 'United States', 'United States of Americal']\n",
    "States = ['AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', 'IA',\n",
    "          'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND',\n",
    "          'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY']\n",
    "\n",
    "for index, element in enumerate(Descriptions):\n",
    "    soup=BeautifulSoup(element,'lxml')\n",
    "    for values in list(Descriptions_df):\n",
    "        temp_tag = soup.find('b', text=re.compile(values))\n",
    "        try:\n",
    "            ul_tag = temp_tag.find_next('ul')\n",
    "            Descriptions_df.at[index,values] = ul_tag.text\n",
    "        except AttributeError:\n",
    "            Descriptions_df.at[index,values]=\"None Found\"\n",
    "        Descriptions_df.at[index,\"Title\"]=Title[index]\n",
    "        Descriptions_df.at[index,\"Location\"]=Location[index]\n",
    "        Descriptions_df.at[index,\"FullDescriptions\"]=FullDescriptions[index]\n",
    "        words = '|'.join(Country)\n",
    "        temp = re.findall(words, Location[index])\n",
    "        if len(temp) != 0:\n",
    "            Descriptions_df.at[index,\"Country\"] = temp[0]\n",
    "        words = '|'.join(States)\n",
    "        temp = re.findall(words, Location[index])\n",
    "        if len(temp) != 0:\n",
    "            Descriptions_df.at[index,\"State\"] = temp[0]\n",
    "        temp = re.findall(r'\\d+', Location[index])\n",
    "        if len(temp) != 0:\n",
    "            Descriptions_df.at[index,\"Zip\"] = temp[0]  \n",
    "            \n",
    "        temp = re.findall(r'[\\w w]+,', Location[index])\n",
    "        if len(temp) != 0:\n",
    "            Descriptions_df.at[index,\"City\"] = re.sub(',', '', temp[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Country</th>\n",
       "      <th>Qualifications</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Responsibilities</th>\n",
       "      <th>Education</th>\n",
       "      <th>Requirement</th>\n",
       "      <th>FullDescriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Big Data Developer</td>\n",
       "      <td>Pittsburgh, PA</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>PA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>You are curious, persistent, logical and clever – a true techie at heart. You enjoy living by the code of your craft and developing elegant solutions for complex problems. If this sounds like you, this could be the perfect opportunity to join EPAM as a Big Data Developer. Scroll down to learn more about the position’s responsibilities and requirements.\\n\\nWe are looking for a Big Data Engineer that will work on the collecting, storing, processing, and analyzing of large sets of data. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. You will also be responsible for integrating them with the architecture used across the company.\\n#Financial_Services\\nWhat You Have\\nA degree in an associated field and/or other advanced certification along with significant experience\\nProficient understanding of distributed computing principles\\nManagement of Hadoop cluster (Cloudera preferred), with all included services\\nAbility to solve any ongoing issues with operating the cluster\\nProficiency with Hadoop v2, MapReduce, HDFS, Sqoop\\nExperience with building stream-processing systems, using solutions such as Storm or Spark-Streaming\\nGood knowledge of big data querying tools, such as Pig, Hive, and Impala\\nExperience with Spark\\nExperience with integration of data from multiple data sources such as MS SQL Server, Oracle\\nGood understanding of SQL queries, joins, stored procedures, relational schemas\\nExperience with NoSQL databases, such as HBase, Cassandra, MongoDB (preferred)\\nKnowledge of various ETL techniques and frameworks, such as Flume\\nExperience with various messaging systems, such as Kafka or RabbitMQ\\nExperience with Cloudera\\nFS domain knowledge is a big plus but not required\\nWhat We Offer\\nMedical, Dental and Vision Insurance (Subsidized)\\nHealth Savings Account\\nFlexible Spending Accounts (Healthcare, Dependent Care, Commuter)\\nShort-Term and Long-Term Disability (Company Provided)\\nLife and AD&amp;D Insurance (Company Provided)\\nEmployee Assistance Program\\nUnlimited access to LinkedIn learning solutions\\nMatched 401(k) Retirement Savings Plan\\nPaid Time Off\\nLegal Plan and Identity Theft Protection\\nAccident Insurance\\nEmployee Discounts\\nPet Insurance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Pittsburgh, PA 15213</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>PA</td>\n",
       "      <td>15213</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Company Overview\\nAt Proofpoint, we have a passion for protecting people, data, and brands from today’s advanced threats and compliance risks. We hire the best people in the business to: Build and enhance our proven security platform; blend innovation and speed in a constantly evolving cloud architecture; analyze new threats and offer deep insight through data-driven intel; collaborate with customers to help solve their toughest security challenges.\\n\\nWe are singularly devoted to helping our customers protect what matters most. That’s why we’re a leader in next-generation cybersecurity—and why more than half of the Fortune 100 trust us as a security partner.\\n\\nWe are seeking a Senior Data Engineer to join our growing team in Pittsburgh. If you've ever wanted to work for an innovative software company, in great environment with great people, this is your chance. We’re a security software-as-a-service company so you’ll be involved both in our day-to-day software development as well as getting exposure to our security efforts.\\n\\nQ: Ok. Who are you?\\nA: We’re comprised of some really smart white hat security hackers, researchers from CMU, software developers and lot of hard working and friendly faces. We also really like data. We really value creating an inclusive, transparent, empathetic, and communicative culture.\\n\\nQ: What would I be working on?\\nA: You know all those data breaches you hear about in the news? Most of them started when a bad guy targeted an employee with a phishing attack. Our customers are mostly large enterprise organizations that are under attack by some pretty nasty bad guys. They use our platform to deliver security education to their employees and figure out who needs extra help. Your job will be to make our customers' experience of reporting on the results of their security awareness program as wonderful as possible.\\n\\nQ: Can you tell me a little more about your product?\\nA: Sure, we have several different ways that we can deliver security training to end users as well as several different ways to assess their security knowledge. One of the really fun ways we test the user is thinking like the bad guys. We send the end users a simulated phishing message. If they fall for it (they click our link, open our attachment, etc.), we show them training right away. It's an unconventional approach to changing user behavior and it works (hint: we have data). Proofpoint is in a growing space to say the least. If you ever wanted to learn more about cyber security and cutting-edge attacks, this is the place to do it. You’ll get to help simulate evil, figure out how to fight evil, and give our customers data that they can use to protect their organization.\\n\\nYour day to day\\nPerform development tasks related to delivering Qlik Sense applications, including design, implementation, testing and deployment\\nComfortable with defining/implementing application and database architectures\\nWork with Product Managers and Quality Engineers to ensure the delivery of great, high-quality features\\nInvestigate, prototype and recommend new technologies and solutions\\nWhat you bring to the team\\nBS/BA in a software related field or incredible experience that makes us not care about a degree.\\n2+ years’ experience of Qlik Sense development (or a combination of Qlik Sense and QlikView experience).\\nYou should have solid experience developing within Qlik Sense (or potentially QlikView). Preferably 2-4 years of experience in both native and mashup environments.\\nThe ability to diagnose and address performance bottlenecks in Qlik.\\nYou should possess an intermediate to advanced knowledge of SQL in either PostgreSQL or MySQL environments (or both). For instance, what are the different kinds of JOINs and when would you use each? What is a window function and why would you use one? What's a CTE? What are some features that are available in MySQL that aren't available in PostgreSQL or vice versa.\\nHave exposure to either MySQL or PostgreSQL environments, preferably MySQL 5.7 and PostgreSQL 10.\\nAt least an intermediate understanding of a HA Qlik deployment. For instance, what's the difference between a central node and a proxy node? How would you begin setting up such an environment or communicating with DevOps around the requirements for such an environment?\\nExperience in data modeling for both relational and analytical systems. What's the difference between 3NF and a star schema? When would it be appropriate to use one kind of model versus another? What are some of the kinds of slowly changing dimensions? In Qlik specifically, how do you approach creating a data model for high performance?\\nExperience with additional BI applications such as PowerBI and Logi. Have you ever created reports or visualizations for an end user using one of these applications (or others)?\\nFamiliarity with AWS is a plus, especially including a subset of the following services: RDS, EC2, S3, Data Pipeline, SNS, Kinesis, Lambda, DynamoDB, EMR, Redshift, and Elasticsearch.\\nComfort in working across multiple operating systems, including macOS and Windows.\\nComfortable with Git for version control.\\nCan work independently and thrives with autonomy.\\nWhy Proofpoint\\n\\nAs a customer focused and driven-to-win organization with leading edge products, there are many exciting reasons to join the Proofpoint team. We believe in hiring the best the brightest and cultivating a culture of collaboration and appreciation. As we continue to grow and expand globally, we understand that hiring the right people and treating them well is key to our success! We are a multi-national company with locations in 10 countries, with each location contributing to Proofpoint’s amazing culture!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Engineer Sr</td>\n",
       "      <td>Pittsburgh, PA 15222</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>PA</td>\n",
       "      <td>15222</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Position Overview\\nAt PNC, our people are our greatest differentiator and competitive advantage in the markets we serve. We are all united in delivering the best experience for our customers.\\n\\n\\nAs a Data Engineer Senior (hadoop) within PNC's Technology and Innovation organization, can be based in Pittsburgh, PA; Cleveland or Columbus, OH; Dallas, TX; Overland Park, KS; or within any PNC footprint nationwide\\n\\n\\nThe following skills are preferred:\\n\\nExperience in Hadoop Architecture &amp; Data Engineering – Cloudera preferred\\nExtensive experience in Data Engineering – Spark, HIVE, Map Reduce, Sqoop, Kafka, NiFi, etc.\\nProficiency in writing SQL on mainstream RDBMSs like Oracle, Teradata etc.\\nTechnical lead and mentoring/coaching experience\\n\\nThe following skills are a plus:\\n\\nHands on experience with large Data Warehousing (Hadoop) implementations\\nProficiency with ingestion tools, Sqoop, Kafka, NiFi, etc.\\nAgile software development environment experience\\nJob Description\\nLeads in developing, supporting and implementing data solutions for multiple applications in order to meet business objectives and user requirements. Leverages technical knowledge and industry experience to design, build and maintain technology solutions.\\nLeads data requirement analysis and the data preparation process development for targeted data solutions.\\nLeads in designing and building data service infrastructure on multiple data platforms, according the workflow.\\nOversees the development and implementation of data solutions for multiple applications to ensure its scalability, availability and maintainability.\\nConsults on data migration and transformation to ensure the accuracy and security of data solutions.\\nPNC Employees take pride in our reputation and to continue building upon that we expect our employees to be:\\nCustomer Focused - Knowledgeable of the values and practices that align customer needs and satisfaction as primary considerations in all business decisions and able to leverage that information in creating customized customer solutions.\\nManaging Risk - Assessing and effectively managing all of the risks associated with their business objectives and activities to ensure they adhere to and support PNC's Enterprise Risk Management Framework.\\nCompetencies\\nApplication Delivery Process – Knowledge of major tasks, deliverables, and formal application delivery methodologies; ability to utilize these in order to deliver new or enhanced applications.\\nBig Data Management and Analytics – Knowledge and ability to plan and execute, big data management and analytics.\\nBusiness Intelligence – Knowledge of and ability to utilize business processes and technologies for gathering, storing, analyzing, and providing access to data that helps the organization make better business decisions.\\nConsulting – Knowledge of techniques, roles, and responsibilities in providing technical or business guidance to clients, both internal and external; ability to apply this knowledge appropriately to diverse situations.\\nData Analysis - Software – Knowledge of the investigation, evaluation, interpretation, and classification of data; the ability to identify, collect and analyze data to facilitate the development, implementation and application of software systems.\\nData Architecture – Knowledge and ability to create models and standards to govern which data is collected, and how it is stored, arranged, integrated, and put to use in data systems and in organizations.\\nDatabase Structures – Knowledge of and the ability to utilize appropriate database structures to organize and store data in a particular manner.\\nProblem Solving – Knowledge of approaches, tools, techniques for recognizing, anticipating, and resolving organizational, operational or process problems; ability to apply this knowledge appropriately to diverse situations.\\nSoftware Development Life Cycle – Knowledge of and experience with using a structured methodology for delivering new or enhanced software products to the marketplace.\\nWork Experience\\nRoles at this level typically require a university / college degree, with 5+ years of industry-relevant experience. Specific certifications are often required. In lieu of a degree, a comparable combination of education and experience (including military service) may be considered.\\nEducation\\nBachelors\\nDisability Accommodations Statement:\\n\\nThe PNC workplace is inclusive and supportive of individual needs. If you have a physical or other impairment that might require an accommodation, including technical assistance with the PNC Careers website or submission process, please call 877-968-7762 and select Option 4: Recruiting or contact us via email at pathfinder@pnc.com.\\nThe Human Resources Service Center hours of operation are Monday - Friday 9:00 AM to 5:00 PM ET.\\nEqual Employment Opportunity (EEO):\\n\\nPNC provides equal employment opportunity to qualified persons regardless of race, color, sex, religion, national origin, age, sexual orientation, gender identity, disability, veteran status, or other categories protected by law.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Technology Engineer Sr</td>\n",
       "      <td>Pittsburgh, PA 15289</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>PA</td>\n",
       "      <td>15289</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Position Overview\\n\\nAt PNC, our people are our greatest differentiator and competitive advantage in the markets we serve. We are all united in delivering the best experience for our customers. As a Technology Engineer Sr. within PNC's ALM Risk organization, you will be based in one of the following locations: Pittsburgh, PA. Cleveland, OH New York, NY New Jersey Washington D.C. area Atlanta, GA Chicago, IL Charlotte, NC Raleigh, NC Relocation assistance may be available for the for the selected candidate. In this contributor role you will support the Technology team partnering with the Balance Sheet Analytics &amp; Modeling LOB, and requires specialized skills and experience with advanced computational and data science related technologies such as Python, SAS, SPARK, Hadoop and related stacks. At PNC, we are building our advanced computation and analytics platforms to support CECL and other subsequent BSAM usecase implementation and we are seeking a Sr. Data Engineer who will perform the following functions: •A self-starter who can align the technology solution with a business goal •Development – Design and build database and data science solutions •Data Modeling – Apply your expertise to help model structured and unstructured data. Own these models at a high level and consult with feature teams to help them model applications. •Data Integration – Plan and build data integrations between systems. Figure out the best way to share information and build the tech needed to execute. •Mentoring – Help teach other team members about data architecture, and also be a consultant for developers who need help with data. •Engineer reusable capabilities and pipelines for DML, DDL, maintenance, and ETL needs that can be shared across teams. •Stay current on technical knowledge and tooling to help the team utilize new technologies. •Establish scalable, efficient, automated processes for large scale data analysis and visualization •Perform data insights analysis using clustering, agglomerative clustering, graph based clustering, and analysis Basic Qualifications •MS with 2+ years of industry experience or Bachelors with 5+ years of experience in Quantitative field (Computer Science, Electrical/ Computer engineering, Financial Engineering, Mathematics, Statistics, Physics) •5+ years of enterprise-level scripting experience using languages (e.g. Python, SPARK, SCALA), or statistical/mathematical software (e.g. R, SAS) •Experience in creating data driven visualizations •Highly skilled in data and math/statistical methods (i.e. modeling, algorithms) •4+ years of experience in system analysis and data management engineering •3+ years of experience in database technologies: Oracle, Cassandra, or Mongo •2+ years of experience with DevOps, CI/CD •Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment Preferred Qualifications •Experience in processing, filtering, and presenting large quantities (Millions to Billions of rows) of data •2+ years of experience in AWS, Google Cloud, or MS Azure •Experience working with Financial, Insurance domains •Strongly prefer Experience in Data Science, Machine Learning, and/or Deep Learning •Strongly prefer prior Experience in programming languages such as Java, or C/C+ •Experience with containerized solutions •Experience with SPARQL and other no-SQL data bases a plus •Experience with XML, XML Schema, XSLT\\n\\nJob Profile\\n\\nLeads in the development of the most complex new and emerging technologies and selects appropriate platforms, integrates and configures solutions. Leverages technical knowledge and industry experience to design, build and maintain technology solutions.\\nDevelops software components and hardware for new and emerging technology projects; aligns these with business strategies and objectives.\\nConsults junior staff regarding complex issues and best practices.\\nProvides a systematic analysis on the most complex client requirements within the traceability framework and resolves any functional problems encountered.\\nOversees the quality of complex project deliverables while ensuring that they are in compliance with relevant standards and processes.\\nPNC Employees take pride in our reputation and to continue building upon that we expect our employees to be:\\nCustomer Focused - Knowledgeable of the values and practices that align customer needs and satisfaction as primary considerations in all business decisions and able to leverage that information in creating customized customer solutions.\\nManaging Risk - Assessing and effectively managing all of the risks associated with their business objectives and activities to ensure they adhere to and support PNC's Enterprise Risk Management Framework.\\nCompetencies\\nApplication Delivery Process – Knowledge of major tasks, deliverables, and formal application delivery methodologies; ability to utilize these in order to deliver new or enhanced applications.\\nConsulting – Knowledge of techniques, roles, and responsibilities in providing technical or business guidance to clients, both internal and external; ability to apply this knowledge appropriately to diverse situations.\\nEffectiveness Measurement – Ability to measure the quality and quantity of work effort for the purpose of improvement.\\nEmerging Technologies – Knowledge of and ability to design, apply and evaluate new information technologies for business environments in order to improve work productivity and accuracy.\\nIndustry Knowledge – Knowledge of the organization's industry group, trends, directions, major issues, regulatory considerations, and trendsetters; ability to apply this knowledge appropriately to diverse situations.\\nIT Industry: Trends &amp; Directions – Knowledge of and ability to analyze marketplace experiences, developments and trends related to the function of Information Technology (IT).\\nIT Standards, Procedures &amp; Policies – Knowledge of and the ability to utilize a variety of administrative skill sets and technical knowledge to manage organizational IT policies, standards, and procedures.\\nPlanning: Tactical, Strategic – Ability to contribute to operational (short term), tactical (1-2 years) and strategic (3-5 years) planning in support of the overall business plan.\\nProblem Solving – Knowledge of approaches, tools, techniques for recognizing, anticipating, and resolving organizational, operational or process problems; ability to apply this knowledge appropriately to diverse situations.\\n\\nWork Experience\\n\\nRoles at this level typically require a university / college degree, with 5+ years of industry-relevant experience. Specific certifications are often required. In lieu of a degree, a comparable combination of education and experience (including military service) may be considered.\\n\\nEducation\\n\\nBachelors\\n\\nDisability Accommodations Statement\\n\\nThe PNC workplace is inclusive and supportive of individual needs. If you have a physical or other impairment that might require an accommodation, including technical assistance with the PNC Careers website or submission process, please call 877-968-7762 and select Option 4: Recruiting or contact us via email at pathfinder@pnc.com. The Human Resources Service Center hours of operation are Monday - Friday 9:00 AM to 5:00 PM ET.\\n\\nEqual Employment Opportunity (EEO)\\n\\nPNC provides equal employment opportunity to qualified persons regardless of race, color, sex, religion, national origin, age, sexual orientation, gender identity, disability, veteran status, or other categories protected by law.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Engineer, Analytics</td>\n",
       "      <td>Warrendale, PA 15086</td>\n",
       "      <td>Warrendale</td>\n",
       "      <td>PA</td>\n",
       "      <td>15086</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\n5 + years of experience designing data models\\n10 + years of experience implementing data models and data architecture\\nExperience with debugging, performance profiling and optimization of data at each phase of the data pipeline\\nDemonstrated analytical capabilities paired with a strong initiative to find ways to improve the analysis and communication of complex data\\nSpecific experience with Microsoft SQL Server Reporting Services (SSRS) and SQL Server toolset. Candidates with extensive experience in other BI/reporting/analytics toolsets may be considered if they have a commitment to learning SSRS and a demonstrated ability to ramp up to proficiency rather quickly (within 2 months) in a primarily self-directed way\\nProficiency in either Tableau, SSRS or Power BI is required\\nCapable of designing complex and performant SQL queries\\n</td>\n",
       "      <td>Description:\\nAs a member of the Digital Solutions and Data and Analytics IT team, this person will be working with various teams to design solutions related to the data pipeline, with special emphasis on data modeling and design.\\n\\nThis role demands a strong knowledge and understanding of the data and the business requirements to build robust, scalable data models, which may be relational as well as dimensional. The role entails having the capability of relating and understanding existing and in-development data models/schemas and the business context they represent.\\n\\nResponsibilities\\n\\n\\nEstablish design principles for data models and create modeling standards\\nDocument, create and maintain logical and physical database models as per the standards\\nWork with the business as well as the technical teams to understand the requirements, to create models that cater to the requirements\\nWork on understanding various data domains, to map and integrate disparate data from a variety of source systems\\nSupport Analytics development from and to a variety of database systems\\nFacilitate data requirements conversation with business and technical stakeholders resolving conflicts to drive decisions and consensus\\nEstablish and maintain comprehensive data model documentation including detailed descriptions of business entities, attributes, and data relationships as well as the definition of business rules governing the integrity, archiving, and audit requirements of the data\\nAnalyze existing systems using manual or automated data analysis/profiling to reverse engineer data requirements\\nDetermine suitable data modeling approach for each project based on business requirements for data capture and access\\nAssist developers with complex query development and performance optimization\\nPerforms additional duties as required\\nProvide subject matter expertise (technical and business context) input and feedback to data/BI teams and development scrum teams as needed.\\nIdentify, communicate, and mitigate risks related to including invalid data, invalid data calculations, formulas or derived insights, and misrepresentation of or otherwise confusing visual representations of data.\\n\\nRequirements:\\nTechnical\\n\\n\\n5 + years of experience designing data models\\n10 + years of experience implementing data models and data architecture\\nExperience with debugging, performance profiling and optimization of data at each phase of the data pipeline\\nDemonstrated analytical capabilities paired with a strong initiative to find ways to improve the analysis and communication of complex data\\nSpecific experience with Microsoft SQL Server Reporting Services (SSRS) and SQL Server toolset. Candidates with extensive experience in other BI/reporting/analytics toolsets may be considered if they have a commitment to learning SSRS and a demonstrated ability to ramp up to proficiency rather quickly (within 2 months) in a primarily self-directed way\\nProficiency in either Tableau, SSRS or Power BI is required\\nCapable of designing complex and performant SQL queries\\n\\nProfessional\\n\\n\\nExcellent interpersonal and organizational acumen by collaborating with both internal team members and external business stakeholders\\nInternally motivated, able to work proficiently both independently and in a team environment\\nStrong written and verbal communication skills with staff and leadership at all levels of seniority and technical experience\\nBachelor’s Degree or higher (Computer Science, Engineering, Human Computer Interaction/Design, or similar/relevant field)\\nMotivated to “stay current” with technical change/commit to professional development to learn relevant new skills/tools/methodologies\\n\\nDesired Additional Competencies\\n\\n\\nExperience with relational database design, SQL DDL, performance tuning relating to indexes, etc.\\nExperience with non-relational “noSQL” data sources\\nExperience with ETL processes and tools\\nHealthcare industry experience not required but a significant plus (supply chain, provider, payer, medical device, life-science, pharmacy, etc.)\\nExperience with other data/BI tools, especially within the Microsoft ecosystem\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Coraopolis, PA 15108</td>\n",
       "      <td>Coraopolis</td>\n",
       "      <td>PA</td>\n",
       "      <td>15108</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>The Data Engineer is a key member of a platform team that contributes to software design, development and overall product lifecycle for a product that delights our users and adds value to the organization. The engineering process is highly collaborative. The Data Engineer is expected to pair on a daily basis as they work through user stories and support products as they evolve. In addition, the Data Engineer may be involved in product configuration, performance tuning and testing as well as production monitoring. As a Data Engineer, you will be part of a team with more experienced engineers to help build and grow your skills while you create, support, and deploy production applications.\\n\\nQualifications\\nBuild the infrastructure to support coding, testing, processing, and maintaining data resources in support of the Data Science, analytics and reporting organizations using SQL, SQOOP, Python, Google Big Query, Kafka and other Big Data technologies.\\nCollaborate with Data Scientists in the development of predictive models using machine learning, natural language and statistical analysis methods.\\nDesign and implement internal process improvements (automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc).\\n\\nBuild analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.\\n\\nWork with stakeholders to assist with data-related technical issues and support their data infrastructure needs.\\n\\nDevelop, refine and oversee data management standards, including establishing and enforcing governance procedures and ensuring data integrity across multiple functions. Responsible for owning data quality metrics and meeting defined data accuracy goals according to industry best practices.\\n\\nBachelor's Degree - Computer Science, Software Engineering, Information Systems or Information Technology or related field required, or equivalent experience\\n\\n1-3 years of experience\\n\\nGoogle Cloud Platform (GCS, BQ, etc), Apache Kafka, Python\\nExperience with NoSQL database technologies (MongoDB, Cassandra, etc)\\n\\nExperience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.\\n\\n\\n#LI-BT1-L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Coraopolis, PA 15108</td>\n",
       "      <td>Coraopolis</td>\n",
       "      <td>PA</td>\n",
       "      <td>15108</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>The Senior Data Engineer is a key member of a platform team that contributes to software design, development and overall product lifecycle for a product that delights our users and adds value to the organization. The engineering process is highly collaborative. The Senior Data Engineer is expected to pair on a daily basis as they work through user stories and support products as they evolve. In addition, the Senior Data Engineer may be involved in product configuration, performance tuning and testing as well as production monitoring. As a Senior Data Engineer, you will be part of a team with more experienced engineers to help build and grow your skills while you create, support, and deploy production applications.\\nQualifications\\nBuild the infrastructure to support coding, testing, processing, and maintaining data resources in support of the Data Science, analytics and reporting organizations using SQL, SQOOP, Python, Google Big Query, Kafka and other Big Data technologies.\\n\\nCollaborate with Data Scientists in the development of predictive models using machine learning, natural language and statistical analysis methods.\\n\\nIdentify, design and implement internal process improvements (automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc).\\nBuild analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.\\nWork with stakeholders to assist with data-related technical issues and support their data infrastructure needs.\\nDevelop, refine and oversee data management standards, including establishing and enforcing governance procedures and ensuring data integrity across multiple functions. Responsible for owning data quality metrics and meeting defined data accuracy goals according to industry best practices.\\nExperience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc. Experience with relational database design methodologies and authoring complex SQL queries\\nExperience with NoSQL database technologies (MongoDB, Cassandra, etc) Experience with Agile Development and Agile Deployment tools and versioning using Git or similar tools\\nExperience with Hadoop and other Big Data technologies such as Spark, PySpark and Kafka Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.\\nExperience with message queuing, stream processing, and highly scalable ‘big data’ data stores. Experience building data pipelines utilizing Google Cloud platform.\\nExperience with git or other code repository tools Experience with Concourse or other CI/CD tools and methodologies.\\n\\nBachelor's Degree\\n\\nComputer Science, Software Engineering, Information Systems or Information Technology or related field required, or equivalent experience\\n\\n\\n3-5 years experience\\n\\nGoogle Cloud Platform (GCS, BQ, etc), Apache Kafka, Python\\n\\n#LI-BT1-L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>West Mifflin, PA 15122</td>\n",
       "      <td>West Mifflin</td>\n",
       "      <td>PA</td>\n",
       "      <td>15122</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Familiarity with building and optimizing data pipelines, architectures, and datasets\\nFamiliarity with data virtualization, transformation, and various data structures\\nFamiliarity with high performance computing\\nDeveloper technologies:\\nSoftware management tools including those for testing, continuous integration, version control, debugging, profiling, and compiler optimization\\nEnvironment Management:\\nData management and file systems\\nSystem metrics and monitoring\\nJob scheduler, resource allocation and job/workflow management</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>BS degree in engineering or Bachelor's degree in a science related field from an accredited college or university and a minimum of four years relevant experience; or\\nMS degree in engineering or Master's degree in a science related field from an accredited college or university and a minimum of two years relevant experience\\nExperience with relational databases, query authoring, programming, and hardware/software troubleshooting.\\n</td>\n",
       "      <td>Description\\nThe Naval Nuclear Laboratory seeks a talented and innovative Data Engineer to join a growing team dedicated to delivering data-driven solutions to the organization. As a data engineer, you will be responsible for developing, constructing, testing, and delivering Program data infrastructure needs. Specifically, the data engineer will help to assess existing data infrastructure hardware and software, and work with key stakeholders to identify, assess, implement, and test improvements to the data infrastructure. The data engineer will interface with data scientists and others at the Laboratory to ensure dataset reporting, querying, and analysis capabilities are based upon reliable, efficient, and scalable data infrastructure. The data engineer will participate in continuous data engineering training programs as well as develop and review corporate policies, instructions, and implementation principles related to data infrastructure and its use in the Program. We develop the world's best nuclear propulsion systems, train Sailors, to operate them, and provide full lifecycle support, from technology development through design to disposal.\\nResponsibilities:\\nInterface with technology and support organizations to create, adapt, maintain, and test optimal Program data pipeline architectures\\nAssemble large, complex datasets that meet functional business requirements\\nIdentify, design, and implement internal data infrastructure process improvements such as automating manual processes, optimizing data delivery, redesigning infrastructure for greater scalability, and opportunities for data acquisition\\nBuild the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using various technologies\\nWork with stakeholders to assist with data-related technical issues and support their data infrastructure needs\\nCreate consistent data infrastructure solutions and access for users at multiple sites\\nAssist management in prioritizing projects\\nDeliver data engineering training\\nContinuous learning and improvement of skills needed to keep current with state-of-the-art data architectures\\nDevelop and review corporate policies, instructions, and principles related to data infrastructure and its use in the Program\\nRequirements\\nAdvanced:\\nBS degree in engineering or Bachelor's degree in a science related field from an accredited college or university and a minimum of four years relevant experience; or\\nMS degree in engineering or Master's degree in a science related field from an accredited college or university and a minimum of two years relevant experience\\nExperience with relational databases, query authoring, programming, and hardware/software troubleshooting.\\nSenior:\\nBS degree in engineering or Bachelor's degree in a science related field from an accredited college or university and a minimum of six years relevant experience; or\\nMS degree in engineering or Master's degree in a science related field from an accredited college or university and a minimum of four years relevant experience\\nExperience with relational databases, query authoring, programming, and hardware/software troubleshooting\\nPreferred Skills\\nFamiliarity with building and optimizing data pipelines, architectures, and datasets\\nFamiliarity with data virtualization, transformation, and various data structures\\nFamiliarity with high performance computing\\nDeveloper technologies:\\nSoftware management tools including those for testing, continuous integration, version control, debugging, profiling, and compiler optimization\\nEnvironment Management:\\nData management and file systems\\nSystem metrics and monitoring\\nJob scheduler, resource allocation and job/workflow management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Assistant/Associate Professor</td>\n",
       "      <td>Pittsburgh, PA</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>PA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Assistant/Associate Professor\\nSCI-Office of the Dean - Pennsylvania-Pittsburgh - (18001834)\\n\\nSchool of Computing and Information Department of Information Culture and Data Stewardship Non-Tenure-Track Faculty Position in Data Stewardship The School of Computing and Information (http://www.ischool.pitt.edu) at the University of Pittsburgh is seeking to fill a faculty position in Data Stewardship at an Assistant/Associate Professor level - Position #0134534 (Non-Tenure Stream). The initial appointment is expected to be three years with consideration for renewal. We are looking for an experienced practitioner and scholar in Data Stewardship who can demonstrate an in-depth understanding of data curation, data documentation and data preservation, specifically: • Current best practices and policy surrounding active data management through the data lifecycle, including data collection, data management plans, data storage, data quality and reproducibility • Experience of handling research data including application of date standards and formats, data description and documentation, metadata schema for disciplinary data, data citation and persistent identifiers, data publication, data analysis, data visualization, data re-use and metrics • Contemporary good practice in data selection and appraisal, data infrastructure including data repository software platforms, and long-term data preservation strategies • An awareness of diverse disciplinary data practices, research workflows and workflow platforms, as well as an in-depth knowledge of particular domain(s). The University of Pittsburgh School is a top-ranked information school (iSchool) offering a wide variety of multidisciplinary opportunities, including an undergraduate program (BSIS), Master's programs in information science (MSIS), telecommunications &amp; networking (MST), library &amp; information science (MLIS), and Ph.D. programs, The new Data Stewardship Pathway for graduate students studying for the MLIS, draws on the concept of \"translational data science\", described by Lyon &amp; Brenner (2015) as: \"the enhanced transition of skills, software tools and intelligence from the iSchool to the marketplace, Which may be interpreted as industry, government, libraries, archives or data centers\". Adopting a translational perspective will enable iSchools to supply and deploy data talent and data products more rapidly to the range of consumers, where there Is currently an acknowledged workforce need\". Development of the Data Stewardship Pathway has been further informed by the results of two small-scale studies, which featured an analysis of requirements for real-world positions in each of the six data science roles (data archivist, data librarian, data steward/ curator, data analyst, data engineer and data journalist) and which highlighted the knowledge, skills and competencies being sought by employers (Lyon, Mattern, Acker &amp; Langmead 2016; Lyon &amp; Mattern 2016). We expect candidates for this position to possess strong experience within the broader data community or in professional data curation environments and to have excellent interpersonal, communication and team skills. The new faculty member is expected to be able to liaise and collaborate with disciplinary faculty and researchers across a range of Schools ahd Departments in the University, but also with the regional, national and international data community. The University is actively addressing the development and adoption of research data management infrastructure, working through the Data Management Committee and administration support services on campus. The successful candidate will contribute to the Data Stewardship Pathway through both research and teaching undergrad and post-graduate students, and will be expected to demonstrate an awareness of current data developments, trends, challenges, emerging fields and a positive commitment to research. As the School offers an online degree program in addition to oncampus programs:, candidates with complementary expertise and experience\\n\\nCandidates applying for the position(s) are expected to hold an earned Doctorate or the equivalent in academic or professional experience. Applicants should present a record of effective teaching, research, and related scholarly activities. Electronic applications should be sent to https://ischoolatpitt.wufoo.com/forms/faculty-position-in-data-stewardship/. Applications should include a cover letter, curriculum vitae, research statement, teaching statement, and the names, addresses (with e-mail), and telephone numbers of three references. For full consideration, applications must be received by February 15, 2017. Questions about the position should be directed to Dr. Richard Cox Chair of Search Committee School of Computing and Information University of Pittsburgh The University of Pittsburgh is an Affirmative Action, Equal Opportunity Employer Minorities/Women/Vets/Disabled.\\n\\nAssignment Category Fulltime-Regular\\nCampus Pittsburgh\\nChild Protection Clearances The following PA Act 153 clearances and background checks may be required prior to commencement of employment and as a condition of continued employment: PA State Police Criminal Record Check, FBI Criminal Record Check, PA Child Abuse History Clearance.\\nRequired Attachments Other (see posting for additional details)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Engineer, Enterprise Data/Integration</td>\n",
       "      <td>Warrendale, PA 15086</td>\n",
       "      <td>Warrendale</td>\n",
       "      <td>PA</td>\n",
       "      <td>15086</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Description:\\nAbout Intalere\\nIntalere is the essential partner for operational excellence in healthcare offering customized solutions that address customers’ individual needs by assisting in managing their entire non-labor spend, providing innovative technologies, products and services, and leveraging the best practices of a provider-led model.\\n\\nIntalere strives to create a high-performance work environment and to maintain our position as an employer of choice. Our Total Rewards benefit package reflects our values of Integrity, Passion, Accountability, Innovation and Excellence.\\n\\nDescription\\nAs a member of the Digital Solutions and Data and Analytics IT team, this person will be a technical lead for data modeling, data integration and data wrangling between various internal and external applications to provide the data foundation for a suite of enterprise applications, business intelligence reporting, analytics and data science focused in cloud environment.\\n\\nThis role demands critical thinking and problem-solving skills to utilize best practices and technology experience to create innovative solutions to create a leading-edge data and analytics products.\\n\\nThis role demands a strong technical integration skillset as well as broader understanding of relational and nonrelational data structures in a hybrid cloud environment.\\n\\nThe senior data engineer will not just implement ETL and other integration solutions via tools like SQL Server Integration Services (SSIS); they will also be responsible for designing the integrations, utilizing technical best practices as well as their analytical skills to obtain a full understanding of underlying data and functional needs/requirements.\\n\\nResponsibilities\\n\\nDesign and develop new data integrations between our hybrid cloud environment as well as lead data ingestion.\\n\\nLead requirements analysis efforts relating to implementing new integrations via direct communication with technical and non-technical stakeholders.\\n\\nMaintain extensive existing set of SSIS packages:\\n\\nTroubleshoot SSIS packages when there are failures (evaluate cause, determine and test solution, implement solution) and provide communication to stakeholders during outage as well as document the situation after it is resolved to support retrospectives/knowledge sharing.\\nIteratively enhance SSIS packages for performance improvement.\\nAdjust scheduling of package execution as need arises.\\nAdjust packages when underlying data schemas/file formats change.\\n\\nContribute to team knowledge sharing/training efforts.\\n\\nDevelop a strong understanding of Intalere and customer data models/context.\\n\\nProvide subject matter expertise (technical and business context) input and feedback to data/BI teams and development scrum teams as needed.\\n\\nIdentify, communicate, and mitigate integration/ETL risks. .\\n\\nRequirements:\\nTechnical\\n5+years of experience architecting integration/ETL processes or managing enterprise databases\\n2+ years of experience with data solutions in Microsoft Azure\\nExperience with Azure Data Factory (ADF)\\nExperience with Azure Data Lake\\nExperience with PowerShell or Terraform\\nDemonstrated ability to quickly learn/understand and discuss data formats/models/standards\\nExperience with debugging, performance profiling and optimization of integration/ETL processes\\nExperience developing database objects such as stored procedures, triggers, constraints and indexes\\nCapable of designing and tuning complex SQL queries\\nSpecific experience with Microsoft SQL Server Integration Services (SSIS) packages and toolset\\nCandidates with extensive experience in other ETL and integration toolsets may be considered if they have a commitment to learning SSIS and a demonstrated ability to ramp up to proficiency rather quickly (within 2 months) in a primarily self-directed way\\n\\nProfessional\\nExcellent interpersonal and organizational acumen with regard to collaborating with both internal team members and external business stakeholders\\nStrong analytical and critical thinking skills\\nInternally motivated, able to work proficiently both independently and in a team environment\\nStrong written and verbal communication skills with staff and leadership at all levels of seniority and technical experience\\nBachelor’s Degree or higher (Computer Science, Engineering, or similar/relevant field)\\nMotivated to “stay current” with technical change/commit to professional development to learn relevant new skills/tools/methodologies\\n\\nDesired Additional Competencies\\nHealthcare industry experience not required but a significant plus (supply chain, provider, payer, medical device, life-science, pharmacy, etc.)\\nExperience developing business insights from complex data sources\\nExperience with non-relational “noSQL” data sources\\nExperience with Azure Data Bricks\\nExperience with Tableau\\nExperience with other data/BI tools, especially within the Microsoft ecosystem (SQL Server Reporting Services (SSRS), Power BI, Power Query, DAX, R)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Engineer (PDP)</td>\n",
       "      <td>Pittsburgh, PA</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>PA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nExperience with:\\nOracle technologies including Oracle database and ODI\\nCloud-based data warehouse technologies such as Snowflake and open source ETL technologies such as Snaplogic.\\n</td>\n",
       "      <td>This position will support our Postsecondary Data Partnership (PDP) project and will be located in our Pittsburgh Collaboration Center.\\n\\nIf you are a self-starter, thrive in a fast-paced environment, and get energized about driving new data driven services, then this job is for you!\\n\\nThe Clearinghouse is seeking a hands-on Data Engineer with a solid background in Data Warehouse architectures, metadata management, data profiling, data modeling, data quality and a proven ability to learn quickly, effectively collaborate with others, and successfully design and implement solutions. Using their excellent communication and presentation skills, the Engineer socializes technical concepts and builds consensus with internal stakeholders.\\n\\nThe Data Engineer reports to the Manager, Application Development and works with the business and development teams to design and implement the appropriate data solutions for Clearinghouse database-driven applications and services. The Engineer accomplishes this by performing data analysis of current and future systems and services, educating on industry best practices and policies, creating proposed database component designs and data models, and working with the architecture and development teams to refine and implement these designs.\\n\\nHow You Contribute:\\nDevelop and maintain the PL/SQL Packages.\\nDevelop and maintain ETL code.\\nDesign Data Marts and create data models.\\nWork with Data owners to document and maintain Data Dictionary.\\nDevelop scripts to maintain data quality and deploying data changes across different environments\\nMonitor, assess and optimize data processing performance.\\nDemonstrate NSC’s competencies, which align with our corporate values.\\nCore Competencies include: Customer Focus, Optimizes Work Processes, Collaborates, Communicates Effectively, and Be Open and Authentic.\\nManager will provide more detail as needed.\\nPosition may be required to perform other duties as required. These essential functions are representative of those that must be met by an employee to successfully perform the job. Reasonable accommodations will be made to enable individuals with disabilities to perform these essential functions.\\n\\nWhat You Bring to the Table:\\nBachelor’s degree required in Computer Science, Systems Engineering, or Information Systems, or some equivalent combination of education and experience, including through military service.\\nProficient in:\\nPL/SQL programming, typically acquired through 4-7 years of experience programming with this technology.\\nDeveloping scripts using Shell, Perl or similar language.\\nExperience working on an Agile/Scrum development team.\\nProficient with:\\nData Warehouse production maintenance.\\nETL development using products such as Oracle Data Integrator.\\nOLTP and data warehouse design.\\nMetadata management.\\nCreating and implementing data models.\\nDatabase performance monitoring and SQL optimization.\\nExcellent communication skills.\\nDemonstrated ability to work independently and directly with the data owners to gather requirements and architect change.\\nLive within a commutable distance of Pittsburgh, PA.\\nAdditional Desired Requirements:\\n\\nExperience with:\\nOracle technologies including Oracle database and ODI\\nCloud-based data warehouse technologies such as Snowflake and open source ETL technologies such as Snaplogic.\\nPhysical Demands:\\nUse of a computer terminal and/or laptop computer for 8 or more hours a day.\\nUse of a copy machine, and telephone.\\nFrequently required to sit for 7 or more hours per day in close proximity to others in an open office environment.\\nOccasionally required to use hands and fingers to operate, handle, and reach.\\nVision abilities include close vision and the ability to adjust focus.\\nNSC strives to hire, promote, and retain the best qualified individuals for our employment opportunities. Our policies are intended to provide equal employment opportunity for all employees and job applicants without regard to race, color, religion, gender, gender identity, sexual orientation, age, disability, national origin, protected veteran status, or any other status protected by law. NSC strives to have a culture that is diverse and equally welcoming to all. As a Federal contractor, NSC is subject to requirements to take affirmative action to employ and advance in employment protected Veterans and individuals with disabilities. NSC is committed to its outreach efforts and practices to promote employment and advancement of members of these groups. To read our entire policy, go to: https://studentclearinghouse.info/careers/human-resource-policies\\nPAY TRANSPARENCY POLICY NSC will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by NSC, or (c) consistent with the NSC’s legal duty to furnish information. 41 C.F.R. 60-1.35(c)\\nPlease view Equal Employment Opportunity Posters provided by OFCCP here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Engineer Sr</td>\n",
       "      <td>Pittsburgh, PA 15289</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>PA</td>\n",
       "      <td>15289</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Position Overview\\n\\nAt PNC, our people are our greatest differentiator and competitive advantage in the markets we serve. We are all united in delivering the best experience for our customers. As a Data Engineer Senior (hadoop) within PNC's Technology and Innovation organization, can be based in Pittsburgh, PA; Cleveland or Columbus, OH; Dallas, TX; Overland Park, KS; or within any PNC footprint nationwide The following skills are preferred: •Experience in Hadoop Architecture &amp; Data Engineering – Cloudera preferred •Extensive experience in Data Engineering – Spark, HIVE, Map Reduce, Sqoop, Kafka, NiFi, etc. •Proficiency in writing SQL on mainstream RDBMSs like Oracle, Teradata etc. •Technical lead and mentoring/coaching experience The following skills are a plus: •Hands on experience with large Data Warehousing (Hadoop) implementations •Proficiency with ingestion tools, Sqoop, Kafka, NiFi, etc. •Agile software development environment experience\\n\\nJob Profile\\n\\nLeads in developing, supporting and implementing data solutions for multiple applications in order to meet business objectives and user requirements. Leverages technical knowledge and industry experience to design, build and maintain technology solutions.\\nLeads data requirement analysis and the data preparation process development for targeted data solutions.\\nLeads in designing and building data service infrastructure on multiple data platforms, according the workflow.\\nOversees the development and implementation of data solutions for multiple applications to ensure its scalability, availability and maintainability.\\nConsults on data migration and transformation to ensure the accuracy and security of data solutions.\\nPNC Employees take pride in our reputation and to continue building upon that we expect our employees to be:\\nCustomer Focused - Knowledgeable of the values and practices that align customer needs and satisfaction as primary considerations in all business decisions and able to leverage that information in creating customized customer solutions.\\nManaging Risk - Assessing and effectively managing all of the risks associated with their business objectives and activities to ensure they adhere to and support PNC's Enterprise Risk Management Framework.\\nCompetencies\\nApplication Delivery Process – Knowledge of major tasks, deliverables, and formal application delivery methodologies; ability to utilize these in order to deliver new or enhanced applications.\\nBig Data Management and Analytics – Knowledge and ability to plan and execute, big data management and analytics.\\nBusiness Intelligence – Knowledge of and ability to utilize business processes and technologies for gathering, storing, analyzing, and providing access to data that helps the organization make better business decisions.\\nConsulting – Knowledge of techniques, roles, and responsibilities in providing technical or business guidance to clients, both internal and external; ability to apply this knowledge appropriately to diverse situations.\\nData Analysis - Software – Knowledge of the investigation, evaluation, interpretation, and classification of data; the ability to identify, collect and analyze data to facilitate the development, implementation and application of software systems.\\nData Architecture – Knowledge and ability to create models and standards to govern which data is collected, and how it is stored, arranged, integrated, and put to use in data systems and in organizations.\\nDatabase Structures – Knowledge of and the ability to utilize appropriate database structures to organize and store data in a particular manner.\\nProblem Solving – Knowledge of approaches, tools, techniques for recognizing, anticipating, and resolving organizational, operational or process problems; ability to apply this knowledge appropriately to diverse situations.\\nSoftware Development Life Cycle – Knowledge of and experience with using a structured methodology for delivering new or enhanced software products to the marketplace.\\n\\nWork Experience\\n\\nRoles at this level typically require a university / college degree, with 5+ years of industry-relevant experience. Specific certifications are often required. In lieu of a degree, a comparable combination of education and experience (including military service) may be considered.\\n\\nEducation\\n\\nBachelors\\n\\nDisability Accommodations Statement\\n\\nThe PNC workplace is inclusive and supportive of individual needs. If you have a physical or other impairment that might require an accommodation, including technical assistance with the PNC Careers website or submission process, please call 877-968-7762 and select Option 4: Recruiting or contact us via email at pathfinder@pnc.com. The Human Resources Service Center hours of operation are Monday - Friday 9:00 AM to 5:00 PM ET.\\n\\nEqual Employment Opportunity (EEO)\\n\\nPNC provides equal employment opportunity to qualified persons regardless of race, color, sex, religion, national origin, age, sexual orientation, gender identity, disability, veteran status, or other categories protected by law.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Pittsburgh, PA</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>PA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nBachelor’s degree in CS, IT/IS, or a field related to a computational science and a minimum two years experience working as a data engineer\\nExperience managing data ETL processes and making data available through service applications and databases.\\nExperience working with query authoring, relational databases, and a familiarity with a variety of databases (Cassandra or Elasticsearch preferred). Ability to write efficient SQL queries\\nExperience (3+ years) with programming languages (Python, Java, R, and/or Scala preferred)\\nFamiliarity with a variety of data processing technologies (e.g. Spark, Kafka, Hadoop)\\nExcellent communication skills, including a knack for clear documentation\\nExperience with or knowledge of REST APIs and making data available through microservices.\\nExperience using version control (Git, Mercurial, SVN, etc.) for collaborative code development.\\nExperience with containerization and related technologies (e.g. Docker, Kubernetes)\\nFamiliarity with core provider services from AWS, Azure or GCP, preferably having supported deployments on one or more of these platforms\\nExperience working with MongoDB, PostgreSQL, and Redis\\nWorking knowledge of bash scripting and/or JavaScript\\nExperience with automation and configuration management\\nExpert level building pipelines using Apache Beam or Spark\\n</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nWork with data scientists to build ML pipelines using heterogeneous sources and provide engineering services for data science applications\\nDesign and implement data warehouses, real-time ETL, and batch processing of data to support modeling and reporting needs\\nWork with team to develop data expertise and resolve upstream issues relating to data quality\\nDefine best practices and design for the management of data\\nWith data scientists, build and maintain internal data processing and visualization tools\\nCreate tools to serve data such as APIs and packages\\nEnsure automation through CI/CD across platforms both in cloud and on-premises\\nAbility to research and assess open source technologies and components to recommend and integrate into the design and implementation\\n</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>The Fort is the new hub for innovation and incubation at Fortive. We have the backing of a large company and the soul of a startup (a Fortune 500 startup, that is), and this is the place where that flame burns brightest.\\n\\nAt The Fort, we combine forces to deploy disruptive technologies and explore new ways of thinking and working. We get out of the office and into the wild to observe first-hand what our customers most need to accelerate progress for the world. We observe, listen, prototype, experiment, analyze, learn, and iterate with passion and speed to fuel Fortive’s growth and build the future. We scout breakthrough ideas and emerging trends from an expansive network stretching from Seattle to Silicon Valley to Shanghai and beyond.\\n\\nThe Fort is built to make growth happen. We start up, we scale up, we shake things up. We face uncertainty head-on and wrestle it to the ground. We fail fast to move our customers forward. We move the needle so much it needs a new gauge. We turn What-if? into What’s next? and How might we? into Wow, we did that! If building a data-driven app in a matter of hours or pushing the frontiers of AI or IoT before lunch sounds like your kind of thing, The Fort just might be your kind of place.\\n\\nYour Impact\\nYou are collaborative, proactive, adaptable, and gritty. You excel at facilitating and reconciling inputs across teams. You balance a passion for deep understanding of innovation with the ability to deliver extraordinary results.\\n\\nThese are the traits we value:\\nAbility to Deliver Results: A track record for being able to set, meet and exceed expectations relative to data engineering.\\nEntrepreneurial Attitude: A proactive outlook that provides the chutzpah needed to overcome barriers, creatively problem solve, and challenge conventional thinking.\\n\\nComfort with Ambiguity: A willingness and aptitude for spending time in and thriving with deep uncertainty and environments where there is no clear “right answer”.\\n\\nPassion for Innovation: A demonstrated interest and desire to participate in innovation through personal study, on-the-job initiative, or other endeavors.\\nPositive Outlook: A desire to look past the challenged in search of the opportunity.\\n\\nEmpathy &amp; a Teacher’s Mindset: The ability to teach and mentor effectively, successfully facilitate teams and different personalities in training sessions, and to care deeply about his/her colleague’s growth, understanding, and experience.\\nBias for Action: A need for speed; demonstrated ability to make decisions quickly and to act upon them.\\n\\nAlongside a team of entrepreneurial, high-performing, curious people, you’ll deliver breakthrough solutions to drive sustainable growth for Fortive. As a Data Engineer, you’ll drive execution and play a vital role in building a culture of innovation at Fortive. You will build, manage, and inspire alongside a multi-functional team, that solves for our toughest growth challenges\\n\\nResponsibilities:\\n\\nWork with data scientists to build ML pipelines using heterogeneous sources and provide engineering services for data science applications\\nDesign and implement data warehouses, real-time ETL, and batch processing of data to support modeling and reporting needs\\nWork with team to develop data expertise and resolve upstream issues relating to data quality\\nDefine best practices and design for the management of data\\nWith data scientists, build and maintain internal data processing and visualization tools\\nCreate tools to serve data such as APIs and packages\\nEnsure automation through CI/CD across platforms both in cloud and on-premises\\nAbility to research and assess open source technologies and components to recommend and integrate into the design and implementation\\n\\nRequired Qualifications:\\n\\nBachelor’s degree in CS, IT/IS, or a field related to a computational science and a minimum two years experience working as a data engineer\\nExperience managing data ETL processes and making data available through service applications and databases.\\nExperience working with query authoring, relational databases, and a familiarity with a variety of databases (Cassandra or Elasticsearch preferred). Ability to write efficient SQL queries\\nExperience (3+ years) with programming languages (Python, Java, R, and/or Scala preferred)\\nFamiliarity with a variety of data processing technologies (e.g. Spark, Kafka, Hadoop)\\nExcellent communication skills, including a knack for clear documentation\\nExperience with or knowledge of REST APIs and making data available through microservices.\\nExperience using version control (Git, Mercurial, SVN, etc.) for collaborative code development.\\nExperience with containerization and related technologies (e.g. Docker, Kubernetes)\\nFamiliarity with core provider services from AWS, Azure or GCP, preferably having supported deployments on one or more of these platforms\\nExperience working with MongoDB, PostgreSQL, and Redis\\nWorking knowledge of bash scripting and/or JavaScript\\nExperience with automation and configuration management\\nExpert level building pipelines using Apache Beam or Spark\\n\\nPreferred Qualifications\\n\\nMS or PhD in Computer Science or related technical field\\nAbility to architect data solutions. Knowledge of machine learning and data science processes\\nExperience supporting data science and analytical efforts is preferred\\nSome experience with frontend web-development\\nExperience defining and implementing APIs\\nSystem monitoring, alerting, and dashboarding experience\\nExperience developing, managing, and optimizing big data architectures and pipelines\\n\\nFortive (NYSE:FTV) is a diversified industrial growth company comprised of Professional Instrumentation and Industrial Technologies businesses that are recognized leaders in attractive markets. With 2018 revenues of $6.5 billion, $1.2 billion in operating profit, and a market cap of $26 billion, Fortive’s well-known brands hold leading positions in field instrumentation, transportation, sensing, product realization, automation and specialty, and franchise distribution.\\n\\nFortive is headquartered in Everett, Washington and employs a team of more than 26,000 research and development, manufacturing, sales, distribution, service and administrative employees in more than 50 countries around the world. With a culture rooted in continuous improvement, the core of our company’s operating model is the Fortive Business System.\\n\\nFortune Magazine ranks Fortive as a part of the “The Future 50” companies with the best prospects for long-term growth. For more information please visit: www.fortive.com.\\n\\nFortive is a global family of more than 20 industry-leading industrial growth and technology companies, united by a shared purpose: to make the world stronger, safer and more effective by providing essential technology for the people who accelerate progress. We take on big challenges that have real impact in fast-moving fields like software development, robotics, transportation, energy and healthcare.\\n\\nWith more than $6.5 billion in annual revenues and a culture rooted in Kaizen, or continuous improvement, Fortive is well positioned to create essential, technology-based solutions to solve the world’s most critical challenges. Our strong capability comes from a team of smart, motivated people who proudly deliver excellence in each of our outstanding brands in the areas of field instrumentation, transportation, sensing, product realization, automation and specialty, and franchise distribution.\\n\\nFortive is headquartered in Everett, Washington and employs a team of more than 26,000 research and development, sales, marketing, product development, innovation, and service employees in more than 50 countries around the world.\\nThis is a place where people who share a drive and passion to make a personal difference can learn, grow, and achieve. And that’s good... for you, for us, for growth.\\n\\nFor more information, please visit: www.fortive.com.\\n\"The company in which you have expressed employment interest is a subsidiary or affiliate of Fortive Corporation. The subsidiary or affiliate is referred to as a Fortive Company. Fortive Corporation and all Fortive Companies are equal opportunity employers that evaluate qualified applicants without regard to race, color, national origin, religion, ancestry, sex (including pregnancy, childbirth and related medical conditions), age, marital status, disability, veteran status, citizenship status, sexual orientation, gender identity or expression, and other characteristics protected by law. The \"EEO is the Law\" poster is available at: http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf. Individuals who need a reasonable accommodation because of a disability for any part of the employment process should call 1-866-272-5573 or e-mail applyassistance@fortive.com to request accommodation.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Pittsburgh, PA 15222</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>PA</td>\n",
       "      <td>15222</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.\\nExperience with relational database design methodologies and authoring complex SQL queries\\nExperience with NoSQL database technologies (MongoDB, Cassandra, etc).\\nExperience with Agile Development and Agile Deployment tools and versioning using Git or similar tools.\\nExperience with Hadoop and other Big Data technologies such as Spark, PySpark and Kafka.\\nExperience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.\\nExperience with message queuing, stream processing, and highly scalable ‘big data’ data stores.\\nExperience building data pipelines utilizing Google Cloud platform.\\nExperience with git or other code repository tools Experience with Concourse or other CI/CD tools and methodologies.\\n3-5 years experience\\nGoogle Cloud Platform (GCS, BQ, etc), Apache Kafka, Python</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Build the infrastructure to support coding, testing, processing, and maintaining data resources in support of the Data Science, analytics and reporting organizations using SQL, SQOOP, Python, Google Big Query, Kafka and other Big Data technologies.\\nCollaborate with Data Scientists in the development of predictive models using machine learning, natural language and statistical analysis methods.\\nIdentify, design and implement internal process improvements (automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc).\\nBuild analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.\\nWork with stakeholders to assist with data-related technical issues and support their data infrastructure needs.\\nDevelop, refine and oversee data management standards, including establishing and enforcing governance procedures and ensuring data integrity across multiple functions.\\nResponsible for owning data quality metrics and meeting defined data accuracy goals according to industry best practices.</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Overview\\nSDLC Partners is actively looking to hire Data Science/Data Engineering professionals. If you are an experienced Data Engineer or Data Scientist looking for a new opportunity in a growing organization, please apply.\\nResponsibilities\\nBuild the infrastructure to support coding, testing, processing, and maintaining data resources in support of the Data Science, analytics and reporting organizations using SQL, SQOOP, Python, Google Big Query, Kafka and other Big Data technologies.\\nCollaborate with Data Scientists in the development of predictive models using machine learning, natural language and statistical analysis methods.\\nIdentify, design and implement internal process improvements (automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc).\\nBuild analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.\\nWork with stakeholders to assist with data-related technical issues and support their data infrastructure needs.\\nDevelop, refine and oversee data management standards, including establishing and enforcing governance procedures and ensuring data integrity across multiple functions.\\nResponsible for owning data quality metrics and meeting defined data accuracy goals according to industry best practices.\\nQualifications\\nExperience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.\\nExperience with relational database design methodologies and authoring complex SQL queries\\nExperience with NoSQL database technologies (MongoDB, Cassandra, etc).\\nExperience with Agile Development and Agile Deployment tools and versioning using Git or similar tools.\\nExperience with Hadoop and other Big Data technologies such as Spark, PySpark and Kafka.\\nExperience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.\\nExperience with message queuing, stream processing, and highly scalable ‘big data’ data stores.\\nExperience building data pipelines utilizing Google Cloud platform.\\nExperience with git or other code repository tools Experience with Concourse or other CI/CD tools and methodologies.\\n3-5 years experience\\nGoogle Cloud Platform (GCS, BQ, etc), Apache Kafka, Python\\n\\nEDUCATION\\nMasters/Bachelor's Degree in Computer Science, Software Engineering, Information Systems or Information Technology or related field required, or equivalent experience\\n\\nSDLC Partners is a dynamic and fast-paced, privately held consulting firm with 400+ employees. We deliver customized digital solutions to transform organizations through our uniquely enabled talent, processes, and leadership. Through full scope partner, strategic, and improvement solutions, we give clients access to some of the best talent available across our service lines. We hire individuals who embody our goal to enable performance for our clients and we believe strongly in growing and developing talent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Technology Engineer Sr</td>\n",
       "      <td>Pittsburgh, PA 15222</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>PA</td>\n",
       "      <td>15222</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Position Overview\\nAt PNC, our people are our greatest differentiator and competitive advantage in the markets we serve. We are all united in delivering the best experience for our customers. As a Technology Engineer Sr. within PNC's ALM Risk organization, you will be based in one of the following locations:\\n\\n\\nPittsburgh, PA.\\n\\nCleveland, OH\\n\\nNew York, NY\\n\\nNew Jersey\\n\\nWashington D.C. area\\n\\nAtlanta, GA\\n\\nChicago, IL\\n\\nCharlotte, NC\\n\\nRaleigh, NC\\n\\n\\nRelocation assistance may be available for the for the selected candidate.\\n\\n\\nIn this contributor role you will support the Technology team partnering with the Balance Sheet Analytics &amp; Modeling LOB, and requires specialized skills and experience with advanced computational and data science related technologies such as Python, SAS, SPARK, Hadoop and related stacks.\\n\\n\\n\\n\\nAt PNC, we are building our advanced computation and analytics platforms to support CECL and other subsequent BSAM usecase implementation and we are seeking a Sr. Data Engineer who will perform the following functions:\\n\\n\\nA self-starter who can align the technology solution with a business goal\\nDevelopment – Design and build database and data science solutions\\nData Modeling – Apply your expertise to help model structured and unstructured data. Own these models at a high level and consult with feature teams to help them model applications.\\nData Integration – Plan and build data integrations between systems. Figure out the best way to share information and build the tech needed to execute.\\nMentoring – Help teach other team members about data architecture, and also be a consultant for developers who need help with data.\\nEngineer reusable capabilities and pipelines for DML, DDL, maintenance, and ETL needs that can be shared across teams.\\nStay current on technical knowledge and tooling to help the team utilize new technologies.\\nEstablish scalable, efficient, automated processes for large scale data analysis and visualization\\nPerform data insights analysis using clustering, agglomerative clustering, graph based clustering, and analysis\\n\\nBasic Qualifications\\n\\n\\nMS with 2+ years of industry experience or Bachelors with 5+ years of experience in Quantitative field (Computer Science, Electrical/ Computer engineering, Financial Engineering, Mathematics, Statistics, Physics)\\n5+ years of enterprise-level scripting experience using languages (e.g. Python, SPARK, SCALA), or statistical/mathematical software (e.g. R, SAS)\\nExperience in creating data driven visualizations\\nHighly skilled in data and math/statistical methods (i.e. modeling, algorithms)\\n4+ years of experience in system analysis and data management engineering\\n3+ years of experience in database technologies: Oracle, Cassandra, or Mongo\\n2+ years of experience with DevOps, CI/CD\\nDemonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment\\n\\nPreferred Qualifications\\n\\n\\nExperience in processing, filtering, and presenting large quantities (Millions to Billions of rows) of data\\n2+ years of experience in AWS, Google Cloud, or MS Azure\\nExperience working with Financial, Insurance domains\\nStrongly prefer Experience in Data Science, Machine Learning, and/or Deep Learning\\nStrongly prefer prior Experience in programming languages such as Java, or C/C+\\nExperience with containerized solutions\\nExperience with SPARQL and other no-SQL data bases a plus\\nExperience with XML, XML Schema, XSLT\\nJob Description\\nLeads in the development of the most complex new and emerging technologies and selects appropriate platforms, integrates and configures solutions. Leverages technical knowledge and industry experience to design, build and maintain technology solutions.\\nDevelops software components and hardware for new and emerging technology projects; aligns these with business strategies and objectives.\\nConsults junior staff regarding complex issues and best practices.\\nProvides a systematic analysis on the most complex client requirements within the traceability framework and resolves any functional problems encountered.\\nOversees the quality of complex project deliverables while ensuring that they are in compliance with relevant standards and processes.\\nPNC Employees take pride in our reputation and to continue building upon that we expect our employees to be:\\nCustomer Focused - Knowledgeable of the values and practices that align customer needs and satisfaction as primary considerations in all business decisions and able to leverage that information in creating customized customer solutions.\\nManaging Risk - Assessing and effectively managing all of the risks associated with their business objectives and activities to ensure they adhere to and support PNC's Enterprise Risk Management Framework.\\nCompetencies\\nApplication Delivery Process – Knowledge of major tasks, deliverables, and formal application delivery methodologies; ability to utilize these in order to deliver new or enhanced applications.\\nConsulting – Knowledge of techniques, roles, and responsibilities in providing technical or business guidance to clients, both internal and external; ability to apply this knowledge appropriately to diverse situations.\\nEffectiveness Measurement – Ability to measure the quality and quantity of work effort for the purpose of improvement.\\nEmerging Technologies – Knowledge of and ability to design, apply and evaluate new information technologies for business environments in order to improve work productivity and accuracy.\\nIndustry Knowledge – Knowledge of the organization's industry group, trends, directions, major issues, regulatory considerations, and trendsetters; ability to apply this knowledge appropriately to diverse situations.\\nIT Industry: Trends &amp; Directions – Knowledge of and ability to analyze marketplace experiences, developments and trends related to the function of Information Technology (IT).\\nIT Standards, Procedures &amp; Policies – Knowledge of and the ability to utilize a variety of administrative skill sets and technical knowledge to manage organizational IT policies, standards, and procedures.\\nPlanning: Tactical, Strategic – Ability to contribute to operational (short term), tactical (1-2 years) and strategic (3-5 years) planning in support of the overall business plan.\\nProblem Solving – Knowledge of approaches, tools, techniques for recognizing, anticipating, and resolving organizational, operational or process problems; ability to apply this knowledge appropriately to diverse situations.\\nWork Experience\\nRoles at this level typically require a university / college degree, with 5+ years of industry-relevant experience. Specific certifications are often required. In lieu of a degree, a comparable combination of education and experience (including military service) may be considered.\\nEducation\\nBachelors\\nDisability Accommodations Statement:\\n\\nThe PNC workplace is inclusive and supportive of individual needs. If you have a physical or other impairment that might require an accommodation, including technical assistance with the PNC Careers website or submission process, please call 877-968-7762 and select Option 4: Recruiting or contact us via email at pathfinder@pnc.com.\\nThe Human Resources Service Center hours of operation are Monday - Friday 9:00 AM to 5:00 PM ET.\\nEqual Employment Opportunity (EEO):\\n\\nPNC provides equal employment opportunity to qualified persons regardless of race, color, sex, religion, national origin, age, sexual orientation, gender identity, disability, veteran status, or other categories protected by law.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ETL Informatica Engineer</td>\n",
       "      <td>Pittsburgh, PA 15220</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>PA</td>\n",
       "      <td>15220</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Minimum 4 years of experience developing and implementing Informatica Powercenter or Informatica Data Quality\\nBachelor’s Degree or Associate’s Degree with 6 years of work experience or equivalent work experience of 12 years</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nIt is currently our objective to assign our people to work near where they live. However, given the nature of our business and our need to serve clients, our employees must be able to travel when needed. This role requires 100% flexibility to travel and work onsite with clients (typically Monday through Thursday).\\nProven success in contributing to a team-oriented environment\\nProven ability to work creatively and analytically in a problem-solving environment\\nDesire to work in an information systems environment\\nExcellent communication (written and oral) and interpersonal skills</td>\n",
       "      <td>Join Accenture and help transform leading organizations and communities around the world. The sheer scale of our capabilities and client engagements and the way we collaborate, operate and deliver value provides an unparalleled opportunity to grow and advance. Choose Accenture, and make delivering innovative work part of your extraordinary career.\\n\\nAs part of our Data Business Group, you will lead technology innovation for our clients through robust delivery of world-class solutions. You will build better software better! There will never be a typical day and that’s why people love it here. The opportunities to make a difference within exciting client initiatives are unlimited in the ever-changing technology landscape. You will be part of a highly collaborative and growing network of technology and data experts, who are taking on today’s biggest, most complex business challenges using the latest data and analytics technologies. We will nurture your talent in an inclusive culture that values diversity. You will have an opportunity to work in roles such as Data Scientist, Data Engineer, or Chief Data Officer covering all aspects of Data including Data Management, Data Governance, Data Intelligence, Knowledge Graphs, and IoT. Come grow your career in Technology at Accenture!\\n\\n Why Should I Join the Accenture Team?\\nDrive innovation. People in our Client Delivery &amp; Operations career track drive delivery and capability excellence through the design, development and/or delivery of a solution, service, capability or offering. They grow into delivery-focused roles, and can progress within their current role, laterally or upward.Learn and grow continuously: Follow personalized training to build skills, while expanding your experience defining and implementing solutions on complex client projects with a scope that is unsurpassed in industry.Thrive in our inclusive environment: Bring your whole self to a company that aims to be the most diverse in the world and delivers real-time performance feedback based on individual strengths—not stats.\\n\\nJob Description\\nData and Analytics professionals define strategies, develop and deliver solutions that enable the collection, processing and management of information from one or more sources, and the subsequent delivery of information to audiences in support of key business processes.\\nExtract, Transform and Load data primarily in Informatica with an emphasis on advocacy toward end-users to produce high quality software designs that are well-documented.\\nDemonstrate an understanding of technology and digital frameworks in the context of data integration utilizing Informatica.\\nEnsure code and design quality through the execution of test plans and assist in development of standards, methodology and repeatable processes, working closely with internal and external design, business, and technical counterparts.\\n\\nBasic Qualifications\\nMinimum 4 years of experience developing and implementing Informatica Powercenter or Informatica Data Quality\\nBachelor’s Degree or Associate’s Degree with 6 years of work experience or equivalent work experience of 12 years\\nPreferred Qualifications\\nExperience in ETL Tools in addition to Informatica, including Business Objects Data Services (BODS), DataStage, Ab Initio, Talend, and Pentaho\\nExperience with a full life-cycle development from functional design to deployment\\nDatabase experience (Teradata, Oracle, SQL Server, DB2, Azure SQL)\\nStrong knowledge and experience of SQL\\nUnderstanding of Entity relationship data models and Dimensional Models\\nExperience with development and production support\\nProfessional Skill Requirements\\n\\nIt is currently our objective to assign our people to work near where they live. However, given the nature of our business and our need to serve clients, our employees must be able to travel when needed. This role requires 100% flexibility to travel and work onsite with clients (typically Monday through Thursday).\\nProven success in contributing to a team-oriented environment\\nProven ability to work creatively and analytically in a problem-solving environment\\nDesire to work in an information systems environment\\nExcellent communication (written and oral) and interpersonal skills\\n\\nAll of our consulting professionals receive comprehensive training covering business acumen, technical and professional skills development. You'll also have opportunities to hone your functional skills and expertise in an area of specialization. We offer a variety of formal and informal training programs at every level to help you acquire and build specialized skills faster. Learning takes place both on the job and through formal training conducted online, in the classroom, or in collaboration with teammates. The sheer variety of work we do, and the experience it offers, provide an unbeatable platform from which to build a career.\\n\\n\\nApplicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status).\\n\\nCandidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.\\n\\nAccenture is an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities.\\n\\nEqual Employment Opportunity\\nAll employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data Engineer, National Robotics Engineering Center (NREC)</td>\n",
       "      <td>Pittsburgh, PA</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>PA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nB.S. in Computer Science, Engineering, Mathematics is required (Any more is a bonus)\\n3-5 years relevant experience is required.\\nDemonstrated understanding and use of software engineering concepts, practices, and procedures.\\nProficient development skills (Python preferred)\\nLinux development experience\\nTechnical communication skills\\nAbility to participate in a multi-disciplinary team</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>The National Robotics Engineering Center (NREC) at Carnegie Mellon University is looking for data scientists to develop tools to support machine learning and data-intensive applications. We are people with a desire to make robust software using agile development processes. You will work on a variety of software for commercial and government organizations. You will bring together open-source, commercial, internal, and your own tools to support diverse data processing workflows. Some of our machine learning software keeps self-driving vehicles safe, automatically discovers new pharmaceuticals, and leads to less waste in agriculture. You will support programs in deep learning for agriculture, artificial intelligence for defense, and autonomous manipulation.\\n\\nWhy NREC?\\nYou will have an impact in shaping the robotics revolution, collaborate with and learn from experts,and build your career in a very fast-growing field. As part of our team, you will develop solutions to solve industrial and government challenges, deploy your technology in real-world situations, work side-by-side with elite robotics experts, and develop a variety of cutting-edge technologies.\\n\\nHave an Impact!\\nRemove waste from farming = more food (link)\\nMake industrial processes environmentally friendly (link)\\nMake hazardous jobs safer (link)\\nImprove efficiency in industry &amp; manufacturing (link)\\nAccelerate screening of pharmaceuticals (link)\\n\\nTake Control of Your Career!\\nSelect the career pathway that interests you\\nInfluence the direction of projects\\nSupportive of a non-standard schedule\\nMaintain work/life balance\\nSwitch between part-time and full-time as life demands\\n\\nNREC is at the center of the robotics ecosystem in Pittsburgh, PA. With over 60 robotics companies, Pittsburgh has become the robotics capital of the world. Geek Wire calls it Robotics Row; others call it Roboburgh. Join the leader in the most exciting time in robotics!\\n\\nJoin the best robotics R&amp;D group\\nJoin our talented team at NREC, an operating unit within the world-renowned Robotics Institute at Carnegie Mellon University. NREC has 20+ years of experience and is globally renowned for developing and deploying robots into many applications across multiple sectors, such as agriculture, mining, defense, energy, and manufacturing. We strive to provide solutions for real world challenges where automation and robots have greater impact on productivity and improve the safety and comfort of the labor force. Our unique expertise places us at the forefront of unmanned ground vehicle design, autonomy, sensing and perception, machine learning, machine vision, operator assistance, 3D mapping and position estimation.\\n\\nWith over 120 robotics professionals, we can solve challenges that no other organization can.\\nNREC also leads in educational outreach through its Robotics Academy, which builds robotics curricula and software for K-12 and college-level students.\\n\\nYour primary responsibilities include:\\nDeveloping software for machine learning and data-science applications\\nArchitecting big-data pipelines\\nAdapting and integrating proprietary and open source software packages and APIs\\nData preparation, integration, verification\\nParticipating in the software process: design, code reviews, etc.\\nDeveloping, documenting, testing, and fixing software\\nSupporting development and acquisition of training and inference hardware\\nDevelopment in a Linux environment\\n\\nYou must be willing to travel for extended periods for field testing.\\n\\nQualifications:\\nB.S. in Computer Science, Engineering, Mathematics is required (Any more is a bonus)\\n3-5 years relevant experience is required.\\nDemonstrated understanding and use of software engineering concepts, practices, and procedures.\\nProficient development skills (Python preferred)\\nLinux development experience\\nTechnical communication skills\\nAbility to participate in a multi-disciplinary team\\n\\nWe especially want to hear from you if you have experience or qualifications in ANY of the following areas:\\nData infrastructure tools (SQL, NoSQL, data version control, etc.)\\nHigh performance computing tools (Hadoop, AWS, Azure, etc.)\\nModel training infrastructure tools (tensorflow, caffe, Petuum, etc.)\\nInference model deployment tools (Docker or other containerization, etc.)\\nCloud, high performance, and distributed computing\\nIngestion and integration of disparate sources\\nData processing (pre-processing, augmentation, post-processing)\\nTools and protocols for reproducible research and data analysis\\nFront end (Data visualization, exploration, labeling)\\nProficient Matlab or R skills\\nProficient C or C++ skills\\nProfessional software development processes\\nNetworking interfaces and applications\\nMixed software and hardware architecture\\nCMake, Valgrind, and other development tools\\nComputer vision, robotics, machine learning, scientific computing, simulation, or graphics\\n\\nAt NREC, we value diversity, support it, and thrive on it for the benefits of our organization, our employees and our community.\\n\\nMore Information\\n\\nPlease visit “Why Carnegie Mellon” to learn more about becoming part of an institution inspiring innovations that change the world. http://www.cmu.edu/jobs/why-cmu/index.html.\\n\\nA listing of employee benefits is available at: http://www.cmu.edu/jobs/benefits-at-a-glance/index.html.\\n\\nCarnegie Mellon University is an Equal Opportunity Employer/Disability/Veteran.\\nJob Function: Engineering\\n\\nPrimary Location: United States-Pennsylvania-Pittsburgh\\n\\nTime Type: Full Time\\n\\nOrganization: ROBOTICS\\n\\nMinimum Education Level: Bachelor's Degree or equivalent\\n\\nPreferred Education Level: Master's Degree or equivalent\\n\\nBudgeted Base Pay: Negotiable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SQL Data Engineer</td>\n",
       "      <td>Pittsburgh, PA 15219</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>PA</td>\n",
       "      <td>15219</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Strong Microsoft SQL Skills including but not limited to views, stored procedures and function creation and optimization\\nEnsure performance and availability of databases\\nETL knowledge and capability\\nData Modeling / Database Design\\nPerform baseline Microsoft SQL database administrative tasks\\nJob creations and failure monitoring\\nEvaluate datasets for quality and accuracy\\nSQL Training to others as needed</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>We are looking for a SQL Data Engineer who has strong SQL skills and the desire to build a sustainable environment that can scale as a business grows. This position will provide the opportunity to build an environment from the ground to customer facing and experience the value of all the time and effort to a solution. You will have the ability to help guide and teach others on SQL optimization as required to improve performance on results and for the betterment of the SQL Server. You will work with Data Analysts, Pricing Analysts and Business Stakeholders to develop solutions to meet data needs.\\n\\nKey Responsibilities:\\nStrong Microsoft SQL Skills including but not limited to views, stored procedures and function creation and optimization\\nEnsure performance and availability of databases\\nETL knowledge and capability\\nData Modeling / Database Design\\nPerform baseline Microsoft SQL database administrative tasks\\nJob creations and failure monitoring\\nEvaluate datasets for quality and accuracy\\nSQL Training to others as needed\\nBachelor’s degree in Computer Science, Information Systems, or equivalent degree or strong industry experience.\\nStrong verbal and written communication skills\\n5-10 years experience in database development/design\\nKnowledge about SQL Server Integration Services and SQL Agent\\nExperience handling multiple concurrent complex activities within a technical environment and ability to project risks and escalate to managers appropriately\\nMust have strong analytical and problem solving skills\\nExperience with Office 365 products a plus\\nExperience with Power Bi a plus\\nExperience with AWS a plus\\nDemonstrate Thermo Fisher Scientific values – Integrity, Intensity, Innovation and Involvement\\n\\nAt Thermo Fisher Scientific, each one of our 50,000 extraordinary minds has a unique story to tell. Join us and contribute to our singular mission—enabling our customers to make the world healthier, cleaner and safer. Apply today\\n\\nThermo Fisher Scientific is an EEO/Affirmative Action Employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability or any other legally protected status.\\n\\n\\n\\n\\nIf you are an individual with a disability who requires reasonable accommodation to complete any part of our application process, for further assistance.\\nThermo Fisher Scientific is an EEO/Affirmative Action Employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability or any other legally protected status.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Senior Analytic Data Engineer</td>\n",
       "      <td>Pittsburgh, PA 15289</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>PA</td>\n",
       "      <td>15289</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Company :\\nHm Health Solutions Inc.\\nJob Description :\\nJOB SUMMARY\\nThis job architects and engineers solutions associated with analytic data for the organization and, working closely with the IT teams, assists with the design, build, and upkeep for these solutions. This includes creating pathways for analysts to access operational, derived, and external data sets. The incumbent is also responsible for the operation of Big Data Platforms as they are associated with analytic data discovery. Provides guidance and education for Intermediate contributors. Meets individually with customers for specific projects.\\nESSENTIAL RESPONSIBILITIES\\nResponsible for large functional efforts for data analytics programs across multiple disciplines with minimal guidance.\\nWorking closely with IT, architect and engineer solutions that provide views for the Analytic Data Warehouse. This would include the working with the proper teams, assisting with the design, building out the design, and providing upkeep for the solution.\\nAssemble, test, process, and maintain the Analytic Discovery Platform for the analytics organizations. This will include working to maintain pipelines with key analytic platforms throughout the organization.\\nWork with alternative analytic data systems to incorporate them into the operational data flow for the Analytics Teams. This may include products purchased by the organization that must be ingested or modeled/derived data maintained by analytic teams.\\nIndependently lead functional efforts for assigned projects with limited supervision. This include the guidance and education of Intermediate contributors within this team. Meet individually with customers for specific projects and attend with Intermediates for support.\\nOther duties as assigned.\\nEDUCATION\\nRequired\\nBachelor's Degree in Computer Systems Analysis, Data Processing, Healthcare Informatics, Management Information Systems, or related field\\nPreferred\\nMaster's Degree in related field\\nEXPERIENCE\\nRequired\\n3 - 5 years of Data Analytics experience\\nPreferred\\n1 - 3 years of Data Warehousing experience\\n1 - 3 years of Database Administration experience\\n5 - 7 years of Healthcare Industry experience\\nQUALIFICATIONS\\nProficient in the following areas:\\nAdvanced data analytic skills\\nAbility to perform data analytics for complex processes with complex business rules\\nAbility to translate complex data analytics results into information that can be used by senior executives to make decisions\\nPowerPoint skills\\nExcel skills\\nTableau skills for data analytics\\nUnderstands business drivers then use the information to provide the right data analytics to support the drivers\\nUnderstanding of our data and how to leverage it for analytics\\nUnderstanding of our business processes in order to interpret metric results and drive improvements in performance by leveraging demand capacity models, proactive monitoring, and predictive analysis\\nCalculating projections\\nBackground with data infrastructure including ETL, data warehouse, and tableau\\nCalculating projections\\nData infrastructure including ETL, data warehouse, and tableau\\nExpert analytical skills\\nLICENSES OR CERTIFICATIONS\\nRequired\\nNone\\nSKILLS\\nTableau for data analytics\\nMicrosoft Office\\nSAS is a plus\\nLanguage Requirement (other than English)\\nNone\\nTravel Requirement\\n0% - 25%\\nPHYSICAL, MENTAL DEMANDS and WORKING CONDITIONS\\nPosition Type\\nOffice-Based\\nTeaches / trains others regularly\\nOccasionally\\nTravel regularly from the office to various work sites or from site-to-site\\nRarely\\nEmployee Referral Level: 2\\nDisclaimer: The job description has been designed to indicate the general nature and essential duties and responsibilities of work performed by employees within this job title. It may not contain a comprehensive inventory of all duties, responsibilities, and qualifications required of employees to do this job.\\nCompliance Requirement: This position adheres to the ethical and legal standards and behavioral expectations as set forth in the code of business conduct and company policies.\\n-\\nHighmark Health and its affiliates prohibit discrimination against qualified individuals based on their status as protected veterans or individuals with disabilities, and prohibit discrimination against all individuals based on their race, color, religion, sex, national origin, sexual orientation/gender identity or any other category protected by applicable federal, state or local law. Highmark Health and its affiliates take affirmative action to employ and advance in employment individuals without regard to race, color, religion, sex, national origin, sexual orientation/gender identity, protected veteran status or disability.\\nEEO is The Law\\nEqual Opportunity Employer Minorities/Women/ProtectedVeterans/Disabled/Sexual Orientation/Gender Identity (http://www1.eeoc.gov/employers/upload/eeoc_self_print_poster.pdf)\\nWe endeavor to make this site accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact number below.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Pittsburgh, PA 15222</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>PA</td>\n",
       "      <td>15222</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Position Overview\\nAt PNC, our people are our greatest differentiator and competitive advantage in the markets we serve. We are all united in delivering the best experience for our customers. As a Data Engineer within PNC's AMG Engineering Team, you will be responsible to provide Data Products in the Big Data space to support our Wealth and Investment Management Business. This position will be based in Pittsburgh, PA. Successful Candidates will have the followiing skills:\\n\\nExtensive Data Modeling experience\\n\\nExtensive Experience with Relational Databases\\n\\nWell-versed scripting in Python / PySpark\\n\\nModerate to Advanced knowledge of Big Data storage concepts and strategies\\n\\nModerate to Advanced experience in Business Intelligence\\n\\nEfficient Data Structures\\n\\nRobust Visualizations\\n\\nExperience with one or more BI Platforms (Tableau, OBIEE, QlikView, Cognos, etc…)\\n\\nModerate understanding of Cloudera’s Hadoop Big Data Platform\\n\\nWorking Experience with NoSQL Databases\\n\\nFamiliarity with creation and maintenance of Oozie workflows\\n\\nExperience working on an agile team a plus\\nJob Description\\nDevelops, supports and implements data services for multiple applications to meet business objectives and user requirements. Uses technical knowledge and industry experience to design, build and maintain technology solutions.\\nWorks closely with users, developers, operations and business partners to define data service requirements and the data preparation process development.\\nDesigns and builds data service infrastructure on multiple data platforms, according to key business processes and the overall workflow.\\nDevelops and implements data solutions for multiple applications to ensure its scalability, availability and maintainability.\\nImplements data migration and transformation activities/processes to ensure the accuracy and security of data solutions.\\nPNC Employees take pride in our reputation and to continue building upon that we expect our employees to be:\\nCustomer Focused - Knowledgeable of the values and practices that align customer needs and satisfaction as primary considerations in all business decisions and able to leverage that information in creating customized customer solutions.\\nManaging Risk - Assessing and effectively managing all of the risks associated with their business objectives and activities to ensure they adhere to and support PNC's Enterprise Risk Management Framework.\\nCompetencies\\nApplication Delivery Process – Knowledge of major tasks, deliverables, and formal application delivery methodologies; ability to utilize these in order to deliver new or enhanced applications.\\nBig Data Management and Analytics – Knowledge and ability to plan and execute, big data management and analytics.\\nBusiness Intelligence – Knowledge of and ability to utilize business processes and technologies for gathering, storing, analyzing, and providing access to data that helps the organization make better business decisions.\\nData Analysis - Software – Knowledge of the investigation, evaluation, interpretation, and classification of data; the ability to identify, collect and analyze data to facilitate the development, implementation and application of software systems.\\nData Architecture – Knowledge and ability to create models and standards to govern which data is collected, and how it is stored, arranged, integrated, and put to use in data systems and in organizations.\\nDatabase Structures – Knowledge of and the ability to utilize appropriate database structures to organize and store data in a particular manner.\\nEffective Communications – Understanding of effective communication concepts, tools and techniques; ability to effectively transmit, receive, and accurately interpret ideas, information, and needs through the application of appropriate communication behaviors.\\nProblem Solving – Knowledge of approaches, tools, techniques for recognizing, anticipating, and resolving organizational, operational or process problems; ability to apply this knowledge appropriately to diverse situations.\\nSoftware Development Life Cycle – Knowledge of and experience with using a structured methodology for delivering new or enhanced software products to the marketplace.\\nWork Experience\\nRoles at this level typically require a university / college degree, with 3+ years of relevant / direct industry experience. Certifications are often desired. In lieu of a degree, a comparable combination of education and experience (including military service) may be considered.\\nEducation\\nBachelors\\nDisability Accommodations Statement:\\n\\nThe PNC workplace is inclusive and supportive of individual needs. If you have a physical or other impairment that might require an accommodation, including technical assistance with the PNC Careers website or submission process, please call 877-968-7762 and select Option 4: Recruiting or contact us via email at pathfinder@pnc.com.\\nThe Human Resources Service Center hours of operation are Monday - Friday 9:00 AM to 5:00 PM ET.\\nEqual Employment Opportunity (EEO):\\n\\nPNC provides equal employment opportunity to qualified persons regardless of race, color, sex, religion, national origin, age, sexual orientation, gender identity, disability, veteran status, or other categories protected by law.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         Title  \\\n",
       "0   Big Data Developer                                           \n",
       "1   Senior Data Engineer                                         \n",
       "2   Data Engineer Sr                                             \n",
       "3   Technology Engineer Sr                                       \n",
       "4   Senior Data Engineer, Analytics                              \n",
       "5   Data Engineer                                                \n",
       "6   Senior Data Engineer                                         \n",
       "7   Data Engineer                                                \n",
       "8   Assistant/Associate Professor                                \n",
       "9   Senior Data Engineer, Enterprise Data/Integration            \n",
       "10  Data Engineer (PDP)                                          \n",
       "11  Data Engineer Sr                                             \n",
       "12  Data Engineer                                                \n",
       "13  Data Engineer                                                \n",
       "14  Technology Engineer Sr                                       \n",
       "15  ETL Informatica Engineer                                     \n",
       "16  Data Engineer, National Robotics Engineering Center (NREC)   \n",
       "17  SQL Data Engineer                                            \n",
       "18  Senior Analytic Data Engineer                                \n",
       "19  Data Engineer                                                \n",
       "\n",
       "                  Location          City State         Zip     Country  \\\n",
       "0   Pittsburgh, PA          Pittsburgh    PA    None Found  None Found   \n",
       "1   Pittsburgh, PA 15213    Pittsburgh    PA    15213       None Found   \n",
       "2   Pittsburgh, PA 15222    Pittsburgh    PA    15222       None Found   \n",
       "3   Pittsburgh, PA 15289    Pittsburgh    PA    15289       None Found   \n",
       "4   Warrendale, PA 15086    Warrendale    PA    15086       None Found   \n",
       "5   Coraopolis, PA 15108    Coraopolis    PA    15108       None Found   \n",
       "6   Coraopolis, PA 15108    Coraopolis    PA    15108       None Found   \n",
       "7   West Mifflin, PA 15122  West Mifflin  PA    15122       None Found   \n",
       "8   Pittsburgh, PA          Pittsburgh    PA    None Found  None Found   \n",
       "9   Warrendale, PA 15086    Warrendale    PA    15086       None Found   \n",
       "10  Pittsburgh, PA          Pittsburgh    PA    None Found  None Found   \n",
       "11  Pittsburgh, PA 15289    Pittsburgh    PA    15289       None Found   \n",
       "12  Pittsburgh, PA          Pittsburgh    PA    None Found  None Found   \n",
       "13  Pittsburgh, PA 15222    Pittsburgh    PA    15222       None Found   \n",
       "14  Pittsburgh, PA 15222    Pittsburgh    PA    15222       None Found   \n",
       "15  Pittsburgh, PA 15220    Pittsburgh    PA    15220       None Found   \n",
       "16  Pittsburgh, PA          Pittsburgh    PA    None Found  None Found   \n",
       "17  Pittsburgh, PA 15219    Pittsburgh    PA    15219       None Found   \n",
       "18  Pittsburgh, PA 15289    Pittsburgh    PA    15289       None Found   \n",
       "19  Pittsburgh, PA 15222    Pittsburgh    PA    15222       None Found   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Qualifications  \\\n",
       "0   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "1   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "2   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "3   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "4   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "5   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "6   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "7   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "8   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "9   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "10  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "11  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "12  \\nBachelor’s degree in CS, IT/IS, or a field related to a computational science and a minimum two years experience working as a data engineer\\nExperience managing data ETL processes and making data available through service applications and databases.\\nExperience working with query authoring, relational databases, and a familiarity with a variety of databases (Cassandra or Elasticsearch preferred). Ability to write efficient SQL queries\\nExperience (3+ years) with programming languages (Python, Java, R, and/or Scala preferred)\\nFamiliarity with a variety of data processing technologies (e.g. Spark, Kafka, Hadoop)\\nExcellent communication skills, including a knack for clear documentation\\nExperience with or knowledge of REST APIs and making data available through microservices.\\nExperience using version control (Git, Mercurial, SVN, etc.) for collaborative code development.\\nExperience with containerization and related technologies (e.g. Docker, Kubernetes)\\nFamiliarity with core provider services from AWS, Azure or GCP, preferably having supported deployments on one or more of these platforms\\nExperience working with MongoDB, PostgreSQL, and Redis\\nWorking knowledge of bash scripting and/or JavaScript\\nExperience with automation and configuration management\\nExpert level building pipelines using Apache Beam or Spark\\n   \n",
       "13  Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.\\nExperience with relational database design methodologies and authoring complex SQL queries\\nExperience with NoSQL database technologies (MongoDB, Cassandra, etc).\\nExperience with Agile Development and Agile Deployment tools and versioning using Git or similar tools.\\nExperience with Hadoop and other Big Data technologies such as Spark, PySpark and Kafka.\\nExperience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.\\nExperience with message queuing, stream processing, and highly scalable ‘big data’ data stores.\\nExperience building data pipelines utilizing Google Cloud platform.\\nExperience with git or other code repository tools Experience with Concourse or other CI/CD tools and methodologies.\\n3-5 years experience\\nGoogle Cloud Platform (GCS, BQ, etc), Apache Kafka, Python                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "14  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "15  Minimum 4 years of experience developing and implementing Informatica Powercenter or Informatica Data Quality\\nBachelor’s Degree or Associate’s Degree with 6 years of work experience or equivalent work experience of 12 years                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "16  \\nB.S. in Computer Science, Engineering, Mathematics is required (Any more is a bonus)\\n3-5 years relevant experience is required.\\nDemonstrated understanding and use of software engineering concepts, practices, and procedures.\\nProficient development skills (Python preferred)\\nLinux development experience\\nTechnical communication skills\\nAbility to participate in a multi-disciplinary team                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "17  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "18  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "19  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Skills  \\\n",
       "0   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "1   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "2   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "3   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "4   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "5   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "6   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "7   Familiarity with building and optimizing data pipelines, architectures, and datasets\\nFamiliarity with data virtualization, transformation, and various data structures\\nFamiliarity with high performance computing\\nDeveloper technologies:\\nSoftware management tools including those for testing, continuous integration, version control, debugging, profiling, and compiler optimization\\nEnvironment Management:\\nData management and file systems\\nSystem metrics and monitoring\\nJob scheduler, resource allocation and job/workflow management   \n",
       "8   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "9   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "10  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "11  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "12  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "13  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "14  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "15  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "16  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "17  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "18  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "19  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Responsibilities  \\\n",
       "0   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "1   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "2   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "3   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "4   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "5   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "6   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "7   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "8   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "9   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "10  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "11  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "12  \\nWork with data scientists to build ML pipelines using heterogeneous sources and provide engineering services for data science applications\\nDesign and implement data warehouses, real-time ETL, and batch processing of data to support modeling and reporting needs\\nWork with team to develop data expertise and resolve upstream issues relating to data quality\\nDefine best practices and design for the management of data\\nWith data scientists, build and maintain internal data processing and visualization tools\\nCreate tools to serve data such as APIs and packages\\nEnsure automation through CI/CD across platforms both in cloud and on-premises\\nAbility to research and assess open source technologies and components to recommend and integrate into the design and implementation\\n                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "13  Build the infrastructure to support coding, testing, processing, and maintaining data resources in support of the Data Science, analytics and reporting organizations using SQL, SQOOP, Python, Google Big Query, Kafka and other Big Data technologies.\\nCollaborate with Data Scientists in the development of predictive models using machine learning, natural language and statistical analysis methods.\\nIdentify, design and implement internal process improvements (automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc).\\nBuild analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.\\nWork with stakeholders to assist with data-related technical issues and support their data infrastructure needs.\\nDevelop, refine and oversee data management standards, including establishing and enforcing governance procedures and ensuring data integrity across multiple functions.\\nResponsible for owning data quality metrics and meeting defined data accuracy goals according to industry best practices.   \n",
       "14  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "15  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "16  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "17  Strong Microsoft SQL Skills including but not limited to views, stored procedures and function creation and optimization\\nEnsure performance and availability of databases\\nETL knowledge and capability\\nData Modeling / Database Design\\nPerform baseline Microsoft SQL database administrative tasks\\nJob creations and failure monitoring\\nEvaluate datasets for quality and accuracy\\nSQL Training to others as needed                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "18  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "19  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "\n",
       "     Education  \\\n",
       "0   None Found   \n",
       "1   None Found   \n",
       "2   None Found   \n",
       "3   None Found   \n",
       "4   None Found   \n",
       "5   None Found   \n",
       "6   None Found   \n",
       "7   None Found   \n",
       "8   None Found   \n",
       "9   None Found   \n",
       "10  None Found   \n",
       "11  None Found   \n",
       "12  None Found   \n",
       "13  None Found   \n",
       "14  None Found   \n",
       "15  None Found   \n",
       "16  None Found   \n",
       "17  None Found   \n",
       "18  None Found   \n",
       "19  None Found   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Requirement  \\\n",
       "0   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "1   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "2   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "3   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "4   \\n5 + years of experience designing data models\\n10 + years of experience implementing data models and data architecture\\nExperience with debugging, performance profiling and optimization of data at each phase of the data pipeline\\nDemonstrated analytical capabilities paired with a strong initiative to find ways to improve the analysis and communication of complex data\\nSpecific experience with Microsoft SQL Server Reporting Services (SSRS) and SQL Server toolset. Candidates with extensive experience in other BI/reporting/analytics toolsets may be considered if they have a commitment to learning SSRS and a demonstrated ability to ramp up to proficiency rather quickly (within 2 months) in a primarily self-directed way\\nProficiency in either Tableau, SSRS or Power BI is required\\nCapable of designing complex and performant SQL queries\\n   \n",
       "5   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "6   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "7   BS degree in engineering or Bachelor's degree in a science related field from an accredited college or university and a minimum of four years relevant experience; or\\nMS degree in engineering or Master's degree in a science related field from an accredited college or university and a minimum of two years relevant experience\\nExperience with relational databases, query authoring, programming, and hardware/software troubleshooting.\\n                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "8   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "9   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "10  \\nExperience with:\\nOracle technologies including Oracle database and ODI\\nCloud-based data warehouse technologies such as Snowflake and open source ETL technologies such as Snaplogic.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "11  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "12  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "13  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "14  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "15  \\nIt is currently our objective to assign our people to work near where they live. However, given the nature of our business and our need to serve clients, our employees must be able to travel when needed. This role requires 100% flexibility to travel and work onsite with clients (typically Monday through Thursday).\\nProven success in contributing to a team-oriented environment\\nProven ability to work creatively and analytically in a problem-solving environment\\nDesire to work in an information systems environment\\nExcellent communication (written and oral) and interpersonal skills                                                                                                                                                                                                                                                                     \n",
       "16  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "17  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "18  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "19  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    FullDescriptions  \n",
       "0   You are curious, persistent, logical and clever – a true techie at heart. You enjoy living by the code of your craft and developing elegant solutions for complex problems. If this sounds like you, this could be the perfect opportunity to join EPAM as a Big Data Developer. Scroll down to learn more about the position’s responsibilities and requirements.\\n\\nWe are looking for a Big Data Engineer that will work on the collecting, storing, processing, and analyzing of large sets of data. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. You will also be responsible for integrating them with the architecture used across the company.\\n#Financial_Services\\nWhat You Have\\nA degree in an associated field and/or other advanced certification along with significant experience\\nProficient understanding of distributed computing principles\\nManagement of Hadoop cluster (Cloudera preferred), with all included services\\nAbility to solve any ongoing issues with operating the cluster\\nProficiency with Hadoop v2, MapReduce, HDFS, Sqoop\\nExperience with building stream-processing systems, using solutions such as Storm or Spark-Streaming\\nGood knowledge of big data querying tools, such as Pig, Hive, and Impala\\nExperience with Spark\\nExperience with integration of data from multiple data sources such as MS SQL Server, Oracle\\nGood understanding of SQL queries, joins, stored procedures, relational schemas\\nExperience with NoSQL databases, such as HBase, Cassandra, MongoDB (preferred)\\nKnowledge of various ETL techniques and frameworks, such as Flume\\nExperience with various messaging systems, such as Kafka or RabbitMQ\\nExperience with Cloudera\\nFS domain knowledge is a big plus but not required\\nWhat We Offer\\nMedical, Dental and Vision Insurance (Subsidized)\\nHealth Savings Account\\nFlexible Spending Accounts (Healthcare, Dependent Care, Commuter)\\nShort-Term and Long-Term Disability (Company Provided)\\nLife and AD&D Insurance (Company Provided)\\nEmployee Assistance Program\\nUnlimited access to LinkedIn learning solutions\\nMatched 401(k) Retirement Savings Plan\\nPaid Time Off\\nLegal Plan and Identity Theft Protection\\nAccident Insurance\\nEmployee Discounts\\nPet Insurance                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "1   Company Overview\\nAt Proofpoint, we have a passion for protecting people, data, and brands from today’s advanced threats and compliance risks. We hire the best people in the business to: Build and enhance our proven security platform; blend innovation and speed in a constantly evolving cloud architecture; analyze new threats and offer deep insight through data-driven intel; collaborate with customers to help solve their toughest security challenges.\\n\\nWe are singularly devoted to helping our customers protect what matters most. That’s why we’re a leader in next-generation cybersecurity—and why more than half of the Fortune 100 trust us as a security partner.\\n\\nWe are seeking a Senior Data Engineer to join our growing team in Pittsburgh. If you've ever wanted to work for an innovative software company, in great environment with great people, this is your chance. We’re a security software-as-a-service company so you’ll be involved both in our day-to-day software development as well as getting exposure to our security efforts.\\n\\nQ: Ok. Who are you?\\nA: We’re comprised of some really smart white hat security hackers, researchers from CMU, software developers and lot of hard working and friendly faces. We also really like data. We really value creating an inclusive, transparent, empathetic, and communicative culture.\\n\\nQ: What would I be working on?\\nA: You know all those data breaches you hear about in the news? Most of them started when a bad guy targeted an employee with a phishing attack. Our customers are mostly large enterprise organizations that are under attack by some pretty nasty bad guys. They use our platform to deliver security education to their employees and figure out who needs extra help. Your job will be to make our customers' experience of reporting on the results of their security awareness program as wonderful as possible.\\n\\nQ: Can you tell me a little more about your product?\\nA: Sure, we have several different ways that we can deliver security training to end users as well as several different ways to assess their security knowledge. One of the really fun ways we test the user is thinking like the bad guys. We send the end users a simulated phishing message. If they fall for it (they click our link, open our attachment, etc.), we show them training right away. It's an unconventional approach to changing user behavior and it works (hint: we have data). Proofpoint is in a growing space to say the least. If you ever wanted to learn more about cyber security and cutting-edge attacks, this is the place to do it. You’ll get to help simulate evil, figure out how to fight evil, and give our customers data that they can use to protect their organization.\\n\\nYour day to day\\nPerform development tasks related to delivering Qlik Sense applications, including design, implementation, testing and deployment\\nComfortable with defining/implementing application and database architectures\\nWork with Product Managers and Quality Engineers to ensure the delivery of great, high-quality features\\nInvestigate, prototype and recommend new technologies and solutions\\nWhat you bring to the team\\nBS/BA in a software related field or incredible experience that makes us not care about a degree.\\n2+ years’ experience of Qlik Sense development (or a combination of Qlik Sense and QlikView experience).\\nYou should have solid experience developing within Qlik Sense (or potentially QlikView). Preferably 2-4 years of experience in both native and mashup environments.\\nThe ability to diagnose and address performance bottlenecks in Qlik.\\nYou should possess an intermediate to advanced knowledge of SQL in either PostgreSQL or MySQL environments (or both). For instance, what are the different kinds of JOINs and when would you use each? What is a window function and why would you use one? What's a CTE? What are some features that are available in MySQL that aren't available in PostgreSQL or vice versa.\\nHave exposure to either MySQL or PostgreSQL environments, preferably MySQL 5.7 and PostgreSQL 10.\\nAt least an intermediate understanding of a HA Qlik deployment. For instance, what's the difference between a central node and a proxy node? How would you begin setting up such an environment or communicating with DevOps around the requirements for such an environment?\\nExperience in data modeling for both relational and analytical systems. What's the difference between 3NF and a star schema? When would it be appropriate to use one kind of model versus another? What are some of the kinds of slowly changing dimensions? In Qlik specifically, how do you approach creating a data model for high performance?\\nExperience with additional BI applications such as PowerBI and Logi. Have you ever created reports or visualizations for an end user using one of these applications (or others)?\\nFamiliarity with AWS is a plus, especially including a subset of the following services: RDS, EC2, S3, Data Pipeline, SNS, Kinesis, Lambda, DynamoDB, EMR, Redshift, and Elasticsearch.\\nComfort in working across multiple operating systems, including macOS and Windows.\\nComfortable with Git for version control.\\nCan work independently and thrives with autonomy.\\nWhy Proofpoint\\n\\nAs a customer focused and driven-to-win organization with leading edge products, there are many exciting reasons to join the Proofpoint team. We believe in hiring the best the brightest and cultivating a culture of collaboration and appreciation. As we continue to grow and expand globally, we understand that hiring the right people and treating them well is key to our success! We are a multi-national company with locations in 10 countries, with each location contributing to Proofpoint’s amazing culture!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "2   Position Overview\\nAt PNC, our people are our greatest differentiator and competitive advantage in the markets we serve. We are all united in delivering the best experience for our customers.\\n\\n\\nAs a Data Engineer Senior (hadoop) within PNC's Technology and Innovation organization, can be based in Pittsburgh, PA; Cleveland or Columbus, OH; Dallas, TX; Overland Park, KS; or within any PNC footprint nationwide\\n\\n\\nThe following skills are preferred:\\n\\nExperience in Hadoop Architecture & Data Engineering – Cloudera preferred\\nExtensive experience in Data Engineering – Spark, HIVE, Map Reduce, Sqoop, Kafka, NiFi, etc.\\nProficiency in writing SQL on mainstream RDBMSs like Oracle, Teradata etc.\\nTechnical lead and mentoring/coaching experience\\n\\nThe following skills are a plus:\\n\\nHands on experience with large Data Warehousing (Hadoop) implementations\\nProficiency with ingestion tools, Sqoop, Kafka, NiFi, etc.\\nAgile software development environment experience\\nJob Description\\nLeads in developing, supporting and implementing data solutions for multiple applications in order to meet business objectives and user requirements. Leverages technical knowledge and industry experience to design, build and maintain technology solutions.\\nLeads data requirement analysis and the data preparation process development for targeted data solutions.\\nLeads in designing and building data service infrastructure on multiple data platforms, according the workflow.\\nOversees the development and implementation of data solutions for multiple applications to ensure its scalability, availability and maintainability.\\nConsults on data migration and transformation to ensure the accuracy and security of data solutions.\\nPNC Employees take pride in our reputation and to continue building upon that we expect our employees to be:\\nCustomer Focused - Knowledgeable of the values and practices that align customer needs and satisfaction as primary considerations in all business decisions and able to leverage that information in creating customized customer solutions.\\nManaging Risk - Assessing and effectively managing all of the risks associated with their business objectives and activities to ensure they adhere to and support PNC's Enterprise Risk Management Framework.\\nCompetencies\\nApplication Delivery Process – Knowledge of major tasks, deliverables, and formal application delivery methodologies; ability to utilize these in order to deliver new or enhanced applications.\\nBig Data Management and Analytics – Knowledge and ability to plan and execute, big data management and analytics.\\nBusiness Intelligence – Knowledge of and ability to utilize business processes and technologies for gathering, storing, analyzing, and providing access to data that helps the organization make better business decisions.\\nConsulting – Knowledge of techniques, roles, and responsibilities in providing technical or business guidance to clients, both internal and external; ability to apply this knowledge appropriately to diverse situations.\\nData Analysis - Software – Knowledge of the investigation, evaluation, interpretation, and classification of data; the ability to identify, collect and analyze data to facilitate the development, implementation and application of software systems.\\nData Architecture – Knowledge and ability to create models and standards to govern which data is collected, and how it is stored, arranged, integrated, and put to use in data systems and in organizations.\\nDatabase Structures – Knowledge of and the ability to utilize appropriate database structures to organize and store data in a particular manner.\\nProblem Solving – Knowledge of approaches, tools, techniques for recognizing, anticipating, and resolving organizational, operational or process problems; ability to apply this knowledge appropriately to diverse situations.\\nSoftware Development Life Cycle – Knowledge of and experience with using a structured methodology for delivering new or enhanced software products to the marketplace.\\nWork Experience\\nRoles at this level typically require a university / college degree, with 5+ years of industry-relevant experience. Specific certifications are often required. In lieu of a degree, a comparable combination of education and experience (including military service) may be considered.\\nEducation\\nBachelors\\nDisability Accommodations Statement:\\n\\nThe PNC workplace is inclusive and supportive of individual needs. If you have a physical or other impairment that might require an accommodation, including technical assistance with the PNC Careers website or submission process, please call 877-968-7762 and select Option 4: Recruiting or contact us via email at pathfinder@pnc.com.\\nThe Human Resources Service Center hours of operation are Monday - Friday 9:00 AM to 5:00 PM ET.\\nEqual Employment Opportunity (EEO):\\n\\nPNC provides equal employment opportunity to qualified persons regardless of race, color, sex, religion, national origin, age, sexual orientation, gender identity, disability, veteran status, or other categories protected by law.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "3   Position Overview\\n\\nAt PNC, our people are our greatest differentiator and competitive advantage in the markets we serve. We are all united in delivering the best experience for our customers. As a Technology Engineer Sr. within PNC's ALM Risk organization, you will be based in one of the following locations: Pittsburgh, PA. Cleveland, OH New York, NY New Jersey Washington D.C. area Atlanta, GA Chicago, IL Charlotte, NC Raleigh, NC Relocation assistance may be available for the for the selected candidate. In this contributor role you will support the Technology team partnering with the Balance Sheet Analytics & Modeling LOB, and requires specialized skills and experience with advanced computational and data science related technologies such as Python, SAS, SPARK, Hadoop and related stacks. At PNC, we are building our advanced computation and analytics platforms to support CECL and other subsequent BSAM usecase implementation and we are seeking a Sr. Data Engineer who will perform the following functions: •A self-starter who can align the technology solution with a business goal •Development – Design and build database and data science solutions •Data Modeling – Apply your expertise to help model structured and unstructured data. Own these models at a high level and consult with feature teams to help them model applications. •Data Integration – Plan and build data integrations between systems. Figure out the best way to share information and build the tech needed to execute. •Mentoring – Help teach other team members about data architecture, and also be a consultant for developers who need help with data. •Engineer reusable capabilities and pipelines for DML, DDL, maintenance, and ETL needs that can be shared across teams. •Stay current on technical knowledge and tooling to help the team utilize new technologies. •Establish scalable, efficient, automated processes for large scale data analysis and visualization •Perform data insights analysis using clustering, agglomerative clustering, graph based clustering, and analysis Basic Qualifications •MS with 2+ years of industry experience or Bachelors with 5+ years of experience in Quantitative field (Computer Science, Electrical/ Computer engineering, Financial Engineering, Mathematics, Statistics, Physics) •5+ years of enterprise-level scripting experience using languages (e.g. Python, SPARK, SCALA), or statistical/mathematical software (e.g. R, SAS) •Experience in creating data driven visualizations •Highly skilled in data and math/statistical methods (i.e. modeling, algorithms) •4+ years of experience in system analysis and data management engineering •3+ years of experience in database technologies: Oracle, Cassandra, or Mongo •2+ years of experience with DevOps, CI/CD •Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment Preferred Qualifications •Experience in processing, filtering, and presenting large quantities (Millions to Billions of rows) of data •2+ years of experience in AWS, Google Cloud, or MS Azure •Experience working with Financial, Insurance domains •Strongly prefer Experience in Data Science, Machine Learning, and/or Deep Learning •Strongly prefer prior Experience in programming languages such as Java, or C/C+ •Experience with containerized solutions •Experience with SPARQL and other no-SQL data bases a plus •Experience with XML, XML Schema, XSLT\\n\\nJob Profile\\n\\nLeads in the development of the most complex new and emerging technologies and selects appropriate platforms, integrates and configures solutions. Leverages technical knowledge and industry experience to design, build and maintain technology solutions.\\nDevelops software components and hardware for new and emerging technology projects; aligns these with business strategies and objectives.\\nConsults junior staff regarding complex issues and best practices.\\nProvides a systematic analysis on the most complex client requirements within the traceability framework and resolves any functional problems encountered.\\nOversees the quality of complex project deliverables while ensuring that they are in compliance with relevant standards and processes.\\nPNC Employees take pride in our reputation and to continue building upon that we expect our employees to be:\\nCustomer Focused - Knowledgeable of the values and practices that align customer needs and satisfaction as primary considerations in all business decisions and able to leverage that information in creating customized customer solutions.\\nManaging Risk - Assessing and effectively managing all of the risks associated with their business objectives and activities to ensure they adhere to and support PNC's Enterprise Risk Management Framework.\\nCompetencies\\nApplication Delivery Process – Knowledge of major tasks, deliverables, and formal application delivery methodologies; ability to utilize these in order to deliver new or enhanced applications.\\nConsulting – Knowledge of techniques, roles, and responsibilities in providing technical or business guidance to clients, both internal and external; ability to apply this knowledge appropriately to diverse situations.\\nEffectiveness Measurement – Ability to measure the quality and quantity of work effort for the purpose of improvement.\\nEmerging Technologies – Knowledge of and ability to design, apply and evaluate new information technologies for business environments in order to improve work productivity and accuracy.\\nIndustry Knowledge – Knowledge of the organization's industry group, trends, directions, major issues, regulatory considerations, and trendsetters; ability to apply this knowledge appropriately to diverse situations.\\nIT Industry: Trends & Directions – Knowledge of and ability to analyze marketplace experiences, developments and trends related to the function of Information Technology (IT).\\nIT Standards, Procedures & Policies – Knowledge of and the ability to utilize a variety of administrative skill sets and technical knowledge to manage organizational IT policies, standards, and procedures.\\nPlanning: Tactical, Strategic – Ability to contribute to operational (short term), tactical (1-2 years) and strategic (3-5 years) planning in support of the overall business plan.\\nProblem Solving – Knowledge of approaches, tools, techniques for recognizing, anticipating, and resolving organizational, operational or process problems; ability to apply this knowledge appropriately to diverse situations.\\n\\nWork Experience\\n\\nRoles at this level typically require a university / college degree, with 5+ years of industry-relevant experience. Specific certifications are often required. In lieu of a degree, a comparable combination of education and experience (including military service) may be considered.\\n\\nEducation\\n\\nBachelors\\n\\nDisability Accommodations Statement\\n\\nThe PNC workplace is inclusive and supportive of individual needs. If you have a physical or other impairment that might require an accommodation, including technical assistance with the PNC Careers website or submission process, please call 877-968-7762 and select Option 4: Recruiting or contact us via email at pathfinder@pnc.com. The Human Resources Service Center hours of operation are Monday - Friday 9:00 AM to 5:00 PM ET.\\n\\nEqual Employment Opportunity (EEO)\\n\\nPNC provides equal employment opportunity to qualified persons regardless of race, color, sex, religion, national origin, age, sexual orientation, gender identity, disability, veteran status, or other categories protected by law.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "4   Description:\\nAs a member of the Digital Solutions and Data and Analytics IT team, this person will be working with various teams to design solutions related to the data pipeline, with special emphasis on data modeling and design.\\n\\nThis role demands a strong knowledge and understanding of the data and the business requirements to build robust, scalable data models, which may be relational as well as dimensional. The role entails having the capability of relating and understanding existing and in-development data models/schemas and the business context they represent.\\n\\nResponsibilities\\n\\n\\nEstablish design principles for data models and create modeling standards\\nDocument, create and maintain logical and physical database models as per the standards\\nWork with the business as well as the technical teams to understand the requirements, to create models that cater to the requirements\\nWork on understanding various data domains, to map and integrate disparate data from a variety of source systems\\nSupport Analytics development from and to a variety of database systems\\nFacilitate data requirements conversation with business and technical stakeholders resolving conflicts to drive decisions and consensus\\nEstablish and maintain comprehensive data model documentation including detailed descriptions of business entities, attributes, and data relationships as well as the definition of business rules governing the integrity, archiving, and audit requirements of the data\\nAnalyze existing systems using manual or automated data analysis/profiling to reverse engineer data requirements\\nDetermine suitable data modeling approach for each project based on business requirements for data capture and access\\nAssist developers with complex query development and performance optimization\\nPerforms additional duties as required\\nProvide subject matter expertise (technical and business context) input and feedback to data/BI teams and development scrum teams as needed.\\nIdentify, communicate, and mitigate risks related to including invalid data, invalid data calculations, formulas or derived insights, and misrepresentation of or otherwise confusing visual representations of data.\\n\\nRequirements:\\nTechnical\\n\\n\\n5 + years of experience designing data models\\n10 + years of experience implementing data models and data architecture\\nExperience with debugging, performance profiling and optimization of data at each phase of the data pipeline\\nDemonstrated analytical capabilities paired with a strong initiative to find ways to improve the analysis and communication of complex data\\nSpecific experience with Microsoft SQL Server Reporting Services (SSRS) and SQL Server toolset. Candidates with extensive experience in other BI/reporting/analytics toolsets may be considered if they have a commitment to learning SSRS and a demonstrated ability to ramp up to proficiency rather quickly (within 2 months) in a primarily self-directed way\\nProficiency in either Tableau, SSRS or Power BI is required\\nCapable of designing complex and performant SQL queries\\n\\nProfessional\\n\\n\\nExcellent interpersonal and organizational acumen by collaborating with both internal team members and external business stakeholders\\nInternally motivated, able to work proficiently both independently and in a team environment\\nStrong written and verbal communication skills with staff and leadership at all levels of seniority and technical experience\\nBachelor’s Degree or higher (Computer Science, Engineering, Human Computer Interaction/Design, or similar/relevant field)\\nMotivated to “stay current” with technical change/commit to professional development to learn relevant new skills/tools/methodologies\\n\\nDesired Additional Competencies\\n\\n\\nExperience with relational database design, SQL DDL, performance tuning relating to indexes, etc.\\nExperience with non-relational “noSQL” data sources\\nExperience with ETL processes and tools\\nHealthcare industry experience not required but a significant plus (supply chain, provider, payer, medical device, life-science, pharmacy, etc.)\\nExperience with other data/BI tools, especially within the Microsoft ecosystem\\n\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "5   The Data Engineer is a key member of a platform team that contributes to software design, development and overall product lifecycle for a product that delights our users and adds value to the organization. The engineering process is highly collaborative. The Data Engineer is expected to pair on a daily basis as they work through user stories and support products as they evolve. In addition, the Data Engineer may be involved in product configuration, performance tuning and testing as well as production monitoring. As a Data Engineer, you will be part of a team with more experienced engineers to help build and grow your skills while you create, support, and deploy production applications.\\n\\nQualifications\\nBuild the infrastructure to support coding, testing, processing, and maintaining data resources in support of the Data Science, analytics and reporting organizations using SQL, SQOOP, Python, Google Big Query, Kafka and other Big Data technologies.\\nCollaborate with Data Scientists in the development of predictive models using machine learning, natural language and statistical analysis methods.\\nDesign and implement internal process improvements (automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc).\\n\\nBuild analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.\\n\\nWork with stakeholders to assist with data-related technical issues and support their data infrastructure needs.\\n\\nDevelop, refine and oversee data management standards, including establishing and enforcing governance procedures and ensuring data integrity across multiple functions. Responsible for owning data quality metrics and meeting defined data accuracy goals according to industry best practices.\\n\\nBachelor's Degree - Computer Science, Software Engineering, Information Systems or Information Technology or related field required, or equivalent experience\\n\\n1-3 years of experience\\n\\nGoogle Cloud Platform (GCS, BQ, etc), Apache Kafka, Python\\nExperience with NoSQL database technologies (MongoDB, Cassandra, etc)\\n\\nExperience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.\\n\\n\\n#LI-BT1-L                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "6   The Senior Data Engineer is a key member of a platform team that contributes to software design, development and overall product lifecycle for a product that delights our users and adds value to the organization. The engineering process is highly collaborative. The Senior Data Engineer is expected to pair on a daily basis as they work through user stories and support products as they evolve. In addition, the Senior Data Engineer may be involved in product configuration, performance tuning and testing as well as production monitoring. As a Senior Data Engineer, you will be part of a team with more experienced engineers to help build and grow your skills while you create, support, and deploy production applications.\\nQualifications\\nBuild the infrastructure to support coding, testing, processing, and maintaining data resources in support of the Data Science, analytics and reporting organizations using SQL, SQOOP, Python, Google Big Query, Kafka and other Big Data technologies.\\n\\nCollaborate with Data Scientists in the development of predictive models using machine learning, natural language and statistical analysis methods.\\n\\nIdentify, design and implement internal process improvements (automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc).\\nBuild analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.\\nWork with stakeholders to assist with data-related technical issues and support their data infrastructure needs.\\nDevelop, refine and oversee data management standards, including establishing and enforcing governance procedures and ensuring data integrity across multiple functions. Responsible for owning data quality metrics and meeting defined data accuracy goals according to industry best practices.\\nExperience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc. Experience with relational database design methodologies and authoring complex SQL queries\\nExperience with NoSQL database technologies (MongoDB, Cassandra, etc) Experience with Agile Development and Agile Deployment tools and versioning using Git or similar tools\\nExperience with Hadoop and other Big Data technologies such as Spark, PySpark and Kafka Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.\\nExperience with message queuing, stream processing, and highly scalable ‘big data’ data stores. Experience building data pipelines utilizing Google Cloud platform.\\nExperience with git or other code repository tools Experience with Concourse or other CI/CD tools and methodologies.\\n\\nBachelor's Degree\\n\\nComputer Science, Software Engineering, Information Systems or Information Technology or related field required, or equivalent experience\\n\\n\\n3-5 years experience\\n\\nGoogle Cloud Platform (GCS, BQ, etc), Apache Kafka, Python\\n\\n#LI-BT1-L                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "7   Description\\nThe Naval Nuclear Laboratory seeks a talented and innovative Data Engineer to join a growing team dedicated to delivering data-driven solutions to the organization. As a data engineer, you will be responsible for developing, constructing, testing, and delivering Program data infrastructure needs. Specifically, the data engineer will help to assess existing data infrastructure hardware and software, and work with key stakeholders to identify, assess, implement, and test improvements to the data infrastructure. The data engineer will interface with data scientists and others at the Laboratory to ensure dataset reporting, querying, and analysis capabilities are based upon reliable, efficient, and scalable data infrastructure. The data engineer will participate in continuous data engineering training programs as well as develop and review corporate policies, instructions, and implementation principles related to data infrastructure and its use in the Program. We develop the world's best nuclear propulsion systems, train Sailors, to operate them, and provide full lifecycle support, from technology development through design to disposal.\\nResponsibilities:\\nInterface with technology and support organizations to create, adapt, maintain, and test optimal Program data pipeline architectures\\nAssemble large, complex datasets that meet functional business requirements\\nIdentify, design, and implement internal data infrastructure process improvements such as automating manual processes, optimizing data delivery, redesigning infrastructure for greater scalability, and opportunities for data acquisition\\nBuild the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using various technologies\\nWork with stakeholders to assist with data-related technical issues and support their data infrastructure needs\\nCreate consistent data infrastructure solutions and access for users at multiple sites\\nAssist management in prioritizing projects\\nDeliver data engineering training\\nContinuous learning and improvement of skills needed to keep current with state-of-the-art data architectures\\nDevelop and review corporate policies, instructions, and principles related to data infrastructure and its use in the Program\\nRequirements\\nAdvanced:\\nBS degree in engineering or Bachelor's degree in a science related field from an accredited college or university and a minimum of four years relevant experience; or\\nMS degree in engineering or Master's degree in a science related field from an accredited college or university and a minimum of two years relevant experience\\nExperience with relational databases, query authoring, programming, and hardware/software troubleshooting.\\nSenior:\\nBS degree in engineering or Bachelor's degree in a science related field from an accredited college or university and a minimum of six years relevant experience; or\\nMS degree in engineering or Master's degree in a science related field from an accredited college or university and a minimum of four years relevant experience\\nExperience with relational databases, query authoring, programming, and hardware/software troubleshooting\\nPreferred Skills\\nFamiliarity with building and optimizing data pipelines, architectures, and datasets\\nFamiliarity with data virtualization, transformation, and various data structures\\nFamiliarity with high performance computing\\nDeveloper technologies:\\nSoftware management tools including those for testing, continuous integration, version control, debugging, profiling, and compiler optimization\\nEnvironment Management:\\nData management and file systems\\nSystem metrics and monitoring\\nJob scheduler, resource allocation and job/workflow management                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "8   Assistant/Associate Professor\\nSCI-Office of the Dean - Pennsylvania-Pittsburgh - (18001834)\\n\\nSchool of Computing and Information Department of Information Culture and Data Stewardship Non-Tenure-Track Faculty Position in Data Stewardship The School of Computing and Information (http://www.ischool.pitt.edu) at the University of Pittsburgh is seeking to fill a faculty position in Data Stewardship at an Assistant/Associate Professor level - Position #0134534 (Non-Tenure Stream). The initial appointment is expected to be three years with consideration for renewal. We are looking for an experienced practitioner and scholar in Data Stewardship who can demonstrate an in-depth understanding of data curation, data documentation and data preservation, specifically: • Current best practices and policy surrounding active data management through the data lifecycle, including data collection, data management plans, data storage, data quality and reproducibility • Experience of handling research data including application of date standards and formats, data description and documentation, metadata schema for disciplinary data, data citation and persistent identifiers, data publication, data analysis, data visualization, data re-use and metrics • Contemporary good practice in data selection and appraisal, data infrastructure including data repository software platforms, and long-term data preservation strategies • An awareness of diverse disciplinary data practices, research workflows and workflow platforms, as well as an in-depth knowledge of particular domain(s). The University of Pittsburgh School is a top-ranked information school (iSchool) offering a wide variety of multidisciplinary opportunities, including an undergraduate program (BSIS), Master's programs in information science (MSIS), telecommunications & networking (MST), library & information science (MLIS), and Ph.D. programs, The new Data Stewardship Pathway for graduate students studying for the MLIS, draws on the concept of \"translational data science\", described by Lyon & Brenner (2015) as: \"the enhanced transition of skills, software tools and intelligence from the iSchool to the marketplace, Which may be interpreted as industry, government, libraries, archives or data centers\". Adopting a translational perspective will enable iSchools to supply and deploy data talent and data products more rapidly to the range of consumers, where there Is currently an acknowledged workforce need\". Development of the Data Stewardship Pathway has been further informed by the results of two small-scale studies, which featured an analysis of requirements for real-world positions in each of the six data science roles (data archivist, data librarian, data steward/ curator, data analyst, data engineer and data journalist) and which highlighted the knowledge, skills and competencies being sought by employers (Lyon, Mattern, Acker & Langmead 2016; Lyon & Mattern 2016). We expect candidates for this position to possess strong experience within the broader data community or in professional data curation environments and to have excellent interpersonal, communication and team skills. The new faculty member is expected to be able to liaise and collaborate with disciplinary faculty and researchers across a range of Schools ahd Departments in the University, but also with the regional, national and international data community. The University is actively addressing the development and adoption of research data management infrastructure, working through the Data Management Committee and administration support services on campus. The successful candidate will contribute to the Data Stewardship Pathway through both research and teaching undergrad and post-graduate students, and will be expected to demonstrate an awareness of current data developments, trends, challenges, emerging fields and a positive commitment to research. As the School offers an online degree program in addition to oncampus programs:, candidates with complementary expertise and experience\\n\\nCandidates applying for the position(s) are expected to hold an earned Doctorate or the equivalent in academic or professional experience. Applicants should present a record of effective teaching, research, and related scholarly activities. Electronic applications should be sent to https://ischoolatpitt.wufoo.com/forms/faculty-position-in-data-stewardship/. Applications should include a cover letter, curriculum vitae, research statement, teaching statement, and the names, addresses (with e-mail), and telephone numbers of three references. For full consideration, applications must be received by February 15, 2017. Questions about the position should be directed to Dr. Richard Cox Chair of Search Committee School of Computing and Information University of Pittsburgh The University of Pittsburgh is an Affirmative Action, Equal Opportunity Employer Minorities/Women/Vets/Disabled.\\n\\nAssignment Category Fulltime-Regular\\nCampus Pittsburgh\\nChild Protection Clearances The following PA Act 153 clearances and background checks may be required prior to commencement of employment and as a condition of continued employment: PA State Police Criminal Record Check, FBI Criminal Record Check, PA Child Abuse History Clearance.\\nRequired Attachments Other (see posting for additional details)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "9   Description:\\nAbout Intalere\\nIntalere is the essential partner for operational excellence in healthcare offering customized solutions that address customers’ individual needs by assisting in managing their entire non-labor spend, providing innovative technologies, products and services, and leveraging the best practices of a provider-led model.\\n\\nIntalere strives to create a high-performance work environment and to maintain our position as an employer of choice. Our Total Rewards benefit package reflects our values of Integrity, Passion, Accountability, Innovation and Excellence.\\n\\nDescription\\nAs a member of the Digital Solutions and Data and Analytics IT team, this person will be a technical lead for data modeling, data integration and data wrangling between various internal and external applications to provide the data foundation for a suite of enterprise applications, business intelligence reporting, analytics and data science focused in cloud environment.\\n\\nThis role demands critical thinking and problem-solving skills to utilize best practices and technology experience to create innovative solutions to create a leading-edge data and analytics products.\\n\\nThis role demands a strong technical integration skillset as well as broader understanding of relational and nonrelational data structures in a hybrid cloud environment.\\n\\nThe senior data engineer will not just implement ETL and other integration solutions via tools like SQL Server Integration Services (SSIS); they will also be responsible for designing the integrations, utilizing technical best practices as well as their analytical skills to obtain a full understanding of underlying data and functional needs/requirements.\\n\\nResponsibilities\\n\\nDesign and develop new data integrations between our hybrid cloud environment as well as lead data ingestion.\\n\\nLead requirements analysis efforts relating to implementing new integrations via direct communication with technical and non-technical stakeholders.\\n\\nMaintain extensive existing set of SSIS packages:\\n\\nTroubleshoot SSIS packages when there are failures (evaluate cause, determine and test solution, implement solution) and provide communication to stakeholders during outage as well as document the situation after it is resolved to support retrospectives/knowledge sharing.\\nIteratively enhance SSIS packages for performance improvement.\\nAdjust scheduling of package execution as need arises.\\nAdjust packages when underlying data schemas/file formats change.\\n\\nContribute to team knowledge sharing/training efforts.\\n\\nDevelop a strong understanding of Intalere and customer data models/context.\\n\\nProvide subject matter expertise (technical and business context) input and feedback to data/BI teams and development scrum teams as needed.\\n\\nIdentify, communicate, and mitigate integration/ETL risks. .\\n\\nRequirements:\\nTechnical\\n5+years of experience architecting integration/ETL processes or managing enterprise databases\\n2+ years of experience with data solutions in Microsoft Azure\\nExperience with Azure Data Factory (ADF)\\nExperience with Azure Data Lake\\nExperience with PowerShell or Terraform\\nDemonstrated ability to quickly learn/understand and discuss data formats/models/standards\\nExperience with debugging, performance profiling and optimization of integration/ETL processes\\nExperience developing database objects such as stored procedures, triggers, constraints and indexes\\nCapable of designing and tuning complex SQL queries\\nSpecific experience with Microsoft SQL Server Integration Services (SSIS) packages and toolset\\nCandidates with extensive experience in other ETL and integration toolsets may be considered if they have a commitment to learning SSIS and a demonstrated ability to ramp up to proficiency rather quickly (within 2 months) in a primarily self-directed way\\n\\nProfessional\\nExcellent interpersonal and organizational acumen with regard to collaborating with both internal team members and external business stakeholders\\nStrong analytical and critical thinking skills\\nInternally motivated, able to work proficiently both independently and in a team environment\\nStrong written and verbal communication skills with staff and leadership at all levels of seniority and technical experience\\nBachelor’s Degree or higher (Computer Science, Engineering, or similar/relevant field)\\nMotivated to “stay current” with technical change/commit to professional development to learn relevant new skills/tools/methodologies\\n\\nDesired Additional Competencies\\nHealthcare industry experience not required but a significant plus (supply chain, provider, payer, medical device, life-science, pharmacy, etc.)\\nExperience developing business insights from complex data sources\\nExperience with non-relational “noSQL” data sources\\nExperience with Azure Data Bricks\\nExperience with Tableau\\nExperience with other data/BI tools, especially within the Microsoft ecosystem (SQL Server Reporting Services (SSRS), Power BI, Power Query, DAX, R)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "10  This position will support our Postsecondary Data Partnership (PDP) project and will be located in our Pittsburgh Collaboration Center.\\n\\nIf you are a self-starter, thrive in a fast-paced environment, and get energized about driving new data driven services, then this job is for you!\\n\\nThe Clearinghouse is seeking a hands-on Data Engineer with a solid background in Data Warehouse architectures, metadata management, data profiling, data modeling, data quality and a proven ability to learn quickly, effectively collaborate with others, and successfully design and implement solutions. Using their excellent communication and presentation skills, the Engineer socializes technical concepts and builds consensus with internal stakeholders.\\n\\nThe Data Engineer reports to the Manager, Application Development and works with the business and development teams to design and implement the appropriate data solutions for Clearinghouse database-driven applications and services. The Engineer accomplishes this by performing data analysis of current and future systems and services, educating on industry best practices and policies, creating proposed database component designs and data models, and working with the architecture and development teams to refine and implement these designs.\\n\\nHow You Contribute:\\nDevelop and maintain the PL/SQL Packages.\\nDevelop and maintain ETL code.\\nDesign Data Marts and create data models.\\nWork with Data owners to document and maintain Data Dictionary.\\nDevelop scripts to maintain data quality and deploying data changes across different environments\\nMonitor, assess and optimize data processing performance.\\nDemonstrate NSC’s competencies, which align with our corporate values.\\nCore Competencies include: Customer Focus, Optimizes Work Processes, Collaborates, Communicates Effectively, and Be Open and Authentic.\\nManager will provide more detail as needed.\\nPosition may be required to perform other duties as required. These essential functions are representative of those that must be met by an employee to successfully perform the job. Reasonable accommodations will be made to enable individuals with disabilities to perform these essential functions.\\n\\nWhat You Bring to the Table:\\nBachelor’s degree required in Computer Science, Systems Engineering, or Information Systems, or some equivalent combination of education and experience, including through military service.\\nProficient in:\\nPL/SQL programming, typically acquired through 4-7 years of experience programming with this technology.\\nDeveloping scripts using Shell, Perl or similar language.\\nExperience working on an Agile/Scrum development team.\\nProficient with:\\nData Warehouse production maintenance.\\nETL development using products such as Oracle Data Integrator.\\nOLTP and data warehouse design.\\nMetadata management.\\nCreating and implementing data models.\\nDatabase performance monitoring and SQL optimization.\\nExcellent communication skills.\\nDemonstrated ability to work independently and directly with the data owners to gather requirements and architect change.\\nLive within a commutable distance of Pittsburgh, PA.\\nAdditional Desired Requirements:\\n\\nExperience with:\\nOracle technologies including Oracle database and ODI\\nCloud-based data warehouse technologies such as Snowflake and open source ETL technologies such as Snaplogic.\\nPhysical Demands:\\nUse of a computer terminal and/or laptop computer for 8 or more hours a day.\\nUse of a copy machine, and telephone.\\nFrequently required to sit for 7 or more hours per day in close proximity to others in an open office environment.\\nOccasionally required to use hands and fingers to operate, handle, and reach.\\nVision abilities include close vision and the ability to adjust focus.\\nNSC strives to hire, promote, and retain the best qualified individuals for our employment opportunities. Our policies are intended to provide equal employment opportunity for all employees and job applicants without regard to race, color, religion, gender, gender identity, sexual orientation, age, disability, national origin, protected veteran status, or any other status protected by law. NSC strives to have a culture that is diverse and equally welcoming to all. As a Federal contractor, NSC is subject to requirements to take affirmative action to employ and advance in employment protected Veterans and individuals with disabilities. NSC is committed to its outreach efforts and practices to promote employment and advancement of members of these groups. To read our entire policy, go to: https://studentclearinghouse.info/careers/human-resource-policies\\nPAY TRANSPARENCY POLICY NSC will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by NSC, or (c) consistent with the NSC’s legal duty to furnish information. 41 C.F.R. 60-1.35(c)\\nPlease view Equal Employment Opportunity Posters provided by OFCCP here.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "11  Position Overview\\n\\nAt PNC, our people are our greatest differentiator and competitive advantage in the markets we serve. We are all united in delivering the best experience for our customers. As a Data Engineer Senior (hadoop) within PNC's Technology and Innovation organization, can be based in Pittsburgh, PA; Cleveland or Columbus, OH; Dallas, TX; Overland Park, KS; or within any PNC footprint nationwide The following skills are preferred: •Experience in Hadoop Architecture & Data Engineering – Cloudera preferred •Extensive experience in Data Engineering – Spark, HIVE, Map Reduce, Sqoop, Kafka, NiFi, etc. •Proficiency in writing SQL on mainstream RDBMSs like Oracle, Teradata etc. •Technical lead and mentoring/coaching experience The following skills are a plus: •Hands on experience with large Data Warehousing (Hadoop) implementations •Proficiency with ingestion tools, Sqoop, Kafka, NiFi, etc. •Agile software development environment experience\\n\\nJob Profile\\n\\nLeads in developing, supporting and implementing data solutions for multiple applications in order to meet business objectives and user requirements. Leverages technical knowledge and industry experience to design, build and maintain technology solutions.\\nLeads data requirement analysis and the data preparation process development for targeted data solutions.\\nLeads in designing and building data service infrastructure on multiple data platforms, according the workflow.\\nOversees the development and implementation of data solutions for multiple applications to ensure its scalability, availability and maintainability.\\nConsults on data migration and transformation to ensure the accuracy and security of data solutions.\\nPNC Employees take pride in our reputation and to continue building upon that we expect our employees to be:\\nCustomer Focused - Knowledgeable of the values and practices that align customer needs and satisfaction as primary considerations in all business decisions and able to leverage that information in creating customized customer solutions.\\nManaging Risk - Assessing and effectively managing all of the risks associated with their business objectives and activities to ensure they adhere to and support PNC's Enterprise Risk Management Framework.\\nCompetencies\\nApplication Delivery Process – Knowledge of major tasks, deliverables, and formal application delivery methodologies; ability to utilize these in order to deliver new or enhanced applications.\\nBig Data Management and Analytics – Knowledge and ability to plan and execute, big data management and analytics.\\nBusiness Intelligence – Knowledge of and ability to utilize business processes and technologies for gathering, storing, analyzing, and providing access to data that helps the organization make better business decisions.\\nConsulting – Knowledge of techniques, roles, and responsibilities in providing technical or business guidance to clients, both internal and external; ability to apply this knowledge appropriately to diverse situations.\\nData Analysis - Software – Knowledge of the investigation, evaluation, interpretation, and classification of data; the ability to identify, collect and analyze data to facilitate the development, implementation and application of software systems.\\nData Architecture – Knowledge and ability to create models and standards to govern which data is collected, and how it is stored, arranged, integrated, and put to use in data systems and in organizations.\\nDatabase Structures – Knowledge of and the ability to utilize appropriate database structures to organize and store data in a particular manner.\\nProblem Solving – Knowledge of approaches, tools, techniques for recognizing, anticipating, and resolving organizational, operational or process problems; ability to apply this knowledge appropriately to diverse situations.\\nSoftware Development Life Cycle – Knowledge of and experience with using a structured methodology for delivering new or enhanced software products to the marketplace.\\n\\nWork Experience\\n\\nRoles at this level typically require a university / college degree, with 5+ years of industry-relevant experience. Specific certifications are often required. In lieu of a degree, a comparable combination of education and experience (including military service) may be considered.\\n\\nEducation\\n\\nBachelors\\n\\nDisability Accommodations Statement\\n\\nThe PNC workplace is inclusive and supportive of individual needs. If you have a physical or other impairment that might require an accommodation, including technical assistance with the PNC Careers website or submission process, please call 877-968-7762 and select Option 4: Recruiting or contact us via email at pathfinder@pnc.com. The Human Resources Service Center hours of operation are Monday - Friday 9:00 AM to 5:00 PM ET.\\n\\nEqual Employment Opportunity (EEO)\\n\\nPNC provides equal employment opportunity to qualified persons regardless of race, color, sex, religion, national origin, age, sexual orientation, gender identity, disability, veteran status, or other categories protected by law.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "12  The Fort is the new hub for innovation and incubation at Fortive. We have the backing of a large company and the soul of a startup (a Fortune 500 startup, that is), and this is the place where that flame burns brightest.\\n\\nAt The Fort, we combine forces to deploy disruptive technologies and explore new ways of thinking and working. We get out of the office and into the wild to observe first-hand what our customers most need to accelerate progress for the world. We observe, listen, prototype, experiment, analyze, learn, and iterate with passion and speed to fuel Fortive’s growth and build the future. We scout breakthrough ideas and emerging trends from an expansive network stretching from Seattle to Silicon Valley to Shanghai and beyond.\\n\\nThe Fort is built to make growth happen. We start up, we scale up, we shake things up. We face uncertainty head-on and wrestle it to the ground. We fail fast to move our customers forward. We move the needle so much it needs a new gauge. We turn What-if? into What’s next? and How might we? into Wow, we did that! If building a data-driven app in a matter of hours or pushing the frontiers of AI or IoT before lunch sounds like your kind of thing, The Fort just might be your kind of place.\\n\\nYour Impact\\nYou are collaborative, proactive, adaptable, and gritty. You excel at facilitating and reconciling inputs across teams. You balance a passion for deep understanding of innovation with the ability to deliver extraordinary results.\\n\\nThese are the traits we value:\\nAbility to Deliver Results: A track record for being able to set, meet and exceed expectations relative to data engineering.\\nEntrepreneurial Attitude: A proactive outlook that provides the chutzpah needed to overcome barriers, creatively problem solve, and challenge conventional thinking.\\n\\nComfort with Ambiguity: A willingness and aptitude for spending time in and thriving with deep uncertainty and environments where there is no clear “right answer”.\\n\\nPassion for Innovation: A demonstrated interest and desire to participate in innovation through personal study, on-the-job initiative, or other endeavors.\\nPositive Outlook: A desire to look past the challenged in search of the opportunity.\\n\\nEmpathy & a Teacher’s Mindset: The ability to teach and mentor effectively, successfully facilitate teams and different personalities in training sessions, and to care deeply about his/her colleague’s growth, understanding, and experience.\\nBias for Action: A need for speed; demonstrated ability to make decisions quickly and to act upon them.\\n\\nAlongside a team of entrepreneurial, high-performing, curious people, you’ll deliver breakthrough solutions to drive sustainable growth for Fortive. As a Data Engineer, you’ll drive execution and play a vital role in building a culture of innovation at Fortive. You will build, manage, and inspire alongside a multi-functional team, that solves for our toughest growth challenges\\n\\nResponsibilities:\\n\\nWork with data scientists to build ML pipelines using heterogeneous sources and provide engineering services for data science applications\\nDesign and implement data warehouses, real-time ETL, and batch processing of data to support modeling and reporting needs\\nWork with team to develop data expertise and resolve upstream issues relating to data quality\\nDefine best practices and design for the management of data\\nWith data scientists, build and maintain internal data processing and visualization tools\\nCreate tools to serve data such as APIs and packages\\nEnsure automation through CI/CD across platforms both in cloud and on-premises\\nAbility to research and assess open source technologies and components to recommend and integrate into the design and implementation\\n\\nRequired Qualifications:\\n\\nBachelor’s degree in CS, IT/IS, or a field related to a computational science and a minimum two years experience working as a data engineer\\nExperience managing data ETL processes and making data available through service applications and databases.\\nExperience working with query authoring, relational databases, and a familiarity with a variety of databases (Cassandra or Elasticsearch preferred). Ability to write efficient SQL queries\\nExperience (3+ years) with programming languages (Python, Java, R, and/or Scala preferred)\\nFamiliarity with a variety of data processing technologies (e.g. Spark, Kafka, Hadoop)\\nExcellent communication skills, including a knack for clear documentation\\nExperience with or knowledge of REST APIs and making data available through microservices.\\nExperience using version control (Git, Mercurial, SVN, etc.) for collaborative code development.\\nExperience with containerization and related technologies (e.g. Docker, Kubernetes)\\nFamiliarity with core provider services from AWS, Azure or GCP, preferably having supported deployments on one or more of these platforms\\nExperience working with MongoDB, PostgreSQL, and Redis\\nWorking knowledge of bash scripting and/or JavaScript\\nExperience with automation and configuration management\\nExpert level building pipelines using Apache Beam or Spark\\n\\nPreferred Qualifications\\n\\nMS or PhD in Computer Science or related technical field\\nAbility to architect data solutions. Knowledge of machine learning and data science processes\\nExperience supporting data science and analytical efforts is preferred\\nSome experience with frontend web-development\\nExperience defining and implementing APIs\\nSystem monitoring, alerting, and dashboarding experience\\nExperience developing, managing, and optimizing big data architectures and pipelines\\n\\nFortive (NYSE:FTV) is a diversified industrial growth company comprised of Professional Instrumentation and Industrial Technologies businesses that are recognized leaders in attractive markets. With 2018 revenues of $6.5 billion, $1.2 billion in operating profit, and a market cap of $26 billion, Fortive’s well-known brands hold leading positions in field instrumentation, transportation, sensing, product realization, automation and specialty, and franchise distribution.\\n\\nFortive is headquartered in Everett, Washington and employs a team of more than 26,000 research and development, manufacturing, sales, distribution, service and administrative employees in more than 50 countries around the world. With a culture rooted in continuous improvement, the core of our company’s operating model is the Fortive Business System.\\n\\nFortune Magazine ranks Fortive as a part of the “The Future 50” companies with the best prospects for long-term growth. For more information please visit: www.fortive.com.\\n\\nFortive is a global family of more than 20 industry-leading industrial growth and technology companies, united by a shared purpose: to make the world stronger, safer and more effective by providing essential technology for the people who accelerate progress. We take on big challenges that have real impact in fast-moving fields like software development, robotics, transportation, energy and healthcare.\\n\\nWith more than $6.5 billion in annual revenues and a culture rooted in Kaizen, or continuous improvement, Fortive is well positioned to create essential, technology-based solutions to solve the world’s most critical challenges. Our strong capability comes from a team of smart, motivated people who proudly deliver excellence in each of our outstanding brands in the areas of field instrumentation, transportation, sensing, product realization, automation and specialty, and franchise distribution.\\n\\nFortive is headquartered in Everett, Washington and employs a team of more than 26,000 research and development, sales, marketing, product development, innovation, and service employees in more than 50 countries around the world.\\nThis is a place where people who share a drive and passion to make a personal difference can learn, grow, and achieve. And that’s good... for you, for us, for growth.\\n\\nFor more information, please visit: www.fortive.com.\\n\"The company in which you have expressed employment interest is a subsidiary or affiliate of Fortive Corporation. The subsidiary or affiliate is referred to as a Fortive Company. Fortive Corporation and all Fortive Companies are equal opportunity employers that evaluate qualified applicants without regard to race, color, national origin, religion, ancestry, sex (including pregnancy, childbirth and related medical conditions), age, marital status, disability, veteran status, citizenship status, sexual orientation, gender identity or expression, and other characteristics protected by law. The \"EEO is the Law\" poster is available at: http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf. Individuals who need a reasonable accommodation because of a disability for any part of the employment process should call 1-866-272-5573 or e-mail applyassistance@fortive.com to request accommodation.\"  \n",
       "13  Overview\\nSDLC Partners is actively looking to hire Data Science/Data Engineering professionals. If you are an experienced Data Engineer or Data Scientist looking for a new opportunity in a growing organization, please apply.\\nResponsibilities\\nBuild the infrastructure to support coding, testing, processing, and maintaining data resources in support of the Data Science, analytics and reporting organizations using SQL, SQOOP, Python, Google Big Query, Kafka and other Big Data technologies.\\nCollaborate with Data Scientists in the development of predictive models using machine learning, natural language and statistical analysis methods.\\nIdentify, design and implement internal process improvements (automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc).\\nBuild analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.\\nWork with stakeholders to assist with data-related technical issues and support their data infrastructure needs.\\nDevelop, refine and oversee data management standards, including establishing and enforcing governance procedures and ensuring data integrity across multiple functions.\\nResponsible for owning data quality metrics and meeting defined data accuracy goals according to industry best practices.\\nQualifications\\nExperience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.\\nExperience with relational database design methodologies and authoring complex SQL queries\\nExperience with NoSQL database technologies (MongoDB, Cassandra, etc).\\nExperience with Agile Development and Agile Deployment tools and versioning using Git or similar tools.\\nExperience with Hadoop and other Big Data technologies such as Spark, PySpark and Kafka.\\nExperience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.\\nExperience with message queuing, stream processing, and highly scalable ‘big data’ data stores.\\nExperience building data pipelines utilizing Google Cloud platform.\\nExperience with git or other code repository tools Experience with Concourse or other CI/CD tools and methodologies.\\n3-5 years experience\\nGoogle Cloud Platform (GCS, BQ, etc), Apache Kafka, Python\\n\\nEDUCATION\\nMasters/Bachelor's Degree in Computer Science, Software Engineering, Information Systems or Information Technology or related field required, or equivalent experience\\n\\nSDLC Partners is a dynamic and fast-paced, privately held consulting firm with 400+ employees. We deliver customized digital solutions to transform organizations through our uniquely enabled talent, processes, and leadership. Through full scope partner, strategic, and improvement solutions, we give clients access to some of the best talent available across our service lines. We hire individuals who embody our goal to enable performance for our clients and we believe strongly in growing and developing talent.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "14  Position Overview\\nAt PNC, our people are our greatest differentiator and competitive advantage in the markets we serve. We are all united in delivering the best experience for our customers. As a Technology Engineer Sr. within PNC's ALM Risk organization, you will be based in one of the following locations:\\n\\n\\nPittsburgh, PA.\\n\\nCleveland, OH\\n\\nNew York, NY\\n\\nNew Jersey\\n\\nWashington D.C. area\\n\\nAtlanta, GA\\n\\nChicago, IL\\n\\nCharlotte, NC\\n\\nRaleigh, NC\\n\\n\\nRelocation assistance may be available for the for the selected candidate.\\n\\n\\nIn this contributor role you will support the Technology team partnering with the Balance Sheet Analytics & Modeling LOB, and requires specialized skills and experience with advanced computational and data science related technologies such as Python, SAS, SPARK, Hadoop and related stacks.\\n\\n\\n\\n\\nAt PNC, we are building our advanced computation and analytics platforms to support CECL and other subsequent BSAM usecase implementation and we are seeking a Sr. Data Engineer who will perform the following functions:\\n\\n\\nA self-starter who can align the technology solution with a business goal\\nDevelopment – Design and build database and data science solutions\\nData Modeling – Apply your expertise to help model structured and unstructured data. Own these models at a high level and consult with feature teams to help them model applications.\\nData Integration – Plan and build data integrations between systems. Figure out the best way to share information and build the tech needed to execute.\\nMentoring – Help teach other team members about data architecture, and also be a consultant for developers who need help with data.\\nEngineer reusable capabilities and pipelines for DML, DDL, maintenance, and ETL needs that can be shared across teams.\\nStay current on technical knowledge and tooling to help the team utilize new technologies.\\nEstablish scalable, efficient, automated processes for large scale data analysis and visualization\\nPerform data insights analysis using clustering, agglomerative clustering, graph based clustering, and analysis\\n\\nBasic Qualifications\\n\\n\\nMS with 2+ years of industry experience or Bachelors with 5+ years of experience in Quantitative field (Computer Science, Electrical/ Computer engineering, Financial Engineering, Mathematics, Statistics, Physics)\\n5+ years of enterprise-level scripting experience using languages (e.g. Python, SPARK, SCALA), or statistical/mathematical software (e.g. R, SAS)\\nExperience in creating data driven visualizations\\nHighly skilled in data and math/statistical methods (i.e. modeling, algorithms)\\n4+ years of experience in system analysis and data management engineering\\n3+ years of experience in database technologies: Oracle, Cassandra, or Mongo\\n2+ years of experience with DevOps, CI/CD\\nDemonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment\\n\\nPreferred Qualifications\\n\\n\\nExperience in processing, filtering, and presenting large quantities (Millions to Billions of rows) of data\\n2+ years of experience in AWS, Google Cloud, or MS Azure\\nExperience working with Financial, Insurance domains\\nStrongly prefer Experience in Data Science, Machine Learning, and/or Deep Learning\\nStrongly prefer prior Experience in programming languages such as Java, or C/C+\\nExperience with containerized solutions\\nExperience with SPARQL and other no-SQL data bases a plus\\nExperience with XML, XML Schema, XSLT\\nJob Description\\nLeads in the development of the most complex new and emerging technologies and selects appropriate platforms, integrates and configures solutions. Leverages technical knowledge and industry experience to design, build and maintain technology solutions.\\nDevelops software components and hardware for new and emerging technology projects; aligns these with business strategies and objectives.\\nConsults junior staff regarding complex issues and best practices.\\nProvides a systematic analysis on the most complex client requirements within the traceability framework and resolves any functional problems encountered.\\nOversees the quality of complex project deliverables while ensuring that they are in compliance with relevant standards and processes.\\nPNC Employees take pride in our reputation and to continue building upon that we expect our employees to be:\\nCustomer Focused - Knowledgeable of the values and practices that align customer needs and satisfaction as primary considerations in all business decisions and able to leverage that information in creating customized customer solutions.\\nManaging Risk - Assessing and effectively managing all of the risks associated with their business objectives and activities to ensure they adhere to and support PNC's Enterprise Risk Management Framework.\\nCompetencies\\nApplication Delivery Process – Knowledge of major tasks, deliverables, and formal application delivery methodologies; ability to utilize these in order to deliver new or enhanced applications.\\nConsulting – Knowledge of techniques, roles, and responsibilities in providing technical or business guidance to clients, both internal and external; ability to apply this knowledge appropriately to diverse situations.\\nEffectiveness Measurement – Ability to measure the quality and quantity of work effort for the purpose of improvement.\\nEmerging Technologies – Knowledge of and ability to design, apply and evaluate new information technologies for business environments in order to improve work productivity and accuracy.\\nIndustry Knowledge – Knowledge of the organization's industry group, trends, directions, major issues, regulatory considerations, and trendsetters; ability to apply this knowledge appropriately to diverse situations.\\nIT Industry: Trends & Directions – Knowledge of and ability to analyze marketplace experiences, developments and trends related to the function of Information Technology (IT).\\nIT Standards, Procedures & Policies – Knowledge of and the ability to utilize a variety of administrative skill sets and technical knowledge to manage organizational IT policies, standards, and procedures.\\nPlanning: Tactical, Strategic – Ability to contribute to operational (short term), tactical (1-2 years) and strategic (3-5 years) planning in support of the overall business plan.\\nProblem Solving – Knowledge of approaches, tools, techniques for recognizing, anticipating, and resolving organizational, operational or process problems; ability to apply this knowledge appropriately to diverse situations.\\nWork Experience\\nRoles at this level typically require a university / college degree, with 5+ years of industry-relevant experience. Specific certifications are often required. In lieu of a degree, a comparable combination of education and experience (including military service) may be considered.\\nEducation\\nBachelors\\nDisability Accommodations Statement:\\n\\nThe PNC workplace is inclusive and supportive of individual needs. If you have a physical or other impairment that might require an accommodation, including technical assistance with the PNC Careers website or submission process, please call 877-968-7762 and select Option 4: Recruiting or contact us via email at pathfinder@pnc.com.\\nThe Human Resources Service Center hours of operation are Monday - Friday 9:00 AM to 5:00 PM ET.\\nEqual Employment Opportunity (EEO):\\n\\nPNC provides equal employment opportunity to qualified persons regardless of race, color, sex, religion, national origin, age, sexual orientation, gender identity, disability, veteran status, or other categories protected by law.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "15  Join Accenture and help transform leading organizations and communities around the world. The sheer scale of our capabilities and client engagements and the way we collaborate, operate and deliver value provides an unparalleled opportunity to grow and advance. Choose Accenture, and make delivering innovative work part of your extraordinary career.\\n\\nAs part of our Data Business Group, you will lead technology innovation for our clients through robust delivery of world-class solutions. You will build better software better! There will never be a typical day and that’s why people love it here. The opportunities to make a difference within exciting client initiatives are unlimited in the ever-changing technology landscape. You will be part of a highly collaborative and growing network of technology and data experts, who are taking on today’s biggest, most complex business challenges using the latest data and analytics technologies. We will nurture your talent in an inclusive culture that values diversity. You will have an opportunity to work in roles such as Data Scientist, Data Engineer, or Chief Data Officer covering all aspects of Data including Data Management, Data Governance, Data Intelligence, Knowledge Graphs, and IoT. Come grow your career in Technology at Accenture!\\n\\n Why Should I Join the Accenture Team?\\nDrive innovation. People in our Client Delivery & Operations career track drive delivery and capability excellence through the design, development and/or delivery of a solution, service, capability or offering. They grow into delivery-focused roles, and can progress within their current role, laterally or upward.Learn and grow continuously: Follow personalized training to build skills, while expanding your experience defining and implementing solutions on complex client projects with a scope that is unsurpassed in industry.Thrive in our inclusive environment: Bring your whole self to a company that aims to be the most diverse in the world and delivers real-time performance feedback based on individual strengths—not stats.\\n\\nJob Description\\nData and Analytics professionals define strategies, develop and deliver solutions that enable the collection, processing and management of information from one or more sources, and the subsequent delivery of information to audiences in support of key business processes.\\nExtract, Transform and Load data primarily in Informatica with an emphasis on advocacy toward end-users to produce high quality software designs that are well-documented.\\nDemonstrate an understanding of technology and digital frameworks in the context of data integration utilizing Informatica.\\nEnsure code and design quality through the execution of test plans and assist in development of standards, methodology and repeatable processes, working closely with internal and external design, business, and technical counterparts.\\n\\nBasic Qualifications\\nMinimum 4 years of experience developing and implementing Informatica Powercenter or Informatica Data Quality\\nBachelor’s Degree or Associate’s Degree with 6 years of work experience or equivalent work experience of 12 years\\nPreferred Qualifications\\nExperience in ETL Tools in addition to Informatica, including Business Objects Data Services (BODS), DataStage, Ab Initio, Talend, and Pentaho\\nExperience with a full life-cycle development from functional design to deployment\\nDatabase experience (Teradata, Oracle, SQL Server, DB2, Azure SQL)\\nStrong knowledge and experience of SQL\\nUnderstanding of Entity relationship data models and Dimensional Models\\nExperience with development and production support\\nProfessional Skill Requirements\\n\\nIt is currently our objective to assign our people to work near where they live. However, given the nature of our business and our need to serve clients, our employees must be able to travel when needed. This role requires 100% flexibility to travel and work onsite with clients (typically Monday through Thursday).\\nProven success in contributing to a team-oriented environment\\nProven ability to work creatively and analytically in a problem-solving environment\\nDesire to work in an information systems environment\\nExcellent communication (written and oral) and interpersonal skills\\n\\nAll of our consulting professionals receive comprehensive training covering business acumen, technical and professional skills development. You'll also have opportunities to hone your functional skills and expertise in an area of specialization. We offer a variety of formal and informal training programs at every level to help you acquire and build specialized skills faster. Learning takes place both on the job and through formal training conducted online, in the classroom, or in collaboration with teammates. The sheer variety of work we do, and the experience it offers, provide an unbeatable platform from which to build a career.\\n\\n\\nApplicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status).\\n\\nCandidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.\\n\\nAccenture is an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities.\\n\\nEqual Employment Opportunity\\nAll employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "16  The National Robotics Engineering Center (NREC) at Carnegie Mellon University is looking for data scientists to develop tools to support machine learning and data-intensive applications. We are people with a desire to make robust software using agile development processes. You will work on a variety of software for commercial and government organizations. You will bring together open-source, commercial, internal, and your own tools to support diverse data processing workflows. Some of our machine learning software keeps self-driving vehicles safe, automatically discovers new pharmaceuticals, and leads to less waste in agriculture. You will support programs in deep learning for agriculture, artificial intelligence for defense, and autonomous manipulation.\\n\\nWhy NREC?\\nYou will have an impact in shaping the robotics revolution, collaborate with and learn from experts,and build your career in a very fast-growing field. As part of our team, you will develop solutions to solve industrial and government challenges, deploy your technology in real-world situations, work side-by-side with elite robotics experts, and develop a variety of cutting-edge technologies.\\n\\nHave an Impact!\\nRemove waste from farming = more food (link)\\nMake industrial processes environmentally friendly (link)\\nMake hazardous jobs safer (link)\\nImprove efficiency in industry & manufacturing (link)\\nAccelerate screening of pharmaceuticals (link)\\n\\nTake Control of Your Career!\\nSelect the career pathway that interests you\\nInfluence the direction of projects\\nSupportive of a non-standard schedule\\nMaintain work/life balance\\nSwitch between part-time and full-time as life demands\\n\\nNREC is at the center of the robotics ecosystem in Pittsburgh, PA. With over 60 robotics companies, Pittsburgh has become the robotics capital of the world. Geek Wire calls it Robotics Row; others call it Roboburgh. Join the leader in the most exciting time in robotics!\\n\\nJoin the best robotics R&D group\\nJoin our talented team at NREC, an operating unit within the world-renowned Robotics Institute at Carnegie Mellon University. NREC has 20+ years of experience and is globally renowned for developing and deploying robots into many applications across multiple sectors, such as agriculture, mining, defense, energy, and manufacturing. We strive to provide solutions for real world challenges where automation and robots have greater impact on productivity and improve the safety and comfort of the labor force. Our unique expertise places us at the forefront of unmanned ground vehicle design, autonomy, sensing and perception, machine learning, machine vision, operator assistance, 3D mapping and position estimation.\\n\\nWith over 120 robotics professionals, we can solve challenges that no other organization can.\\nNREC also leads in educational outreach through its Robotics Academy, which builds robotics curricula and software for K-12 and college-level students.\\n\\nYour primary responsibilities include:\\nDeveloping software for machine learning and data-science applications\\nArchitecting big-data pipelines\\nAdapting and integrating proprietary and open source software packages and APIs\\nData preparation, integration, verification\\nParticipating in the software process: design, code reviews, etc.\\nDeveloping, documenting, testing, and fixing software\\nSupporting development and acquisition of training and inference hardware\\nDevelopment in a Linux environment\\n\\nYou must be willing to travel for extended periods for field testing.\\n\\nQualifications:\\nB.S. in Computer Science, Engineering, Mathematics is required (Any more is a bonus)\\n3-5 years relevant experience is required.\\nDemonstrated understanding and use of software engineering concepts, practices, and procedures.\\nProficient development skills (Python preferred)\\nLinux development experience\\nTechnical communication skills\\nAbility to participate in a multi-disciplinary team\\n\\nWe especially want to hear from you if you have experience or qualifications in ANY of the following areas:\\nData infrastructure tools (SQL, NoSQL, data version control, etc.)\\nHigh performance computing tools (Hadoop, AWS, Azure, etc.)\\nModel training infrastructure tools (tensorflow, caffe, Petuum, etc.)\\nInference model deployment tools (Docker or other containerization, etc.)\\nCloud, high performance, and distributed computing\\nIngestion and integration of disparate sources\\nData processing (pre-processing, augmentation, post-processing)\\nTools and protocols for reproducible research and data analysis\\nFront end (Data visualization, exploration, labeling)\\nProficient Matlab or R skills\\nProficient C or C++ skills\\nProfessional software development processes\\nNetworking interfaces and applications\\nMixed software and hardware architecture\\nCMake, Valgrind, and other development tools\\nComputer vision, robotics, machine learning, scientific computing, simulation, or graphics\\n\\nAt NREC, we value diversity, support it, and thrive on it for the benefits of our organization, our employees and our community.\\n\\nMore Information\\n\\nPlease visit “Why Carnegie Mellon” to learn more about becoming part of an institution inspiring innovations that change the world. http://www.cmu.edu/jobs/why-cmu/index.html.\\n\\nA listing of employee benefits is available at: http://www.cmu.edu/jobs/benefits-at-a-glance/index.html.\\n\\nCarnegie Mellon University is an Equal Opportunity Employer/Disability/Veteran.\\nJob Function: Engineering\\n\\nPrimary Location: United States-Pennsylvania-Pittsburgh\\n\\nTime Type: Full Time\\n\\nOrganization: ROBOTICS\\n\\nMinimum Education Level: Bachelor's Degree or equivalent\\n\\nPreferred Education Level: Master's Degree or equivalent\\n\\nBudgeted Base Pay: Negotiable                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "17  We are looking for a SQL Data Engineer who has strong SQL skills and the desire to build a sustainable environment that can scale as a business grows. This position will provide the opportunity to build an environment from the ground to customer facing and experience the value of all the time and effort to a solution. You will have the ability to help guide and teach others on SQL optimization as required to improve performance on results and for the betterment of the SQL Server. You will work with Data Analysts, Pricing Analysts and Business Stakeholders to develop solutions to meet data needs.\\n\\nKey Responsibilities:\\nStrong Microsoft SQL Skills including but not limited to views, stored procedures and function creation and optimization\\nEnsure performance and availability of databases\\nETL knowledge and capability\\nData Modeling / Database Design\\nPerform baseline Microsoft SQL database administrative tasks\\nJob creations and failure monitoring\\nEvaluate datasets for quality and accuracy\\nSQL Training to others as needed\\nBachelor’s degree in Computer Science, Information Systems, or equivalent degree or strong industry experience.\\nStrong verbal and written communication skills\\n5-10 years experience in database development/design\\nKnowledge about SQL Server Integration Services and SQL Agent\\nExperience handling multiple concurrent complex activities within a technical environment and ability to project risks and escalate to managers appropriately\\nMust have strong analytical and problem solving skills\\nExperience with Office 365 products a plus\\nExperience with Power Bi a plus\\nExperience with AWS a plus\\nDemonstrate Thermo Fisher Scientific values – Integrity, Intensity, Innovation and Involvement\\n\\nAt Thermo Fisher Scientific, each one of our 50,000 extraordinary minds has a unique story to tell. Join us and contribute to our singular mission—enabling our customers to make the world healthier, cleaner and safer. Apply today\\n\\nThermo Fisher Scientific is an EEO/Affirmative Action Employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability or any other legally protected status.\\n\\n\\n\\n\\nIf you are an individual with a disability who requires reasonable accommodation to complete any part of our application process, for further assistance.\\nThermo Fisher Scientific is an EEO/Affirmative Action Employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability or any other legally protected status.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "18  Company :\\nHm Health Solutions Inc.\\nJob Description :\\nJOB SUMMARY\\nThis job architects and engineers solutions associated with analytic data for the organization and, working closely with the IT teams, assists with the design, build, and upkeep for these solutions. This includes creating pathways for analysts to access operational, derived, and external data sets. The incumbent is also responsible for the operation of Big Data Platforms as they are associated with analytic data discovery. Provides guidance and education for Intermediate contributors. Meets individually with customers for specific projects.\\nESSENTIAL RESPONSIBILITIES\\nResponsible for large functional efforts for data analytics programs across multiple disciplines with minimal guidance.\\nWorking closely with IT, architect and engineer solutions that provide views for the Analytic Data Warehouse. This would include the working with the proper teams, assisting with the design, building out the design, and providing upkeep for the solution.\\nAssemble, test, process, and maintain the Analytic Discovery Platform for the analytics organizations. This will include working to maintain pipelines with key analytic platforms throughout the organization.\\nWork with alternative analytic data systems to incorporate them into the operational data flow for the Analytics Teams. This may include products purchased by the organization that must be ingested or modeled/derived data maintained by analytic teams.\\nIndependently lead functional efforts for assigned projects with limited supervision. This include the guidance and education of Intermediate contributors within this team. Meet individually with customers for specific projects and attend with Intermediates for support.\\nOther duties as assigned.\\nEDUCATION\\nRequired\\nBachelor's Degree in Computer Systems Analysis, Data Processing, Healthcare Informatics, Management Information Systems, or related field\\nPreferred\\nMaster's Degree in related field\\nEXPERIENCE\\nRequired\\n3 - 5 years of Data Analytics experience\\nPreferred\\n1 - 3 years of Data Warehousing experience\\n1 - 3 years of Database Administration experience\\n5 - 7 years of Healthcare Industry experience\\nQUALIFICATIONS\\nProficient in the following areas:\\nAdvanced data analytic skills\\nAbility to perform data analytics for complex processes with complex business rules\\nAbility to translate complex data analytics results into information that can be used by senior executives to make decisions\\nPowerPoint skills\\nExcel skills\\nTableau skills for data analytics\\nUnderstands business drivers then use the information to provide the right data analytics to support the drivers\\nUnderstanding of our data and how to leverage it for analytics\\nUnderstanding of our business processes in order to interpret metric results and drive improvements in performance by leveraging demand capacity models, proactive monitoring, and predictive analysis\\nCalculating projections\\nBackground with data infrastructure including ETL, data warehouse, and tableau\\nCalculating projections\\nData infrastructure including ETL, data warehouse, and tableau\\nExpert analytical skills\\nLICENSES OR CERTIFICATIONS\\nRequired\\nNone\\nSKILLS\\nTableau for data analytics\\nMicrosoft Office\\nSAS is a plus\\nLanguage Requirement (other than English)\\nNone\\nTravel Requirement\\n0% - 25%\\nPHYSICAL, MENTAL DEMANDS and WORKING CONDITIONS\\nPosition Type\\nOffice-Based\\nTeaches / trains others regularly\\nOccasionally\\nTravel regularly from the office to various work sites or from site-to-site\\nRarely\\nEmployee Referral Level: 2\\nDisclaimer: The job description has been designed to indicate the general nature and essential duties and responsibilities of work performed by employees within this job title. It may not contain a comprehensive inventory of all duties, responsibilities, and qualifications required of employees to do this job.\\nCompliance Requirement: This position adheres to the ethical and legal standards and behavioral expectations as set forth in the code of business conduct and company policies.\\n-\\nHighmark Health and its affiliates prohibit discrimination against qualified individuals based on their status as protected veterans or individuals with disabilities, and prohibit discrimination against all individuals based on their race, color, religion, sex, national origin, sexual orientation/gender identity or any other category protected by applicable federal, state or local law. Highmark Health and its affiliates take affirmative action to employ and advance in employment individuals without regard to race, color, religion, sex, national origin, sexual orientation/gender identity, protected veteran status or disability.\\nEEO is The Law\\nEqual Opportunity Employer Minorities/Women/ProtectedVeterans/Disabled/Sexual Orientation/Gender Identity (http://www1.eeoc.gov/employers/upload/eeoc_self_print_poster.pdf)\\nWe endeavor to make this site accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact number below.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "19  Position Overview\\nAt PNC, our people are our greatest differentiator and competitive advantage in the markets we serve. We are all united in delivering the best experience for our customers. As a Data Engineer within PNC's AMG Engineering Team, you will be responsible to provide Data Products in the Big Data space to support our Wealth and Investment Management Business. This position will be based in Pittsburgh, PA. Successful Candidates will have the followiing skills:\\n\\nExtensive Data Modeling experience\\n\\nExtensive Experience with Relational Databases\\n\\nWell-versed scripting in Python / PySpark\\n\\nModerate to Advanced knowledge of Big Data storage concepts and strategies\\n\\nModerate to Advanced experience in Business Intelligence\\n\\nEfficient Data Structures\\n\\nRobust Visualizations\\n\\nExperience with one or more BI Platforms (Tableau, OBIEE, QlikView, Cognos, etc…)\\n\\nModerate understanding of Cloudera’s Hadoop Big Data Platform\\n\\nWorking Experience with NoSQL Databases\\n\\nFamiliarity with creation and maintenance of Oozie workflows\\n\\nExperience working on an agile team a plus\\nJob Description\\nDevelops, supports and implements data services for multiple applications to meet business objectives and user requirements. Uses technical knowledge and industry experience to design, build and maintain technology solutions.\\nWorks closely with users, developers, operations and business partners to define data service requirements and the data preparation process development.\\nDesigns and builds data service infrastructure on multiple data platforms, according to key business processes and the overall workflow.\\nDevelops and implements data solutions for multiple applications to ensure its scalability, availability and maintainability.\\nImplements data migration and transformation activities/processes to ensure the accuracy and security of data solutions.\\nPNC Employees take pride in our reputation and to continue building upon that we expect our employees to be:\\nCustomer Focused - Knowledgeable of the values and practices that align customer needs and satisfaction as primary considerations in all business decisions and able to leverage that information in creating customized customer solutions.\\nManaging Risk - Assessing and effectively managing all of the risks associated with their business objectives and activities to ensure they adhere to and support PNC's Enterprise Risk Management Framework.\\nCompetencies\\nApplication Delivery Process – Knowledge of major tasks, deliverables, and formal application delivery methodologies; ability to utilize these in order to deliver new or enhanced applications.\\nBig Data Management and Analytics – Knowledge and ability to plan and execute, big data management and analytics.\\nBusiness Intelligence – Knowledge of and ability to utilize business processes and technologies for gathering, storing, analyzing, and providing access to data that helps the organization make better business decisions.\\nData Analysis - Software – Knowledge of the investigation, evaluation, interpretation, and classification of data; the ability to identify, collect and analyze data to facilitate the development, implementation and application of software systems.\\nData Architecture – Knowledge and ability to create models and standards to govern which data is collected, and how it is stored, arranged, integrated, and put to use in data systems and in organizations.\\nDatabase Structures – Knowledge of and the ability to utilize appropriate database structures to organize and store data in a particular manner.\\nEffective Communications – Understanding of effective communication concepts, tools and techniques; ability to effectively transmit, receive, and accurately interpret ideas, information, and needs through the application of appropriate communication behaviors.\\nProblem Solving – Knowledge of approaches, tools, techniques for recognizing, anticipating, and resolving organizational, operational or process problems; ability to apply this knowledge appropriately to diverse situations.\\nSoftware Development Life Cycle – Knowledge of and experience with using a structured methodology for delivering new or enhanced software products to the marketplace.\\nWork Experience\\nRoles at this level typically require a university / college degree, with 3+ years of relevant / direct industry experience. Certifications are often desired. In lieu of a degree, a comparable combination of education and experience (including military service) may be considered.\\nEducation\\nBachelors\\nDisability Accommodations Statement:\\n\\nThe PNC workplace is inclusive and supportive of individual needs. If you have a physical or other impairment that might require an accommodation, including technical assistance with the PNC Careers website or submission process, please call 877-968-7762 and select Option 4: Recruiting or contact us via email at pathfinder@pnc.com.\\nThe Human Resources Service Center hours of operation are Monday - Friday 9:00 AM to 5:00 PM ET.\\nEqual Employment Opportunity (EEO):\\n\\nPNC provides equal employment opportunity to qualified persons regardless of race, color, sex, religion, national origin, age, sexual orientation, gender identity, disability, veteran status, or other categories protected by law.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Descriptions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Descriptions_df.to_csv('Descriptions_df_DE_Pittsburgh.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
