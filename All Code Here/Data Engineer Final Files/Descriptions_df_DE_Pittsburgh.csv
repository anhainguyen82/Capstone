,Title,Location,City,State,Zip,Country,Qualifications,Skills,Responsibilities,Education,Requirement,FullDescriptions
0,Big Data Developer,"Pittsburgh, PA",Pittsburgh,PA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"You are curious, persistent, logical and clever – a true techie at heart. You enjoy living by the code of your craft and developing elegant solutions for complex problems. If this sounds like you, this could be the perfect opportunity to join EPAM as a Big Data Developer. Scroll down to learn more about the position’s responsibilities and requirements.

We are looking for a Big Data Engineer that will work on the collecting, storing, processing, and analyzing of large sets of data. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. You will also be responsible for integrating them with the architecture used across the company.
#Financial_Services
What You Have
A degree in an associated field and/or other advanced certification along with significant experience
Proficient understanding of distributed computing principles
Management of Hadoop cluster (Cloudera preferred), with all included services
Ability to solve any ongoing issues with operating the cluster
Proficiency with Hadoop v2, MapReduce, HDFS, Sqoop
Experience with building stream-processing systems, using solutions such as Storm or Spark-Streaming
Good knowledge of big data querying tools, such as Pig, Hive, and Impala
Experience with Spark
Experience with integration of data from multiple data sources such as MS SQL Server, Oracle
Good understanding of SQL queries, joins, stored procedures, relational schemas
Experience with NoSQL databases, such as HBase, Cassandra, MongoDB (preferred)
Knowledge of various ETL techniques and frameworks, such as Flume
Experience with various messaging systems, such as Kafka or RabbitMQ
Experience with Cloudera
FS domain knowledge is a big plus but not required
What We Offer
Medical, Dental and Vision Insurance (Subsidized)
Health Savings Account
Flexible Spending Accounts (Healthcare, Dependent Care, Commuter)
Short-Term and Long-Term Disability (Company Provided)
Life and AD&D Insurance (Company Provided)
Employee Assistance Program
Unlimited access to LinkedIn learning solutions
Matched 401(k) Retirement Savings Plan
Paid Time Off
Legal Plan and Identity Theft Protection
Accident Insurance
Employee Discounts
Pet Insurance"
1,Senior Data Engineer,"Pittsburgh, PA 15213",Pittsburgh,PA,15213,None Found,None Found,None Found,None Found,None Found,None Found,"Company Overview
At Proofpoint, we have a passion for protecting people, data, and brands from today’s advanced threats and compliance risks. We hire the best people in the business to: Build and enhance our proven security platform; blend innovation and speed in a constantly evolving cloud architecture; analyze new threats and offer deep insight through data-driven intel; collaborate with customers to help solve their toughest security challenges.

We are singularly devoted to helping our customers protect what matters most. That’s why we’re a leader in next-generation cybersecurity—and why more than half of the Fortune 100 trust us as a security partner.

We are seeking a Senior Data Engineer to join our growing team in Pittsburgh. If you've ever wanted to work for an innovative software company, in great environment with great people, this is your chance. We’re a security software-as-a-service company so you’ll be involved both in our day-to-day software development as well as getting exposure to our security efforts.

Q: Ok. Who are you?
A: We’re comprised of some really smart white hat security hackers, researchers from CMU, software developers and lot of hard working and friendly faces. We also really like data. We really value creating an inclusive, transparent, empathetic, and communicative culture.

Q: What would I be working on?
A: You know all those data breaches you hear about in the news? Most of them started when a bad guy targeted an employee with a phishing attack. Our customers are mostly large enterprise organizations that are under attack by some pretty nasty bad guys. They use our platform to deliver security education to their employees and figure out who needs extra help. Your job will be to make our customers' experience of reporting on the results of their security awareness program as wonderful as possible.

Q: Can you tell me a little more about your product?
A: Sure, we have several different ways that we can deliver security training to end users as well as several different ways to assess their security knowledge. One of the really fun ways we test the user is thinking like the bad guys. We send the end users a simulated phishing message. If they fall for it (they click our link, open our attachment, etc.), we show them training right away. It's an unconventional approach to changing user behavior and it works (hint: we have data). Proofpoint is in a growing space to say the least. If you ever wanted to learn more about cyber security and cutting-edge attacks, this is the place to do it. You’ll get to help simulate evil, figure out how to fight evil, and give our customers data that they can use to protect their organization.

Your day to day
Perform development tasks related to delivering Qlik Sense applications, including design, implementation, testing and deployment
Comfortable with defining/implementing application and database architectures
Work with Product Managers and Quality Engineers to ensure the delivery of great, high-quality features
Investigate, prototype and recommend new technologies and solutions
What you bring to the team
BS/BA in a software related field or incredible experience that makes us not care about a degree.
2+ years’ experience of Qlik Sense development (or a combination of Qlik Sense and QlikView experience).
You should have solid experience developing within Qlik Sense (or potentially QlikView). Preferably 2-4 years of experience in both native and mashup environments.
The ability to diagnose and address performance bottlenecks in Qlik.
You should possess an intermediate to advanced knowledge of SQL in either PostgreSQL or MySQL environments (or both). For instance, what are the different kinds of JOINs and when would you use each? What is a window function and why would you use one? What's a CTE? What are some features that are available in MySQL that aren't available in PostgreSQL or vice versa.
Have exposure to either MySQL or PostgreSQL environments, preferably MySQL 5.7 and PostgreSQL 10.
At least an intermediate understanding of a HA Qlik deployment. For instance, what's the difference between a central node and a proxy node? How would you begin setting up such an environment or communicating with DevOps around the requirements for such an environment?
Experience in data modeling for both relational and analytical systems. What's the difference between 3NF and a star schema? When would it be appropriate to use one kind of model versus another? What are some of the kinds of slowly changing dimensions? In Qlik specifically, how do you approach creating a data model for high performance?
Experience with additional BI applications such as PowerBI and Logi. Have you ever created reports or visualizations for an end user using one of these applications (or others)?
Familiarity with AWS is a plus, especially including a subset of the following services: RDS, EC2, S3, Data Pipeline, SNS, Kinesis, Lambda, DynamoDB, EMR, Redshift, and Elasticsearch.
Comfort in working across multiple operating systems, including macOS and Windows.
Comfortable with Git for version control.
Can work independently and thrives with autonomy.
Why Proofpoint

As a customer focused and driven-to-win organization with leading edge products, there are many exciting reasons to join the Proofpoint team. We believe in hiring the best the brightest and cultivating a culture of collaboration and appreciation. As we continue to grow and expand globally, we understand that hiring the right people and treating them well is key to our success! We are a multi-national company with locations in 10 countries, with each location contributing to Proofpoint’s amazing culture!"
2,Data Engineer Sr,"Pittsburgh, PA 15222",Pittsburgh,PA,15222,None Found,None Found,None Found,None Found,None Found,None Found,"Position Overview
At PNC, our people are our greatest differentiator and competitive advantage in the markets we serve. We are all united in delivering the best experience for our customers.


As a Data Engineer Senior (hadoop) within PNC's Technology and Innovation organization, can be based in Pittsburgh, PA; Cleveland or Columbus, OH; Dallas, TX; Overland Park, KS; or within any PNC footprint nationwide


The following skills are preferred:

Experience in Hadoop Architecture & Data Engineering – Cloudera preferred
Extensive experience in Data Engineering – Spark, HIVE, Map Reduce, Sqoop, Kafka, NiFi, etc.
Proficiency in writing SQL on mainstream RDBMSs like Oracle, Teradata etc.
Technical lead and mentoring/coaching experience

The following skills are a plus:

Hands on experience with large Data Warehousing (Hadoop) implementations
Proficiency with ingestion tools, Sqoop, Kafka, NiFi, etc.
Agile software development environment experience
Job Description
Leads in developing, supporting and implementing data solutions for multiple applications in order to meet business objectives and user requirements. Leverages technical knowledge and industry experience to design, build and maintain technology solutions.
Leads data requirement analysis and the data preparation process development for targeted data solutions.
Leads in designing and building data service infrastructure on multiple data platforms, according the workflow.
Oversees the development and implementation of data solutions for multiple applications to ensure its scalability, availability and maintainability.
Consults on data migration and transformation to ensure the accuracy and security of data solutions.
PNC Employees take pride in our reputation and to continue building upon that we expect our employees to be:
Customer Focused - Knowledgeable of the values and practices that align customer needs and satisfaction as primary considerations in all business decisions and able to leverage that information in creating customized customer solutions.
Managing Risk - Assessing and effectively managing all of the risks associated with their business objectives and activities to ensure they adhere to and support PNC's Enterprise Risk Management Framework.
Competencies
Application Delivery Process – Knowledge of major tasks, deliverables, and formal application delivery methodologies; ability to utilize these in order to deliver new or enhanced applications.
Big Data Management and Analytics – Knowledge and ability to plan and execute, big data management and analytics.
Business Intelligence – Knowledge of and ability to utilize business processes and technologies for gathering, storing, analyzing, and providing access to data that helps the organization make better business decisions.
Consulting – Knowledge of techniques, roles, and responsibilities in providing technical or business guidance to clients, both internal and external; ability to apply this knowledge appropriately to diverse situations.
Data Analysis - Software – Knowledge of the investigation, evaluation, interpretation, and classification of data; the ability to identify, collect and analyze data to facilitate the development, implementation and application of software systems.
Data Architecture – Knowledge and ability to create models and standards to govern which data is collected, and how it is stored, arranged, integrated, and put to use in data systems and in organizations.
Database Structures – Knowledge of and the ability to utilize appropriate database structures to organize and store data in a particular manner.
Problem Solving – Knowledge of approaches, tools, techniques for recognizing, anticipating, and resolving organizational, operational or process problems; ability to apply this knowledge appropriately to diverse situations.
Software Development Life Cycle – Knowledge of and experience with using a structured methodology for delivering new or enhanced software products to the marketplace.
Work Experience
Roles at this level typically require a university / college degree, with 5+ years of industry-relevant experience. Specific certifications are often required. In lieu of a degree, a comparable combination of education and experience (including military service) may be considered.
Education
Bachelors
Disability Accommodations Statement:

The PNC workplace is inclusive and supportive of individual needs. If you have a physical or other impairment that might require an accommodation, including technical assistance with the PNC Careers website or submission process, please call 877-968-7762 and select Option 4: Recruiting or contact us via email at pathfinder@pnc.com.
The Human Resources Service Center hours of operation are Monday - Friday 9:00 AM to 5:00 PM ET.
Equal Employment Opportunity (EEO):

PNC provides equal employment opportunity to qualified persons regardless of race, color, sex, religion, national origin, age, sexual orientation, gender identity, disability, veteran status, or other categories protected by law."
3,Technology Engineer Sr,"Pittsburgh, PA 15289",Pittsburgh,PA,15289,None Found,None Found,None Found,None Found,None Found,None Found,"Position Overview

At PNC, our people are our greatest differentiator and competitive advantage in the markets we serve. We are all united in delivering the best experience for our customers. As a Technology Engineer Sr. within PNC's ALM Risk organization, you will be based in one of the following locations: Pittsburgh, PA. Cleveland, OH New York, NY New Jersey Washington D.C. area Atlanta, GA Chicago, IL Charlotte, NC Raleigh, NC Relocation assistance may be available for the for the selected candidate. In this contributor role you will support the Technology team partnering with the Balance Sheet Analytics & Modeling LOB, and requires specialized skills and experience with advanced computational and data science related technologies such as Python, SAS, SPARK, Hadoop and related stacks. At PNC, we are building our advanced computation and analytics platforms to support CECL and other subsequent BSAM usecase implementation and we are seeking a Sr. Data Engineer who will perform the following functions: •A self-starter who can align the technology solution with a business goal •Development – Design and build database and data science solutions •Data Modeling – Apply your expertise to help model structured and unstructured data. Own these models at a high level and consult with feature teams to help them model applications. •Data Integration – Plan and build data integrations between systems. Figure out the best way to share information and build the tech needed to execute. •Mentoring – Help teach other team members about data architecture, and also be a consultant for developers who need help with data. •Engineer reusable capabilities and pipelines for DML, DDL, maintenance, and ETL needs that can be shared across teams. •Stay current on technical knowledge and tooling to help the team utilize new technologies. •Establish scalable, efficient, automated processes for large scale data analysis and visualization •Perform data insights analysis using clustering, agglomerative clustering, graph based clustering, and analysis Basic Qualifications •MS with 2+ years of industry experience or Bachelors with 5+ years of experience in Quantitative field (Computer Science, Electrical/ Computer engineering, Financial Engineering, Mathematics, Statistics, Physics) •5+ years of enterprise-level scripting experience using languages (e.g. Python, SPARK, SCALA), or statistical/mathematical software (e.g. R, SAS) •Experience in creating data driven visualizations •Highly skilled in data and math/statistical methods (i.e. modeling, algorithms) •4+ years of experience in system analysis and data management engineering •3+ years of experience in database technologies: Oracle, Cassandra, or Mongo •2+ years of experience with DevOps, CI/CD •Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment Preferred Qualifications •Experience in processing, filtering, and presenting large quantities (Millions to Billions of rows) of data •2+ years of experience in AWS, Google Cloud, or MS Azure •Experience working with Financial, Insurance domains •Strongly prefer Experience in Data Science, Machine Learning, and/or Deep Learning •Strongly prefer prior Experience in programming languages such as Java, or C/C+ •Experience with containerized solutions •Experience with SPARQL and other no-SQL data bases a plus •Experience with XML, XML Schema, XSLT

Job Profile

Leads in the development of the most complex new and emerging technologies and selects appropriate platforms, integrates and configures solutions. Leverages technical knowledge and industry experience to design, build and maintain technology solutions.
Develops software components and hardware for new and emerging technology projects; aligns these with business strategies and objectives.
Consults junior staff regarding complex issues and best practices.
Provides a systematic analysis on the most complex client requirements within the traceability framework and resolves any functional problems encountered.
Oversees the quality of complex project deliverables while ensuring that they are in compliance with relevant standards and processes.
PNC Employees take pride in our reputation and to continue building upon that we expect our employees to be:
Customer Focused - Knowledgeable of the values and practices that align customer needs and satisfaction as primary considerations in all business decisions and able to leverage that information in creating customized customer solutions.
Managing Risk - Assessing and effectively managing all of the risks associated with their business objectives and activities to ensure they adhere to and support PNC's Enterprise Risk Management Framework.
Competencies
Application Delivery Process – Knowledge of major tasks, deliverables, and formal application delivery methodologies; ability to utilize these in order to deliver new or enhanced applications.
Consulting – Knowledge of techniques, roles, and responsibilities in providing technical or business guidance to clients, both internal and external; ability to apply this knowledge appropriately to diverse situations.
Effectiveness Measurement – Ability to measure the quality and quantity of work effort for the purpose of improvement.
Emerging Technologies – Knowledge of and ability to design, apply and evaluate new information technologies for business environments in order to improve work productivity and accuracy.
Industry Knowledge – Knowledge of the organization's industry group, trends, directions, major issues, regulatory considerations, and trendsetters; ability to apply this knowledge appropriately to diverse situations.
IT Industry: Trends & Directions – Knowledge of and ability to analyze marketplace experiences, developments and trends related to the function of Information Technology (IT).
IT Standards, Procedures & Policies – Knowledge of and the ability to utilize a variety of administrative skill sets and technical knowledge to manage organizational IT policies, standards, and procedures.
Planning: Tactical, Strategic – Ability to contribute to operational (short term), tactical (1-2 years) and strategic (3-5 years) planning in support of the overall business plan.
Problem Solving – Knowledge of approaches, tools, techniques for recognizing, anticipating, and resolving organizational, operational or process problems; ability to apply this knowledge appropriately to diverse situations.

Work Experience

Roles at this level typically require a university / college degree, with 5+ years of industry-relevant experience. Specific certifications are often required. In lieu of a degree, a comparable combination of education and experience (including military service) may be considered.

Education

Bachelors

Disability Accommodations Statement

The PNC workplace is inclusive and supportive of individual needs. If you have a physical or other impairment that might require an accommodation, including technical assistance with the PNC Careers website or submission process, please call 877-968-7762 and select Option 4: Recruiting or contact us via email at pathfinder@pnc.com. The Human Resources Service Center hours of operation are Monday - Friday 9:00 AM to 5:00 PM ET.

Equal Employment Opportunity (EEO)

PNC provides equal employment opportunity to qualified persons regardless of race, color, sex, religion, national origin, age, sexual orientation, gender identity, disability, veteran status, or other categories protected by law."
4,"Senior Data Engineer, Analytics","Warrendale, PA 15086",Warrendale,PA,15086,None Found,None Found,None Found,None Found,None Found,"
5 + years of experience designing data models
10 + years of experience implementing data models and data architecture
Experience with debugging, performance profiling and optimization of data at each phase of the data pipeline
Demonstrated analytical capabilities paired with a strong initiative to find ways to improve the analysis and communication of complex data
Specific experience with Microsoft SQL Server Reporting Services (SSRS) and SQL Server toolset. Candidates with extensive experience in other BI/reporting/analytics toolsets may be considered if they have a commitment to learning SSRS and a demonstrated ability to ramp up to proficiency rather quickly (within 2 months) in a primarily self-directed way
Proficiency in either Tableau, SSRS or Power BI is required
Capable of designing complex and performant SQL queries
","Description:
As a member of the Digital Solutions and Data and Analytics IT team, this person will be working with various teams to design solutions related to the data pipeline, with special emphasis on data modeling and design.

This role demands a strong knowledge and understanding of the data and the business requirements to build robust, scalable data models, which may be relational as well as dimensional. The role entails having the capability of relating and understanding existing and in-development data models/schemas and the business context they represent.

Responsibilities


Establish design principles for data models and create modeling standards
Document, create and maintain logical and physical database models as per the standards
Work with the business as well as the technical teams to understand the requirements, to create models that cater to the requirements
Work on understanding various data domains, to map and integrate disparate data from a variety of source systems
Support Analytics development from and to a variety of database systems
Facilitate data requirements conversation with business and technical stakeholders resolving conflicts to drive decisions and consensus
Establish and maintain comprehensive data model documentation including detailed descriptions of business entities, attributes, and data relationships as well as the definition of business rules governing the integrity, archiving, and audit requirements of the data
Analyze existing systems using manual or automated data analysis/profiling to reverse engineer data requirements
Determine suitable data modeling approach for each project based on business requirements for data capture and access
Assist developers with complex query development and performance optimization
Performs additional duties as required
Provide subject matter expertise (technical and business context) input and feedback to data/BI teams and development scrum teams as needed.
Identify, communicate, and mitigate risks related to including invalid data, invalid data calculations, formulas or derived insights, and misrepresentation of or otherwise confusing visual representations of data.

Requirements:
Technical


5 + years of experience designing data models
10 + years of experience implementing data models and data architecture
Experience with debugging, performance profiling and optimization of data at each phase of the data pipeline
Demonstrated analytical capabilities paired with a strong initiative to find ways to improve the analysis and communication of complex data
Specific experience with Microsoft SQL Server Reporting Services (SSRS) and SQL Server toolset. Candidates with extensive experience in other BI/reporting/analytics toolsets may be considered if they have a commitment to learning SSRS and a demonstrated ability to ramp up to proficiency rather quickly (within 2 months) in a primarily self-directed way
Proficiency in either Tableau, SSRS or Power BI is required
Capable of designing complex and performant SQL queries

Professional


Excellent interpersonal and organizational acumen by collaborating with both internal team members and external business stakeholders
Internally motivated, able to work proficiently both independently and in a team environment
Strong written and verbal communication skills with staff and leadership at all levels of seniority and technical experience
Bachelor’s Degree or higher (Computer Science, Engineering, Human Computer Interaction/Design, or similar/relevant field)
Motivated to “stay current” with technical change/commit to professional development to learn relevant new skills/tools/methodologies

Desired Additional Competencies


Experience with relational database design, SQL DDL, performance tuning relating to indexes, etc.
Experience with non-relational “noSQL” data sources
Experience with ETL processes and tools
Healthcare industry experience not required but a significant plus (supply chain, provider, payer, medical device, life-science, pharmacy, etc.)
Experience with other data/BI tools, especially within the Microsoft ecosystem

"
5,Data Engineer,"Coraopolis, PA 15108",Coraopolis,PA,15108,None Found,None Found,None Found,None Found,None Found,None Found,"The Data Engineer is a key member of a platform team that contributes to software design, development and overall product lifecycle for a product that delights our users and adds value to the organization. The engineering process is highly collaborative. The Data Engineer is expected to pair on a daily basis as they work through user stories and support products as they evolve. In addition, the Data Engineer may be involved in product configuration, performance tuning and testing as well as production monitoring. As a Data Engineer, you will be part of a team with more experienced engineers to help build and grow your skills while you create, support, and deploy production applications.

Qualifications
Build the infrastructure to support coding, testing, processing, and maintaining data resources in support of the Data Science, analytics and reporting organizations using SQL, SQOOP, Python, Google Big Query, Kafka and other Big Data technologies.
Collaborate with Data Scientists in the development of predictive models using machine learning, natural language and statistical analysis methods.
Design and implement internal process improvements (automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc).

Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.

Work with stakeholders to assist with data-related technical issues and support their data infrastructure needs.

Develop, refine and oversee data management standards, including establishing and enforcing governance procedures and ensuring data integrity across multiple functions. Responsible for owning data quality metrics and meeting defined data accuracy goals according to industry best practices.

Bachelor's Degree - Computer Science, Software Engineering, Information Systems or Information Technology or related field required, or equivalent experience

1-3 years of experience

Google Cloud Platform (GCS, BQ, etc), Apache Kafka, Python
Experience with NoSQL database technologies (MongoDB, Cassandra, etc)

Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.


#LI-BT1-L"
6,Senior Data Engineer,"Coraopolis, PA 15108",Coraopolis,PA,15108,None Found,None Found,None Found,None Found,None Found,None Found,"The Senior Data Engineer is a key member of a platform team that contributes to software design, development and overall product lifecycle for a product that delights our users and adds value to the organization. The engineering process is highly collaborative. The Senior Data Engineer is expected to pair on a daily basis as they work through user stories and support products as they evolve. In addition, the Senior Data Engineer may be involved in product configuration, performance tuning and testing as well as production monitoring. As a Senior Data Engineer, you will be part of a team with more experienced engineers to help build and grow your skills while you create, support, and deploy production applications.
Qualifications
Build the infrastructure to support coding, testing, processing, and maintaining data resources in support of the Data Science, analytics and reporting organizations using SQL, SQOOP, Python, Google Big Query, Kafka and other Big Data technologies.

Collaborate with Data Scientists in the development of predictive models using machine learning, natural language and statistical analysis methods.

Identify, design and implement internal process improvements (automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc).
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders to assist with data-related technical issues and support their data infrastructure needs.
Develop, refine and oversee data management standards, including establishing and enforcing governance procedures and ensuring data integrity across multiple functions. Responsible for owning data quality metrics and meeting defined data accuracy goals according to industry best practices.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc. Experience with relational database design methodologies and authoring complex SQL queries
Experience with NoSQL database technologies (MongoDB, Cassandra, etc) Experience with Agile Development and Agile Deployment tools and versioning using Git or similar tools
Experience with Hadoop and other Big Data technologies such as Spark, PySpark and Kafka Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.
Experience with message queuing, stream processing, and highly scalable ‘big data’ data stores. Experience building data pipelines utilizing Google Cloud platform.
Experience with git or other code repository tools Experience with Concourse or other CI/CD tools and methodologies.

Bachelor's Degree

Computer Science, Software Engineering, Information Systems or Information Technology or related field required, or equivalent experience


3-5 years experience

Google Cloud Platform (GCS, BQ, etc), Apache Kafka, Python

#LI-BT1-L"
7,Data Engineer,"West Mifflin, PA 15122",West Mifflin,PA,15122,None Found,None Found,"Familiarity with building and optimizing data pipelines, architectures, and datasets
Familiarity with data virtualization, transformation, and various data structures
Familiarity with high performance computing
Developer technologies:
Software management tools including those for testing, continuous integration, version control, debugging, profiling, and compiler optimization
Environment Management:
Data management and file systems
System metrics and monitoring
Job scheduler, resource allocation and job/workflow management",None Found,None Found,"BS degree in engineering or Bachelor's degree in a science related field from an accredited college or university and a minimum of four years relevant experience; or
MS degree in engineering or Master's degree in a science related field from an accredited college or university and a minimum of two years relevant experience
Experience with relational databases, query authoring, programming, and hardware/software troubleshooting.
","Description
The Naval Nuclear Laboratory seeks a talented and innovative Data Engineer to join a growing team dedicated to delivering data-driven solutions to the organization. As a data engineer, you will be responsible for developing, constructing, testing, and delivering Program data infrastructure needs. Specifically, the data engineer will help to assess existing data infrastructure hardware and software, and work with key stakeholders to identify, assess, implement, and test improvements to the data infrastructure. The data engineer will interface with data scientists and others at the Laboratory to ensure dataset reporting, querying, and analysis capabilities are based upon reliable, efficient, and scalable data infrastructure. The data engineer will participate in continuous data engineering training programs as well as develop and review corporate policies, instructions, and implementation principles related to data infrastructure and its use in the Program. We develop the world's best nuclear propulsion systems, train Sailors, to operate them, and provide full lifecycle support, from technology development through design to disposal.
Responsibilities:
Interface with technology and support organizations to create, adapt, maintain, and test optimal Program data pipeline architectures
Assemble large, complex datasets that meet functional business requirements
Identify, design, and implement internal data infrastructure process improvements such as automating manual processes, optimizing data delivery, redesigning infrastructure for greater scalability, and opportunities for data acquisition
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using various technologies
Work with stakeholders to assist with data-related technical issues and support their data infrastructure needs
Create consistent data infrastructure solutions and access for users at multiple sites
Assist management in prioritizing projects
Deliver data engineering training
Continuous learning and improvement of skills needed to keep current with state-of-the-art data architectures
Develop and review corporate policies, instructions, and principles related to data infrastructure and its use in the Program
Requirements
Advanced:
BS degree in engineering or Bachelor's degree in a science related field from an accredited college or university and a minimum of four years relevant experience; or
MS degree in engineering or Master's degree in a science related field from an accredited college or university and a minimum of two years relevant experience
Experience with relational databases, query authoring, programming, and hardware/software troubleshooting.
Senior:
BS degree in engineering or Bachelor's degree in a science related field from an accredited college or university and a minimum of six years relevant experience; or
MS degree in engineering or Master's degree in a science related field from an accredited college or university and a minimum of four years relevant experience
Experience with relational databases, query authoring, programming, and hardware/software troubleshooting
Preferred Skills
Familiarity with building and optimizing data pipelines, architectures, and datasets
Familiarity with data virtualization, transformation, and various data structures
Familiarity with high performance computing
Developer technologies:
Software management tools including those for testing, continuous integration, version control, debugging, profiling, and compiler optimization
Environment Management:
Data management and file systems
System metrics and monitoring
Job scheduler, resource allocation and job/workflow management"
8,Assistant/Associate Professor,"Pittsburgh, PA",Pittsburgh,PA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Assistant/Associate Professor
SCI-Office of the Dean - Pennsylvania-Pittsburgh - (18001834)

School of Computing and Information Department of Information Culture and Data Stewardship Non-Tenure-Track Faculty Position in Data Stewardship The School of Computing and Information (http://www.ischool.pitt.edu) at the University of Pittsburgh is seeking to fill a faculty position in Data Stewardship at an Assistant/Associate Professor level - Position #0134534 (Non-Tenure Stream). The initial appointment is expected to be three years with consideration for renewal. We are looking for an experienced practitioner and scholar in Data Stewardship who can demonstrate an in-depth understanding of data curation, data documentation and data preservation, specifically: • Current best practices and policy surrounding active data management through the data lifecycle, including data collection, data management plans, data storage, data quality and reproducibility • Experience of handling research data including application of date standards and formats, data description and documentation, metadata schema for disciplinary data, data citation and persistent identifiers, data publication, data analysis, data visualization, data re-use and metrics • Contemporary good practice in data selection and appraisal, data infrastructure including data repository software platforms, and long-term data preservation strategies • An awareness of diverse disciplinary data practices, research workflows and workflow platforms, as well as an in-depth knowledge of particular domain(s). The University of Pittsburgh School is a top-ranked information school (iSchool) offering a wide variety of multidisciplinary opportunities, including an undergraduate program (BSIS), Master's programs in information science (MSIS), telecommunications & networking (MST), library & information science (MLIS), and Ph.D. programs, The new Data Stewardship Pathway for graduate students studying for the MLIS, draws on the concept of ""translational data science"", described by Lyon & Brenner (2015) as: ""the enhanced transition of skills, software tools and intelligence from the iSchool to the marketplace, Which may be interpreted as industry, government, libraries, archives or data centers"". Adopting a translational perspective will enable iSchools to supply and deploy data talent and data products more rapidly to the range of consumers, where there Is currently an acknowledged workforce need"". Development of the Data Stewardship Pathway has been further informed by the results of two small-scale studies, which featured an analysis of requirements for real-world positions in each of the six data science roles (data archivist, data librarian, data steward/ curator, data analyst, data engineer and data journalist) and which highlighted the knowledge, skills and competencies being sought by employers (Lyon, Mattern, Acker & Langmead 2016; Lyon & Mattern 2016). We expect candidates for this position to possess strong experience within the broader data community or in professional data curation environments and to have excellent interpersonal, communication and team skills. The new faculty member is expected to be able to liaise and collaborate with disciplinary faculty and researchers across a range of Schools ahd Departments in the University, but also with the regional, national and international data community. The University is actively addressing the development and adoption of research data management infrastructure, working through the Data Management Committee and administration support services on campus. The successful candidate will contribute to the Data Stewardship Pathway through both research and teaching undergrad and post-graduate students, and will be expected to demonstrate an awareness of current data developments, trends, challenges, emerging fields and a positive commitment to research. As the School offers an online degree program in addition to oncampus programs:, candidates with complementary expertise and experience

Candidates applying for the position(s) are expected to hold an earned Doctorate or the equivalent in academic or professional experience. Applicants should present a record of effective teaching, research, and related scholarly activities. Electronic applications should be sent to https://ischoolatpitt.wufoo.com/forms/faculty-position-in-data-stewardship/. Applications should include a cover letter, curriculum vitae, research statement, teaching statement, and the names, addresses (with e-mail), and telephone numbers of three references. For full consideration, applications must be received by February 15, 2017. Questions about the position should be directed to Dr. Richard Cox Chair of Search Committee School of Computing and Information University of Pittsburgh The University of Pittsburgh is an Affirmative Action, Equal Opportunity Employer Minorities/Women/Vets/Disabled.

Assignment Category Fulltime-Regular
Campus Pittsburgh
Child Protection Clearances The following PA Act 153 clearances and background checks may be required prior to commencement of employment and as a condition of continued employment: PA State Police Criminal Record Check, FBI Criminal Record Check, PA Child Abuse History Clearance.
Required Attachments Other (see posting for additional details)"
9,"Senior Data Engineer, Enterprise Data/Integration","Warrendale, PA 15086",Warrendale,PA,15086,None Found,None Found,None Found,None Found,None Found,None Found,"Description:
About Intalere
Intalere is the essential partner for operational excellence in healthcare offering customized solutions that address customers’ individual needs by assisting in managing their entire non-labor spend, providing innovative technologies, products and services, and leveraging the best practices of a provider-led model.

Intalere strives to create a high-performance work environment and to maintain our position as an employer of choice. Our Total Rewards benefit package reflects our values of Integrity, Passion, Accountability, Innovation and Excellence.

Description
As a member of the Digital Solutions and Data and Analytics IT team, this person will be a technical lead for data modeling, data integration and data wrangling between various internal and external applications to provide the data foundation for a suite of enterprise applications, business intelligence reporting, analytics and data science focused in cloud environment.

This role demands critical thinking and problem-solving skills to utilize best practices and technology experience to create innovative solutions to create a leading-edge data and analytics products.

This role demands a strong technical integration skillset as well as broader understanding of relational and nonrelational data structures in a hybrid cloud environment.

The senior data engineer will not just implement ETL and other integration solutions via tools like SQL Server Integration Services (SSIS); they will also be responsible for designing the integrations, utilizing technical best practices as well as their analytical skills to obtain a full understanding of underlying data and functional needs/requirements.

Responsibilities

Design and develop new data integrations between our hybrid cloud environment as well as lead data ingestion.

Lead requirements analysis efforts relating to implementing new integrations via direct communication with technical and non-technical stakeholders.

Maintain extensive existing set of SSIS packages:

Troubleshoot SSIS packages when there are failures (evaluate cause, determine and test solution, implement solution) and provide communication to stakeholders during outage as well as document the situation after it is resolved to support retrospectives/knowledge sharing.
Iteratively enhance SSIS packages for performance improvement.
Adjust scheduling of package execution as need arises.
Adjust packages when underlying data schemas/file formats change.

Contribute to team knowledge sharing/training efforts.

Develop a strong understanding of Intalere and customer data models/context.

Provide subject matter expertise (technical and business context) input and feedback to data/BI teams and development scrum teams as needed.

Identify, communicate, and mitigate integration/ETL risks. .

Requirements:
Technical
5+years of experience architecting integration/ETL processes or managing enterprise databases
2+ years of experience with data solutions in Microsoft Azure
Experience with Azure Data Factory (ADF)
Experience with Azure Data Lake
Experience with PowerShell or Terraform
Demonstrated ability to quickly learn/understand and discuss data formats/models/standards
Experience with debugging, performance profiling and optimization of integration/ETL processes
Experience developing database objects such as stored procedures, triggers, constraints and indexes
Capable of designing and tuning complex SQL queries
Specific experience with Microsoft SQL Server Integration Services (SSIS) packages and toolset
Candidates with extensive experience in other ETL and integration toolsets may be considered if they have a commitment to learning SSIS and a demonstrated ability to ramp up to proficiency rather quickly (within 2 months) in a primarily self-directed way

Professional
Excellent interpersonal and organizational acumen with regard to collaborating with both internal team members and external business stakeholders
Strong analytical and critical thinking skills
Internally motivated, able to work proficiently both independently and in a team environment
Strong written and verbal communication skills with staff and leadership at all levels of seniority and technical experience
Bachelor’s Degree or higher (Computer Science, Engineering, or similar/relevant field)
Motivated to “stay current” with technical change/commit to professional development to learn relevant new skills/tools/methodologies

Desired Additional Competencies
Healthcare industry experience not required but a significant plus (supply chain, provider, payer, medical device, life-science, pharmacy, etc.)
Experience developing business insights from complex data sources
Experience with non-relational “noSQL” data sources
Experience with Azure Data Bricks
Experience with Tableau
Experience with other data/BI tools, especially within the Microsoft ecosystem (SQL Server Reporting Services (SSRS), Power BI, Power Query, DAX, R)"
10,Data Engineer (PDP),"Pittsburgh, PA",Pittsburgh,PA,None Found,None Found,None Found,None Found,None Found,None Found,"
Experience with:
Oracle technologies including Oracle database and ODI
Cloud-based data warehouse technologies such as Snowflake and open source ETL technologies such as Snaplogic.
","This position will support our Postsecondary Data Partnership (PDP) project and will be located in our Pittsburgh Collaboration Center.

If you are a self-starter, thrive in a fast-paced environment, and get energized about driving new data driven services, then this job is for you!

The Clearinghouse is seeking a hands-on Data Engineer with a solid background in Data Warehouse architectures, metadata management, data profiling, data modeling, data quality and a proven ability to learn quickly, effectively collaborate with others, and successfully design and implement solutions. Using their excellent communication and presentation skills, the Engineer socializes technical concepts and builds consensus with internal stakeholders.

The Data Engineer reports to the Manager, Application Development and works with the business and development teams to design and implement the appropriate data solutions for Clearinghouse database-driven applications and services. The Engineer accomplishes this by performing data analysis of current and future systems and services, educating on industry best practices and policies, creating proposed database component designs and data models, and working with the architecture and development teams to refine and implement these designs.

How You Contribute:
Develop and maintain the PL/SQL Packages.
Develop and maintain ETL code.
Design Data Marts and create data models.
Work with Data owners to document and maintain Data Dictionary.
Develop scripts to maintain data quality and deploying data changes across different environments
Monitor, assess and optimize data processing performance.
Demonstrate NSC’s competencies, which align with our corporate values.
Core Competencies include: Customer Focus, Optimizes Work Processes, Collaborates, Communicates Effectively, and Be Open and Authentic.
Manager will provide more detail as needed.
Position may be required to perform other duties as required. These essential functions are representative of those that must be met by an employee to successfully perform the job. Reasonable accommodations will be made to enable individuals with disabilities to perform these essential functions.

What You Bring to the Table:
Bachelor’s degree required in Computer Science, Systems Engineering, or Information Systems, or some equivalent combination of education and experience, including through military service.
Proficient in:
PL/SQL programming, typically acquired through 4-7 years of experience programming with this technology.
Developing scripts using Shell, Perl or similar language.
Experience working on an Agile/Scrum development team.
Proficient with:
Data Warehouse production maintenance.
ETL development using products such as Oracle Data Integrator.
OLTP and data warehouse design.
Metadata management.
Creating and implementing data models.
Database performance monitoring and SQL optimization.
Excellent communication skills.
Demonstrated ability to work independently and directly with the data owners to gather requirements and architect change.
Live within a commutable distance of Pittsburgh, PA.
Additional Desired Requirements:

Experience with:
Oracle technologies including Oracle database and ODI
Cloud-based data warehouse technologies such as Snowflake and open source ETL technologies such as Snaplogic.
Physical Demands:
Use of a computer terminal and/or laptop computer for 8 or more hours a day.
Use of a copy machine, and telephone.
Frequently required to sit for 7 or more hours per day in close proximity to others in an open office environment.
Occasionally required to use hands and fingers to operate, handle, and reach.
Vision abilities include close vision and the ability to adjust focus.
NSC strives to hire, promote, and retain the best qualified individuals for our employment opportunities. Our policies are intended to provide equal employment opportunity for all employees and job applicants without regard to race, color, religion, gender, gender identity, sexual orientation, age, disability, national origin, protected veteran status, or any other status protected by law. NSC strives to have a culture that is diverse and equally welcoming to all. As a Federal contractor, NSC is subject to requirements to take affirmative action to employ and advance in employment protected Veterans and individuals with disabilities. NSC is committed to its outreach efforts and practices to promote employment and advancement of members of these groups. To read our entire policy, go to: https://studentclearinghouse.info/careers/human-resource-policies
PAY TRANSPARENCY POLICY NSC will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by NSC, or (c) consistent with the NSC’s legal duty to furnish information. 41 C.F.R. 60-1.35(c)
Please view Equal Employment Opportunity Posters provided by OFCCP here."
11,Data Engineer Sr,"Pittsburgh, PA 15289",Pittsburgh,PA,15289,None Found,None Found,None Found,None Found,None Found,None Found,"Position Overview

At PNC, our people are our greatest differentiator and competitive advantage in the markets we serve. We are all united in delivering the best experience for our customers. As a Data Engineer Senior (hadoop) within PNC's Technology and Innovation organization, can be based in Pittsburgh, PA; Cleveland or Columbus, OH; Dallas, TX; Overland Park, KS; or within any PNC footprint nationwide The following skills are preferred: •Experience in Hadoop Architecture & Data Engineering – Cloudera preferred •Extensive experience in Data Engineering – Spark, HIVE, Map Reduce, Sqoop, Kafka, NiFi, etc. •Proficiency in writing SQL on mainstream RDBMSs like Oracle, Teradata etc. •Technical lead and mentoring/coaching experience The following skills are a plus: •Hands on experience with large Data Warehousing (Hadoop) implementations •Proficiency with ingestion tools, Sqoop, Kafka, NiFi, etc. •Agile software development environment experience

Job Profile

Leads in developing, supporting and implementing data solutions for multiple applications in order to meet business objectives and user requirements. Leverages technical knowledge and industry experience to design, build and maintain technology solutions.
Leads data requirement analysis and the data preparation process development for targeted data solutions.
Leads in designing and building data service infrastructure on multiple data platforms, according the workflow.
Oversees the development and implementation of data solutions for multiple applications to ensure its scalability, availability and maintainability.
Consults on data migration and transformation to ensure the accuracy and security of data solutions.
PNC Employees take pride in our reputation and to continue building upon that we expect our employees to be:
Customer Focused - Knowledgeable of the values and practices that align customer needs and satisfaction as primary considerations in all business decisions and able to leverage that information in creating customized customer solutions.
Managing Risk - Assessing and effectively managing all of the risks associated with their business objectives and activities to ensure they adhere to and support PNC's Enterprise Risk Management Framework.
Competencies
Application Delivery Process – Knowledge of major tasks, deliverables, and formal application delivery methodologies; ability to utilize these in order to deliver new or enhanced applications.
Big Data Management and Analytics – Knowledge and ability to plan and execute, big data management and analytics.
Business Intelligence – Knowledge of and ability to utilize business processes and technologies for gathering, storing, analyzing, and providing access to data that helps the organization make better business decisions.
Consulting – Knowledge of techniques, roles, and responsibilities in providing technical or business guidance to clients, both internal and external; ability to apply this knowledge appropriately to diverse situations.
Data Analysis - Software – Knowledge of the investigation, evaluation, interpretation, and classification of data; the ability to identify, collect and analyze data to facilitate the development, implementation and application of software systems.
Data Architecture – Knowledge and ability to create models and standards to govern which data is collected, and how it is stored, arranged, integrated, and put to use in data systems and in organizations.
Database Structures – Knowledge of and the ability to utilize appropriate database structures to organize and store data in a particular manner.
Problem Solving – Knowledge of approaches, tools, techniques for recognizing, anticipating, and resolving organizational, operational or process problems; ability to apply this knowledge appropriately to diverse situations.
Software Development Life Cycle – Knowledge of and experience with using a structured methodology for delivering new or enhanced software products to the marketplace.

Work Experience

Roles at this level typically require a university / college degree, with 5+ years of industry-relevant experience. Specific certifications are often required. In lieu of a degree, a comparable combination of education and experience (including military service) may be considered.

Education

Bachelors

Disability Accommodations Statement

The PNC workplace is inclusive and supportive of individual needs. If you have a physical or other impairment that might require an accommodation, including technical assistance with the PNC Careers website or submission process, please call 877-968-7762 and select Option 4: Recruiting or contact us via email at pathfinder@pnc.com. The Human Resources Service Center hours of operation are Monday - Friday 9:00 AM to 5:00 PM ET.

Equal Employment Opportunity (EEO)

PNC provides equal employment opportunity to qualified persons regardless of race, color, sex, religion, national origin, age, sexual orientation, gender identity, disability, veteran status, or other categories protected by law."
12,Data Engineer,"Pittsburgh, PA",Pittsburgh,PA,None Found,None Found,"
Bachelor’s degree in CS, IT/IS, or a field related to a computational science and a minimum two years experience working as a data engineer
Experience managing data ETL processes and making data available through service applications and databases.
Experience working with query authoring, relational databases, and a familiarity with a variety of databases (Cassandra or Elasticsearch preferred). Ability to write efficient SQL queries
Experience (3+ years) with programming languages (Python, Java, R, and/or Scala preferred)
Familiarity with a variety of data processing technologies (e.g. Spark, Kafka, Hadoop)
Excellent communication skills, including a knack for clear documentation
Experience with or knowledge of REST APIs and making data available through microservices.
Experience using version control (Git, Mercurial, SVN, etc.) for collaborative code development.
Experience with containerization and related technologies (e.g. Docker, Kubernetes)
Familiarity with core provider services from AWS, Azure or GCP, preferably having supported deployments on one or more of these platforms
Experience working with MongoDB, PostgreSQL, and Redis
Working knowledge of bash scripting and/or JavaScript
Experience with automation and configuration management
Expert level building pipelines using Apache Beam or Spark
",None Found,"
Work with data scientists to build ML pipelines using heterogeneous sources and provide engineering services for data science applications
Design and implement data warehouses, real-time ETL, and batch processing of data to support modeling and reporting needs
Work with team to develop data expertise and resolve upstream issues relating to data quality
Define best practices and design for the management of data
With data scientists, build and maintain internal data processing and visualization tools
Create tools to serve data such as APIs and packages
Ensure automation through CI/CD across platforms both in cloud and on-premises
Ability to research and assess open source technologies and components to recommend and integrate into the design and implementation
",None Found,None Found,"The Fort is the new hub for innovation and incubation at Fortive. We have the backing of a large company and the soul of a startup (a Fortune 500 startup, that is), and this is the place where that flame burns brightest.

At The Fort, we combine forces to deploy disruptive technologies and explore new ways of thinking and working. We get out of the office and into the wild to observe first-hand what our customers most need to accelerate progress for the world. We observe, listen, prototype, experiment, analyze, learn, and iterate with passion and speed to fuel Fortive’s growth and build the future. We scout breakthrough ideas and emerging trends from an expansive network stretching from Seattle to Silicon Valley to Shanghai and beyond.

The Fort is built to make growth happen. We start up, we scale up, we shake things up. We face uncertainty head-on and wrestle it to the ground. We fail fast to move our customers forward. We move the needle so much it needs a new gauge. We turn What-if? into What’s next? and How might we? into Wow, we did that! If building a data-driven app in a matter of hours or pushing the frontiers of AI or IoT before lunch sounds like your kind of thing, The Fort just might be your kind of place.

Your Impact
You are collaborative, proactive, adaptable, and gritty. You excel at facilitating and reconciling inputs across teams. You balance a passion for deep understanding of innovation with the ability to deliver extraordinary results.

These are the traits we value:
Ability to Deliver Results: A track record for being able to set, meet and exceed expectations relative to data engineering.
Entrepreneurial Attitude: A proactive outlook that provides the chutzpah needed to overcome barriers, creatively problem solve, and challenge conventional thinking.

Comfort with Ambiguity: A willingness and aptitude for spending time in and thriving with deep uncertainty and environments where there is no clear “right answer”.

Passion for Innovation: A demonstrated interest and desire to participate in innovation through personal study, on-the-job initiative, or other endeavors.
Positive Outlook: A desire to look past the challenged in search of the opportunity.

Empathy & a Teacher’s Mindset: The ability to teach and mentor effectively, successfully facilitate teams and different personalities in training sessions, and to care deeply about his/her colleague’s growth, understanding, and experience.
Bias for Action: A need for speed; demonstrated ability to make decisions quickly and to act upon them.

Alongside a team of entrepreneurial, high-performing, curious people, you’ll deliver breakthrough solutions to drive sustainable growth for Fortive. As a Data Engineer, you’ll drive execution and play a vital role in building a culture of innovation at Fortive. You will build, manage, and inspire alongside a multi-functional team, that solves for our toughest growth challenges

Responsibilities:

Work with data scientists to build ML pipelines using heterogeneous sources and provide engineering services for data science applications
Design and implement data warehouses, real-time ETL, and batch processing of data to support modeling and reporting needs
Work with team to develop data expertise and resolve upstream issues relating to data quality
Define best practices and design for the management of data
With data scientists, build and maintain internal data processing and visualization tools
Create tools to serve data such as APIs and packages
Ensure automation through CI/CD across platforms both in cloud and on-premises
Ability to research and assess open source technologies and components to recommend and integrate into the design and implementation

Required Qualifications:

Bachelor’s degree in CS, IT/IS, or a field related to a computational science and a minimum two years experience working as a data engineer
Experience managing data ETL processes and making data available through service applications and databases.
Experience working with query authoring, relational databases, and a familiarity with a variety of databases (Cassandra or Elasticsearch preferred). Ability to write efficient SQL queries
Experience (3+ years) with programming languages (Python, Java, R, and/or Scala preferred)
Familiarity with a variety of data processing technologies (e.g. Spark, Kafka, Hadoop)
Excellent communication skills, including a knack for clear documentation
Experience with or knowledge of REST APIs and making data available through microservices.
Experience using version control (Git, Mercurial, SVN, etc.) for collaborative code development.
Experience with containerization and related technologies (e.g. Docker, Kubernetes)
Familiarity with core provider services from AWS, Azure or GCP, preferably having supported deployments on one or more of these platforms
Experience working with MongoDB, PostgreSQL, and Redis
Working knowledge of bash scripting and/or JavaScript
Experience with automation and configuration management
Expert level building pipelines using Apache Beam or Spark

Preferred Qualifications

MS or PhD in Computer Science or related technical field
Ability to architect data solutions. Knowledge of machine learning and data science processes
Experience supporting data science and analytical efforts is preferred
Some experience with frontend web-development
Experience defining and implementing APIs
System monitoring, alerting, and dashboarding experience
Experience developing, managing, and optimizing big data architectures and pipelines

Fortive (NYSE:FTV) is a diversified industrial growth company comprised of Professional Instrumentation and Industrial Technologies businesses that are recognized leaders in attractive markets. With 2018 revenues of $6.5 billion, $1.2 billion in operating profit, and a market cap of $26 billion, Fortive’s well-known brands hold leading positions in field instrumentation, transportation, sensing, product realization, automation and specialty, and franchise distribution.

Fortive is headquartered in Everett, Washington and employs a team of more than 26,000 research and development, manufacturing, sales, distribution, service and administrative employees in more than 50 countries around the world. With a culture rooted in continuous improvement, the core of our company’s operating model is the Fortive Business System.

Fortune Magazine ranks Fortive as a part of the “The Future 50” companies with the best prospects for long-term growth. For more information please visit: www.fortive.com.

Fortive is a global family of more than 20 industry-leading industrial growth and technology companies, united by a shared purpose: to make the world stronger, safer and more effective by providing essential technology for the people who accelerate progress. We take on big challenges that have real impact in fast-moving fields like software development, robotics, transportation, energy and healthcare.

With more than $6.5 billion in annual revenues and a culture rooted in Kaizen, or continuous improvement, Fortive is well positioned to create essential, technology-based solutions to solve the world’s most critical challenges. Our strong capability comes from a team of smart, motivated people who proudly deliver excellence in each of our outstanding brands in the areas of field instrumentation, transportation, sensing, product realization, automation and specialty, and franchise distribution.

Fortive is headquartered in Everett, Washington and employs a team of more than 26,000 research and development, sales, marketing, product development, innovation, and service employees in more than 50 countries around the world.
This is a place where people who share a drive and passion to make a personal difference can learn, grow, and achieve. And that’s good... for you, for us, for growth.

For more information, please visit: www.fortive.com.
""The company in which you have expressed employment interest is a subsidiary or affiliate of Fortive Corporation. The subsidiary or affiliate is referred to as a Fortive Company. Fortive Corporation and all Fortive Companies are equal opportunity employers that evaluate qualified applicants without regard to race, color, national origin, religion, ancestry, sex (including pregnancy, childbirth and related medical conditions), age, marital status, disability, veteran status, citizenship status, sexual orientation, gender identity or expression, and other characteristics protected by law. The ""EEO is the Law"" poster is available at: http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf. Individuals who need a reasonable accommodation because of a disability for any part of the employment process should call 1-866-272-5573 or e-mail applyassistance@fortive.com to request accommodation."""
13,Data Engineer,"Pittsburgh, PA 15222",Pittsburgh,PA,15222,None Found,"Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Experience with relational database design methodologies and authoring complex SQL queries
Experience with NoSQL database technologies (MongoDB, Cassandra, etc).
Experience with Agile Development and Agile Deployment tools and versioning using Git or similar tools.
Experience with Hadoop and other Big Data technologies such as Spark, PySpark and Kafka.
Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.
Experience with message queuing, stream processing, and highly scalable ‘big data’ data stores.
Experience building data pipelines utilizing Google Cloud platform.
Experience with git or other code repository tools Experience with Concourse or other CI/CD tools and methodologies.
3-5 years experience
Google Cloud Platform (GCS, BQ, etc), Apache Kafka, Python",None Found,"Build the infrastructure to support coding, testing, processing, and maintaining data resources in support of the Data Science, analytics and reporting organizations using SQL, SQOOP, Python, Google Big Query, Kafka and other Big Data technologies.
Collaborate with Data Scientists in the development of predictive models using machine learning, natural language and statistical analysis methods.
Identify, design and implement internal process improvements (automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc).
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders to assist with data-related technical issues and support their data infrastructure needs.
Develop, refine and oversee data management standards, including establishing and enforcing governance procedures and ensuring data integrity across multiple functions.
Responsible for owning data quality metrics and meeting defined data accuracy goals according to industry best practices.",None Found,None Found,"Overview
SDLC Partners is actively looking to hire Data Science/Data Engineering professionals. If you are an experienced Data Engineer or Data Scientist looking for a new opportunity in a growing organization, please apply.
Responsibilities
Build the infrastructure to support coding, testing, processing, and maintaining data resources in support of the Data Science, analytics and reporting organizations using SQL, SQOOP, Python, Google Big Query, Kafka and other Big Data technologies.
Collaborate with Data Scientists in the development of predictive models using machine learning, natural language and statistical analysis methods.
Identify, design and implement internal process improvements (automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc).
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders to assist with data-related technical issues and support their data infrastructure needs.
Develop, refine and oversee data management standards, including establishing and enforcing governance procedures and ensuring data integrity across multiple functions.
Responsible for owning data quality metrics and meeting defined data accuracy goals according to industry best practices.
Qualifications
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Experience with relational database design methodologies and authoring complex SQL queries
Experience with NoSQL database technologies (MongoDB, Cassandra, etc).
Experience with Agile Development and Agile Deployment tools and versioning using Git or similar tools.
Experience with Hadoop and other Big Data technologies such as Spark, PySpark and Kafka.
Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.
Experience with message queuing, stream processing, and highly scalable ‘big data’ data stores.
Experience building data pipelines utilizing Google Cloud platform.
Experience with git or other code repository tools Experience with Concourse or other CI/CD tools and methodologies.
3-5 years experience
Google Cloud Platform (GCS, BQ, etc), Apache Kafka, Python

EDUCATION
Masters/Bachelor's Degree in Computer Science, Software Engineering, Information Systems or Information Technology or related field required, or equivalent experience

SDLC Partners is a dynamic and fast-paced, privately held consulting firm with 400+ employees. We deliver customized digital solutions to transform organizations through our uniquely enabled talent, processes, and leadership. Through full scope partner, strategic, and improvement solutions, we give clients access to some of the best talent available across our service lines. We hire individuals who embody our goal to enable performance for our clients and we believe strongly in growing and developing talent."
14,Technology Engineer Sr,"Pittsburgh, PA 15222",Pittsburgh,PA,15222,None Found,None Found,None Found,None Found,None Found,None Found,"Position Overview
At PNC, our people are our greatest differentiator and competitive advantage in the markets we serve. We are all united in delivering the best experience for our customers. As a Technology Engineer Sr. within PNC's ALM Risk organization, you will be based in one of the following locations:


Pittsburgh, PA.

Cleveland, OH

New York, NY

New Jersey

Washington D.C. area

Atlanta, GA

Chicago, IL

Charlotte, NC

Raleigh, NC


Relocation assistance may be available for the for the selected candidate.


In this contributor role you will support the Technology team partnering with the Balance Sheet Analytics & Modeling LOB, and requires specialized skills and experience with advanced computational and data science related technologies such as Python, SAS, SPARK, Hadoop and related stacks.




At PNC, we are building our advanced computation and analytics platforms to support CECL and other subsequent BSAM usecase implementation and we are seeking a Sr. Data Engineer who will perform the following functions:


A self-starter who can align the technology solution with a business goal
Development – Design and build database and data science solutions
Data Modeling – Apply your expertise to help model structured and unstructured data. Own these models at a high level and consult with feature teams to help them model applications.
Data Integration – Plan and build data integrations between systems. Figure out the best way to share information and build the tech needed to execute.
Mentoring – Help teach other team members about data architecture, and also be a consultant for developers who need help with data.
Engineer reusable capabilities and pipelines for DML, DDL, maintenance, and ETL needs that can be shared across teams.
Stay current on technical knowledge and tooling to help the team utilize new technologies.
Establish scalable, efficient, automated processes for large scale data analysis and visualization
Perform data insights analysis using clustering, agglomerative clustering, graph based clustering, and analysis

Basic Qualifications


MS with 2+ years of industry experience or Bachelors with 5+ years of experience in Quantitative field (Computer Science, Electrical/ Computer engineering, Financial Engineering, Mathematics, Statistics, Physics)
5+ years of enterprise-level scripting experience using languages (e.g. Python, SPARK, SCALA), or statistical/mathematical software (e.g. R, SAS)
Experience in creating data driven visualizations
Highly skilled in data and math/statistical methods (i.e. modeling, algorithms)
4+ years of experience in system analysis and data management engineering
3+ years of experience in database technologies: Oracle, Cassandra, or Mongo
2+ years of experience with DevOps, CI/CD
Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment

Preferred Qualifications


Experience in processing, filtering, and presenting large quantities (Millions to Billions of rows) of data
2+ years of experience in AWS, Google Cloud, or MS Azure
Experience working with Financial, Insurance domains
Strongly prefer Experience in Data Science, Machine Learning, and/or Deep Learning
Strongly prefer prior Experience in programming languages such as Java, or C/C+
Experience with containerized solutions
Experience with SPARQL and other no-SQL data bases a plus
Experience with XML, XML Schema, XSLT
Job Description
Leads in the development of the most complex new and emerging technologies and selects appropriate platforms, integrates and configures solutions. Leverages technical knowledge and industry experience to design, build and maintain technology solutions.
Develops software components and hardware for new and emerging technology projects; aligns these with business strategies and objectives.
Consults junior staff regarding complex issues and best practices.
Provides a systematic analysis on the most complex client requirements within the traceability framework and resolves any functional problems encountered.
Oversees the quality of complex project deliverables while ensuring that they are in compliance with relevant standards and processes.
PNC Employees take pride in our reputation and to continue building upon that we expect our employees to be:
Customer Focused - Knowledgeable of the values and practices that align customer needs and satisfaction as primary considerations in all business decisions and able to leverage that information in creating customized customer solutions.
Managing Risk - Assessing and effectively managing all of the risks associated with their business objectives and activities to ensure they adhere to and support PNC's Enterprise Risk Management Framework.
Competencies
Application Delivery Process – Knowledge of major tasks, deliverables, and formal application delivery methodologies; ability to utilize these in order to deliver new or enhanced applications.
Consulting – Knowledge of techniques, roles, and responsibilities in providing technical or business guidance to clients, both internal and external; ability to apply this knowledge appropriately to diverse situations.
Effectiveness Measurement – Ability to measure the quality and quantity of work effort for the purpose of improvement.
Emerging Technologies – Knowledge of and ability to design, apply and evaluate new information technologies for business environments in order to improve work productivity and accuracy.
Industry Knowledge – Knowledge of the organization's industry group, trends, directions, major issues, regulatory considerations, and trendsetters; ability to apply this knowledge appropriately to diverse situations.
IT Industry: Trends & Directions – Knowledge of and ability to analyze marketplace experiences, developments and trends related to the function of Information Technology (IT).
IT Standards, Procedures & Policies – Knowledge of and the ability to utilize a variety of administrative skill sets and technical knowledge to manage organizational IT policies, standards, and procedures.
Planning: Tactical, Strategic – Ability to contribute to operational (short term), tactical (1-2 years) and strategic (3-5 years) planning in support of the overall business plan.
Problem Solving – Knowledge of approaches, tools, techniques for recognizing, anticipating, and resolving organizational, operational or process problems; ability to apply this knowledge appropriately to diverse situations.
Work Experience
Roles at this level typically require a university / college degree, with 5+ years of industry-relevant experience. Specific certifications are often required. In lieu of a degree, a comparable combination of education and experience (including military service) may be considered.
Education
Bachelors
Disability Accommodations Statement:

The PNC workplace is inclusive and supportive of individual needs. If you have a physical or other impairment that might require an accommodation, including technical assistance with the PNC Careers website or submission process, please call 877-968-7762 and select Option 4: Recruiting or contact us via email at pathfinder@pnc.com.
The Human Resources Service Center hours of operation are Monday - Friday 9:00 AM to 5:00 PM ET.
Equal Employment Opportunity (EEO):

PNC provides equal employment opportunity to qualified persons regardless of race, color, sex, religion, national origin, age, sexual orientation, gender identity, disability, veteran status, or other categories protected by law."
15,ETL Informatica Engineer,"Pittsburgh, PA 15220",Pittsburgh,PA,15220,None Found,"Minimum 4 years of experience developing and implementing Informatica Powercenter or Informatica Data Quality
Bachelor’s Degree or Associate’s Degree with 6 years of work experience or equivalent work experience of 12 years",None Found,None Found,None Found,"
It is currently our objective to assign our people to work near where they live. However, given the nature of our business and our need to serve clients, our employees must be able to travel when needed. This role requires 100% flexibility to travel and work onsite with clients (typically Monday through Thursday).
Proven success in contributing to a team-oriented environment
Proven ability to work creatively and analytically in a problem-solving environment
Desire to work in an information systems environment
Excellent communication (written and oral) and interpersonal skills","Join Accenture and help transform leading organizations and communities around the world. The sheer scale of our capabilities and client engagements and the way we collaborate, operate and deliver value provides an unparalleled opportunity to grow and advance. Choose Accenture, and make delivering innovative work part of your extraordinary career.

As part of our Data Business Group, you will lead technology innovation for our clients through robust delivery of world-class solutions. You will build better software better! There will never be a typical day and that’s why people love it here. The opportunities to make a difference within exciting client initiatives are unlimited in the ever-changing technology landscape. You will be part of a highly collaborative and growing network of technology and data experts, who are taking on today’s biggest, most complex business challenges using the latest data and analytics technologies. We will nurture your talent in an inclusive culture that values diversity. You will have an opportunity to work in roles such as Data Scientist, Data Engineer, or Chief Data Officer covering all aspects of Data including Data Management, Data Governance, Data Intelligence, Knowledge Graphs, and IoT. Come grow your career in Technology at Accenture!

 Why Should I Join the Accenture Team?
Drive innovation. People in our Client Delivery & Operations career track drive delivery and capability excellence through the design, development and/or delivery of a solution, service, capability or offering. They grow into delivery-focused roles, and can progress within their current role, laterally or upward.Learn and grow continuously: Follow personalized training to build skills, while expanding your experience defining and implementing solutions on complex client projects with a scope that is unsurpassed in industry.Thrive in our inclusive environment: Bring your whole self to a company that aims to be the most diverse in the world and delivers real-time performance feedback based on individual strengths—not stats.

Job Description
Data and Analytics professionals define strategies, develop and deliver solutions that enable the collection, processing and management of information from one or more sources, and the subsequent delivery of information to audiences in support of key business processes.
Extract, Transform and Load data primarily in Informatica with an emphasis on advocacy toward end-users to produce high quality software designs that are well-documented.
Demonstrate an understanding of technology and digital frameworks in the context of data integration utilizing Informatica.
Ensure code and design quality through the execution of test plans and assist in development of standards, methodology and repeatable processes, working closely with internal and external design, business, and technical counterparts.

Basic Qualifications
Minimum 4 years of experience developing and implementing Informatica Powercenter or Informatica Data Quality
Bachelor’s Degree or Associate’s Degree with 6 years of work experience or equivalent work experience of 12 years
Preferred Qualifications
Experience in ETL Tools in addition to Informatica, including Business Objects Data Services (BODS), DataStage, Ab Initio, Talend, and Pentaho
Experience with a full life-cycle development from functional design to deployment
Database experience (Teradata, Oracle, SQL Server, DB2, Azure SQL)
Strong knowledge and experience of SQL
Understanding of Entity relationship data models and Dimensional Models
Experience with development and production support
Professional Skill Requirements

It is currently our objective to assign our people to work near where they live. However, given the nature of our business and our need to serve clients, our employees must be able to travel when needed. This role requires 100% flexibility to travel and work onsite with clients (typically Monday through Thursday).
Proven success in contributing to a team-oriented environment
Proven ability to work creatively and analytically in a problem-solving environment
Desire to work in an information systems environment
Excellent communication (written and oral) and interpersonal skills

All of our consulting professionals receive comprehensive training covering business acumen, technical and professional skills development. You'll also have opportunities to hone your functional skills and expertise in an area of specialization. We offer a variety of formal and informal training programs at every level to help you acquire and build specialized skills faster. Learning takes place both on the job and through formal training conducted online, in the classroom, or in collaboration with teammates. The sheer variety of work we do, and the experience it offers, provide an unbeatable platform from which to build a career.


Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status).

Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.

Accenture is an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities.

Equal Employment Opportunity
All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or"
16,"Data Engineer, National Robotics Engineering Center (NREC)","Pittsburgh, PA",Pittsburgh,PA,None Found,None Found,"
B.S. in Computer Science, Engineering, Mathematics is required (Any more is a bonus)
3-5 years relevant experience is required.
Demonstrated understanding and use of software engineering concepts, practices, and procedures.
Proficient development skills (Python preferred)
Linux development experience
Technical communication skills
Ability to participate in a multi-disciplinary team",None Found,None Found,None Found,None Found,"The National Robotics Engineering Center (NREC) at Carnegie Mellon University is looking for data scientists to develop tools to support machine learning and data-intensive applications. We are people with a desire to make robust software using agile development processes. You will work on a variety of software for commercial and government organizations. You will bring together open-source, commercial, internal, and your own tools to support diverse data processing workflows. Some of our machine learning software keeps self-driving vehicles safe, automatically discovers new pharmaceuticals, and leads to less waste in agriculture. You will support programs in deep learning for agriculture, artificial intelligence for defense, and autonomous manipulation.

Why NREC?
You will have an impact in shaping the robotics revolution, collaborate with and learn from experts,and build your career in a very fast-growing field. As part of our team, you will develop solutions to solve industrial and government challenges, deploy your technology in real-world situations, work side-by-side with elite robotics experts, and develop a variety of cutting-edge technologies.

Have an Impact!
Remove waste from farming = more food (link)
Make industrial processes environmentally friendly (link)
Make hazardous jobs safer (link)
Improve efficiency in industry & manufacturing (link)
Accelerate screening of pharmaceuticals (link)

Take Control of Your Career!
Select the career pathway that interests you
Influence the direction of projects
Supportive of a non-standard schedule
Maintain work/life balance
Switch between part-time and full-time as life demands

NREC is at the center of the robotics ecosystem in Pittsburgh, PA. With over 60 robotics companies, Pittsburgh has become the robotics capital of the world. Geek Wire calls it Robotics Row; others call it Roboburgh. Join the leader in the most exciting time in robotics!

Join the best robotics R&D group
Join our talented team at NREC, an operating unit within the world-renowned Robotics Institute at Carnegie Mellon University. NREC has 20+ years of experience and is globally renowned for developing and deploying robots into many applications across multiple sectors, such as agriculture, mining, defense, energy, and manufacturing. We strive to provide solutions for real world challenges where automation and robots have greater impact on productivity and improve the safety and comfort of the labor force. Our unique expertise places us at the forefront of unmanned ground vehicle design, autonomy, sensing and perception, machine learning, machine vision, operator assistance, 3D mapping and position estimation.

With over 120 robotics professionals, we can solve challenges that no other organization can.
NREC also leads in educational outreach through its Robotics Academy, which builds robotics curricula and software for K-12 and college-level students.

Your primary responsibilities include:
Developing software for machine learning and data-science applications
Architecting big-data pipelines
Adapting and integrating proprietary and open source software packages and APIs
Data preparation, integration, verification
Participating in the software process: design, code reviews, etc.
Developing, documenting, testing, and fixing software
Supporting development and acquisition of training and inference hardware
Development in a Linux environment

You must be willing to travel for extended periods for field testing.

Qualifications:
B.S. in Computer Science, Engineering, Mathematics is required (Any more is a bonus)
3-5 years relevant experience is required.
Demonstrated understanding and use of software engineering concepts, practices, and procedures.
Proficient development skills (Python preferred)
Linux development experience
Technical communication skills
Ability to participate in a multi-disciplinary team

We especially want to hear from you if you have experience or qualifications in ANY of the following areas:
Data infrastructure tools (SQL, NoSQL, data version control, etc.)
High performance computing tools (Hadoop, AWS, Azure, etc.)
Model training infrastructure tools (tensorflow, caffe, Petuum, etc.)
Inference model deployment tools (Docker or other containerization, etc.)
Cloud, high performance, and distributed computing
Ingestion and integration of disparate sources
Data processing (pre-processing, augmentation, post-processing)
Tools and protocols for reproducible research and data analysis
Front end (Data visualization, exploration, labeling)
Proficient Matlab or R skills
Proficient C or C++ skills
Professional software development processes
Networking interfaces and applications
Mixed software and hardware architecture
CMake, Valgrind, and other development tools
Computer vision, robotics, machine learning, scientific computing, simulation, or graphics

At NREC, we value diversity, support it, and thrive on it for the benefits of our organization, our employees and our community.

More Information

Please visit “Why Carnegie Mellon” to learn more about becoming part of an institution inspiring innovations that change the world. http://www.cmu.edu/jobs/why-cmu/index.html.

A listing of employee benefits is available at: http://www.cmu.edu/jobs/benefits-at-a-glance/index.html.

Carnegie Mellon University is an Equal Opportunity Employer/Disability/Veteran.
Job Function: Engineering

Primary Location: United States-Pennsylvania-Pittsburgh

Time Type: Full Time

Organization: ROBOTICS

Minimum Education Level: Bachelor's Degree or equivalent

Preferred Education Level: Master's Degree or equivalent

Budgeted Base Pay: Negotiable"
17,SQL Data Engineer,"Pittsburgh, PA 15219",Pittsburgh,PA,15219,None Found,None Found,None Found,"Strong Microsoft SQL Skills including but not limited to views, stored procedures and function creation and optimization
Ensure performance and availability of databases
ETL knowledge and capability
Data Modeling / Database Design
Perform baseline Microsoft SQL database administrative tasks
Job creations and failure monitoring
Evaluate datasets for quality and accuracy
SQL Training to others as needed",None Found,None Found,"We are looking for a SQL Data Engineer who has strong SQL skills and the desire to build a sustainable environment that can scale as a business grows. This position will provide the opportunity to build an environment from the ground to customer facing and experience the value of all the time and effort to a solution. You will have the ability to help guide and teach others on SQL optimization as required to improve performance on results and for the betterment of the SQL Server. You will work with Data Analysts, Pricing Analysts and Business Stakeholders to develop solutions to meet data needs.

Key Responsibilities:
Strong Microsoft SQL Skills including but not limited to views, stored procedures and function creation and optimization
Ensure performance and availability of databases
ETL knowledge and capability
Data Modeling / Database Design
Perform baseline Microsoft SQL database administrative tasks
Job creations and failure monitoring
Evaluate datasets for quality and accuracy
SQL Training to others as needed
Bachelor’s degree in Computer Science, Information Systems, or equivalent degree or strong industry experience.
Strong verbal and written communication skills
5-10 years experience in database development/design
Knowledge about SQL Server Integration Services and SQL Agent
Experience handling multiple concurrent complex activities within a technical environment and ability to project risks and escalate to managers appropriately
Must have strong analytical and problem solving skills
Experience with Office 365 products a plus
Experience with Power Bi a plus
Experience with AWS a plus
Demonstrate Thermo Fisher Scientific values – Integrity, Intensity, Innovation and Involvement

At Thermo Fisher Scientific, each one of our 50,000 extraordinary minds has a unique story to tell. Join us and contribute to our singular mission—enabling our customers to make the world healthier, cleaner and safer. Apply today

Thermo Fisher Scientific is an EEO/Affirmative Action Employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability or any other legally protected status.




If you are an individual with a disability who requires reasonable accommodation to complete any part of our application process, for further assistance.
Thermo Fisher Scientific is an EEO/Affirmative Action Employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability or any other legally protected status."
18,Senior Analytic Data Engineer,"Pittsburgh, PA 15289",Pittsburgh,PA,15289,None Found,None Found,None Found,None Found,None Found,None Found,"Company :
Hm Health Solutions Inc.
Job Description :
JOB SUMMARY
This job architects and engineers solutions associated with analytic data for the organization and, working closely with the IT teams, assists with the design, build, and upkeep for these solutions. This includes creating pathways for analysts to access operational, derived, and external data sets. The incumbent is also responsible for the operation of Big Data Platforms as they are associated with analytic data discovery. Provides guidance and education for Intermediate contributors. Meets individually with customers for specific projects.
ESSENTIAL RESPONSIBILITIES
Responsible for large functional efforts for data analytics programs across multiple disciplines with minimal guidance.
Working closely with IT, architect and engineer solutions that provide views for the Analytic Data Warehouse. This would include the working with the proper teams, assisting with the design, building out the design, and providing upkeep for the solution.
Assemble, test, process, and maintain the Analytic Discovery Platform for the analytics organizations. This will include working to maintain pipelines with key analytic platforms throughout the organization.
Work with alternative analytic data systems to incorporate them into the operational data flow for the Analytics Teams. This may include products purchased by the organization that must be ingested or modeled/derived data maintained by analytic teams.
Independently lead functional efforts for assigned projects with limited supervision. This include the guidance and education of Intermediate contributors within this team. Meet individually with customers for specific projects and attend with Intermediates for support.
Other duties as assigned.
EDUCATION
Required
Bachelor's Degree in Computer Systems Analysis, Data Processing, Healthcare Informatics, Management Information Systems, or related field
Preferred
Master's Degree in related field
EXPERIENCE
Required
3 - 5 years of Data Analytics experience
Preferred
1 - 3 years of Data Warehousing experience
1 - 3 years of Database Administration experience
5 - 7 years of Healthcare Industry experience
QUALIFICATIONS
Proficient in the following areas:
Advanced data analytic skills
Ability to perform data analytics for complex processes with complex business rules
Ability to translate complex data analytics results into information that can be used by senior executives to make decisions
PowerPoint skills
Excel skills
Tableau skills for data analytics
Understands business drivers then use the information to provide the right data analytics to support the drivers
Understanding of our data and how to leverage it for analytics
Understanding of our business processes in order to interpret metric results and drive improvements in performance by leveraging demand capacity models, proactive monitoring, and predictive analysis
Calculating projections
Background with data infrastructure including ETL, data warehouse, and tableau
Calculating projections
Data infrastructure including ETL, data warehouse, and tableau
Expert analytical skills
LICENSES OR CERTIFICATIONS
Required
None
SKILLS
Tableau for data analytics
Microsoft Office
SAS is a plus
Language Requirement (other than English)
None
Travel Requirement
0% - 25%
PHYSICAL, MENTAL DEMANDS and WORKING CONDITIONS
Position Type
Office-Based
Teaches / trains others regularly
Occasionally
Travel regularly from the office to various work sites or from site-to-site
Rarely
Employee Referral Level: 2
Disclaimer: The job description has been designed to indicate the general nature and essential duties and responsibilities of work performed by employees within this job title. It may not contain a comprehensive inventory of all duties, responsibilities, and qualifications required of employees to do this job.
Compliance Requirement: This position adheres to the ethical and legal standards and behavioral expectations as set forth in the code of business conduct and company policies.
-
Highmark Health and its affiliates prohibit discrimination against qualified individuals based on their status as protected veterans or individuals with disabilities, and prohibit discrimination against all individuals based on their race, color, religion, sex, national origin, sexual orientation/gender identity or any other category protected by applicable federal, state or local law. Highmark Health and its affiliates take affirmative action to employ and advance in employment individuals without regard to race, color, religion, sex, national origin, sexual orientation/gender identity, protected veteran status or disability.
EEO is The Law
Equal Opportunity Employer Minorities/Women/ProtectedVeterans/Disabled/Sexual Orientation/Gender Identity (http://www1.eeoc.gov/employers/upload/eeoc_self_print_poster.pdf)
We endeavor to make this site accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact number below."
19,Data Engineer,"Pittsburgh, PA 15222",Pittsburgh,PA,15222,None Found,None Found,None Found,None Found,None Found,None Found,"Position Overview
At PNC, our people are our greatest differentiator and competitive advantage in the markets we serve. We are all united in delivering the best experience for our customers. As a Data Engineer within PNC's AMG Engineering Team, you will be responsible to provide Data Products in the Big Data space to support our Wealth and Investment Management Business. This position will be based in Pittsburgh, PA. Successful Candidates will have the followiing skills:

Extensive Data Modeling experience

Extensive Experience with Relational Databases

Well-versed scripting in Python / PySpark

Moderate to Advanced knowledge of Big Data storage concepts and strategies

Moderate to Advanced experience in Business Intelligence

Efficient Data Structures

Robust Visualizations

Experience with one or more BI Platforms (Tableau, OBIEE, QlikView, Cognos, etc…)

Moderate understanding of Cloudera’s Hadoop Big Data Platform

Working Experience with NoSQL Databases

Familiarity with creation and maintenance of Oozie workflows

Experience working on an agile team a plus
Job Description
Develops, supports and implements data services for multiple applications to meet business objectives and user requirements. Uses technical knowledge and industry experience to design, build and maintain technology solutions.
Works closely with users, developers, operations and business partners to define data service requirements and the data preparation process development.
Designs and builds data service infrastructure on multiple data platforms, according to key business processes and the overall workflow.
Develops and implements data solutions for multiple applications to ensure its scalability, availability and maintainability.
Implements data migration and transformation activities/processes to ensure the accuracy and security of data solutions.
PNC Employees take pride in our reputation and to continue building upon that we expect our employees to be:
Customer Focused - Knowledgeable of the values and practices that align customer needs and satisfaction as primary considerations in all business decisions and able to leverage that information in creating customized customer solutions.
Managing Risk - Assessing and effectively managing all of the risks associated with their business objectives and activities to ensure they adhere to and support PNC's Enterprise Risk Management Framework.
Competencies
Application Delivery Process – Knowledge of major tasks, deliverables, and formal application delivery methodologies; ability to utilize these in order to deliver new or enhanced applications.
Big Data Management and Analytics – Knowledge and ability to plan and execute, big data management and analytics.
Business Intelligence – Knowledge of and ability to utilize business processes and technologies for gathering, storing, analyzing, and providing access to data that helps the organization make better business decisions.
Data Analysis - Software – Knowledge of the investigation, evaluation, interpretation, and classification of data; the ability to identify, collect and analyze data to facilitate the development, implementation and application of software systems.
Data Architecture – Knowledge and ability to create models and standards to govern which data is collected, and how it is stored, arranged, integrated, and put to use in data systems and in organizations.
Database Structures – Knowledge of and the ability to utilize appropriate database structures to organize and store data in a particular manner.
Effective Communications – Understanding of effective communication concepts, tools and techniques; ability to effectively transmit, receive, and accurately interpret ideas, information, and needs through the application of appropriate communication behaviors.
Problem Solving – Knowledge of approaches, tools, techniques for recognizing, anticipating, and resolving organizational, operational or process problems; ability to apply this knowledge appropriately to diverse situations.
Software Development Life Cycle – Knowledge of and experience with using a structured methodology for delivering new or enhanced software products to the marketplace.
Work Experience
Roles at this level typically require a university / college degree, with 3+ years of relevant / direct industry experience. Certifications are often desired. In lieu of a degree, a comparable combination of education and experience (including military service) may be considered.
Education
Bachelors
Disability Accommodations Statement:

The PNC workplace is inclusive and supportive of individual needs. If you have a physical or other impairment that might require an accommodation, including technical assistance with the PNC Careers website or submission process, please call 877-968-7762 and select Option 4: Recruiting or contact us via email at pathfinder@pnc.com.
The Human Resources Service Center hours of operation are Monday - Friday 9:00 AM to 5:00 PM ET.
Equal Employment Opportunity (EEO):

PNC provides equal employment opportunity to qualified persons regardless of race, color, sex, religion, national origin, age, sexual orientation, gender identity, disability, veteran status, or other categories protected by law."
