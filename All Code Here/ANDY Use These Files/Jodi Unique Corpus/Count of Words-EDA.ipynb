{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows-10-10.0.18362-SP0\n",
      "Python 3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]\n",
      "Requests 2.22.0\n",
      "Pandas 0.25.0\n",
      "Numpy 1.16.5\n",
      "NLTK 3.4.4\n",
      "Re 2.2.1\n",
      "Pandas 0.25.0\n",
      "nltk 3.4.4\n",
      "spacy 2.2.1\n",
      "pattern 3.6\n",
      "CapScrape\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf\n",
    "#import tensorflow_hub as hub\n",
    "import platform; print(platform.platform())\n",
    "import sys; print(\"Python\", sys.version)\n",
    "import urllib3.request\n",
    "import requests; print(\"Requests\", requests.__version__)\n",
    "import pandas as pd; print(\"Pandas\", pd.__version__)\n",
    "import numpy as np; print(\"Numpy\", np.__version__)\n",
    "import nltk; print(\"NLTK\", nltk.__version__)\n",
    "import re; print(\"Re\", re.__version__)\n",
    "import json; print(\"Pandas\", pd.__version__)\n",
    "import pprint\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import nltk; print(\"nltk\", nltk.__version__)\n",
    "import spacy; print(\"spacy\", spacy.__version__)\n",
    "import unidecode\n",
    "import unicodedata\n",
    "import pattern; print (\"pattern\", pattern.__version__)\n",
    "import string\n",
    "import time\n",
    "\n",
    "from collections import OrderedDict\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import collections\n",
    "#nltk.download('stopwords')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "print (os.environ['CONDA_DEFAULT_ENV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "new_stopwords = ['preferred', 'quality', 'field', 'environment', 'learning', 'work', 'strong', 'working', 'etc', 'large', 'experience', 'skills', 'work', 'ability', 'knowledge', 'years', 'related', 'required', 'including', 'ensure', 'or', 'and', 'studies', 'excellent', 'provide', 'requirements', 'skills', 'strong', 'new', 'high', 'using', 'equivalent', 'system']\n",
    "stop_words = stop_words.union(new_stopwords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataAnalyst = pd.read_csv(\"DataAnalyst_Corpus.csv\",encoding = \"ISO-8859-1\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove line breaks and ‘\\n’\n",
    "for n in range (0, len(DataAnalyst)) :\n",
    "   DataAnalyst.Corpus[n] = DataAnalyst.Corpus[n].replace('\\n', ' ').replace('*', ' ').replace(':', ' ').replace('#', ' ').replace('(', ' ').replace(')', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SearchTitle</th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>FullDescriptions</th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analytics Lead (Marketing)</td>\n",
       "      <td>Englewood, CO 80110</td>\n",
       "      <td>Englewood</td>\n",
       "      <td>CO</td>\n",
       "      <td>Summary\\nSling TV L.L.C. provides an over-the-...</td>\n",
       "      <td>A strategic and innovative thinker who is agi...</td>\n",
       "      <td>A strategic innovative thinker agile possesses...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst, Naturally Slim</td>\n",
       "      <td>Dallas, TX</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>TX</td>\n",
       "      <td>Does organizing and interpreting data make you...</td>\n",
       "      <td>Bachelorâs degree in Computer Science, Info...</td>\n",
       "      <td>Bachelorâs degree Computer Science, Informat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Washington</td>\n",
       "      <td>DC</td>\n",
       "      <td>Analytica is seeking a Data Analyst to support...</td>\n",
       "      <td>Bachelorâs Degree 5+ years of experience in ...</td>\n",
       "      <td>Bachelorâs Degree 5+ statistical methodologi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Oakland, CA</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>CA</td>\n",
       "      <td>At thredUP, weâre working to revolutionize t...</td>\n",
       "      <td>Dive into our clickstream data to understan...</td>\n",
       "      <td>Dive clickstream data understand user behavior...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>GIS Data Analyst</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>Denver</td>\n",
       "      <td>CO</td>\n",
       "      <td>The Geophysics Team Lead applies Geographic In...</td>\n",
       "      <td>Prefer bachelor's degree in Graphic Informatio...</td>\n",
       "      <td>Prefer bachelor's degree Graphic Information S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SearchTitle                            Title             Location  \\\n",
       "0  Data Analyst  Data Analytics Lead (Marketing)  Englewood, CO 80110   \n",
       "1  Data Analyst     Data Analyst, Naturally Slim           Dallas, TX   \n",
       "2  Data Analyst                     Data Analyst       Washington, DC   \n",
       "3  Data Analyst                     Data Analyst          Oakland, CA   \n",
       "4  Data Analyst                 GIS Data Analyst           Denver, CO   \n",
       "\n",
       "         City State                                   FullDescriptions  \\\n",
       "0   Englewood    CO  Summary\\nSling TV L.L.C. provides an over-the-...   \n",
       "1      Dallas    TX  Does organizing and interpreting data make you...   \n",
       "2  Washington    DC  Analytica is seeking a Data Analyst to support...   \n",
       "3     Oakland    CA  At thredUP, weâre working to revolutionize t...   \n",
       "4      Denver    CO  The Geophysics Team Lead applies Geographic In...   \n",
       "\n",
       "                                              Corpus  \\\n",
       "0   A strategic and innovative thinker who is agi...   \n",
       "1   Bachelorâs degree in Computer Science, Info...   \n",
       "2  Bachelorâs Degree 5+ years of experience in ...   \n",
       "3     Dive into our clickstream data to understan...   \n",
       "4  Prefer bachelor's degree in Graphic Informatio...   \n",
       "\n",
       "                                               Clean  \n",
       "0  A strategic innovative thinker agile possesses...  \n",
       "1  Bachelorâs degree Computer Science, Informat...  \n",
       "2  Bachelorâs Degree 5+ statistical methodologi...  \n",
       "3  Dive clickstream data understand user behavior...  \n",
       "4  Prefer bachelor's degree Graphic Information S...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataAnalyst['Clean']=(DataAnalyst['Corpus'].str.split()\n",
    "                            .apply(lambda x: [item for item in x if item not in stop_words])\n",
    "                            .str.join(' '))\n",
    "DataAnalyst.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SearchTitle</th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>FullDescriptions</th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Clean</th>\n",
       "      <th>UniqueClean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analytics Lead (Marketing)</td>\n",
       "      <td>Englewood, CO 80110</td>\n",
       "      <td>Englewood</td>\n",
       "      <td>CO</td>\n",
       "      <td>Summary\\nSling TV L.L.C. provides an over-the-...</td>\n",
       "      <td>A strategic and innovative thinker who is agi...</td>\n",
       "      <td>A strategic innovative thinker agile possesses...</td>\n",
       "      <td>A strategic innovative thinker agile possesses...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst, Naturally Slim</td>\n",
       "      <td>Dallas, TX</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>TX</td>\n",
       "      <td>Does organizing and interpreting data make you...</td>\n",
       "      <td>Bachelorâs degree in Computer Science, Info...</td>\n",
       "      <td>Bachelorâs degree Computer Science, Informat...</td>\n",
       "      <td>Bachelorâs degree Computer Science, Informat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Washington</td>\n",
       "      <td>DC</td>\n",
       "      <td>Analytica is seeking a Data Analyst to support...</td>\n",
       "      <td>Bachelorâs Degree 5+ years of experience in ...</td>\n",
       "      <td>Bachelorâs Degree 5+ statistical methodologi...</td>\n",
       "      <td>Bachelorâs Degree 5+ statistical methodologi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Oakland, CA</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>CA</td>\n",
       "      <td>At thredUP, weâre working to revolutionize t...</td>\n",
       "      <td>Dive into our clickstream data to understan...</td>\n",
       "      <td>Dive clickstream data understand user behavior...</td>\n",
       "      <td>Dive clickstream data understand user behavior...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>GIS Data Analyst</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>Denver</td>\n",
       "      <td>CO</td>\n",
       "      <td>The Geophysics Team Lead applies Geographic In...</td>\n",
       "      <td>Prefer bachelor's degree in Graphic Informatio...</td>\n",
       "      <td>Prefer bachelor's degree Graphic Information S...</td>\n",
       "      <td>Prefer bachelor's degree Graphic Information S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SearchTitle                            Title             Location  \\\n",
       "0  Data Analyst  Data Analytics Lead (Marketing)  Englewood, CO 80110   \n",
       "1  Data Analyst     Data Analyst, Naturally Slim           Dallas, TX   \n",
       "2  Data Analyst                     Data Analyst       Washington, DC   \n",
       "3  Data Analyst                     Data Analyst          Oakland, CA   \n",
       "4  Data Analyst                 GIS Data Analyst           Denver, CO   \n",
       "\n",
       "         City State                                   FullDescriptions  \\\n",
       "0   Englewood    CO  Summary\\nSling TV L.L.C. provides an over-the-...   \n",
       "1      Dallas    TX  Does organizing and interpreting data make you...   \n",
       "2  Washington    DC  Analytica is seeking a Data Analyst to support...   \n",
       "3     Oakland    CA  At thredUP, weâre working to revolutionize t...   \n",
       "4      Denver    CO  The Geophysics Team Lead applies Geographic In...   \n",
       "\n",
       "                                              Corpus  \\\n",
       "0   A strategic and innovative thinker who is agi...   \n",
       "1   Bachelorâs degree in Computer Science, Info...   \n",
       "2  Bachelorâs Degree 5+ years of experience in ...   \n",
       "3     Dive into our clickstream data to understan...   \n",
       "4  Prefer bachelor's degree in Graphic Informatio...   \n",
       "\n",
       "                                               Clean  \\\n",
       "0  A strategic innovative thinker agile possesses...   \n",
       "1  Bachelorâs degree Computer Science, Informat...   \n",
       "2  Bachelorâs Degree 5+ statistical methodologi...   \n",
       "3  Dive clickstream data understand user behavior...   \n",
       "4  Prefer bachelor's degree Graphic Information S...   \n",
       "\n",
       "                                         UniqueClean  \n",
       "0  A strategic innovative thinker agile possesses...  \n",
       "1  Bachelorâs degree Computer Science, Informat...  \n",
       "2  Bachelorâs Degree 5+ statistical methodologi...  \n",
       "3  Dive clickstream data understand user behavior...  \n",
       "4  Prefer bachelor's degree Graphic Information S...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataAnalyst['UniqueClean'] = (DataAnalyst['Clean'].str.split()\n",
    "                              .apply(lambda x: OrderedDict.fromkeys(x).keys())\n",
    "                              .str.join(' '))\n",
    "DataAnalyst.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniqueClean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A strategic innovative thinker agile possesses...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bachelorâs degree Computer Science, Informat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bachelorâs Degree 5+ statistical methodologi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dive clickstream data understand user behavior...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prefer bachelor's degree Graphic Information S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         UniqueClean\n",
       "0  A strategic innovative thinker agile possesses...\n",
       "1  Bachelorâs degree Computer Science, Informat...\n",
       "2  Bachelorâs Degree 5+ statistical methodologi...\n",
       "3  Dive clickstream data understand user behavior...\n",
       "4  Prefer bachelor's degree Graphic Information S..."
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataAnalyst_UniqueClean=pd.DataFrame([DataAnalyst.UniqueClean]).transpose()\n",
    "DataAnalyst_UniqueClean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataAnalyst_UniqueClean.to_csv('DataAnalyst_UniqueClean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataAnalyst1 = pd.read_csv(\"DataAnalyst_UniqueClean.csv\",encoding = \"ISO-8859-1\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('unnamed', 1), ('uniqueclean', 1)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_top_n_words(corpus, n=None):\n",
    "    vec = CountVectorizer().fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "common_words = get_top_n_words(DataAnalyst1, 50)\n",
    "for word, freq in common_words:\n",
    "    dfDataAnalyst = pd.DataFrame(common_words, columns = ['UniqueClean' , 'count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Database = pd.read_csv(\"Database_Corpus.csv\",encoding = \"ISO-8859-1\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove line breaks and ‘\\n’\n",
    "for n in range (0, len(Database)) :\n",
    "   Database.Corpus[n] = Database.Corpus[n].replace('\\n', ' ').replace('*', ' ').replace(':', ' ').replace('#', ' ').replace('(', ' ').replace(')', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Database['UniqueCorpus'] = (Database['Corpus'].str.split()\n",
    "                              .apply(lambda x: OrderedDict.fromkeys(x).keys())\n",
    "                              .str.join(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Database['CleanUnique']=(Database['UniqueCorpus'].str.split()\n",
    "                            .apply(lambda x: [item for item in x if item not in stop_words])\n",
    "                            .str.join(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Database.to_csv('Database_UniqueCorpus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Database = pd.read_csv(\"Database_UniqueCorpus.csv\",encoding = \"ISO-8859-1\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_top_n_words(corpus, n=None):\n",
    "    vec = CountVectorizer().fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "common_words = get_top_n_words(Database['CleanUnique'], 50)\n",
    "for word, freq in common_words:\n",
    "    dfDatabase = pd.DataFrame(common_words, columns = ['CleanUnique' , 'count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataEngineer = pd.read_csv(\"DataEngineer_Corpus.csv\",encoding = \"ISO-8859-1\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove line breaks and ‘\\n’\n",
    "for n in range (0, len(DataEngineer)) :\n",
    "   DataEngineer.Corpus[n] = DataEngineer.Corpus[n].replace('\\n', ' ').replace('*', ' ').replace(':', ' ').replace('#', ' ').replace('(', ' ').replace(')', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataEngineer['UniqueCorpus'] = (DataEngineer['Corpus'].str.split()\n",
    "                              .apply(lambda x: OrderedDict.fromkeys(x).keys())\n",
    "                              .str.join(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataEngineer['CleanUnique']=(DataEngineer['UniqueCorpus'].str.split()\n",
    "                            .apply(lambda x: [item for item in x if item not in stop_words])\n",
    "                            .str.join(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataEngineer.to_csv('DataEngineer_UniqueCorpus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataEngineer = pd.read_csv(\"DataEngineer_UniqueCorpus.csv\",encoding = \"ISO-8859-1\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_top_n_words(corpus, n=None):\n",
    "    vec = CountVectorizer().fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "common_words = get_top_n_words(DataEngineer['CleanUnique'], 50)\n",
    "for word, freq in common_words:\n",
    "    dfDataEngineer = pd.DataFrame(common_words, columns = ['CleanUnique' , 'count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataScientist = pd.read_csv(\"DataScientist_Corpus.csv\",encoding = \"ISO-8859-1\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove line breaks and ‘\\n’\n",
    "for n in range (0, len(DataScientist)) :\n",
    "   DataScientist.Corpus[n] = DataScientist.Corpus[n].replace('\\n', ' ').replace('*', ' ').replace(':', ' ').replace('#', ' ').replace('(', ' ').replace(')', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataScientist['UniqueCorpus'] = (DataScientist['Corpus'].str.split()\n",
    "                              .apply(lambda x: OrderedDict.fromkeys(x).keys())\n",
    "                              .str.join(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataScientist['CleanUnique']=(DataScientist['UniqueCorpus'].str.split()\n",
    "                            .apply(lambda x: [item for item in x if item not in stop_words])\n",
    "                            .str.join(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataScientist.to_csv('DataScientist_UniqueCorpus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataScientist = pd.read_csv(\"DataScientist_UniqueCorpus.csv\",encoding = \"ISO-8859-1\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_top_n_words(corpus, n=None):\n",
    "    vec = CountVectorizer().fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "common_words = get_top_n_words(DataScientist['CleanUnique'], 50)\n",
    "for word, freq in common_words:\n",
    "    dfDataScientist = pd.DataFrame(common_words, columns = ['CleanUnique' , 'count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Software Engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "SoftwareEngineer = pd.read_csv(\"SoftwareEngineer_Corpus.csv\",encoding = \"ISO-8859-1\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove line breaks and ‘\\n’\n",
    "for n in range (0, len(SoftwareEngineer)) :\n",
    "   SoftwareEngineer.Corpus[n] = SoftwareEngineer.Corpus[n].replace('\\n', ' ').replace('*', ' ').replace(':', ' ').replace('#', ' ').replace('(', ' ').replace(')', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "SoftwareEngineer['UniqueCorpus'] = (SoftwareEngineer['Corpus'].str.split()\n",
    "                              .apply(lambda x: OrderedDict.fromkeys(x).keys())\n",
    "                              .str.join(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "SoftwareEngineer['CleanUnique']=(SoftwareEngineer['UniqueCorpus'].str.split()\n",
    "                            .apply(lambda x: [item for item in x if item not in stop_words])\n",
    "                            .str.join(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "SoftwareEngineer.to_csv('SoftwareEngineer_UniqueCorpus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "SoftwareEngineer = pd.read_csv(\"SoftwareEngineer_UniqueCorpus.csv\",encoding = \"ISO-8859-1\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_top_n_words(corpus, n=None):\n",
    "    vec = CountVectorizer().fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "common_words = get_top_n_words(SoftwareEngineer['CleanUnique'], 50)\n",
    "for word, freq in common_words:\n",
    "    dfSoftwareEngineer = pd.DataFrame(common_words, columns = ['CleanUnique' , 'count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistician"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "Statistician = pd.read_csv(\"Statistician_Corpus.csv\",encoding = \"ISO-8859-1\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove line breaks and ‘\\n’\n",
    "for n in range (0, len(Statistician)) :\n",
    "   Statistician.Corpus[n] = Statistician.Corpus[n].replace('\\n', ' ').replace('*', ' ').replace(':', ' ').replace('#', ' ').replace('(', ' ').replace(')', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Statistician['UniqueCorpus'] = (Statistician['Corpus'].str.split()\n",
    "                              .apply(lambda x: OrderedDict.fromkeys(x).keys())\n",
    "                              .str.join(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "Statistician['CleanUnique']=(Statistician['UniqueCorpus'].str.split()\n",
    "                            .apply(lambda x: [item for item in x if item not in stop_words])\n",
    "                            .str.join(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "Statistician.to_csv('Statistician_UniqueCorpus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "Statistician = pd.read_csv(\"Statistician_UniqueCorpus.csv\",encoding = \"ISO-8859-1\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_top_n_words(corpus, n=None):\n",
    "    vec = CountVectorizer().fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "common_words = get_top_n_words(Statistician['CleanUnique'], 50)\n",
    "for word, freq in common_words:\n",
    "    dfStatistician = pd.DataFrame(common_words, columns = ['CleanUnique' , 'count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Count df to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfStatistician.to_csv('StatisticianCount.csv')\n",
    "#dfSoftwareEngineer.to_csv('SoftwareEngineerCount.csv')\n",
    "#dfDataScientist.to_csv('DataScientistCount.csv')\n",
    "#dfDataEngineer.to_csv('DataEngineerCount.csv')\n",
    "#dfDatabase.to_csv('DatabaseCount.csv')\n",
    "dfDataAnalyst.to_csv('DataAnalystCount.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
