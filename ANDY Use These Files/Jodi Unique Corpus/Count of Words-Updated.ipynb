{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas 0.25.0\n",
      "NLTK 3.4.4\n",
      "Re 2.2.1\n",
      "spacy 2.2.1\n",
      "pattern 3.6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd; print(\"Pandas\", pd.__version__)\n",
    "import nltk; print(\"NLTK\", nltk.__version__)\n",
    "import re; print(\"Re\", re.__version__)\n",
    "from collections import defaultdict\n",
    "import spacy; print(\"spacy\", spacy.__version__)\n",
    "import unidecode\n",
    "import unicodedata\n",
    "import pattern; print (\"pattern\", pattern.__version__)\n",
    "import string\n",
    "from collections import OrderedDict\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import collections\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_defined_stop_words = ['preferred', 'quality', 'field', 'environment', 'learning', 'work', 'strong', 'working', 'etc', 'large', 'experience', 'skills', 'work', 'ability', 'knowledge', 'years', 'related', 'required', 'including', 'ensure', 'or', 'and', 'studies', 'excellent', 'provide', 'requirements', 'skills', 'strong', 'new', 'high', 'using', 'equivalent', 'system'] \n",
    "i = nltk.corpus.stopwords.words('english')\n",
    "j = list(string.punctuation) + user_defined_stop_words\n",
    "\n",
    "stopwords = set(i).union(j)\n",
    "\n",
    "def preprocess(x):\n",
    "    x = re.sub('[^a-z\\s]', '', x.lower())  \n",
    "    x = [w for w in x.split() if w not in set(stopwords)]\n",
    "    return ' '.join(x) \n",
    "\n",
    "def get_top_n_words(corpus, n=None):\n",
    "    vec = CountVectorizer().fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataAnalyst = pd.read_csv(\"DataAnalyst_Corpus.csv\",encoding = \"ISO-8859-1\") \n",
    "# Remove line breaks and ‘\\n’\n",
    "for n in range (0, len(DataAnalyst)) :\n",
    "   DataAnalyst.Corpus[n] = DataAnalyst.Corpus[n].replace('<br>', '. ').replace('.', '. ').replace('\\n', ' ').replace('*', ' ').replace(':', ' ').replace('#', ' ').replace('(', ' ').replace(')', ' ')\n",
    "\n",
    "DACorpus= pd.DataFrame(DataAnalyst['Corpus'])\n",
    "DACorpus['Clean']=DACorpus['Corpus'].apply(preprocess)\n",
    "\n",
    "DACorpus['UniqueClean'] = (DACorpus['Clean'].str.split()\n",
    "                              .apply(lambda x: OrderedDict.fromkeys(x).keys())\n",
    "                              .str.join(' '))\n",
    "DACorpus.to_csv('DACorpus_UniqueClean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAcommon_words = get_top_n_words(DACorpus['UniqueClean'], 50)\n",
    "for word, freq in DAcommon_words:\n",
    "    dfDataAnalyst = pd.DataFrame(DAcommon_words, columns = ['DAwords' , 'DAcount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDataAnalyst.to_csv('DataAnalystCount.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "DatabaseAdministrator = pd.read_csv(\"Database_Corpus.csv\",encoding = \"ISO-8859-1\") \n",
    "# Remove line breaks and ‘\\n’\n",
    "for n in range (0, len(DatabaseAdministrator)) :\n",
    "   DatabaseAdministrator.Corpus[n] = DatabaseAdministrator.Corpus[n].replace('<br>', '. ').replace('.', '. ').replace('\\n', ' ').replace('*', ' ').replace(':', ' ').replace('#', ' ').replace('(', ' ').replace(')', ' ')\n",
    "\n",
    "DBACorpus= pd.DataFrame(DatabaseAdministrator['Corpus'])\n",
    "DBACorpus['Clean']=DBACorpus['Corpus'].apply(preprocess)\n",
    "\n",
    "DBACorpus['UniqueClean'] = (DBACorpus['Clean'].str.split()\n",
    "                              .apply(lambda x: OrderedDict.fromkeys(x).keys())\n",
    "                              .str.join(' '))\n",
    "DBACorpus.to_csv('DBACorpus_UniqueClean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "DBAcommon_words = get_top_n_words(DBACorpus['UniqueClean'], 50)\n",
    "for word, freq in DBAcommon_words:\n",
    "    dfDatabaseAdministrator = pd.DataFrame(DBAcommon_words, columns = ['DBAwords' , 'DBAcount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDatabaseAdministrator.to_csv('DatabaseAdministratorCount.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataEngineer = pd.read_csv(\"DataEngineer_Corpus.csv\",encoding = \"ISO-8859-1\") \n",
    "# Remove line breaks and ‘\\n’\n",
    "for n in range (0, len(DataEngineer)) :\n",
    "   DataEngineer.Corpus[n] = DataEngineer.Corpus[n].replace('<br>', '. ').replace('.', '. ').replace('\\n', ' ').replace('*', ' ').replace(':', ' ').replace('#', ' ').replace('(', ' ').replace(')', ' ')\n",
    "\n",
    "DECorpus= pd.DataFrame(DataEngineer['Corpus'])\n",
    "DECorpus['Clean']=DECorpus['Corpus'].apply(preprocess)\n",
    "\n",
    "DECorpus['UniqueClean'] = (DECorpus['Clean'].str.split()\n",
    "                              .apply(lambda x: OrderedDict.fromkeys(x).keys())\n",
    "                              .str.join(' '))\n",
    "DECorpus.to_csv('DECorpus_UniqueClean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEcommon_words = get_top_n_words(DECorpus['UniqueClean'], 50)\n",
    "for word, freq in DEcommon_words:\n",
    "    dfDataEngineer = pd.DataFrame(DEcommon_words, columns = ['DEwords' , 'DEcount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDataEngineer.to_csv('DataEngineerCount.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataScientist = pd.read_csv(\"DataScientist_Corpus.csv\",encoding = \"ISO-8859-1\") \n",
    "# Remove line breaks and ‘\\n’\n",
    "for n in range (0, len(DataScientist)) :\n",
    "   DataScientist.Corpus[n] = DataScientist.Corpus[n].replace('<br>', '. ').replace('.', '. ').replace('\\n', ' ').replace('*', ' ').replace(':', ' ').replace('#', ' ').replace('(', ' ').replace(')', ' ')\n",
    "\n",
    "DSCorpus= pd.DataFrame(DataScientist['Corpus'])\n",
    "DSCorpus['Clean']=DSCorpus['Corpus'].apply(preprocess)\n",
    "\n",
    "DSCorpus['UniqueClean'] = (DSCorpus['Clean'].str.split()\n",
    "                              .apply(lambda x: OrderedDict.fromkeys(x).keys())\n",
    "                              .str.join(' '))\n",
    "DSCorpus.to_csv('DSCorpus_UniqueClean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DScommon_words = get_top_n_words(DSCorpus['UniqueClean'], 50)\n",
    "for word, freq in DScommon_words:\n",
    "    dfDataScientist = pd.DataFrame(DScommon_words, columns = ['DSwords' , 'DScount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDataScientist.to_csv('DataScientistCount.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Software Engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "SoftwareEngineer = pd.read_csv(\"SoftwareEngineer_Corpus.csv\",encoding = \"ISO-8859-1\") \n",
    "# Remove line breaks and ‘\\n’\n",
    "for n in range (0, len(SoftwareEngineer)) :\n",
    "   SoftwareEngineer.Corpus[n] = SoftwareEngineer.Corpus[n].replace('<br>', '. ').replace('.', '. ').replace('\\n', ' ').replace('*', ' ').replace(':', ' ').replace('#', ' ').replace('(', ' ').replace(')', ' ')\n",
    "\n",
    "SECorpus= pd.DataFrame(SoftwareEngineer['Corpus'])\n",
    "SECorpus['Clean']=SECorpus['Corpus'].apply(preprocess)\n",
    "\n",
    "SECorpus['UniqueClean'] = (SECorpus['Clean'].str.split()\n",
    "                              .apply(lambda x: OrderedDict.fromkeys(x).keys())\n",
    "                              .str.join(' '))\n",
    "SECorpus.to_csv('SECorpus_UniqueClean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEcommon_words = get_top_n_words(SECorpus['UniqueClean'], 50)\n",
    "for word, freq in SEcommon_words:\n",
    "    dfSoftwareEngineer = pd.DataFrame(SEcommon_words, columns = ['SEwords' , 'SEcount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSoftwareEngineer.to_csv('SoftwareEngineerCount.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistician"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "Statistician = pd.read_csv(\"Statistician_Corpus.csv\",encoding = \"ISO-8859-1\") \n",
    "# Remove line breaks and ‘\\n’\n",
    "for n in range (0, len(Statistician)) :\n",
    "   Statistician.Corpus[n] = Statistician.Corpus[n].replace('<br>', '. ').replace('.', '. ').replace('\\n', ' ').replace('*', ' ').replace(':', ' ').replace('#', ' ').replace('(', ' ').replace(')', ' ')\n",
    "\n",
    "StatCorpus= pd.DataFrame(Statistician['Corpus'])\n",
    "StatCorpus['Clean']=StatCorpus['Corpus'].apply(preprocess)\n",
    "\n",
    "StatCorpus['UniqueClean'] = (StatCorpus['Clean'].str.split()\n",
    "                              .apply(lambda x: OrderedDict.fromkeys(x).keys())\n",
    "                              .str.join(' '))\n",
    "StatCorpus.to_csv('StatCorpus_UniqueClean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "Statcommon_words = get_top_n_words(StatCorpus['UniqueClean'], 50)\n",
    "for word, freq in Statcommon_words:\n",
    "    dfStatistician = pd.DataFrame(Statcommon_words, columns = ['Statwords' , 'Statcount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStatistician.to_csv('StatisticianCount.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Count df to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Top50 = pd.read_csv(\"Top50Words.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
