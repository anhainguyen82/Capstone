{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows-10-10.0.18362-SP0\n",
      "Python 3.6.8 |Anaconda, Inc.| (default, Feb 21 2019, 18:30:04) [MSC v.1916 64 bit (AMD64)]\n",
      "Requests 2.22.0\n",
      "Pandas 0.24.2\n",
      "Numpy 1.17.2\n",
      "NLTK 3.4.5\n",
      "Re 2.2.1\n",
      "Pandas 0.24.2\n",
      "nltk 3.4.5\n",
      "spacy 2.0.11\n",
      "pattern 3.6\n",
      "Python 3.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import platform; print(platform.platform())\n",
    "import sys; print(\"Python\", sys.version)\n",
    "import urllib3.request\n",
    "import requests; print(\"Requests\", requests.__version__)\n",
    "import pandas as pd; print(\"Pandas\", pd.__version__)\n",
    "import numpy as np; print(\"Numpy\", np.__version__)\n",
    "import nltk; print(\"NLTK\", nltk.__version__)\n",
    "import re; print(\"Re\", re.__version__)\n",
    "import json; print(\"Pandas\", pd.__version__)\n",
    "import pprint\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import nltk; print(\"nltk\", nltk.__version__)\n",
    "import spacy; print(\"spacy\", spacy.__version__)\n",
    "import unidecode\n",
    "import unicodedata\n",
    "import pattern; print (\"pattern\", pattern.__version__)\n",
    "import string\n",
    "import time\n",
    "\n",
    "print (os.environ['CONDA_DEFAULT_ENV'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Job Posting Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    SearchTitle                            Title             Location  \\\n",
      "0  Data Analyst  Data Analytics Lead (Marketing)  Englewood, CO 80110   \n",
      "1  Data Analyst     Data Analyst, Naturally Slim           Dallas, TX   \n",
      "2  Data Analyst                     Data Analyst       Washington, DC   \n",
      "3  Data Analyst                     Data Analyst          Oakland, CA   \n",
      "4  Data Analyst                 GIS Data Analyst           Denver, CO   \n",
      "\n",
      "         City State                                   FullDescriptions  \\\n",
      "0   Englewood    CO  Summary\\r\\nSling TV L.L.C. provides an over-th...   \n",
      "1      Dallas    TX  Does organizing and interpreting data make you...   \n",
      "2  Washington    DC  Analytica is seeking a Data Analyst to support...   \n",
      "3     Oakland    CA  At thredUP, we’re working to revolutionize the...   \n",
      "4      Denver    CO  The Geophysics Team Lead applies Geographic In...   \n",
      "\n",
      "                                              Corpus  \n",
      "0  \\r\\nA strategic and innovative thinker who is ...  \n",
      "1  \\r\\nBachelor’s degree in Computer Science, Inf...  \n",
      "2  Bachelor’s Degree\\r\\n5+ years of experience in...  \n",
      "3    \\r\\nDive into our clickstream data to unders...  \n",
      "4  Prefer bachelor's degree in Graphic Informatio...  \n",
      "877\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('C:/Users/anhai/Desktop/SMU/Capstone/ANDY Use These Files/DataAnalyst_Corpus.csv')\n",
    "print(data.head())\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove line breaks and special symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove line breaks and '\\n'\n",
    "for n in range (0, len(df)) :\n",
    "    data.FullDescriptions[n] = df.FullDescriptions[n].replace('\\n', ' ').replace('*', ' ').replace(':', ' ').replace('#', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SearchTitle</th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>FullDescriptions</th>\n",
       "      <th>Corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analytics Lead (Marketing)</td>\n",
       "      <td>Englewood, CO 80110</td>\n",
       "      <td>Englewood</td>\n",
       "      <td>CO</td>\n",
       "      <td>Summary\\r Sling TV L.L.C. provides an over-the...</td>\n",
       "      <td>\\r\\nA strategic and innovative thinker who is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst, Naturally Slim</td>\n",
       "      <td>Dallas, TX</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>TX</td>\n",
       "      <td>Does organizing and interpreting data make you...</td>\n",
       "      <td>\\r\\nBachelor’s degree in Computer Science, Inf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Washington</td>\n",
       "      <td>DC</td>\n",
       "      <td>Analytica is seeking a Data Analyst to support...</td>\n",
       "      <td>Bachelor’s Degree\\r\\n5+ years of experience in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Oakland, CA</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>CA</td>\n",
       "      <td>At thredUP, we’re working to revolutionize the...</td>\n",
       "      <td>\\r\\nDive into our clickstream data to unders...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>GIS Data Analyst</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>Denver</td>\n",
       "      <td>CO</td>\n",
       "      <td>The Geophysics Team Lead applies Geographic In...</td>\n",
       "      <td>Prefer bachelor's degree in Graphic Informatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analytics Teaching Assistant - UC Berkele...</td>\n",
       "      <td>Belmont, CA</td>\n",
       "      <td>Belmont</td>\n",
       "      <td>CA</td>\n",
       "      <td>Trilogy Education partners with universities t...</td>\n",
       "      <td>\\r\\nPython Pandas\\r\\nMatplotlib\\r\\nBeautif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bank Operational Data Analyst &amp; Scientist</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>The Bank Operational Data Analyst &amp; Scientist ...</td>\n",
       "      <td>\\r\\nIndependently or with limited supervision:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst II - Structured Finance</td>\n",
       "      <td>Austin, TX 78705</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "      <td>Monitors and manages large volumes of transact...</td>\n",
       "      <td>\\r\\nExcellent analytical and problem-solving ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst Intern</td>\n",
       "      <td>Los Angeles, CA 90064</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "      <td>Job Description\\r \\r We are hiring a Data Anal...</td>\n",
       "      <td>\\r\\n Analyzing project/product needs, antici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst- MATLAB Developer</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>Analyze and visualize signals in time, frequen...</td>\n",
       "      <td>Strong experience in signal pre-processing te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Sr. Data Analyst</td>\n",
       "      <td>Atlanta, GA 30309</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>Invesco is one of the world's leading global i...</td>\n",
       "      <td>\\r\\nBecome a trusted advisor to business par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Intelligence Analyst</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "      <td>Job Posting Title \\r Data Intelligence Analyst...</td>\n",
       "      <td>Bachelors or Master's degree with major course...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst - MR</td>\n",
       "      <td>Greentree, PA</td>\n",
       "      <td>Greentree</td>\n",
       "      <td>PA</td>\n",
       "      <td>Overview\\r Marketing and advertising materials...</td>\n",
       "      <td>Bachelor’s Degree- concentration or previous w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Scientist - Data Analyst - Experienced As...</td>\n",
       "      <td>Washington, DC 20006</td>\n",
       "      <td>Washington</td>\n",
       "      <td>DC</td>\n",
       "      <td>Overview\\r What do you get when you bring toge...</td>\n",
       "      <td>\\r\\nStatistical analysis;\\r\\nAdvanced analytic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Master Data Analyst III</td>\n",
       "      <td>Kent, WA</td>\n",
       "      <td>Kent</td>\n",
       "      <td>WA</td>\n",
       "      <td>Description \\r As part of a small, passionate ...</td>\n",
       "      <td>Minimum of 5 years' experience in Master Data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst Clinically Integrated Network</td>\n",
       "      <td>Houston, TX 77002</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>CHI St. Luke’s Health is a part of Catholic He...</td>\n",
       "      <td>Experience with the use of healthcare data (a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst, Field Operations</td>\n",
       "      <td>Englewood, CO</td>\n",
       "      <td>Englewood</td>\n",
       "      <td>CO</td>\n",
       "      <td>Bigger challenges. Bolder ideas. Global impact...</td>\n",
       "      <td>\\r\\n4 Year College Degree in Business, Mathe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Media Data Analyst</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "      <td>Los Angeles, CA (Local Candidates Only)\\r At B...</td>\n",
       "      <td>Strong proficiency with MS Excel, PowerPoint ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Lineage Sr. Analyst Associate</td>\n",
       "      <td>Pittsburgh, PA</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>PA</td>\n",
       "      <td>Overview\\r The EXL Finance Transformation team...</td>\n",
       "      <td>Bachelors degree\\r\\nSolid knowledge and abilit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst, Innovation Analytics</td>\n",
       "      <td>Atlanta, GA 30340</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>Aaron’s has a long legacy as an industry leade...</td>\n",
       "      <td>\\r\\nProficient SQL programming skills to extr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Master Data Analyst</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>Role Objectives  Master Data Analyst is respon...</td>\n",
       "      <td>Prepares source data for computer entry by c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>Overview\\r Senior Data Analyst\\r \\r Steritech ...</td>\n",
       "      <td>\\r\\nInterpret data, analyze results using st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Senior Data Analyst - HEDIS and Medicare Star</td>\n",
       "      <td>Long Beach, CA</td>\n",
       "      <td>Long Beach</td>\n",
       "      <td>CA</td>\n",
       "      <td>Senior Data Analyst - HEDIS and Medicare Star\\...</td>\n",
       "      <td>5+ years of analytical experience, includi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Sr. PL Data Analyst/Data Analyst II</td>\n",
       "      <td>Quincy, MA</td>\n",
       "      <td>Quincy</td>\n",
       "      <td>MA</td>\n",
       "      <td>As a Sr. Data Analyst/Data Analyst II, you’ll ...</td>\n",
       "      <td>Analyze strategic and tactical growth opport...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Asset Management - Global Equities - Data Scie...</td>\n",
       "      <td>New York, NY 10172</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>JPMorgan Chase &amp; Co. is a leading global finan...</td>\n",
       "      <td>\\r\\nA demonstrable practical interest in data ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SearchTitle                                              Title  \\\n",
       "0   Data Analyst                    Data Analytics Lead (Marketing)   \n",
       "1   Data Analyst                       Data Analyst, Naturally Slim   \n",
       "2   Data Analyst                                       Data Analyst   \n",
       "3   Data Analyst                                       Data Analyst   \n",
       "4   Data Analyst                                   GIS Data Analyst   \n",
       "5   Data Analyst  Data Analytics Teaching Assistant - UC Berkele...   \n",
       "6   Data Analyst          Bank Operational Data Analyst & Scientist   \n",
       "7   Data Analyst               Data Analyst II - Structured Finance   \n",
       "8   Data Analyst                                Data Analyst Intern   \n",
       "9   Data Analyst                     Data Analyst- MATLAB Developer   \n",
       "10  Data Analyst                                   Sr. Data Analyst   \n",
       "11  Data Analyst                          Data Intelligence Analyst   \n",
       "12  Data Analyst                                  Data Analyst - MR   \n",
       "13  Data Analyst  Data Scientist - Data Analyst - Experienced As...   \n",
       "14  Data Analyst                            Master Data Analyst III   \n",
       "15  Data Analyst         Data Analyst Clinically Integrated Network   \n",
       "16  Data Analyst                     Data Analyst, Field Operations   \n",
       "17  Data Analyst                                 Media Data Analyst   \n",
       "18  Data Analyst                 Data Lineage Sr. Analyst Associate   \n",
       "19  Data Analyst                 Data Analyst, Innovation Analytics   \n",
       "20  Data Analyst                                Master Data Analyst   \n",
       "21  Data Analyst                                Senior Data Analyst   \n",
       "22  Data Analyst      Senior Data Analyst - HEDIS and Medicare Star   \n",
       "23  Data Analyst                Sr. PL Data Analyst/Data Analyst II   \n",
       "24  Data Analyst  Asset Management - Global Equities - Data Scie...   \n",
       "\n",
       "                 Location         City State  \\\n",
       "0     Englewood, CO 80110    Englewood    CO   \n",
       "1              Dallas, TX       Dallas    TX   \n",
       "2          Washington, DC   Washington    DC   \n",
       "3             Oakland, CA      Oakland    CA   \n",
       "4              Denver, CO       Denver    CO   \n",
       "5             Belmont, CA      Belmont    CA   \n",
       "6             Chicago, IL      Chicago    IL   \n",
       "7        Austin, TX 78705       Austin    TX   \n",
       "8   Los Angeles, CA 90064  Los Angeles    CA   \n",
       "9             Houston, TX      Houston    TX   \n",
       "10      Atlanta, GA 30309      Atlanta    GA   \n",
       "11             Austin, TX       Austin    TX   \n",
       "12          Greentree, PA    Greentree    PA   \n",
       "13   Washington, DC 20006   Washington    DC   \n",
       "14               Kent, WA         Kent    WA   \n",
       "15      Houston, TX 77002      Houston    TX   \n",
       "16          Englewood, CO    Englewood    CO   \n",
       "17        Los Angeles, CA  Los Angeles    CA   \n",
       "18         Pittsburgh, PA   Pittsburgh    PA   \n",
       "19      Atlanta, GA 30340      Atlanta    GA   \n",
       "20            Houston, TX      Houston    TX   \n",
       "21            Chicago, IL      Chicago    IL   \n",
       "22         Long Beach, CA   Long Beach    CA   \n",
       "23             Quincy, MA       Quincy    MA   \n",
       "24     New York, NY 10172     New York    NY   \n",
       "\n",
       "                                     FullDescriptions  \\\n",
       "0   Summary\\r Sling TV L.L.C. provides an over-the...   \n",
       "1   Does organizing and interpreting data make you...   \n",
       "2   Analytica is seeking a Data Analyst to support...   \n",
       "3   At thredUP, we’re working to revolutionize the...   \n",
       "4   The Geophysics Team Lead applies Geographic In...   \n",
       "5   Trilogy Education partners with universities t...   \n",
       "6   The Bank Operational Data Analyst & Scientist ...   \n",
       "7   Monitors and manages large volumes of transact...   \n",
       "8   Job Description\\r \\r We are hiring a Data Anal...   \n",
       "9   Analyze and visualize signals in time, frequen...   \n",
       "10  Invesco is one of the world's leading global i...   \n",
       "11  Job Posting Title \\r Data Intelligence Analyst...   \n",
       "12  Overview\\r Marketing and advertising materials...   \n",
       "13  Overview\\r What do you get when you bring toge...   \n",
       "14  Description \\r As part of a small, passionate ...   \n",
       "15  CHI St. Luke’s Health is a part of Catholic He...   \n",
       "16  Bigger challenges. Bolder ideas. Global impact...   \n",
       "17  Los Angeles, CA (Local Candidates Only)\\r At B...   \n",
       "18  Overview\\r The EXL Finance Transformation team...   \n",
       "19  Aaron’s has a long legacy as an industry leade...   \n",
       "20  Role Objectives  Master Data Analyst is respon...   \n",
       "21  Overview\\r Senior Data Analyst\\r \\r Steritech ...   \n",
       "22  Senior Data Analyst - HEDIS and Medicare Star\\...   \n",
       "23  As a Sr. Data Analyst/Data Analyst II, you’ll ...   \n",
       "24  JPMorgan Chase & Co. is a leading global finan...   \n",
       "\n",
       "                                               Corpus  \n",
       "0   \\r\\nA strategic and innovative thinker who is ...  \n",
       "1   \\r\\nBachelor’s degree in Computer Science, Inf...  \n",
       "2   Bachelor’s Degree\\r\\n5+ years of experience in...  \n",
       "3     \\r\\nDive into our clickstream data to unders...  \n",
       "4   Prefer bachelor's degree in Graphic Informatio...  \n",
       "5       \\r\\nPython Pandas\\r\\nMatplotlib\\r\\nBeautif...  \n",
       "6   \\r\\nIndependently or with limited supervision:...  \n",
       "7    \\r\\nExcellent analytical and problem-solving ...  \n",
       "8     \\r\\n Analyzing project/product needs, antici...  \n",
       "9    Strong experience in signal pre-processing te...  \n",
       "10    \\r\\nBecome a trusted advisor to business par...  \n",
       "11  Bachelors or Master's degree with major course...  \n",
       "12  Bachelor’s Degree- concentration or previous w...  \n",
       "13  \\r\\nStatistical analysis;\\r\\nAdvanced analytic...  \n",
       "14  Minimum of 5 years' experience in Master Data ...  \n",
       "15   Experience with the use of healthcare data (a...  \n",
       "16    \\r\\n4 Year College Degree in Business, Mathe...  \n",
       "17   Strong proficiency with MS Excel, PowerPoint ...  \n",
       "18  Bachelors degree\\r\\nSolid knowledge and abilit...  \n",
       "19   \\r\\nProficient SQL programming skills to extr...  \n",
       "20    Prepares source data for computer entry by c...  \n",
       "21    \\r\\nInterpret data, analyze results using st...  \n",
       "22      5+ years of analytical experience, includi...  \n",
       "23    Analyze strategic and tactical growth opport...  \n",
       "24  \\r\\nA demonstrable practical interest in data ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Universal Sentence Encoder - one corpus at a time - TAKES 30 SECONDS PER corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempCorpus = df['FullDescriptions']\n",
    "dummy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Graph().as_default():\n",
    "    embed = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder/2\")\n",
    "    \n",
    "    for corpus in tempCorpus :\n",
    "        messages = [corpus]\n",
    "        output = embed(messages)\n",
    " \n",
    "        with tf.Session() as session:\n",
    "            session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "            t1 = time.time()\n",
    "            message_embeddings = session.run(output)\n",
    "            print(time.time() - t1)\n",
    "            dummy.append(message_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.02395125e-02,  1.60463080e-02, -2.23891102e-02,\n",
       "        -4.34342166e-03,  6.44785399e-03, -9.03625861e-02,\n",
       "         1.22285234e-02,  2.78480612e-02, -2.59086229e-02,\n",
       "         3.79698128e-02, -1.95618309e-02,  5.08786775e-02,\n",
       "        -5.15983067e-02,  5.73120825e-02,  9.76173300e-03,\n",
       "         2.70774812e-02,  2.05946229e-02, -9.61376820e-03,\n",
       "         9.41379368e-02, -2.22235490e-02,  6.18627928e-02,\n",
       "        -3.83428335e-02, -5.98125495e-02,  9.38614011e-02,\n",
       "        -4.54228278e-03,  5.61258681e-02, -3.17748524e-02,\n",
       "        -2.19284613e-02,  3.10339388e-02, -7.94195458e-02,\n",
       "         4.92859967e-02,  4.32612784e-02, -3.25758159e-02,\n",
       "        -5.29966764e-02,  8.15892592e-02,  1.73796993e-02,\n",
       "        -1.55277792e-02, -9.54639614e-02, -1.64624061e-02,\n",
       "         4.38066153e-03, -7.02854842e-02,  8.67424533e-03,\n",
       "         1.35337822e-02,  3.58423330e-02, -2.49423627e-02,\n",
       "         7.55811185e-02,  2.23724078e-02, -5.77496924e-03,\n",
       "         1.82581879e-03, -9.24453884e-02,  7.30333850e-02,\n",
       "         1.98422447e-02,  8.77850577e-02, -2.29238588e-02,\n",
       "         2.78235804e-02,  4.22851406e-02,  6.75320253e-02,\n",
       "        -7.49554411e-02,  3.49826515e-02, -4.13480625e-02,\n",
       "         1.34092243e-02,  2.74860370e-03,  4.62094843e-02,\n",
       "         4.20360230e-02, -8.46582800e-02, -6.63060397e-02,\n",
       "         7.80769885e-02,  2.83197407e-02,  7.36962333e-02,\n",
       "         1.44342622e-02, -6.41282126e-02, -1.97098851e-02,\n",
       "        -2.59408131e-02,  3.16821486e-02, -1.94297247e-02,\n",
       "        -1.01155462e-02,  5.47459982e-02,  5.85917383e-02,\n",
       "         2.85805818e-02, -8.70040357e-02,  5.16783595e-02,\n",
       "         3.94477174e-02,  2.49362347e-04,  4.05779220e-02,\n",
       "        -6.87193051e-02,  5.05114160e-02,  9.08970833e-02,\n",
       "         3.78879160e-02,  1.36697767e-02, -2.88913641e-02,\n",
       "         3.46053168e-02,  2.59322599e-02, -1.99167877e-02,\n",
       "        -7.17911944e-02,  2.70469561e-02,  3.00197266e-02,\n",
       "         5.45408130e-02, -5.55577725e-02,  2.38526724e-02,\n",
       "         6.18617609e-02, -2.21226877e-03, -1.83965024e-02,\n",
       "        -3.94835696e-02,  7.30466284e-03, -1.72538832e-02,\n",
       "        -3.84899788e-02, -5.42800315e-02, -1.38120605e-02,\n",
       "         5.19663692e-02,  1.25090387e-02, -6.02523563e-03,\n",
       "        -2.55985954e-03,  6.70236275e-02,  2.41719987e-02,\n",
       "        -3.43110636e-02,  5.47360629e-02,  3.94313261e-02,\n",
       "        -3.55348140e-02, -1.08833099e-02,  6.23414591e-02,\n",
       "        -6.97129816e-02, -5.76279499e-02, -5.12933880e-02,\n",
       "         1.44118955e-02,  3.45319174e-02, -6.04921915e-02,\n",
       "        -4.19445743e-04, -1.99828669e-02,  5.76435439e-02,\n",
       "         3.56684029e-02,  4.94775102e-02,  5.01390398e-02,\n",
       "        -8.39938819e-02,  1.32328905e-02, -8.64055380e-03,\n",
       "        -2.32608765e-02,  5.83274662e-02, -4.75263372e-02,\n",
       "         3.34728286e-02,  2.03846339e-02,  2.00710837e-02,\n",
       "         5.97015060e-02, -6.19449317e-02,  8.75050947e-03,\n",
       "        -2.67512966e-02,  4.85146344e-02, -2.95641441e-02,\n",
       "         8.41149315e-02,  9.03612822e-02,  5.56636676e-02,\n",
       "         8.01119022e-03, -9.99923237e-03,  3.13545093e-02,\n",
       "         2.21682154e-02,  3.32799032e-02,  7.53081143e-02,\n",
       "         2.66731698e-02, -9.77739692e-02, -6.48633316e-02,\n",
       "         4.44735251e-02, -4.24860045e-02, -1.67908031e-03,\n",
       "         3.40321697e-02,  4.80308458e-02,  5.01864310e-03,\n",
       "         4.63064313e-02,  6.29285444e-03,  6.60640895e-02,\n",
       "         4.33431752e-02,  9.18008108e-03, -4.82209995e-02,\n",
       "         7.14606373e-03,  1.57420542e-02,  3.92013900e-02,\n",
       "         2.25768220e-02,  5.64404353e-02,  7.08608702e-02,\n",
       "         4.05612774e-03, -3.19559537e-02,  3.55147123e-02,\n",
       "         9.01545305e-03,  1.02262571e-02, -6.40547872e-02,\n",
       "         3.03588640e-02,  4.42260429e-02, -6.04182407e-02,\n",
       "         5.43153845e-02,  4.77431305e-02,  7.81392157e-02,\n",
       "        -1.27675040e-02,  3.00534051e-02,  5.53844534e-02,\n",
       "        -4.07225303e-02,  6.75241724e-02, -3.74393240e-02,\n",
       "        -2.77388450e-02,  3.84803638e-02,  2.16012131e-02,\n",
       "        -5.19658327e-02,  1.31838275e-02, -6.99839368e-03,\n",
       "         9.26853716e-02,  6.98926151e-02,  6.76912218e-02,\n",
       "        -4.59519811e-02,  1.90882459e-02, -2.99672652e-02,\n",
       "        -4.26954968e-04,  7.48540163e-02,  4.01852699e-03,\n",
       "         3.09038498e-02,  1.84874367e-02, -8.48474130e-02,\n",
       "        -6.42861128e-02, -9.55876242e-03,  7.63196964e-03,\n",
       "        -3.11830770e-02,  3.51857208e-02,  1.50023699e-02,\n",
       "         6.17400073e-02,  9.57095549e-02, -7.64626414e-02,\n",
       "        -3.29683870e-02,  1.37853976e-02, -9.78732016e-03,\n",
       "         3.07769608e-02,  6.12210436e-03, -3.08207981e-03,\n",
       "        -7.11454228e-02, -1.53976046e-02, -9.20778606e-03,\n",
       "        -4.13502753e-02,  3.49388309e-02,  1.39361927e-02,\n",
       "         2.55254228e-02, -8.91620480e-03,  8.28788131e-02,\n",
       "         6.17044456e-02, -5.13078533e-02, -2.61591114e-02,\n",
       "        -1.65810604e-02,  5.55063132e-03, -3.72633431e-03,\n",
       "        -4.29536216e-02, -4.14932668e-02, -2.40191780e-02,\n",
       "         5.89907840e-02, -2.37004412e-03, -1.51731269e-02,\n",
       "        -5.82341403e-02,  6.05481006e-02,  1.09488787e-02,\n",
       "        -4.80835959e-02, -1.66242495e-02, -5.42531125e-02,\n",
       "         8.70180316e-03,  5.17576858e-02, -1.99162196e-02,\n",
       "         6.64651673e-03, -3.55510563e-02, -5.46128564e-02,\n",
       "        -1.83025189e-02, -3.63218808e-03,  6.22031093e-02,\n",
       "         4.13999297e-02, -4.34008799e-03, -9.87400264e-02,\n",
       "        -2.68602464e-03,  9.60562006e-02, -6.44233376e-02,\n",
       "        -6.29661381e-02, -2.38053128e-02, -7.85500854e-02,\n",
       "         6.13595806e-02, -4.04021181e-02, -2.73264218e-02,\n",
       "         4.48824503e-02, -3.45965731e-03,  3.45025398e-02,\n",
       "         2.63365265e-02, -5.29414490e-02,  5.48067316e-02,\n",
       "         6.37659989e-03, -1.68817136e-02, -1.49401762e-02,\n",
       "         1.47647923e-02,  4.05585654e-02, -8.84646177e-03,\n",
       "        -6.15531504e-02, -5.14744967e-03,  6.17288006e-03,\n",
       "        -1.92263406e-02, -5.19232713e-02, -5.51373176e-02,\n",
       "         1.39818224e-03,  1.75834652e-02, -3.34585737e-03,\n",
       "        -3.48298661e-02, -8.40608627e-02,  6.64556101e-02,\n",
       "        -7.82611687e-03, -3.08700111e-02,  8.77099155e-05,\n",
       "         8.90980125e-04,  7.53043592e-02, -6.75174524e-04,\n",
       "        -1.34354401e-02, -3.47651467e-02, -3.45069431e-02,\n",
       "         2.26921979e-02, -4.06537205e-02,  1.22714229e-03,\n",
       "        -6.49365634e-02,  3.26329432e-02,  3.64577584e-02,\n",
       "         4.39823186e-03,  4.20660339e-02, -2.19999757e-02,\n",
       "        -4.95878980e-03,  1.77614298e-02, -2.47093420e-02,\n",
       "        -3.37537704e-03, -5.95557503e-02,  3.91195266e-04,\n",
       "        -4.73301001e-02, -4.66334540e-03,  6.38783723e-02,\n",
       "        -1.19137845e-03, -9.05575678e-02,  4.76693809e-02,\n",
       "        -4.10710014e-02,  7.01191276e-03, -4.79963273e-05,\n",
       "         1.79926527e-03,  6.39764816e-02,  2.93470714e-02,\n",
       "        -1.50241591e-02,  2.07723640e-02,  5.88316703e-03,\n",
       "         2.39252355e-02, -3.70864733e-03, -5.29501960e-03,\n",
       "         9.16099772e-02,  9.35618058e-02, -4.50710114e-03,\n",
       "        -8.56462568e-02, -1.44766970e-03, -7.67741278e-02,\n",
       "         5.24818636e-02, -4.61807288e-02,  9.28532332e-03,\n",
       "        -5.64916991e-03, -1.88175458e-02,  2.68574674e-02,\n",
       "        -8.90283212e-02,  1.36189386e-02,  1.15357563e-02,\n",
       "         5.94581924e-02, -4.01210040e-02,  4.18650396e-02,\n",
       "        -1.52477091e-02, -5.91837708e-03, -3.36391269e-04,\n",
       "        -4.04719338e-02,  6.34108623e-03,  6.90060407e-02,\n",
       "        -1.22632866e-03,  9.27345604e-02,  5.97114936e-02,\n",
       "         2.88319234e-02,  3.63664962e-02,  3.92979309e-02,\n",
       "        -1.33984778e-02,  4.61521186e-02,  5.52782789e-02,\n",
       "        -6.60556257e-02, -2.86795292e-02, -3.61897349e-02,\n",
       "        -8.18020701e-02,  1.93639565e-02,  9.34301540e-02,\n",
       "         7.06440508e-02, -1.17703937e-02,  2.66074184e-02,\n",
       "         1.34622315e-02, -2.68559288e-02, -3.06539871e-02,\n",
       "         9.55777432e-05, -8.38358924e-02, -3.00702807e-02,\n",
       "         1.10562034e-02,  1.89065225e-02, -1.00654112e-02,\n",
       "         1.38574978e-03,  3.38705778e-02, -6.05424307e-02,\n",
       "        -2.98951566e-02,  5.25997132e-02,  4.34664562e-02,\n",
       "         3.00718155e-02,  5.31612858e-02, -3.57381441e-02,\n",
       "        -6.78736567e-02,  5.68883009e-02, -7.21790865e-02,\n",
       "         1.76812746e-02, -8.06583986e-02,  3.43084447e-02,\n",
       "        -6.39987960e-02, -2.24155542e-02,  6.75475225e-02,\n",
       "         3.70064676e-02,  5.64591261e-03, -2.94814706e-02,\n",
       "         6.97938651e-02, -1.92060154e-02, -3.74092832e-02,\n",
       "         7.21017867e-02,  8.75423178e-02,  5.41235432e-02,\n",
       "         1.54184736e-02, -1.73595957e-02,  7.92499445e-03,\n",
       "        -9.94691363e-05, -5.44757629e-03, -1.43678552e-02,\n",
       "         9.25232749e-03, -4.11607251e-02, -2.64778193e-02,\n",
       "         4.05815803e-02,  3.07452250e-02, -2.40348559e-02,\n",
       "         4.87561338e-03, -3.24613824e-02,  8.45701713e-03,\n",
       "         2.64476817e-02,  3.66245322e-02, -2.55641602e-02,\n",
       "        -5.21988496e-02,  3.65577415e-02,  6.69031292e-02,\n",
       "        -1.91523936e-02, -2.94655301e-02, -1.68850776e-02,\n",
       "        -5.74400611e-02, -3.67255025e-02,  3.85405608e-02,\n",
       "        -1.60313006e-02,  4.01397794e-02,  7.46786743e-02,\n",
       "         2.87330709e-02,  2.40590479e-02,  8.91829189e-03,\n",
       "         4.16549072e-02,  5.14229387e-02, -5.13696447e-02,\n",
       "         2.01209933e-02, -2.02281252e-02,  4.38083038e-02,\n",
       "        -2.83494852e-02,  5.67444542e-04,  1.32720703e-02,\n",
       "         8.35857764e-02,  3.92508283e-02, -3.01937689e-03,\n",
       "         3.23265344e-02,  6.45708740e-02, -4.00073789e-02,\n",
       "        -1.94430053e-02, -3.50163355e-02, -1.12588210e-02,\n",
       "        -9.80091840e-02,  5.79205230e-02, -1.35421911e-02,\n",
       "        -1.84660009e-03,  1.27397978e-03, -2.84245256e-02,\n",
       "         1.18475128e-02, -9.54147987e-03,  2.53700595e-02,\n",
       "         5.36647663e-02,  2.31339037e-02, -2.18717847e-02,\n",
       "        -4.64501157e-02, -6.29933476e-02,  5.52947037e-02,\n",
       "        -3.19607090e-03,  3.91095430e-02, -3.72561812e-02,\n",
       "        -6.03947677e-02, -2.33417656e-02,  1.87905692e-02,\n",
       "         2.71613561e-02,  5.22766709e-02,  4.38508950e-02,\n",
       "        -2.40759961e-02,  6.49449751e-02, -7.32823089e-02,\n",
       "         5.18900016e-03,  7.89699797e-03, -1.40597029e-02,\n",
       "        -2.38092989e-02,  5.79959266e-02,  6.12842962e-02,\n",
       "        -1.12906527e-02, -1.71525329e-02,  5.73532991e-02,\n",
       "        -8.24698061e-02,  1.68740917e-02, -6.15204386e-02,\n",
       "        -1.90277360e-02, -6.52386621e-02]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "# Add Feature Vectors to dataframe\n",
    "df['Feature_Vector'] = dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export dataframe to CSV\n",
    "df.to_csv(r'DS_25_Feature_Vectors.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send Corpus as one complete list  - DOES NOT WORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempBatch = tempCorpus.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"About Pivot Bio ---------------  Fueled by an innovative drive and a deep understanding of the soil microbiome, Pivot Bio is pioneering game-changing advances in agriculture. Our first commercial product harnesses the power of naturally-occurring microbes to provide nutrients to crops. We are dedicated to providing new sustainable ways for farmers to improve yield as they work to help feed the world's growing population.  The Field Technology team measures and models the performance of Pivot's microbial product. We aim to use this proprietary data to increase the value of our product. The Senior Data Scientist will analyze large, complex data sets to create and optimize predictive models using machine learning and other statistical tools. They will own the prototyping and early development of data products that can complement our microbial nitrogen fertilizer.  Location  Berkeley, CA  Responsibilities   Own the development of predictive analytics that quantify the impact and increase the value of our core microbial product. Help develop Pivot's technical partnership strategy for creating value from data. Work with Pivot's data engineering team to translate statistical models from R&D to production. Communicate the impact of our work to internal and external stakeholders.  Required Skills and Experience   Ph.D. in a quantitative discipline plus 2+ years experience in industry or M.S. and equivalent practical experience, particularly in agricultural/plant, remote sensing, or biological data. Experience using Python and developing statistical models in a shared on-cloud database. Knowledge of R is a plus. Understanding of how to structure and analyze problems with machine learning, from both a conceptual standpoint, as well as having practical knowledge of libraries such as sklearn, PyTorch, and TensorFlow Experience working with complex structured spatial and time-series data, from exploratory analysis to hierarchical or ML modeling. Knowledge of Bayesian methods is a plus. Must be authorized to work in the U.S.  What we offer   Competitive package in an early-stage, disruptive startup Health/Dental/Vision 401(k) plan Flexible vacation policy Exciting opportunity to work with a talented and fun team  \""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempBatch[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't convert 'text': Shape TensorShape([Dimension(1), Dimension(25)]) is incompatible with TensorShape([Dimension(None)])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-fad15efdf417>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0membed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://tfhub.dev/google/universal-sentence-encoder/2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmessages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtempBatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow_hub/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, _sentinel, signature, as_dict)\u001b[0m\n\u001b[1;32m    248\u001b[0m     dict_inputs = _convert_dict_inputs(\n\u001b[1;32m    249\u001b[0m         inputs, self._spec.get_input_info_dict(signature=signature,\n\u001b[0;32m--> 250\u001b[0;31m                                                tags=self._tags))\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     dict_outputs = self._impl.create_apply_graph(\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow_hub/module.py\u001b[0m in \u001b[0;36m_convert_dict_inputs\u001b[0;34m(inputs, tensor_info_map)\u001b[0m\n\u001b[1;32m    450\u001b[0m   \u001b[0mdict_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_dict_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_info_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m   return tensor_info.convert_dict_to_compatible_tensor(dict_inputs,\n\u001b[0;32m--> 452\u001b[0;31m                                                        tensor_info_map)\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow_hub/tensor_info.py\u001b[0m in \u001b[0;36mconvert_dict_to_compatible_tensor\u001b[0;34m(values, targets)\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     result[key] = _convert_to_compatible_tensor(\n\u001b[0;32m--> 150\u001b[0;31m         value, targets[key], error_prefix=\"Can't convert %r\" % key)\n\u001b[0m\u001b[1;32m    151\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow_hub/tensor_info.py\u001b[0m in \u001b[0;36m_convert_to_compatible_tensor\u001b[0;34m(value, target, error_prefix)\u001b[0m\n\u001b[1;32m    127\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     raise TypeError(\"%s: Shape %r is incompatible with %r\" %\n\u001b[0;32m--> 129\u001b[0;31m                     (error_prefix, tensor.get_shape(), target.get_shape()))\n\u001b[0m\u001b[1;32m    130\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can't convert 'text': Shape TensorShape([Dimension(1), Dimension(25)]) is incompatible with TensorShape([Dimension(None)])"
     ]
    }
   ],
   "source": [
    "dummy_2 = []\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    embed = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder/2\")\n",
    "    messages = [tempBatch]\n",
    "    output = embed(messages)\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    t1 = time.time()\n",
    "    message_embeddings = session.run(output)\n",
    "    print(time.time() - t1)\n",
    "    dummy_2.append(message_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce logging output.\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "with tf.Session() as session:\n",
    "  session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "  message_embeddings = session.run(embed(messages))\n",
    "\n",
    "  for i, message_embedding in enumerate(np.array(message_embeddings).tolist()):\n",
    "    print(\"Message: {}\".format(messages[i]))\n",
    "    print(\"Embedding size: {}\".format(len(message_embedding)))\n",
    "    message_embedding_snippet = \", \".join(\n",
    "        (str(x) for x in message_embedding[:3]))\n",
    "    print(\"Embedding: [{}, ...]\\n\".format(message_embedding_snippet))\n",
    "    dummy.append(message_embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
