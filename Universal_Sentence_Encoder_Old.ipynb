{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.7\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Darwin-18.7.0-x86_64-i386-64bit\n",
      "Python 3.7.2 (default, Dec 29 2018, 00:00:04) \n",
      "[Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "Requests 2.19.1\n",
      "Pandas 0.24.2\n",
      "Numpy 1.16.4\n",
      "NLTK 3.3\n",
      "Re 2.2.1\n",
      "Pandas 0.24.2\n",
      "nltk 3.3\n",
      "spacy 2.1.4\n",
      "pattern 3.6\n",
      "base\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import platform; print(platform.platform())\n",
    "import sys; print(\"Python\", sys.version)\n",
    "import urllib3.request\n",
    "import requests; print(\"Requests\", requests.__version__)\n",
    "import pandas as pd; print(\"Pandas\", pd.__version__)\n",
    "import numpy as np; print(\"Numpy\", np.__version__)\n",
    "import nltk; print(\"NLTK\", nltk.__version__)\n",
    "import re; print(\"Re\", re.__version__)\n",
    "import json; print(\"Pandas\", pd.__version__)\n",
    "import pprint\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import nltk; print(\"nltk\", nltk.__version__)\n",
    "import spacy; print(\"spacy\", spacy.__version__)\n",
    "import unidecode\n",
    "import unicodedata\n",
    "import pattern; print (\"pattern\", pattern.__version__)\n",
    "import string\n",
    "import time\n",
    "\n",
    "print (os.environ['CONDA_DEFAULT_ENV'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Job Posting Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                  Title            Location           City State  \\\n",
      "0           0         Data Scientist       Cambridge, MA      Cambridge    MA   \n",
      "1           2         Data Scientist        Berkeley, CA       Berkeley    CA   \n",
      "2           3  Senior Data Scientist  Berkeley, CA 94710       Berkeley    CA   \n",
      "3           4  Senior Data Scientist        Berkeley, CA       Berkeley    CA   \n",
      "4           5         Data Scientist   Beverly Hills, CA  Beverly Hills    CA   \n",
      "\n",
      "          Zip     Country                                     Qualifications  \\\n",
      "0  None Found  None Found                                         None Found   \n",
      "1  None Found  None Found  \\nProficiency in Python, including both data s...   \n",
      "2       94710  None Found                                         None Found   \n",
      "3  None Found  None Found                                         None Found   \n",
      "4  None Found  None Found                                         None Found   \n",
      "\n",
      "                                              Skills  \\\n",
      "0                                         None Found   \n",
      "1                                         None Found   \n",
      "2  \\nPh.D. in a quantitative discipline plus 2+ y...   \n",
      "3                                         None Found   \n",
      "4                                         None Found   \n",
      "\n",
      "                                    Responsibilities   Education Requirement  \\\n",
      "0                                         None Found  None Found  None Found   \n",
      "1  \\nHelp develop KoBold’s proprietary software c...  None Found  None Found   \n",
      "2  \\nOwn the development of predictive analytics ...  None Found  None Found   \n",
      "3                                         None Found  None Found  None Found   \n",
      "4                                         None Found  None Found  None Found   \n",
      "\n",
      "                                    FullDescriptions  \n",
      "0  ------\\n\\n------\\n\\n--------------------------...  \n",
      "1  About the company\\nKoBold Metals is using mach...  \n",
      "2  About Pivot Bio\\n---------------\\n\\nFueled by ...  \n",
      "3  Senior Data Scientist\\nSenior Data Scientists ...  \n",
      "4  Fandango is seeking a driven, analytically cur...  \n",
      "1740\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('datascientist.csv')\n",
    "print(data.head())\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove line breaks and special symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Remove line breaks and '\\n'\n",
    "for n in range (0, len(df)) :\n",
    "    data.FullDescriptions[n] = df.FullDescriptions[n].replace('\\n', ' ').replace('*', ' ').replace(':', ' ').replace('#', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Country</th>\n",
       "      <th>Qualifications</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Responsibilities</th>\n",
       "      <th>Education</th>\n",
       "      <th>Requirement</th>\n",
       "      <th>FullDescriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Cambridge, MA</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>MA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>------  ------  ------------------------------...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Berkeley, CA</td>\n",
       "      <td>Berkeley</td>\n",
       "      <td>CA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nProficiency in Python, including both data s...</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nHelp develop KoBold’s proprietary software c...</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>About the company KoBold Metals is using machi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Berkeley, CA 94710</td>\n",
       "      <td>Berkeley</td>\n",
       "      <td>CA</td>\n",
       "      <td>94710</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nPh.D. in a quantitative discipline plus 2+ y...</td>\n",
       "      <td>\\nOwn the development of predictive analytics ...</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>About Pivot Bio ---------------  Fueled by an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Berkeley, CA</td>\n",
       "      <td>Berkeley</td>\n",
       "      <td>CA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Senior Data Scientist Senior Data Scientists o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Beverly Hills, CA</td>\n",
       "      <td>Beverly Hills</td>\n",
       "      <td>CA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Fandango is seeking a driven, analytically cur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>-------- About Us --------  KeyMe is a New Yor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>----------------------------------------------...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Brisbane, CA 94005</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>CA</td>\n",
       "      <td>94005</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Ph.D in Physics, Computational Biology or Comp...</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Help design and produce analytical data pipeli...</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Headquartered in Brisbane, Calif., CareDx, Inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13</td>\n",
       "      <td>Artificial Intelligence/Analytics Data Scienti...</td>\n",
       "      <td>Burbank, CA</td>\n",
       "      <td>Burbank</td>\n",
       "      <td>CA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Qualifications: 1 – 3 years experience, Bachel...</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Candidates should be flexible / willing to wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14</td>\n",
       "      <td>Data Scientist Manager - Hiring in Burbank!</td>\n",
       "      <td>Burbank, CA</td>\n",
       "      <td>Burbank</td>\n",
       "      <td>CA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Qualifications: 7 – 10 (3 years min relevant e...</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>5-10 years professional work experience as a d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15</td>\n",
       "      <td>Senior Lead Machine Learning Engineer/Data Sci...</td>\n",
       "      <td>New York, NY 10020</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>10020</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nLead a team of machine learning engineers, d...</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\n5+ years' experience developing, maintaining...</td>\n",
       "      <td>(We are not sponsoring for this role or in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Manhattan, NY</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>NY</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Non 55-a Program candidates interested in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>17</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Burlingame, CA</td>\n",
       "      <td>Burlingame</td>\n",
       "      <td>CA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Who you are The first Data Scientist at Finris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18</td>\n",
       "      <td>TV Data Scientist</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Boston</td>\n",
       "      <td>MA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>TV Data Scientist           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>19</td>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Data Scientist Intern   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Boulder, CO 80301</td>\n",
       "      <td>Boulder</td>\n",
       "      <td>CO</td>\n",
       "      <td>80301</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Description    At Pearson, we are committed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>22</td>\n",
       "      <td>Data Scientist - Grid Analytics</td>\n",
       "      <td>Burlingame, CA 94010</td>\n",
       "      <td>Burlingame</td>\n",
       "      <td>CA</td>\n",
       "      <td>94010</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nDegree in computer science, applied math, st...</td>\n",
       "      <td>Description  Sentient Energy is looking for a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>23</td>\n",
       "      <td>Data Scientist - Grid Analytics</td>\n",
       "      <td>Burlingame, CA 94010</td>\n",
       "      <td>Burlingame</td>\n",
       "      <td>CA</td>\n",
       "      <td>94010</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nDegree in computer science, applied math, st...</td>\n",
       "      <td>Description  Sentient Energy is looking for a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>24</td>\n",
       "      <td>Data Scientist - Product BURLINGAME, CALIFORNI...</td>\n",
       "      <td>Burlingame, CA 94010</td>\n",
       "      <td>Burlingame</td>\n",
       "      <td>CA</td>\n",
       "      <td>94010</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\n3+ years of data analysis in an industry set...</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Lyra is transforming mental health care by cre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>25</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nB.A./B.S. in Mathematics, Computer Science, ...</td>\n",
       "      <td>[Job Details]  Position Overview  The Data Sci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>27</td>\n",
       "      <td>Artificial Intelligence - Data Science - Houston</td>\n",
       "      <td>Houston, TX 77010</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>77010</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Qualification: 12+ years experience, Bachelor’...</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>10+ years professional work experience as a da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>28</td>\n",
       "      <td>Senior Associate, Data Scientist</td>\n",
       "      <td>New York, NY 10011</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>10011</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>11 West 19th Street (22008), United States of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>29</td>\n",
       "      <td>Data Scientist (United Income)</td>\n",
       "      <td>Fairfax, VA</td>\n",
       "      <td>Fairfax</td>\n",
       "      <td>VA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nAt least a Master’s Degree OR a Bachelor’s D...</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>1660 L Street NW (19006), United States of Ame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>31</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Arlington, VA</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>VA</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nCreating machine learning models from develo...</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>2+ years professional experience as a data sci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>33</td>\n",
       "      <td>2020 Spring Internship - Data Science</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Washington</td>\n",
       "      <td>DC</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>You must be a student or recent college gradua...</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Understand client background and needs, includ...</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>2020 Spring Internship - Data Science(Job Numb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                              Title  \\\n",
       "0            0                                     Data Scientist   \n",
       "1            2                                     Data Scientist   \n",
       "2            3                              Senior Data Scientist   \n",
       "3            4                              Senior Data Scientist   \n",
       "4            5                                     Data Scientist   \n",
       "5            6                                     Data Scientist   \n",
       "6           10                              Senior Data Scientist   \n",
       "7           12                                     Data Scientist   \n",
       "8           13  Artificial Intelligence/Analytics Data Scienti...   \n",
       "9           14        Data Scientist Manager - Hiring in Burbank!   \n",
       "10          15  Senior Lead Machine Learning Engineer/Data Sci...   \n",
       "11          16                                     Data Scientist   \n",
       "12          17                                     Data Scientist   \n",
       "13          18                                  TV Data Scientist   \n",
       "14          19                                Data Science Intern   \n",
       "15          20                              Senior Data Scientist   \n",
       "16          22                    Data Scientist - Grid Analytics   \n",
       "17          23                    Data Scientist - Grid Analytics   \n",
       "18          24  Data Scientist - Product BURLINGAME, CALIFORNI...   \n",
       "19          25                                     Data Scientist   \n",
       "20          27   Artificial Intelligence - Data Science - Houston   \n",
       "21          28                   Senior Associate, Data Scientist   \n",
       "22          29                     Data Scientist (United Income)   \n",
       "23          31                                     Data Scientist   \n",
       "24          33              2020 Spring Internship - Data Science   \n",
       "\n",
       "                Location           City State         Zip     Country  \\\n",
       "0          Cambridge, MA      Cambridge    MA  None Found  None Found   \n",
       "1           Berkeley, CA       Berkeley    CA  None Found  None Found   \n",
       "2     Berkeley, CA 94710       Berkeley    CA       94710  None Found   \n",
       "3           Berkeley, CA       Berkeley    CA  None Found  None Found   \n",
       "4      Beverly Hills, CA  Beverly Hills    CA  None Found  None Found   \n",
       "5           New York, NY       New York    NY  None Found  None Found   \n",
       "6            Chicago, IL        Chicago    IL  None Found  None Found   \n",
       "7     Brisbane, CA 94005       Brisbane    CA       94005  None Found   \n",
       "8            Burbank, CA        Burbank    CA  None Found  None Found   \n",
       "9            Burbank, CA        Burbank    CA  None Found  None Found   \n",
       "10    New York, NY 10020       New York    NY       10020  None Found   \n",
       "11         Manhattan, NY      Manhattan    NY  None Found  None Found   \n",
       "12        Burlingame, CA     Burlingame    CA  None Found  None Found   \n",
       "13            Boston, MA         Boston    MA  None Found  None Found   \n",
       "14          New York, NY       New York    NY  None Found  None Found   \n",
       "15     Boulder, CO 80301        Boulder    CO       80301  None Found   \n",
       "16  Burlingame, CA 94010     Burlingame    CA       94010  None Found   \n",
       "17  Burlingame, CA 94010     Burlingame    CA       94010  None Found   \n",
       "18  Burlingame, CA 94010     Burlingame    CA       94010  None Found   \n",
       "19           Houston, TX        Houston    TX  None Found  None Found   \n",
       "20     Houston, TX 77010        Houston    TX       77010  None Found   \n",
       "21    New York, NY 10011       New York    NY       10011  None Found   \n",
       "22           Fairfax, VA        Fairfax    VA  None Found  None Found   \n",
       "23         Arlington, VA      Arlington    VA  None Found  None Found   \n",
       "24        Washington, DC     Washington    DC  None Found  None Found   \n",
       "\n",
       "                                       Qualifications  \\\n",
       "0                                          None Found   \n",
       "1   \\nProficiency in Python, including both data s...   \n",
       "2                                          None Found   \n",
       "3                                          None Found   \n",
       "4                                          None Found   \n",
       "5                                          None Found   \n",
       "6                                          None Found   \n",
       "7   Ph.D in Physics, Computational Biology or Comp...   \n",
       "8   Qualifications: 1 – 3 years experience, Bachel...   \n",
       "9   Qualifications: 7 – 10 (3 years min relevant e...   \n",
       "10                                         None Found   \n",
       "11                                         None Found   \n",
       "12                                         None Found   \n",
       "13                                         None Found   \n",
       "14                                         None Found   \n",
       "15                                         None Found   \n",
       "16                                         None Found   \n",
       "17                                         None Found   \n",
       "18  \\n3+ years of data analysis in an industry set...   \n",
       "19                                         None Found   \n",
       "20  Qualification: 12+ years experience, Bachelor’...   \n",
       "21                                         None Found   \n",
       "22  \\nAt least a Master’s Degree OR a Bachelor’s D...   \n",
       "23                                         None Found   \n",
       "24  You must be a student or recent college gradua...   \n",
       "\n",
       "                                               Skills  \\\n",
       "0                                          None Found   \n",
       "1                                          None Found   \n",
       "2   \\nPh.D. in a quantitative discipline plus 2+ y...   \n",
       "3                                          None Found   \n",
       "4                                          None Found   \n",
       "5                                          None Found   \n",
       "6                                          None Found   \n",
       "7                                          None Found   \n",
       "8                                          None Found   \n",
       "9                                          None Found   \n",
       "10                                         None Found   \n",
       "11                                         None Found   \n",
       "12                                         None Found   \n",
       "13                                         None Found   \n",
       "14                                         None Found   \n",
       "15                                         None Found   \n",
       "16                                         None Found   \n",
       "17                                         None Found   \n",
       "18                                         None Found   \n",
       "19                                         None Found   \n",
       "20                                         None Found   \n",
       "21                                         None Found   \n",
       "22                                         None Found   \n",
       "23                                         None Found   \n",
       "24                                         None Found   \n",
       "\n",
       "                                     Responsibilities   Education  \\\n",
       "0                                          None Found  None Found   \n",
       "1   \\nHelp develop KoBold’s proprietary software c...  None Found   \n",
       "2   \\nOwn the development of predictive analytics ...  None Found   \n",
       "3                                          None Found  None Found   \n",
       "4                                          None Found  None Found   \n",
       "5                                          None Found  None Found   \n",
       "6                                          None Found  None Found   \n",
       "7   Help design and produce analytical data pipeli...  None Found   \n",
       "8                                          None Found  None Found   \n",
       "9                                          None Found  None Found   \n",
       "10  \\nLead a team of machine learning engineers, d...  None Found   \n",
       "11                                         None Found  None Found   \n",
       "12                                         None Found  None Found   \n",
       "13                                         None Found  None Found   \n",
       "14                                         None Found  None Found   \n",
       "15                                         None Found  None Found   \n",
       "16                                         None Found  None Found   \n",
       "17                                         None Found  None Found   \n",
       "18                                         None Found  None Found   \n",
       "19                                         None Found  None Found   \n",
       "20                                         None Found  None Found   \n",
       "21                                         None Found  None Found   \n",
       "22                                         None Found  None Found   \n",
       "23  \\nCreating machine learning models from develo...  None Found   \n",
       "24  Understand client background and needs, includ...  None Found   \n",
       "\n",
       "                                          Requirement  \\\n",
       "0                                          None Found   \n",
       "1                                          None Found   \n",
       "2                                          None Found   \n",
       "3                                          None Found   \n",
       "4                                          None Found   \n",
       "5                                          None Found   \n",
       "6                                          None Found   \n",
       "7                                          None Found   \n",
       "8                                          None Found   \n",
       "9                                          None Found   \n",
       "10  \\n5+ years' experience developing, maintaining...   \n",
       "11                                         None Found   \n",
       "12                                         None Found   \n",
       "13                                         None Found   \n",
       "14                                         None Found   \n",
       "15                                         None Found   \n",
       "16  \\nDegree in computer science, applied math, st...   \n",
       "17  \\nDegree in computer science, applied math, st...   \n",
       "18                                         None Found   \n",
       "19  \\nB.A./B.S. in Mathematics, Computer Science, ...   \n",
       "20                                         None Found   \n",
       "21                                         None Found   \n",
       "22                                         None Found   \n",
       "23                                         None Found   \n",
       "24                                         None Found   \n",
       "\n",
       "                                     FullDescriptions  \n",
       "0   ------  ------  ------------------------------...  \n",
       "1   About the company KoBold Metals is using machi...  \n",
       "2   About Pivot Bio ---------------  Fueled by an ...  \n",
       "3   Senior Data Scientist Senior Data Scientists o...  \n",
       "4   Fandango is seeking a driven, analytically cur...  \n",
       "5   -------- About Us --------  KeyMe is a New Yor...  \n",
       "6   ----------------------------------------------...  \n",
       "7   Headquartered in Brisbane, Calif., CareDx, Inc...  \n",
       "8   Candidates should be flexible / willing to wor...  \n",
       "9   5-10 years professional work experience as a d...  \n",
       "10  (We are not sponsoring for this role or in the...  \n",
       "11      Non 55-a Program candidates interested in ...  \n",
       "12  Who you are The first Data Scientist at Finris...  \n",
       "13                    TV Data Scientist           ...  \n",
       "14                        Data Scientist Intern   ...  \n",
       "15    Description    At Pearson, we are committed ...  \n",
       "16  Description  Sentient Energy is looking for a ...  \n",
       "17  Description  Sentient Energy is looking for a ...  \n",
       "18  Lyra is transforming mental health care by cre...  \n",
       "19  [Job Details]  Position Overview  The Data Sci...  \n",
       "20  10+ years professional work experience as a da...  \n",
       "21  11 West 19th Street (22008), United States of ...  \n",
       "22  1660 L Street NW (19006), United States of Ame...  \n",
       "23  2+ years professional experience as a data sci...  \n",
       "24  2020 Spring Internship - Data Science(Job Numb...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Universal Sentence Encoder - one corpus at a time - TAKES 30 SECONDS PER corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempCorpus = df['FullDescriptions']\n",
    "dummy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1011 10:50:15.862906 4466746816 deprecation.py:323] From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1011 10:50:18.517322 4466746816 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.004863977432251\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1011 10:50:57.649492 4466746816 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.885284185409546\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1011 10:51:34.591351 4466746816 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3377420902252197\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1011 10:52:12.036261 4466746816 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.605326175689697\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1011 10:52:55.222585 4466746816 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.23716402053833\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1011 10:53:36.435087 4466746816 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.50217080116272\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1011 10:54:21.842096 4466746816 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.705016136169434\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1011 10:55:06.427030 4466746816 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.121757984161377\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1011 10:55:56.777892 4466746816 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.5614259243011475\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1011 10:56:44.523284 4466746816 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.807256698608398\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1011 10:57:36.879331 4466746816 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.500216007232666\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1011 10:58:28.149122 4466746816 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.334321022033691\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1011 10:59:21.587717 4466746816 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.448514223098755\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1011 11:00:19.380846 4466746816 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.211966037750244\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1011 11:01:19.405903 4466746816 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.125347137451172\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1011 11:02:21.529685 4466746816 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.74996304512024\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1011 11:03:28.354215 4466746816 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.713587999343872\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1011 11:04:31.090391 4466746816 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.167265176773071\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1011 11:05:38.231642 4466746816 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.668013095855713\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1011 11:06:51.422817 4466746816 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.835729837417603\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1011 11:08:05.467258 4466746816 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.884557008743286\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1011 11:09:20.287137 4466746816 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.82181191444397\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1011 11:10:40.383900 4466746816 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.304362058639526\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1011 11:12:02.695706 4466746816 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.818544864654541\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1011 11:13:25.844139 4466746816 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.881635189056396\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    embed = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder/2\")\n",
    "    \n",
    "    for corpus in tempCorpus :\n",
    "        messages = [corpus]\n",
    "        output = embed(messages)\n",
    " \n",
    "        with tf.Session() as session:\n",
    "            session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "            t1 = time.time()\n",
    "            message_embeddings = session.run(output)\n",
    "            print(time.time() - t1)\n",
    "            dummy.append(message_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.02395125e-02,  1.60463080e-02, -2.23891102e-02,\n",
       "        -4.34342166e-03,  6.44785399e-03, -9.03625861e-02,\n",
       "         1.22285234e-02,  2.78480612e-02, -2.59086229e-02,\n",
       "         3.79698128e-02, -1.95618309e-02,  5.08786775e-02,\n",
       "        -5.15983067e-02,  5.73120825e-02,  9.76173300e-03,\n",
       "         2.70774812e-02,  2.05946229e-02, -9.61376820e-03,\n",
       "         9.41379368e-02, -2.22235490e-02,  6.18627928e-02,\n",
       "        -3.83428335e-02, -5.98125495e-02,  9.38614011e-02,\n",
       "        -4.54228278e-03,  5.61258681e-02, -3.17748524e-02,\n",
       "        -2.19284613e-02,  3.10339388e-02, -7.94195458e-02,\n",
       "         4.92859967e-02,  4.32612784e-02, -3.25758159e-02,\n",
       "        -5.29966764e-02,  8.15892592e-02,  1.73796993e-02,\n",
       "        -1.55277792e-02, -9.54639614e-02, -1.64624061e-02,\n",
       "         4.38066153e-03, -7.02854842e-02,  8.67424533e-03,\n",
       "         1.35337822e-02,  3.58423330e-02, -2.49423627e-02,\n",
       "         7.55811185e-02,  2.23724078e-02, -5.77496924e-03,\n",
       "         1.82581879e-03, -9.24453884e-02,  7.30333850e-02,\n",
       "         1.98422447e-02,  8.77850577e-02, -2.29238588e-02,\n",
       "         2.78235804e-02,  4.22851406e-02,  6.75320253e-02,\n",
       "        -7.49554411e-02,  3.49826515e-02, -4.13480625e-02,\n",
       "         1.34092243e-02,  2.74860370e-03,  4.62094843e-02,\n",
       "         4.20360230e-02, -8.46582800e-02, -6.63060397e-02,\n",
       "         7.80769885e-02,  2.83197407e-02,  7.36962333e-02,\n",
       "         1.44342622e-02, -6.41282126e-02, -1.97098851e-02,\n",
       "        -2.59408131e-02,  3.16821486e-02, -1.94297247e-02,\n",
       "        -1.01155462e-02,  5.47459982e-02,  5.85917383e-02,\n",
       "         2.85805818e-02, -8.70040357e-02,  5.16783595e-02,\n",
       "         3.94477174e-02,  2.49362347e-04,  4.05779220e-02,\n",
       "        -6.87193051e-02,  5.05114160e-02,  9.08970833e-02,\n",
       "         3.78879160e-02,  1.36697767e-02, -2.88913641e-02,\n",
       "         3.46053168e-02,  2.59322599e-02, -1.99167877e-02,\n",
       "        -7.17911944e-02,  2.70469561e-02,  3.00197266e-02,\n",
       "         5.45408130e-02, -5.55577725e-02,  2.38526724e-02,\n",
       "         6.18617609e-02, -2.21226877e-03, -1.83965024e-02,\n",
       "        -3.94835696e-02,  7.30466284e-03, -1.72538832e-02,\n",
       "        -3.84899788e-02, -5.42800315e-02, -1.38120605e-02,\n",
       "         5.19663692e-02,  1.25090387e-02, -6.02523563e-03,\n",
       "        -2.55985954e-03,  6.70236275e-02,  2.41719987e-02,\n",
       "        -3.43110636e-02,  5.47360629e-02,  3.94313261e-02,\n",
       "        -3.55348140e-02, -1.08833099e-02,  6.23414591e-02,\n",
       "        -6.97129816e-02, -5.76279499e-02, -5.12933880e-02,\n",
       "         1.44118955e-02,  3.45319174e-02, -6.04921915e-02,\n",
       "        -4.19445743e-04, -1.99828669e-02,  5.76435439e-02,\n",
       "         3.56684029e-02,  4.94775102e-02,  5.01390398e-02,\n",
       "        -8.39938819e-02,  1.32328905e-02, -8.64055380e-03,\n",
       "        -2.32608765e-02,  5.83274662e-02, -4.75263372e-02,\n",
       "         3.34728286e-02,  2.03846339e-02,  2.00710837e-02,\n",
       "         5.97015060e-02, -6.19449317e-02,  8.75050947e-03,\n",
       "        -2.67512966e-02,  4.85146344e-02, -2.95641441e-02,\n",
       "         8.41149315e-02,  9.03612822e-02,  5.56636676e-02,\n",
       "         8.01119022e-03, -9.99923237e-03,  3.13545093e-02,\n",
       "         2.21682154e-02,  3.32799032e-02,  7.53081143e-02,\n",
       "         2.66731698e-02, -9.77739692e-02, -6.48633316e-02,\n",
       "         4.44735251e-02, -4.24860045e-02, -1.67908031e-03,\n",
       "         3.40321697e-02,  4.80308458e-02,  5.01864310e-03,\n",
       "         4.63064313e-02,  6.29285444e-03,  6.60640895e-02,\n",
       "         4.33431752e-02,  9.18008108e-03, -4.82209995e-02,\n",
       "         7.14606373e-03,  1.57420542e-02,  3.92013900e-02,\n",
       "         2.25768220e-02,  5.64404353e-02,  7.08608702e-02,\n",
       "         4.05612774e-03, -3.19559537e-02,  3.55147123e-02,\n",
       "         9.01545305e-03,  1.02262571e-02, -6.40547872e-02,\n",
       "         3.03588640e-02,  4.42260429e-02, -6.04182407e-02,\n",
       "         5.43153845e-02,  4.77431305e-02,  7.81392157e-02,\n",
       "        -1.27675040e-02,  3.00534051e-02,  5.53844534e-02,\n",
       "        -4.07225303e-02,  6.75241724e-02, -3.74393240e-02,\n",
       "        -2.77388450e-02,  3.84803638e-02,  2.16012131e-02,\n",
       "        -5.19658327e-02,  1.31838275e-02, -6.99839368e-03,\n",
       "         9.26853716e-02,  6.98926151e-02,  6.76912218e-02,\n",
       "        -4.59519811e-02,  1.90882459e-02, -2.99672652e-02,\n",
       "        -4.26954968e-04,  7.48540163e-02,  4.01852699e-03,\n",
       "         3.09038498e-02,  1.84874367e-02, -8.48474130e-02,\n",
       "        -6.42861128e-02, -9.55876242e-03,  7.63196964e-03,\n",
       "        -3.11830770e-02,  3.51857208e-02,  1.50023699e-02,\n",
       "         6.17400073e-02,  9.57095549e-02, -7.64626414e-02,\n",
       "        -3.29683870e-02,  1.37853976e-02, -9.78732016e-03,\n",
       "         3.07769608e-02,  6.12210436e-03, -3.08207981e-03,\n",
       "        -7.11454228e-02, -1.53976046e-02, -9.20778606e-03,\n",
       "        -4.13502753e-02,  3.49388309e-02,  1.39361927e-02,\n",
       "         2.55254228e-02, -8.91620480e-03,  8.28788131e-02,\n",
       "         6.17044456e-02, -5.13078533e-02, -2.61591114e-02,\n",
       "        -1.65810604e-02,  5.55063132e-03, -3.72633431e-03,\n",
       "        -4.29536216e-02, -4.14932668e-02, -2.40191780e-02,\n",
       "         5.89907840e-02, -2.37004412e-03, -1.51731269e-02,\n",
       "        -5.82341403e-02,  6.05481006e-02,  1.09488787e-02,\n",
       "        -4.80835959e-02, -1.66242495e-02, -5.42531125e-02,\n",
       "         8.70180316e-03,  5.17576858e-02, -1.99162196e-02,\n",
       "         6.64651673e-03, -3.55510563e-02, -5.46128564e-02,\n",
       "        -1.83025189e-02, -3.63218808e-03,  6.22031093e-02,\n",
       "         4.13999297e-02, -4.34008799e-03, -9.87400264e-02,\n",
       "        -2.68602464e-03,  9.60562006e-02, -6.44233376e-02,\n",
       "        -6.29661381e-02, -2.38053128e-02, -7.85500854e-02,\n",
       "         6.13595806e-02, -4.04021181e-02, -2.73264218e-02,\n",
       "         4.48824503e-02, -3.45965731e-03,  3.45025398e-02,\n",
       "         2.63365265e-02, -5.29414490e-02,  5.48067316e-02,\n",
       "         6.37659989e-03, -1.68817136e-02, -1.49401762e-02,\n",
       "         1.47647923e-02,  4.05585654e-02, -8.84646177e-03,\n",
       "        -6.15531504e-02, -5.14744967e-03,  6.17288006e-03,\n",
       "        -1.92263406e-02, -5.19232713e-02, -5.51373176e-02,\n",
       "         1.39818224e-03,  1.75834652e-02, -3.34585737e-03,\n",
       "        -3.48298661e-02, -8.40608627e-02,  6.64556101e-02,\n",
       "        -7.82611687e-03, -3.08700111e-02,  8.77099155e-05,\n",
       "         8.90980125e-04,  7.53043592e-02, -6.75174524e-04,\n",
       "        -1.34354401e-02, -3.47651467e-02, -3.45069431e-02,\n",
       "         2.26921979e-02, -4.06537205e-02,  1.22714229e-03,\n",
       "        -6.49365634e-02,  3.26329432e-02,  3.64577584e-02,\n",
       "         4.39823186e-03,  4.20660339e-02, -2.19999757e-02,\n",
       "        -4.95878980e-03,  1.77614298e-02, -2.47093420e-02,\n",
       "        -3.37537704e-03, -5.95557503e-02,  3.91195266e-04,\n",
       "        -4.73301001e-02, -4.66334540e-03,  6.38783723e-02,\n",
       "        -1.19137845e-03, -9.05575678e-02,  4.76693809e-02,\n",
       "        -4.10710014e-02,  7.01191276e-03, -4.79963273e-05,\n",
       "         1.79926527e-03,  6.39764816e-02,  2.93470714e-02,\n",
       "        -1.50241591e-02,  2.07723640e-02,  5.88316703e-03,\n",
       "         2.39252355e-02, -3.70864733e-03, -5.29501960e-03,\n",
       "         9.16099772e-02,  9.35618058e-02, -4.50710114e-03,\n",
       "        -8.56462568e-02, -1.44766970e-03, -7.67741278e-02,\n",
       "         5.24818636e-02, -4.61807288e-02,  9.28532332e-03,\n",
       "        -5.64916991e-03, -1.88175458e-02,  2.68574674e-02,\n",
       "        -8.90283212e-02,  1.36189386e-02,  1.15357563e-02,\n",
       "         5.94581924e-02, -4.01210040e-02,  4.18650396e-02,\n",
       "        -1.52477091e-02, -5.91837708e-03, -3.36391269e-04,\n",
       "        -4.04719338e-02,  6.34108623e-03,  6.90060407e-02,\n",
       "        -1.22632866e-03,  9.27345604e-02,  5.97114936e-02,\n",
       "         2.88319234e-02,  3.63664962e-02,  3.92979309e-02,\n",
       "        -1.33984778e-02,  4.61521186e-02,  5.52782789e-02,\n",
       "        -6.60556257e-02, -2.86795292e-02, -3.61897349e-02,\n",
       "        -8.18020701e-02,  1.93639565e-02,  9.34301540e-02,\n",
       "         7.06440508e-02, -1.17703937e-02,  2.66074184e-02,\n",
       "         1.34622315e-02, -2.68559288e-02, -3.06539871e-02,\n",
       "         9.55777432e-05, -8.38358924e-02, -3.00702807e-02,\n",
       "         1.10562034e-02,  1.89065225e-02, -1.00654112e-02,\n",
       "         1.38574978e-03,  3.38705778e-02, -6.05424307e-02,\n",
       "        -2.98951566e-02,  5.25997132e-02,  4.34664562e-02,\n",
       "         3.00718155e-02,  5.31612858e-02, -3.57381441e-02,\n",
       "        -6.78736567e-02,  5.68883009e-02, -7.21790865e-02,\n",
       "         1.76812746e-02, -8.06583986e-02,  3.43084447e-02,\n",
       "        -6.39987960e-02, -2.24155542e-02,  6.75475225e-02,\n",
       "         3.70064676e-02,  5.64591261e-03, -2.94814706e-02,\n",
       "         6.97938651e-02, -1.92060154e-02, -3.74092832e-02,\n",
       "         7.21017867e-02,  8.75423178e-02,  5.41235432e-02,\n",
       "         1.54184736e-02, -1.73595957e-02,  7.92499445e-03,\n",
       "        -9.94691363e-05, -5.44757629e-03, -1.43678552e-02,\n",
       "         9.25232749e-03, -4.11607251e-02, -2.64778193e-02,\n",
       "         4.05815803e-02,  3.07452250e-02, -2.40348559e-02,\n",
       "         4.87561338e-03, -3.24613824e-02,  8.45701713e-03,\n",
       "         2.64476817e-02,  3.66245322e-02, -2.55641602e-02,\n",
       "        -5.21988496e-02,  3.65577415e-02,  6.69031292e-02,\n",
       "        -1.91523936e-02, -2.94655301e-02, -1.68850776e-02,\n",
       "        -5.74400611e-02, -3.67255025e-02,  3.85405608e-02,\n",
       "        -1.60313006e-02,  4.01397794e-02,  7.46786743e-02,\n",
       "         2.87330709e-02,  2.40590479e-02,  8.91829189e-03,\n",
       "         4.16549072e-02,  5.14229387e-02, -5.13696447e-02,\n",
       "         2.01209933e-02, -2.02281252e-02,  4.38083038e-02,\n",
       "        -2.83494852e-02,  5.67444542e-04,  1.32720703e-02,\n",
       "         8.35857764e-02,  3.92508283e-02, -3.01937689e-03,\n",
       "         3.23265344e-02,  6.45708740e-02, -4.00073789e-02,\n",
       "        -1.94430053e-02, -3.50163355e-02, -1.12588210e-02,\n",
       "        -9.80091840e-02,  5.79205230e-02, -1.35421911e-02,\n",
       "        -1.84660009e-03,  1.27397978e-03, -2.84245256e-02,\n",
       "         1.18475128e-02, -9.54147987e-03,  2.53700595e-02,\n",
       "         5.36647663e-02,  2.31339037e-02, -2.18717847e-02,\n",
       "        -4.64501157e-02, -6.29933476e-02,  5.52947037e-02,\n",
       "        -3.19607090e-03,  3.91095430e-02, -3.72561812e-02,\n",
       "        -6.03947677e-02, -2.33417656e-02,  1.87905692e-02,\n",
       "         2.71613561e-02,  5.22766709e-02,  4.38508950e-02,\n",
       "        -2.40759961e-02,  6.49449751e-02, -7.32823089e-02,\n",
       "         5.18900016e-03,  7.89699797e-03, -1.40597029e-02,\n",
       "        -2.38092989e-02,  5.79959266e-02,  6.12842962e-02,\n",
       "        -1.12906527e-02, -1.71525329e-02,  5.73532991e-02,\n",
       "        -8.24698061e-02,  1.68740917e-02, -6.15204386e-02,\n",
       "        -1.90277360e-02, -6.52386621e-02]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "# Add Feature Vectors to dataframe\n",
    "df['Feature_Vector'] = dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export dataframe to CSV\n",
    "df.to_csv(r'DS_25_Feature_Vectors.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send Corpus as one complete list  - DOES NOT WORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempBatch = tempCorpus.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"About Pivot Bio ---------------  Fueled by an innovative drive and a deep understanding of the soil microbiome, Pivot Bio is pioneering game-changing advances in agriculture. Our first commercial product harnesses the power of naturally-occurring microbes to provide nutrients to crops. We are dedicated to providing new sustainable ways for farmers to improve yield as they work to help feed the world's growing population.  The Field Technology team measures and models the performance of Pivot's microbial product. We aim to use this proprietary data to increase the value of our product. The Senior Data Scientist will analyze large, complex data sets to create and optimize predictive models using machine learning and other statistical tools. They will own the prototyping and early development of data products that can complement our microbial nitrogen fertilizer.  Location  Berkeley, CA  Responsibilities   Own the development of predictive analytics that quantify the impact and increase the value of our core microbial product. Help develop Pivot's technical partnership strategy for creating value from data. Work with Pivot's data engineering team to translate statistical models from R&D to production. Communicate the impact of our work to internal and external stakeholders.  Required Skills and Experience   Ph.D. in a quantitative discipline plus 2+ years experience in industry or M.S. and equivalent practical experience, particularly in agricultural/plant, remote sensing, or biological data. Experience using Python and developing statistical models in a shared on-cloud database. Knowledge of R is a plus. Understanding of how to structure and analyze problems with machine learning, from both a conceptual standpoint, as well as having practical knowledge of libraries such as sklearn, PyTorch, and TensorFlow Experience working with complex structured spatial and time-series data, from exploratory analysis to hierarchical or ML modeling. Knowledge of Bayesian methods is a plus. Must be authorized to work in the U.S.  What we offer   Competitive package in an early-stage, disruptive startup Health/Dental/Vision 401(k) plan Flexible vacation policy Exciting opportunity to work with a talented and fun team  \""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempBatch[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't convert 'text': Shape TensorShape([Dimension(1), Dimension(25)]) is incompatible with TensorShape([Dimension(None)])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-fad15efdf417>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0membed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://tfhub.dev/google/universal-sentence-encoder/2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmessages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtempBatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow_hub/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, _sentinel, signature, as_dict)\u001b[0m\n\u001b[1;32m    248\u001b[0m     dict_inputs = _convert_dict_inputs(\n\u001b[1;32m    249\u001b[0m         inputs, self._spec.get_input_info_dict(signature=signature,\n\u001b[0;32m--> 250\u001b[0;31m                                                tags=self._tags))\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     dict_outputs = self._impl.create_apply_graph(\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow_hub/module.py\u001b[0m in \u001b[0;36m_convert_dict_inputs\u001b[0;34m(inputs, tensor_info_map)\u001b[0m\n\u001b[1;32m    450\u001b[0m   \u001b[0mdict_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_dict_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_info_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m   return tensor_info.convert_dict_to_compatible_tensor(dict_inputs,\n\u001b[0;32m--> 452\u001b[0;31m                                                        tensor_info_map)\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow_hub/tensor_info.py\u001b[0m in \u001b[0;36mconvert_dict_to_compatible_tensor\u001b[0;34m(values, targets)\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     result[key] = _convert_to_compatible_tensor(\n\u001b[0;32m--> 150\u001b[0;31m         value, targets[key], error_prefix=\"Can't convert %r\" % key)\n\u001b[0m\u001b[1;32m    151\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow_hub/tensor_info.py\u001b[0m in \u001b[0;36m_convert_to_compatible_tensor\u001b[0;34m(value, target, error_prefix)\u001b[0m\n\u001b[1;32m    127\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     raise TypeError(\"%s: Shape %r is incompatible with %r\" %\n\u001b[0;32m--> 129\u001b[0;31m                     (error_prefix, tensor.get_shape(), target.get_shape()))\n\u001b[0m\u001b[1;32m    130\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can't convert 'text': Shape TensorShape([Dimension(1), Dimension(25)]) is incompatible with TensorShape([Dimension(None)])"
     ]
    }
   ],
   "source": [
    "dummy_2 = []\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    embed = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder/2\")\n",
    "    messages = [tempBatch]\n",
    "    output = embed(messages)\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    t1 = time.time()\n",
    "    message_embeddings = session.run(output)\n",
    "    print(time.time() - t1)\n",
    "    dummy_2.append(message_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce logging output.\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "with tf.Session() as session:\n",
    "  session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "  message_embeddings = session.run(embed(messages))\n",
    "\n",
    "  for i, message_embedding in enumerate(np.array(message_embeddings).tolist()):\n",
    "    print(\"Message: {}\".format(messages[i]))\n",
    "    print(\"Embedding size: {}\".format(len(message_embedding)))\n",
    "    message_embedding_snippet = \", \".join(\n",
    "        (str(x) for x in message_embedding[:3]))\n",
    "    print(\"Embedding: [{}, ...]\\n\".format(message_embedding_snippet))\n",
    "    dummy.append(message_embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
