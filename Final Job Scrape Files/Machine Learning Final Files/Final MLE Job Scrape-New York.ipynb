{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "import pandas as pd\n",
    "import requests\n",
    "from requests import get\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pulling all links off of the search pages (up to 3000) and putting them in a dataframe to scrape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_template=\"http://www.indeed.com/jobs?q=%22Machine+Learning+Engineer%22&l=New+York%2C+NY&start={}\"\n",
    "max_results=250\n",
    "Linkdf=[]\n",
    "\n",
    "for start in range(0, max_results, 7):\n",
    "    url=url_template.format(start)\n",
    "    html=requests.get(url)\n",
    "    soup=BeautifulSoup(html.content,'html.parser', from_encoding=\"utf-8\")\n",
    "    \n",
    "    #for each in soup.find_all(a_=\"href\"):\n",
    "    page_links=soup.find_all('a',{'href':re.compile(\"/rc/\")})\n",
    "    for items in page_links:\n",
    "        Linkdf.append(items['href'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity Check\n",
    "len(Linkdf)\n",
    "#print(Linkdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This code allows the code to display the full website instead of truncating\n",
    "pd.set_option('display.max_colwidth',-1)\n",
    "\n",
    "#Moving it to a data frame\n",
    "data = {'links':Linkdf}\n",
    "df = pd.DataFrame(data, columns=['links'])\n",
    "\n",
    "#append indeed.com to the front of each\n",
    "df['Web'] = 'https://www.indeed.com'\n",
    "df['URL'] = df.Web.str.cat(df.links)\n",
    "\n",
    "#pull out just a list of the websites.\n",
    "websites=list(df['URL'])\n",
    "\n",
    "#Sanity Check\n",
    "#print(websites)\n",
    "len(websites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "websites1=set(websites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(websites1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looping through websites...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Title=[]\n",
    "Descriptions=[]\n",
    "Location=[]\n",
    "FullDescriptions=[]\n",
    "\n",
    "for url in websites1:\n",
    "    response=get(url)\n",
    "    soup=BeautifulSoup(response.text,'html.parser')\n",
    "    \n",
    "    description_containers= soup.find(class_='jobsearch-jobDescriptionText')\n",
    "    title_containers=soup.find('h3')\n",
    "    try:\n",
    "        location_containers=soup.find('',{'class':'jobsearch-CompanyInfoWithoutHeaderImage'}).find_all('div')[-1]\n",
    "    except:\n",
    "        location_containers='None Found'\n",
    "    \n",
    "    job_descriptions=str(description_containers)\n",
    "    job_title=str(title_containers.text)\n",
    "    try:\n",
    "        locations=str(location_containers.text)\n",
    "    except AttributeError:\n",
    "        locations = 'None Found'\n",
    "    try:\n",
    "        full_descriptions = str(description_containers.text)\n",
    "    except AttributeError:\n",
    "        full_descriptions= 'None Found'\n",
    "    \n",
    "    Descriptions.append(job_descriptions)\n",
    "    Title.append(job_title)\n",
    "    Location.append(locations)\n",
    "    FullDescriptions.append(full_descriptions)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting what we want from the Descriptions Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'Location' left in for sanity check. Should be removed once code is confirmed to work\n",
    "Descriptions_df = pd.DataFrame(columns = ['Title', 'Location','City', 'State', 'Zip', 'Country', 'Qualifications', 'Skills', 'Responsibilities', 'Education', 'Requirement', 'FullDescriptions'])\n",
    "Country = ['US', 'USA', 'United States', 'United States of Americal']\n",
    "States = ['AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', 'IA',\n",
    "          'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND',\n",
    "          'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY']\n",
    "\n",
    "for index, element in enumerate(Descriptions):\n",
    "    soup=BeautifulSoup(element,'lxml')\n",
    "    for values in list(Descriptions_df):\n",
    "        temp_tag = soup.find('b', text=re.compile(values))\n",
    "        try:\n",
    "            ul_tag = temp_tag.find_next('ul')\n",
    "            Descriptions_df.at[index,values] = ul_tag.text\n",
    "        except AttributeError:\n",
    "            Descriptions_df.at[index,values]=\"None Found\"\n",
    "        Descriptions_df.at[index,\"Title\"]=Title[index]\n",
    "        Descriptions_df.at[index,\"Location\"]=Location[index]\n",
    "        Descriptions_df.at[index,\"FullDescriptions\"]=FullDescriptions[index]\n",
    "        words = '|'.join(Country)\n",
    "        temp = re.findall(words, Location[index])\n",
    "        if len(temp) != 0:\n",
    "            Descriptions_df.at[index,\"Country\"] = temp[0]\n",
    "        words = '|'.join(States)\n",
    "        temp = re.findall(words, Location[index])\n",
    "        if len(temp) != 0:\n",
    "            Descriptions_df.at[index,\"State\"] = temp[0]\n",
    "        temp = re.findall(r'\\d+', Location[index])\n",
    "        if len(temp) != 0:\n",
    "            Descriptions_df.at[index,\"Zip\"] = temp[0]  \n",
    "            \n",
    "        temp = re.findall(r'[\\w w]+,', Location[index])\n",
    "        if len(temp) != 0:\n",
    "            Descriptions_df.at[index,\"City\"] = re.sub(',', '', temp[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Country</th>\n",
       "      <th>Qualifications</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Responsibilities</th>\n",
       "      <th>Education</th>\n",
       "      <th>Requirement</th>\n",
       "      <th>FullDescriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Machine Learning Engineer</td>\n",
       "      <td>New York, NY 10121</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>10121</td>\n",
       "      <td>None Found</td>\n",
       "      <td>BS/MS degree in Computer Science, Computer Engineering, or a related subject.\\n5+ years of demonstrated experience in Python.\\nIn-depth knowledge of Python data processing and machine learning libraries.\\nExperience with and understanding of the Python ML frameworks such as TensorFlow and PyTorch\\nExperience with API design &amp; development\\nUnderstanding of the data layer integration (both SQL and no-SQL)\\nExperience with cloud deployments is a plus\\nUnderstanding AWS / Azure / GCP data ETL capabilities is a plus\\nExperience with C/C++, Java and/or Scala plus.\\nPassion for writing well structured, testable code with a focus on readability and maintainability.\\nExperience with open source CI tools is a plus.\\nData modeling experience is a plus.\\nExcellent communication skills.\\n</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Collaborate with the product owner, technical lead, product designer, and other stakeholders to design, prototype and develop enterprise-class data intensive applications.\\nMaintain existing code and make improvements to increase maintainability, performance, and scalability.\\nSupport software rollouts to production.\\nConstantly improve code quality and test coverage.\\nUnderstand full-stack dependencies to minimize regressions and attain improved designs.\\nGuide and mentor junior engineers. Serve as team lead if appropriate.\\n</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>We are seeking a highly-experienced Senior Backend / ML Engineer to join our team building advanced Business Intelligence, Machine Learning, and Data Processing applications.\\nYour Impact\\nAs a Backend Engineer, you will develop advanced tools that allow our customers to build highly-sophisticated Business Intelligence applications for their stakeholders. You will work as a member of an engineering “feature team,” responsible for delivering value to our customers. In this role, you will design, implement, and deliver enterprise-grade machine learning applications for both internal- and external-facing consumers. You will be part of a dynamic team of engineers who are developing cutting edge technology that fuels the premier BI platform in the industry. Your work will be deployed to production and used by dozens of major corporations such as FedEx, US Bank, and Mastercard to help drive their business goals and service their customers.\\nWhile mostly focusing in ML models productizing and data processing you will be expected to contribute to the model development. You believe that good design is the key to good coding - “measure twice, cut once.” You write excellent-quality code (if you do say so yourself), and understand how to best practices of SW architecture, development and testing.\\n Responsibilities\\nCollaborate with the product owner, technical lead, product designer, and other stakeholders to design, prototype and develop enterprise-class data intensive applications.\\nMaintain existing code and make improvements to increase maintainability, performance, and scalability.\\nSupport software rollouts to production.\\nConstantly improve code quality and test coverage.\\nUnderstand full-stack dependencies to minimize regressions and attain improved designs.\\nGuide and mentor junior engineers. Serve as team lead if appropriate.\\nQualifications\\nBS/MS degree in Computer Science, Computer Engineering, or a related subject.\\n5+ years of demonstrated experience in Python.\\nIn-depth knowledge of Python data processing and machine learning libraries.\\nExperience with and understanding of the Python ML frameworks such as TensorFlow and PyTorch\\nExperience with API design &amp; development\\nUnderstanding of the data layer integration (both SQL and no-SQL)\\nExperience with cloud deployments is a plus\\nUnderstanding AWS / Azure / GCP data ETL capabilities is a plus\\nExperience with C/C++, Java and/or Scala plus.\\nPassion for writing well structured, testable code with a focus on readability and maintainability.\\nExperience with open source CI tools is a plus.\\nData modeling experience is a plus.\\nExcellent communication skills.\\nInformation Builders helps organizations transform data into business value. Our software solutions for business intelligence and analytics, integration, and data integrity empower people to make smarter decisions, strengthen customer relationships, and drive growth. Our dedication to customer success is unmatched in the industry. That’s why thousands of leading organizations rely on Information Builders to be their trusted partner. Founded in 1975, Information Builders is headquartered in New York City, with offices around the world, and remains one of the largest independent, privately held companies in the industry.\\nInformation Builders, Inc. is an Equal Opportunity Employer: All qualified applicants will receive consideration for employment and will not be discriminated against based on their race, gender, disability, veteran status, or other protected classification.\\n#LI-LO1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Machine Learning Engineer - Natural Language Processing (NLP)</td>\n",
       "      <td>New York, NY 10018</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>10018</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nMSc or PhD in Computer Science, Machine Learning, Maths, Stats (or related field).\\nExperience with Machine Learning techniques for supervised &amp; unsupervised learning e.g. CNN's, DNN's &amp; RNN's.\\nStrong knowledge of Machine Learning frameworks such as Tensorflow &amp; Keras.\\nExperience with Natural Language Processing.\\nExcellent programming skills preferably with Python.\\n</td>\n",
       "      <td>Why join LYNK?\\nLYNK is a VC-backed, product-driven startup working with leading institutional clients, top level experts and thought leaders globally\\nWe operate in a high-octane environment where our people think about the big picture and always strive to “make it happen”\\nOur team, spread across four countries today (and growing!), is multinational, multilingual and multicultural. Our clients have likened us to a mini United Nations.\\nYou will be constantly challenged with new problems to solve every day.\\nWe are here to realize big dreams and have a firm belief in our core mission – to democratize access to knowledge.\\n\\nWhat You’ll Do:\\nJoin us, and tackle some of the most challenging problems in natural language processing and large scale applied machine learning. You will build cutting edge natural language understanding technologies and deploy them on a global scale.\\n\\nBuild data pipelines that clean, transform and aggregate data into databases and adopt data warehouse solutions in AWS Redshift\\nGather and process raw data at scale (including writing scripts, web scraping, calling APIs, write SQL queries, writing applications, etc.).\\nDevelop data pipelines that unify various data sources into one cohesive platform for data access.\\nDesign and Develop NLP engine and applications.\\nDevelop sourcing, cleansing, structuring and ingesting new data sources.\\nApply machine learning and predictive modelling techniques.\\nDevelop creative solutions to business problems using mathematical algorithms.\\nEvaluate different NLP technology and tools.\\nWork on very large text-based data sets, applying the latest techniques for entity recognition and sentiment extraction, with the goal of identifying features of real-time text feeds\\nRequirements\\nWhat Expertise You’ll Add To The Team:\\nMSc or PhD in Computer Science, Machine Learning, Maths, Stats (or related field).\\nExperience with Machine Learning techniques for supervised &amp; unsupervised learning e.g. CNN's, DNN's &amp; RNN's.\\nStrong knowledge of Machine Learning frameworks such as Tensorflow &amp; Keras.\\nExperience with Natural Language Processing.\\nExcellent programming skills preferably with Python.\\n\\nBonus Attributes:\\nStrong passion for creative content curation and building brand awareness\\nPassion for business and enthusiastic about taking part in shaping LYNK’s growth\\nFunction well in a very fast-paced startup environment\\nTrack record of excelling in small teams\\nTeam players who thrive in uncertainty and like to “make things happen”!\\nBenefits\\nWhat We Commit To You\\nCompetitive remuneration package in a rapidly-expanding startup\\nWork in a collaborative, co-creation hub in the heart of the city - with amazing facilities\\nComprehensive medical insurance coverage, including dental\\nGenerous leave policy, including a ‘work remote policy’\\nThe opportunity to travel and work around the globe with our international clients and growing number of offices (Hong Kong, Singapore, Mumbai, New York City)\\nThe opportunity to be a part of something impactful\\n\\nVisit http://lynk.global for more info.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Human Resources – Workforce Analytics – Lead Machine Learning Engineer - Vice President</td>\n",
       "      <td>Jersey City, NJ 07310</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>NJ</td>\n",
       "      <td>07310</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>JPMorgan Chase &amp; Co. (NYSE: JPM) is a leading global financial services firm with assets of $2.6 trillion and operations worldwide. The firm is a leader in investment banking, financial services for consumers and small business, commercial banking, financial transaction processing, and asset management. A component of the Dow Jones Industrial Average, JPMorgan Chase &amp; Co. serves millions of consumers in the United States and many of the world's most prominent corporate, institutional and government clients under its J.P. Morgan and Chase brands. Information about JPMorgan Chase &amp; Co. is available at www.jpmorganchase.com.\\n\\nHuman Resources plays an integral role in designing, implementing, and managing global initiatives across the firm. The functional areas within HR include global Recruiting, Training, Talent and Development, Diversity, Compensation, Benefits, Employee Relations, Technology, Finance, HR Service Delivery, and the Chief Data &amp; Analytics Office.\\nWorkforce Analytics (WFA) is the firm’s centralized global HR analytics function, positioned within the HR Chief Data &amp; Analytics Office. WFA applies quantitative methods, technology, and research to people data and people decisions across the firm.\\nPosition Overview &amp; Responsibilities:\\nThe Lead ML Engineer will be responsible for designing, building, and deploying data products that integrate ML and NLP with other internal applications and platforms. This individual will report to the Head of Data Science and join a cross-functional data science team that leads some of the most critical projects in HR.\\nCandidate Profile\\nThe ideal candidate will be skilled, innovative, self-motivated, and inclined to create genuine business value through the alignment of technology, data, and business interests. He or she will have hands-on experience with the development of data products, from data ingestion to deployment. Additionally, excellent communication skills and a collaborative attitude will be crucial to success, as this role will partner closely with aligned Technology teams in addition to the immediate data science team.\\nKey Responsibilities\\nLead the redevelopment of Python-based monolithic ML &amp; NLP products as RESTful microservices\\nDeploy data science products using standard CI/CD workflows into the firm’s cloud and Hadoop platforms\\nCollaborate with a team of data scientists and engineers on a variety of innovative machine learning and natural language processing projects\\nPrototype and build data pipelines. Support configuration and management of ETL and scheduling jobs/software. Perform ad-hoc ingestion of data from varied sources into HDFS.\\nRequirements\\nBachelor’s Degree in Computer Science or a related field desired\\n3+ years of experience in software engineering, preferably in a data-driven domain\\nExperience leading an engineering team is preferred\\nFamiliarity with Python, Flask, SQL, API or web service development, and Hadoop is preferred\\nExperience with Docker, Kubernetes, the SDLC process &amp; tools, and ML model management is desired\\nProfessional maturity and the ability to work/deliver with limited supervision\\nExcellent verbal and written communication skills and a team-oriented attitude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Description\\nDS/ML stack:\\nLanguages: Python, PySpark, SQL\\nData Tools: Spark, AWS RedShift, AWS Athena, pandas, numpy, scipy, parquet\\nModeling Tools: SparkML, scikit-learn, Tensorflow, Tensorflow-Serving, Keras (Tensorflow and Theano backend)\\nAlgorithms: Classifications, Regressions, Neural Networks, Time series, Graphs\\nVisualization: Tableau or similar\\nInfrastructure: AWS (including S3, EMR, EC2, Lambda)\\n\\n\\nWhat will you do?\\nUnderstand business decisions that need to be supported by data e.g. risk of readmission to hospital\\nIdentify relevant internal or external data sources for various business needs\\nResearch the state of a problem and existing solutions then quickly summarize research\\nHelp identify new business opportunities and value propositions from existing data\\nUtilize raw or aggregated data to build predictive models in SPARK, sql, or Python\\nUnderstand quality of models and impact on business problems\\nCommunicate summaries of analyses and predictive modeling efforts to product and business teams\\nCommunicate insights to stakeholders in data engineering, product and clinical teams.\\nBecome expert on projects to help strategize plans of attack in terms of technology and team education.\\nEnsure that all security procedures within their area of responsibility are carried out to achieve compliance with security policies and standards.\\nLeading multiple initiatives across both existing and innovative work\\nProvide continuous mentoring to junior resources\\nWe are looking for someone with:\\n7+ year’s professional experience as a data scientist or machine learning engineer\\n7+ year’s professional experience working in quantitative computational role\\n5+ year’s professional experience working with big data and relational databases\\nVery strong knowledge of advanced applied data science (machine learning, neural networks, etc.), mathematical modeling, computational, statistical, data mining techniques (regression, decision trees, clustering etc.), as well as dimensionality reduction techniques\\nStrong hands-on modeling experience in a business environment with a goal of productionalizing models.\\nStrong experience using machine learning and deep learning packages\\nStrong experience with data manipulation, analysis and visualization\\nProven track record of fully understanding the scope, commitment to quality, and end-to-end ownership to meet upon agreed timelines.\\nQuick learner that can manage multiple projects at the same time successfully\\nDeveloped and designed real-time prediction software\\nStrong experience mentoring junior colleagues\\nExcellent written and verbal communication skills\\nAdvanced degree in physics, applied mathematics, statistics or related field is preferred\\nHealthcare industry experience is a plus\\n\\nAbout Us\\n\\nRemedy Partners delivers software and services that enable payers, employers and at-risk providers to organize and finance healthcare delivery around a patient's episode of care. For healthcare providers, Remedy Partners’ software, analytics and administrative services support bundled payment contracts with Medicare and Commercial Insurers, often through shared-risk partnerships. For payers, Remedy Partners empowers the development of bundled payment contracting programs and guides development of bundled payment networks. Remedy Partners presently delivers its services to partners at more than 1,000 healthcare locations nationwide.\\n\\nPlease note that all Remedy employees are required to adhere to all organizational policies, the Code of Conduct and participate in all compliance-related training and education.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist- Machine Learning Engineer</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nMS/PhD preferred\\n2+ years experience in data science/machine learning preferred\\nExperience with making predictions from both structured and unstructured data\\nPractical knowledge of Python and its scientific libraries SciPy, Scikit, Pandas, and NumPy, with extensive knowledge of programming best practices\\nSolid foundation in machine learning models, processes, and theories, with the ability to evaluate different algorithmic approaches\\nWorking knowledge of statistics and probability (statistical inference, Bayesian statistics)\\nEmbodiment of our core company values of motivation, positivity, curiosity, humility and integrity, and buy-in for our company mission of eliminating bias in hiring\\nWillingness to relocate or regularly travel to the NYC metro area\\n</td>\n",
       "      <td>Using neuroscience-based assessments and machine learning algorithms, pymetrics is reinventing the recruiting industry by matching candidates to jobs where they are most likely to succeed. We are leading the charge in an evolving industry and growing our amazing team to support the mission of using data to unleash one's full potential.\\nWe are looking for a talented data scientist with strong machine learning experience to join our core product development team. Data scientists on the core team contribute to the predictive modeling used throughout pymetrics to match job candidates to roles, audit algorithms for potential bias, and optimize solutions for faster, more robust analyses. You will work on an academically diverse team (with backgrounds in machine learning, statistics, behavioral science, and computer science) to test new methods and optimize existing solutions.\\nThe ideal candidate would bring experience building scalable predictive algorithms in a production environment. We value an ability to communicate with a bright team from diverse backgrounds, and the initiative to tackle interesting problems independently and with scientific rigor.\\nResponsibilities include:\\nDevelop machine learning solutions for new and existing data products relating to hiring\\nWrite production level code for practical application of data products\\nApply statistical and machine learning techniques to identify trends in data\\nWork with clients to apply custom data science solutions to unique problems\\nCollaborate with and train other members of the data science team\\nInteract with data scientists, analysts, engineers and product managers on other data products implemented at pymetrics, including language analysis, psychometric assessment, statistical analysis and data visualization\\n\\nRequirements\\nAbout you:\\nMS/PhD preferred\\n2+ years experience in data science/machine learning preferred\\nExperience with making predictions from both structured and unstructured data\\nPractical knowledge of Python and its scientific libraries SciPy, Scikit, Pandas, and NumPy, with extensive knowledge of programming best practices\\nSolid foundation in machine learning models, processes, and theories, with the ability to evaluate different algorithmic approaches\\nWorking knowledge of statistics and probability (statistical inference, Bayesian statistics)\\nEmbodiment of our core company values of motivation, positivity, curiosity, humility and integrity, and buy-in for our company mission of eliminating bias in hiring\\nWillingness to relocate or regularly travel to the NYC metro area\\nNice to Haves:\\n1+ years experience in deep learning, including familiarity with Keras, TensorFlow and/or PyTorch\\nComfort with SQL\\nKnowledge of psych/cogsci/neuroscience research\\nInterest in issues of transparency and fairness in AI\\nEye for data visualization and presentation of data-driven insights\\nWe are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\\nBenefits\\nHealth care plan (medical, dental &amp; vision)\\nFlexible paid time off\\nFamily leave (maternity, paternity)\\n401k\\nTeam budget for training &amp; development\\nStock option plan\\nCommuter transportation reimbursement\\nDog-friendly workplace\\nFun, diverse and intellectually eager coworkers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Machine Learning Engineer</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nDeep understanding of ML problems such as classification, clustering, anomaly detection, association rules, deep learning, and recommendation\\nDeep understanding of test analysis\\nPrevious work with Spark MLlib\\nPrevious work with TensorFlow\\nB.S. or M.S in Computer Science\\n</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nBuild &amp; maintain production ready ML pipelines\\nBuild &amp; maintain a production-ready experimentation platform to run models in parallel and A/B test\\nPrepare and preprocess data in collaboration with the data engineering team\\n</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>The machine learning engineering team is developing the brain of the BounceX communication and personalization platform. As a Senior Machine Learning Engineer, you will be working with a team of Data Engineers and Data Scientists in order to build out our next-generation platform. You will be utilizing cutting edge technologies such as Spark MLLib, Tensorflow, Google AI Platform, and Cloud Dataproc to build the required ML pipelines to enhance our customer's experience.\\n\\nResponsibilities:\\n\\nBuild &amp; maintain production ready ML pipelines\\nBuild &amp; maintain a production-ready experimentation platform to run models in parallel and A/B test\\nPrepare and preprocess data in collaboration with the data engineering team\\n\\nQualifications:\\n\\nDeep understanding of ML problems such as classification, clustering, anomaly detection, association rules, deep learning, and recommendation\\nDeep understanding of test analysis\\nPrevious work with Spark MLlib\\nPrevious work with TensorFlow\\nB.S. or M.S in Computer Science\\n\\nNice to have:\\n\\nExperience with Google Cloud BigQuery\\nExperience with Google Cloud BigTable\\n\\nBounceX is proud to be an equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.\\n\\nJOIN US ON OUR MISSION\\n\\nBounceX is a global marketing technology company that has been recognized as a best place to work by Glassdoor and Crain's, and one of America's fastest-growing SaaS companies.\\n\\nMore than 300 companies including JetBlue, Uniqlo, HelloFresh, and Comcast use BounceX to orchestrate real-time, multichannel marketing programs customized for every individual web visitor.\\n\\nWith offices in New York City and London, BounceX is built on the belief that the success of a company is rooted in the strength of its team, so we've created a collaborative, inclusive environment where people love coming to work.\\n\\nWe provide career coaching, growth and development opportunities, and benefits that are in the 95th percentile of all technology companies. Some highlights include excellent healthcare that starts day one, best-in-class fully paid family leave, 401(k) match, flexible work hours, and more.\\n\\nWhat bonds our community together is our commitment to 5 Core Values:\\n\\n\\nCome Hungry\\nCarry Each Other\\nDrive Undeniable Performance\\nRespect People, Privacy, Ideas\\nBounce Back\\n\\nCome join us on our mission.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ML Software Engineer - Event Detection</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nBS, MS, or PhD in computer science or a related quantitative field with 4+ years of software engineering experience\\nExperience with software engineering best practices (e.g. unit testing, code reviews, design documentation)</td>\n",
       "      <td>Who We Are:\\n\\n\\nWhen an event occurs in the real-world, it often breaks out on Twitter. The Event Detection team builds, scales and maintains the software services that power the discovery of interesting and eventful conversation across the product. We detect and surface what’s happening, contextualizing by finding the most interesting content around events, including Trends, Moments, and Live Videos for users. We are a tightly knit and passionate group that loves working together, and we are looking for exceptional additions to our flock.\\n\\n\\nWhat You'll Do:\\nEvents are one of the central use-cases for Twitter and millions of people are informed about their world through our work. The team’s purpose is to automatically detect such Events on Twitter. As an ML engineer on our team, you will apply machine learning and data science techniques to a modeling and relevance problems related to automatic Event detection. You will participate in the engineering life-cycle at Twitter, including building and analyzing datasets, working with offline data pipelines, writing production code, conducting code reviews, and working alongside our systems engineers. Although you will work on cutting-edge problems, please note that this is not a research position. You will work directly with multiple teams across the company who are innovating on the product and refining Twitter to make it the best place to see and talk about what's happening in the world.\\n\\n\\nWho You Are:\\n\\n\\nYou have a passion for machine learning and improving the ways people consume what’s happening in the world. You are a relevance engineer, applied data scientist or machine-learning engineer who wants to work on exciting algorithmic and infrastructure issues. You are experienced solving large scale relevance problems and comfortable building brand new systems to enable future quality improvements.\\n\\n\\nKnowledgeable in one or more of the following: machine-learning, information retrieval, recommendation systems, social network analysis\\nA strong technical advocate with a background in Java, Scala, or Python. Preferably familiar with Jupyter notebook environments and Spark or pySpark.\\nPassionate about working with large unstructured and structured data sets and developing new approaches to relevance problems.\\nExperienced in collaborating across multiple teams including analytics, product management, and operations.\\nRequirements:\\n\\nBS, MS, or PhD in computer science or a related quantitative field with 4+ years of software engineering experience\\nExperience with software engineering best practices (e.g. unit testing, code reviews, design documentation)\\n\\n\\nWe are committed to an inclusive and diverse Twitter. Twitter is an equal opportunity employer. We do not discriminate based on race, ethnicity, color, ancestry, national origin, religion, sex, sexual orientation, gender identity, age, disability, veteran status, genetic information, marital status or any other legally protected status.\\n\\nSan Francisco applicants: Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Machine Learning Engineer - Search</td>\n",
       "      <td>Hoboken, NJ 07030</td>\n",
       "      <td>Hoboken</td>\n",
       "      <td>NJ</td>\n",
       "      <td>07030</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>The search team at Walmart Labs and Jet is dedicated to the mission of helping millions of customers every day in finding the right products. We are at the forefront of attacking one of the most complex problems of e-commerce. Whenever a user types in a query or browses through product categories on the web site, phone or iPad, our service goes to work. We mine billions of search queries and tens of millions of products to find the most relevant products for our customers. Team members take end-to-end responsibility in analyzing large amounts of data, creating complex models, improving their accuracy and deploying these models to serve customers. E-commerce product search, much like web search, has always been a fertile area of AI innovation. Search algorithm team at Walmart Labs and Jet is working on fascinating AI/ML problems like deep NLP based query understanding, improving relevance ranking of products, semantic matching of query &lt;-&gt; item pairs using embeddings, visual search to enable search by image, etc. As part of this team, you'll solve some of the most challenging and impactful problems in machine learning, information retrieval, natural language processing, computer vision or statistical measurement. Your work will be visible to hundreds of millions of customers and you will have a direct impact on the goals of the Fortune #1 company. If you speak and think machine learning then we want to talk to you. Come join our team and be part of this exciting journey.\\n\\nWhat you will do:\\n\\nBuild advanced machine learning models and improve the accuracy of those models\\nDeploy the models in production where it will serve customers in real time\\nPut on the hacker's hat quickly convert an idea to a demonstration\\nPresent your work to the internal and external community\\nWork alongside senior machine learning researchers and define the right solution to implement\\n\\n\\nWhat you will have:\\n\\n4+ years of experience in Software engineering.\\nAbility to write high performance production quality code. Experience in Python, Scala and other equivalent languages is a plus.\\nExperience building and productionizing innovative end-to-end Machine Learning systems.\\nGood understanding of common families of models, feature engineering, feature selection and other practical machine learning issues, such as overfitting.\\n\\n\\nBonus Points\\n\\nExperience building and/or maintaining machine learning models and pipelines\\nFunctional programming experience is a plus.\\nExperience building and maintaining large scale data pipelines in online advertising, recommender system, ecommerce or relevant areas\\nFamiliarity with Deep Learning.\\n\\nAbout Jet\\n\\nJet is reshaping ecommerce as we know it. Based in Hoboken NJ (just 10 min from Manhattan), we are a shopping site on the relentless pursuit to build the greatest shopping experience in the world. At Jet, we believe in bold. That means taking risks, asking “why not”, looking where no ones looked before and bringing it! Our engineers are utilizing world class technologies, to optimize the supply chain, remove unnecessary costs, sprinkle in some surprise and delight all while saving customers every penny possible and we’re just getting started. At Jet, we have worked hard to build a culture that stresses the importance of learning and sharing knowledge. If you want to be part of the team that is changing the shopping norm and learning a lot along the way, we have a hunch you’d look good in purple.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Machine Learning Engineer - Health ML</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Are you an engineer who’s interested in tackling very challenging adversarial problems and passionate about defending online users against abuse, spam, and manipulation? Do you love working on challenging problems that require a multi-disciplinary approach, creative solutions, and rapid product iterations? Will you be proud to work on a real-time, scalable system that serves millions of users daily? If so, you should join us.\\n\\nWho We Are\\n\\nThe Health ML engineering team is responsible for building scalable detection systems that keep spam, manipulation, and abuse at bay. We use ML and relevance techniques to make Twitter safer and to limit the spread of misinformation on the platform. Our team works across the product to detect abusive and spammy users and content, increase action on bad actors, drive changes in user behavior, and detect and remediate accounts that are violating the terms of service on Twitter.\\n\\nWe develop, maintain, and contribute to several machine learning models and systems, including:\\n\\nModels that detect unwanted interactions\\nModels to prioritize human review of accounts violating Twitter's policies to more quickly take action and limit their damage\\nDetection of bots that misuse the platform or spread misinformation\\nDetection of repeat abusive offenders who create new accounts after being suspended\\nReal-time rule engines and clustering systems to identify and action on clusters of bad actors at scale\\nWhat You’ll Do\\n\\nAlthough you will work on cutting-edge problems, this position is not a pure research position. You will participate in the engineering life-cycle at Twitter, including designing distributed systems, writing production code and data pipelines, conducting code reviews and working alongside our infrastructure and reliability teams. You’ll apply data science, machine learning, and/or graph analysis techniques to a variety of modeling and relevance problems involving users, their social graph, their tweets, and their behavior.\\n\\nWho You Are\\n\\nYou’re a relevance engineer, applied data scientist, or machine-learning engineer who wants to work on exciting algorithmic and deep infrastructure issues to improve the health of the public conversation on Twitter. You’re experienced at solving large scale relevance problems and comfortable doing incremental quality work while building brand new systems to enable future improvements.\\n\\nYou are knowledgeable in one or more of the following: machine learning (including deep learning), information retrieval, recommendation systems, social network analysis.\\nYou are a strong technical advocate with a background in Java, C++, or Scala, and Python.\\nYou strive to find the right balance between moving fast to deliver quality improvements to users and accumulating technical debt that drags down productivity.\\nYou have a collaborative working style with a strong focus on disciplined execution and results.\\nYou like to ground decisions in data and reasoning and solve root causes of problems rather than surface issues.\\nYou are adept at communicating relevant information clearly and concisely.\\nYou look ahead to identify opportunities and thrive in a culture of innovation.\\n\\n\\nHere’s all the legal good stuff:\\n\\nWe are committed to an inclusive and diverse Twitter. Twitter is an equal opportunity employer. We do not discriminate based on race, ethnicity, color, ancestry, national origin, religion, sex, sexual orientation, gender identity, age, disability, veteran, genetic information, marital status or any other legally protected status.\\n\\nSan Francisco applicants: Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist / Senior Machine Learning Engineer</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Company\\n\\nWell-funded stealth company focused on disrupting healthcare through a differentiated consumer experience and a world-class data &amp; analytics engine to drive engagement and behavior change. The product will sell directly to Fortune 500 CEOs and full risk populations, integrating layers of analytics, digital, concierge services, behavioral health, telemedicine, care management and wellness services to drive sustained engagement, lower costs and improve health.\\n\\nReporting To\\n\\nHead of Data Science and AI with dotted line to Chief Analytics and Marketing Officer\\n\\nPosition Summary\\n\\n\\nThe overall goal is to engage consumers in differentiated ways that will drive better health outcomes. As one of the early hires of the Analytics organization, the primary mission will be to launch the modeling and optimization platform (the \"Health Engine\") to deliver member recommendations that improve health, cost of delivery, and engagement.\\nYou will leverage a wide range of disparate data sources across healthcare (member, payor, employer, provider, partner). Ideal candidates will have a detailed understanding of healthcare data with experience analyzing large longitudinal health datasets.\\nYou will lead in the creation of operational predictive models using current and emerging methodologies in data science. Ideal candidates will possess a deep understanding of statistics, machine learning, causal predictive modeling, and most importantly, a willingness to teach and mentor others in these areas.\\nYou will collaborate across the organization to drive projects from beginning to end: frame business questions, collect and analyze data, research, prototype, build pipelines, and share insights. You will work with engineering to ensure robust translation to production environments and create solutions that operate effectively at scale.\\n\\nMinimum Qualifications\\n\\n\\n5+ years' industry experience in data science or machine learning focused roles.\\nAdvanced degree (MS or PhD) in a quantitative field such as Statistics, Computer Science, Mathematics, Physics, Engineering, Economics, or similar.\\nDemonstrated experience using Python for data analysis and machine learning (numpy, pandas, scikit-learn, xgboost, spacy, pytorch, stan/pymc3, etc.). Proficiency with SQL and databases. Experience using Unix/OSX from the command line, version control (git), and general software development best practices for contributing to a collaborative code base. Experience configuring and executing analyses in the cloud (GCP, AWS).\\nStrong communication and collaboration skills required. Ability to communicate technical modeling concepts and relevant aspects of modeling platforms to non-technical audiences.\\nWillingness to teach and mentor others across all technical skill areas and in knowledge of the healthcare domain. Ability to work in a start-up environment that is fast paced and maintain a focus on rapid prototyping of capabilities.\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>New York, NY 10010</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>10010</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Machine Learning Engineer – New York, NY\\n\\nKasisto enables financial institutions to service, engage and acquire customers via human-like, intelligent conversations – anytime, anywhere. Kasisto’s Conversational AI platform, KAI, powers omni-channel virtual assistants and chatbots who are fluent in banking across mobile apps, websites, messaging platforms, and voice-enabled devices.\\n\\nKAI is the leading Conversational AI platform for the finance industry. Kasisto’s customers include J.P. Morgan, Mastercard, TD Bank, Standard Chartered, DBS Bank, among others. They chose KAI Banking for its proven track record to drive business results while improving customer experiences. The platform is engaging with millions of consumers around the world, across multiple channels, in different languages, and is optimized for performance, scalability, security, and compliance.\\n\\nBuilt with the deepest AI portfolio in the industry, KAI includes Platform Tools and Services to customize and continually improve consumer experiences as well as seamlessly add new features, channels, and markets.\\n\\nThis position\\n\\nWe are looking for an experienced Machine Learning Engineer. This position’s primary focus will be our platform’s core natural language understanding (NLU) engine, including accuracy improvements, performance evaluation, and the development of new features. The ideal candidate will have experience with machine learning-based approaches to text classification, named entity recognition, parameter extraction, and/or representation learning, as well as with the creation and evaluation of annotated training corpora. As Kasisto has an international customer-base, we welcome candidates with experience in languages besides English.\\n\\nYou should have the ability to work independently within a small, creative, deadline-driven environment. This is an excellent opportunity for someone looking to grow professionally within a fast-moving tech startup with a global reach.\\n\\nWhat you will be doing\\n\\nBuild machine learning models to understand documents and drive insights.\\nDesign and implement efficient pipelines for data manipulation, processing and delivery to our end users\\nCreate tools for automated quality assurance and anomaly detection to alert stakeholders of changes in the quality of machine learning models and analytics\\nDevelop quality software through code reviews, automated testing and design reviews\\nBuilding better-annotated training corpora by assessing data collection and annotation processes\\nAssisting in the implementation of new features and tools for both internal and external consumption\\nWhat you need in this position\\n\\n3+ years professional experience with machine learning\\nStrong proficiency in Java; Python or Scala experience a plus\\nExperience with deploying machine learning-based systems in production environments\\nExperience with multilingual NLP systems a plus\\nFamiliarity with a major machine learning/deep learning framework a plus (Keras, Tensorflow, Torch, Spark-ML, h2o.ai, etc.)\\nLocation – New York City, Flatiron District\\n\\nApplicants must be authorized to work in the US as we are unable to sponsor. Kasisto is an equal opportunity employer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Functional Area:\\nFA - Finance\\nEstimated Travel Percentage (%): No Travel\\nRelocation Provided: No\\nAIG Europe (Services) Limited\\nJob ID: JR1903962 Machine Learning Engineer\\nYour Future Team\\n\\nAbout Investments AI at AIG:\\nAIG is an insurance company that’s helped people solve important problems for almost a century. We’ve long been known for our technical expertise, and creating innovative solutions for new and developing areas of risk that our clients may face.\\nThe Investments AI team at AIG supports this ethos by developing AI-first products – that is, apps and services that use machine learning to inform and assist their users – for AIG’s insurance and investments businesses.\\nOur mission to create a safer world through the power of AI is achieved mainly through:\\nThe incubation of disruptive innovation via our diverse team of scientists, engineers, and designers who work collaboratively.\\nAI, ML and NLP R&amp;D contribution, including publications in top conferences and journals.\\nThe provision of machine learning advisory and consulting to AIG’s global businesses.\\nOur solutions and innovations aim to reinvent AIG’s internal processes, improve AIG’s offerings, and ultimately disrupt the industry.\\nAs a critical role in Investment AI’s success, we’re looking to hire machine learning engineers to join our team and contribute to the development of the algorithmic core of a series of exciting new products and projects.\\nYour Contribution at AIG\\nBased from our New York office, this is an exceptional opportunity for those who want to enjoy state-of-the-art R&amp;D and be challenged and grow as a machine learning engineer. Along the way, this role will contribute to game-changing products that use AIG’s global network to deliver impact and change.\\nResponsibilities and Performance Objectives\\nTake ownership of a significant part of the team’s solution development\\nDemonstrate end-to-end understanding of applications being created\\nPartner with ML Researchers to push the boundaries on the performance of the latest methods applied to big problems across the investments domain\\nContribute to peer review process to ensure code quality\\nWhat we are looking for\\nAbility to formalize learning problems with mathematical notation\\nHands-on experience solving Machine Learning problems\\nSolid understanding of algorithms and data structures\\nDetailed knowledge of Machine Learning evaluation metrics and best-practice\\nUp to date knowledge of Machine Learning literature and libraries (e.g. Tensorflow, Pytorch)\\nFamiliarity with build automation and continuous integration (e.g., Gulp, Grunt, Jenkins, CodePipeline)\\nAdvanced degree in a related field such as Machine Learning or Statistics (highly preferred)\\nGood communicator and a team player\\nAn ideal candidate (is not required to, but) will also have:\\nLinux SysAdmin skills\\nEngineering for scale using cloud platforms (e.g. Amazon Web Services)\\nInfrastructure-as-Code (e.g. Terraform, Cloudformation, etc.)\\nIt has been and will continue to be the policy of American International Group, Inc., its subsidiaries and affiliates to be an Equal Opportunity Employer. We provide equal opportunity to all qualified individuals regardless of race, color, religion, age, gender, gender expression, national origin, veteran status, disability or any other legally protected categories.\\nAt AIG, we believe that diversity and inclusion are critical to our future and our mission – creating a foundation for a creative workplace that leads to innovation, growth, and profitability. Through a wide variety of programs and initiatives, we invest in each employee, seeking to ensure that our people are not only respected as individuals, but also truly valued for their unique perspectives.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>New York, NY 10011</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>10011</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Explore the possibilities across our global house of brands.\\nDefined by inclusivity rather than exclusivity, Tapestry embraces the exploration of individuality and invests in helping you grow personally and professionally. Every individual in our global house has the opportunity to make an impact, learn and be part of our growing and unique story.\\nAt Tapestry, we have the freedom to express ourselves and run with our best ideas across Coach, Kate Spade New York, and Stuart Weitzman. We share a profound belief in both our individual and collective potential, and know that with hard work and dedication, anything is possible.\\n\\nPurpose\\nRetail as an industry is changing. With an increasing amount of shopping done online, traditional retailers must innovate to stay relevant. The Data Labs Team (https://datalabs.tapestry.com) at Tapestry is tackling these challenges by leveraging our deep data assets to provide a best in class, worldwide capability to drive actionable customer understanding across all of our brands: Coach, Kate Spade and Stuart Weitzman. We are looking for individuals with a passion for discovery, innovation, and the power of advanced analytics to drive financial results and improve customer experiences. We work collaboratively with business partners across the organization to define the questions to ask, pursue the best opportunities, share insights, and develop practical business recommendations.\\nThe optimal candidate will have the opportunity to work on innovative projects with the goal of enabling Tapestry to execute on the bleeding edge in the applications of machine learning and artificial intelligence within the fashion retail industry. The candidate will leverage both internal and external data along with a suite of machine learning algorithms to develop and deploy pipelines that allow both the data and the models to provide actionable insights that produce value across the organization.\\nWe are looking for team player to support with guiding and implementing in production application of data science and machine learning methods with an eye and passion for software engineering, and the ability to connect analytics to business impact. The ideal person will lead and potentially grow the existing team to amplify impact through the combination of analytical and tooling innovation, scaled execution, science leadership, data partnership, and high pace of execution.\\n\\nThe successful individual will leverage their proficiency in Engineering and Advanced Analytics to…\\nInvestigate areas of the business that could benefit from machine learning solutions, engaging with technology and operational leaders to understand the problems they are looking to solve, as well as educating them on what is an achievable outcome.\\nAct as the ML Engineering Lead to manage the production, delivery, and integration of the solution within the business.\\nImplement in production machine learning systems using Python, R, and AWS.\\nSolutions will include but will not be limited to: inventory allocation, supply chain optimization, pricing models, targeting models, customer segmentation, customer loyalty and retention, competitive benchmarking, recommendation systems, computer vision applications.\\nSolution and develop architecture for model evaluation and model serving infrastructure.\\nWork with a team of world class data scientists, business analysts, statisticians, and creative technologists.\\nAsk not, “What is the best algorithm?”, but instead, “What is the best system?” to solve a problem.\\nWork closely with different business units (Strategy, Marketing, e-Commerce, Retail, Outlet, Pricing, Supply Chain among others) to identify business needs and challenges that can be addressed through data-driven advanced analytics.\\n\\nThe accomplished individual will possess…\\nMaster’s degree in a quantitative field or the work experience equivalent\\n2+ years of software or data engineering experience\\n2+ years of experience or exposure to applications of machine learning\\nStrong background of creating data processing and model deployment pipelines (Apache Airflow, Apache Beam, PySpark, Amazon Pipeline)\\nAdvanced knowledge of Linux (bash), Python, and SQL (MySQL, PostgreSQL)\\nExperience building and maintaining model monitoring frameworks.\\nExperience leveraging Amazon Web Services to build software microservices.\\nKnowledge of software development principles including but not limited to, software development lifecycle, agile methodologies, code reviews\\nKnowledge of data management and storage principles\\nWorking understanding of core ML/Statistics principles.\\nExcellent written and verbal communication skills\\n\\nThe accomplished individual will also be…\\nAn achiever that maintains a high standard but understands that perfection is the enemy of progress\\nAn innovator who can execute as an individual and is proactive in solving problems\\nAn autodidact, with a passion for both the acquisition and application of knowledge\\nA catalyst who can deliver from ideas and inspires others towards that shared vision\\nA collaborator who recognizes the value of and can action on not only managing junior resources but of managing up to influence executives while collaborating laterally\\nA believer in the spirit of entrepreneurship that understands the power of perseverance\\n\\nTapestry, Inc. is an equal opportunity and affirmative action employer and we pride ourselves on hiring and developing the best people. All employment decisions (including recruitment, hiring, promotion, compensation, transfer, training, discipline and termination) are based on the applicant’s or employee’s qualifications as they relate to the requirements of the position under consideration. These decisions are made without regard to age, sex, sexual orientation, gender identity, genetic characteristics, race, color, creed, religion, ethnicity, national origin, alienage, citizenship, disability, marital status, military status, pregnancy, or any other legally-recognized protected basis prohibited by applicable law. Visit Tapestry, Inc. at http://www.tapestry.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Staff Machine Learning Engineer - Search</td>\n",
       "      <td>Hoboken, NJ</td>\n",
       "      <td>Hoboken</td>\n",
       "      <td>NJ</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>The search team at Walmart Labs and Jet is dedicated to the mission of helping millions of customers every day in finding the right products. We are at the forefront of attacking one of the most complex problems of e-commerce. Whenever a user types in a query or browses through product categories on the web site, phone or iPad, our service goes to work. We mine billions of search queries and tens of millions of products to find the most relevant products for our customers. Team members take end-to-end responsibility in analyzing large amounts of data, creating complex models, improving their accuracy and deploying these models to serve customers. E-commerce product search, much like web search, has always been a fertile area of AI innovation. Search algorithm team at Walmart Labs and Jet is working on fascinating AI/ML problems like deep NLP based query understanding, improving relevance ranking of products, semantic matching of query item pairs using embeddings, visual search to enable search by image, etc. As part of this team, you'll solve some of the most challenging and impactful problems in machine learning, information retrieval, natural language processing, computer vision or statistical measurement. Your work will be visible to hundreds of millions of customers and you will have a direct impact on the goals of the Fortune #1 company. If you speak and think machine learning then we want to talk to you. Come join our team and be part of this exciting journey.\\n\\nWhat you will do:\\n\\nBuild advanced machine learning models and improve the accuracy of those models\\nDeploy the models in production where it will serve customers in real time\\nPut on the hacker's hat quickly convert an idea to a demonstration\\nPresent your work to the internal and external community\\nWork alongside senior machine learning researchers and define the right solution to implement\\n\\nWhat you will have:\\n\\n7+ years of experience in Software engineering.\\nAbility to write high performance production quality code. Experience in Python, Scala and other equivalent languages is a plus.\\nFunctional programming experience is a plus.\\nExperience building and productionizing innovative end-to-end Machine Learning systems.\\nGood understanding of common families of models, feature engineering, feature selection and other practical machine learning issues, such as overfitting.\\n\\nBonus Points\\n\\n\\nExperience building and/or maintaining machine learning models and pipelines\\nExperience building and maintaining large scale data pipelines in online advertising, recommender system, ecommerce or relevant areas\\nFamiliarity with Deep Learning.\\n\\nAbout Jet\\n\\nJet is reshaping ecommerce as we know it. Based in Hoboken NJ (just 10 min from Manhattan), we are a shopping site on the relentless pursuit to build the greatest shopping experience in the world. At Jet, we believe in bold. That means taking risks, asking \"why not\", looking where no ones looked before and bringing it! Our engineers are utilizing world class technologies, to optimize the supply chain, remove unnecessary costs, sprinkle in some surprise and delight all while saving customers every penny possible and we're just getting started. At Jet, we have worked hard to build a culture that stresses the importance of learning and sharing knowledge. If you want to be part of the team that is changing the shopping norm and learning a lot along the way, we have a hunch you'd look good in purple.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Associate Cloud Developer, A2C Relaunch</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>BS level technical degree or equivalent experience; Computer Science or Engineering background preferred; Masters Degree desired.Experience with one of the following programming languages: Java, Python, Ruby, Node.js, C#, or C++Experience with Networking fundamentals, Security, Databases (Relational and/or NoSQL), Operating Systems (Unix, Linux, and/or Windows)Exposure to Agile development methodologies\\n\\nReturner Program Details:\\nReturn to work and come build the future of cloud computing with Amazon Web Services.The AWS Returners Program offers individuals who have been on a career break an opportunity to return to full time employment within a breadth of different roles. The program is designed to support Returners back into a permanent position, setting them up with the skills and knowledge needed for success at AWS!\\n\\nAmazon aims to be the most customer centric company on earth. Amazon Web Services (AWS) provides a highly reliable, scalable, low-cost infrastructure platform in the cloud that powers critical applications for hundreds of thousands of businesses in 190 countries around the world.\\n\\nWhat are we looking for?\\nIf you have been out of the workforce for longer than two years, and want to restart your career, the AWS Returners Program could be for you. As a Returner:\\nYou will bring your voice. At AWS we value individual expression, respect different opinions, and work together to create a culture where each of us is able to contribute fully.You will accelerate your growth. The scope and scale of what we do for our customers drive us to experiment with new possibilities, take risks and learn quickly.You will chart your own path. The possibilities you explore, the opportunities you take advantage of, and the impact you have is driven by your ideas and initiative.You will embrace the challenge. At AWS building the future is inspiring and fun and we embrace the challenge that comes with inventing and delivering things that were never thought possible.\\nYou will use our Leadership Principles every day. Whether discussing ideas for new projects or deciding on the best approach to solving a problem our Leadership Principles is just one of the things that makes Amazon peculiar. Learn more about our Leadership principles here.\\nWhat does the AWS Returners Program Offer?\\nIn Amazon Web Services, we don't mind being called \"peculiar.\" We have our own way of doing things. We're obsessed with customers, we see beauty in simplifying the complex, and we're comfortable with being misunderstood. That might sound unorthodox, but our unusual approach and our culture - focused on removing obstacles so builders can build - are part of why our employees enjoy working in AWS.\\n\\nAWS is helping over a million customers in 190 countries leverage the power of cloud computing. Being a global company isn’t just about worldwide availability or working with international customers; we also see the value in building global teams. Here are some of the great benefits that you’ll get from joining us on our program.\\n\\nFor more information please visit.\\nhttps://www.amazon.jobs/en/landing_pages/awsreturners\\n\\nProfessional Services:\\n\\nWe are looking for motivated technologists who possess a unique balance of technical depth, business knowledge, and strong interpersonal skills who have been on a career break an opportunity to return. This program is designed to help and support you back into a full-time permanent role. Our goal is to set you up with the skills and knowledge you need for success.\\n\\nDuring your first 6 months as a Returner, you will receive instruction and on-the-job training on a range of AWS services and solutions. By the end of the first year, you will choose a specialty track suited to your strengths and preferences (subject to business availability). These tracks include:\\n\\nApplication Developer – AppDev resources are specialists in designing applications that run natively in the cloud. They are experts in building programs that run on any number of platforms including virtualized instances, containers, or serverless architecture.\\nCloud Infrastructure Architect – An expert in cloud-based networking and system rollouts. CIAs specialize in network performance, infrastructure provisioning, and building Application Programming Interfaces (APIs).\\nDevOps Specialist – A leader in building advanced computing systems that harness continuous integration/continuous deployment pipelines and utilize the strengths of cloud computing to build scalable and economical systems for customers.\\nData Lake &amp; Analytics Specialist – This role will specifically focus on data processing capabilities and helping our customers and partners to remove the constraints that prevent our customers from leveraging their data to develop business insights. Engagements will include migration of existing applications and development of new applications using AWS cloud services.\\nData Warehouse &amp; Massive Parallel Processing Specialist – This role will specifically focus on large scale data warehousing and database migration capabilities. Engagements will include Redshift implementations and helping customers to migrate from their existing on-premises data warehouses using other databases to Amazon Redshift.\\nData &amp; Machine Learning Engineer – In this role, you will work with our partners and customers with a focus on our AWS Analytics and ML services offering such Amazon Kinesis, AWS Glue, Amazon Redshift, Amazon EMR, Athena, Amazon SageMaker, and more. You will help our customers and partners to remove the constraints that prevent them from leveraging their data to develop business insights.\\n\\nOur consultants deliver proof-of-concept projects, topical workshops, and lead implementation projects. These professional services engagements focus on key customer solutions such as, web applications, enterprise applications, HPC, batch processing and big data, archiving and disaster recovery, education and government.\\n\\nResponsibilities include:\\nExpertise - Collaborate with AWS field sales, pre-sales, training and support teams to help partners and customers learn and use AWS services such as Amazon Elastic Compute Cloud (EC2), Amazon Simple Storage Service (S3), Amazon SimpleDB/RDS databases, AWS Identity and Access Management (IAM), etc.Solutions - Define and deliver on-site technical engagements with partners and customers. This includes participating in pre-sales on-site visits, understanding customer requirements, and proposing and delivering packaged offerings, and delivering custom solution engagements.Delivery - Engagements include short on-site projects proving the use of AWS services to support new distributed computing solutions that often span private cloud and public cloud services. Engagements will include migration of existing applications and development of new applications using AWS cloud services.Insights - Work with AWS engineering and support teams to convey partner and customer needs and feedback as input to technology roadmaps. Share real world implementation challenges and recommend new capabilities that would simplify adoption and drive greater value from use of AWS cloud services.\\n\\nTroubleshooting: Experience with QA, testing, helpdesk, IT support, or any technician or quality assurance type workCloud Awareness: Experience implementing a cloud-based technology solutionExperience with systems administration (Linux/Windows) or network administration (DNS, IPsec, BGP, VPN, Load Balancing)Scripting skills (e.g. Powershell, Python, Bash, Ruby, Perl, etc.)Passion for experiencing new technologies, cultures, and locations in the US and around the world\\nAmazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation/Age\\n\\nPursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.\\n\\nPursuant to the Los Angeles Fair Chance Ordinance, we will consider for employment\\nqualified applicants with arrest and conviction records.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Machine Learning Engineer, Sustainability</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Who are we?\\n\\nSidewalk Labs is an Alphabet company tackling the challenges of urban growth. Our vision for cities is rooted in a cross-disciplinary approach that is reflected in our team, composed of experts from real estate, government, finance, technology, engineering and more. Since its founding in 2015, Sidewalk Labs has evolved into an organization of over 100 employees based primarily in New York and Toronto.\\n\\nWe are currently designing a new kind of mixed-use, complete community on Toronto's waterfront in partnership with the tripartite agency Waterfront Toronto and the local community. This joint effort, called Sidewalk Toronto, will combine forward-thinking urban design and new digital technology to create a people-centered neighborhood that achieves precedent-setting levels of sustainability, affordability, mobility, and economic opportunity.\\n\\nWe are working to achieve something unprecedented — help us build it.\\n\\nWhat is the role?\\n\\nTo improve sustainability in cities, Sidewalk Labs is developing new technology that will drastically reduce greenhouse gas emissions compared to the status quo, empower smarter management of resources, and reduce the cost of future upgrades and maintenance. We plan for a 75%-85% reduction in greenhouse gas emissions compared to similar projects, aiming for Climate Positive.\\n\\nTo achieve our sustainability goals in Quayside, we plan to pilot and scale different kinds of innovation to tackle the thorniest problems in building environment performance. Success requires bold innovation around electricity and thermal systems.\\n\\nWe are looking for a machine learning engineer to join our team in our New York City office. In your first project you will build models and programs that reduce energy use in buildings and cut greenhouse gas emissions through analysis of building management system (BMS) data and other similar systems.\\n\\nIt's a bonus (but not a requirement) if you are familiar with building systems and IoT sensors, their data, and analysis of it (e.g., HVAC, occupancy, temperature, lighting, etc.).\\n\\nWhat is required is passion for sustainability and the desire to create a climate positive community.\\n\\nWhat you have you achieve:\\nWithin your first 6 months, you will:\\n\\nBuild from scratch our initial models for studying and reducing energy usage.\\nModel energy use and reductions, including creating regression-based energy baselines.\\nBuild and refine recommendation engines and predictive models (e.g. time to reach set point, monthly energy consumption).\\nCreate dashboards and interactive visualizations to share ongoing data.\\nDesign communication models catered to cohorts.\\nDesign and build data pipelines and processes for optimal and secure processing of complex data sets.\\nDevelop methods and naming schemas to unify (messy) data from building systems, sensors, APIs, and other sources, enabling a streamlined way to analyze data and prototype use cases.\\nBuild in security and privacy by design.\\n\\nWhat we expect:\\n\\nKnow your computer science.\\nHave a CS background to choose the right algorithms, systems approaches and patterns to solve problems without reinventing the wheel.\\nCandidates must be able to hit the ground running. Therefore, we generally look for 3+ years of industry experience in a world-class engineering organization.\\nExperience with Python and at least one systems programming language (C++, Java, or Go). Experience with Google Cloud Platform and/or Kubernetes a plus\\nHave in-depth experience delivering algorithms and implementing end-to-end data processing pipelines.\\nBe a technologist.\\nBias towards action and shipping. Once you've sketched out an idea, you find the fastest path to a prototype to prove the concept.\\nYou are obsessed with privacy and constantly ask how we can build privacy into product design.\\nBe comfortable with a range of languages and open source tools and frameworks, and make good decisions about which to use to solve a problem. You are excited to learn something new when the need arises.\\nBe creative: you'll come up with new ideas based on your broad understanding of technological possibilities and city domain knowledge.\\nSolve problems, together.\\nCome up with novel solutions, working well with technologists and non-technologists alike.\\nAsk hard questions and challenge assumptions to ensure that we're solving the right problems.\\nHave flexibility to work on the team's most pressing problems.\\nPassionate about cities.\\nYou have thought about the urban environment and care deeply about improving the lives of urban citizens.\\n\\nWe are very excited to hear from you.\\n\\nThe community of the future is a place for everyone, and Sidewalk Labs is proud to be an equal opportunity employer. We encourage members of underrepresented communities to apply. All employment is based on merit and business need.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Senior Machine Learning Engineer - Search</td>\n",
       "      <td>Hoboken, NJ</td>\n",
       "      <td>Hoboken</td>\n",
       "      <td>NJ</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>The search team at Walmart Labs and Jet is dedicated to the mission of helping millions of customers every day in finding the right products. We are at the forefront of attacking one of the most complex problems of e-commerce. Whenever a user types in a query or browses through product categories on the web site, phone or iPad, our service goes to work. We mine billions of search queries and tens of millions of products to find the most relevant products for our customers. Team members take end-to-end responsibility in analyzing large amounts of data, creating complex models, improving their accuracy and deploying these models to serve customers. E-commerce product search, much like web search, has always been a fertile area of AI innovation. Search algorithm team at Walmart Labs and Jet is working on fascinating AI/ML problems like deep NLP based query understanding, improving relevance ranking of products, semantic matching of query item pairs using embeddings, visual search to enable search by image, etc. As part of this team, you'll solve some of the most challenging and impactful problems in machine learning, information retrieval, natural language processing, computer vision or statistical measurement. Your work will be visible to hundreds of millions of customers and you will have a direct impact on the goals of the Fortune #1 company. If you speak and think machine learning then we want to talk to you. Come join our team and be part of this exciting journey.\\n\\nWhat you will do:\\n\\nBuild advanced machine learning models and improve the accuracy of those models\\nDeploy the models in production where it will serve customers in real time\\nPut on the hacker's hat quickly convert an idea to a demonstration\\nPresent your work to the internal and external community\\nWork alongside senior machine learning researchers and define the right solution to implement\\n\\nWhat you will have:\\n\\n4+ years of experience in Software engineering.\\nAbility to write high performance production quality code. Experience in Python, Scala and other equivalent languages is a plus.\\nExperience building and productionizing innovative end-to-end Machine Learning systems.\\nGood understanding of common families of models, feature engineering, feature selection and other practical machine learning issues, such as overfitting.\\n\\nBonus Points\\n\\n\\nExperience building and/or maintaining machine learning models and pipelines\\nFunctional programming experience is a plus.\\nExperience building and maintaining large scale data pipelines in online advertising, recommender system, ecommerce or relevant areas\\nFamiliarity with Deep Learning.\\n\\nAbout Jet\\n\\nJet is reshaping ecommerce as we know it. Based in Hoboken NJ (just 10 min from Manhattan), we are a shopping site on the relentless pursuit to build the greatest shopping experience in the world. At Jet, we believe in bold. That means taking risks, asking \"why not\", looking where no ones looked before and bringing it! Our engineers are utilizing world class technologies, to optimize the supply chain, remove unnecessary costs, sprinkle in some surprise and delight all while saving customers every penny possible and we're just getting started. At Jet, we have worked hard to build a culture that stresses the importance of learning and sharing knowledge. If you want to be part of the team that is changing the shopping norm and learning a lot along the way, we have a hunch you'd look good in purple.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Senior Machine Learning Engineer</td>\n",
       "      <td>New York, NY 10012</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>10012</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Getting together with real people in real life makes powerful things happen. Side hustles become careers, ideas become movements, and chance encounters become lifelong connections. Meetup brings people together to build thriving communities. Show up. Change lives.\\n\\nEvery year, millions of people RSVP to an eclectic variety of Meetups around the world. Activity on Meetup is growing faster than ever and by studying it, we're learning how to help members discover the groups and events that are right for them -- sparking new ways to make their worlds come alive than ever before. We are a collaborative and dedicated team seeking machine learning engineers to join us in designing and building the future vision of Meetup.\\n\\nRole and responsibilities\\n\\nYou imagine a world more easily connected, where people come together in real life, meet, and do more of the things that empower personal growth through real human connections. We are looking to add engineers to our machine learning team to:\\n\\n\\nUse machine learning to improve Meetup's recommendation, search and notification systems\\nDesign, build, and own every aspect of our low-latency personalization platform\\nDevelop your leadership skills while mentoring other specialists\\nCollaborate with product and design to leverage data and algorithms to improve user experience\\nRecruit and present on behalf of Meetup at technical conferences and Meetup events\\n\\nPreferred qualifications:\\n\\nBS+ degree in Computer Science, Engineering, Statistics or related STEM field\\n5+ years work/educational experience with recommendations, predictions, or NLP\\nContributed to a large codebase in Scala (most of our codebase), Java or Python\\nHands-on experience using machine learning frameworks to robustly build, validate, test, and monitor statistical models\\nImplement machine learning algorithms in cloud (AWS) and horizontally scalable environments (MapReduce, Hadoop, Spark)\\nExperience with both relational and NoSQL (DynamoDB, Redis) databases and RESTful APIs\\n\\nOur values:\\nMeetup employees are bold, supportive, and passionate about enabling people coming together and creating the future of real community; a future where people embrace their differences and similarities, show up, do things, and turn to each other to improve their lives. We care about moving fast, real-world change, and proud to be an equal opportunity employer committed to hiring and developing diverse, dynamic teams in a safe and inclusive environment.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>B.S. degree in mathematics, statistics, computer science or a similar quantitative field5+ years work experience in relevant fieldExperience in using SQL to analyze data in a database or data warehouse and be able to use a major programming (e.g. Java/C) and/or a scripting language (Perl, Unix shell, Python) to process data for modelingExperience working with a wide range of predictive and decision models and data mining techniques, as well as tools for developing such models\\n\\nExcited by using massive amounts of data to develop Machine Learning (ML) and Deep Learning (DL) models? Want to help the largest global enterprises derive business value through the adoption of Artificial Intelligence (AI)? Eager to learn from many different enterprise’s use cases of AWS ML and DL? Thrilled to be key part of Amazon, who has been investing in Machine Learning for decades, pioneering and shaping the world’s AI technology?\\n\\nAt Amazon Web Services (AWS), we are helping large enterprises build ML and DL models on the AWS Cloud. We are applying predictive technology to large volumes of data and against a wide spectrum of problems. Our Professional Services organization works together with our AWS customers to address their business needs using AI.\\n\\nAWS Professional Services is a unique consulting team. We pride ourselves on being customer obsessed and highly focused on the AI enablement of our customers. If you have experience with AI, including building ML or DL models, we’d like to have you join our team. You will get to work with an innovative company, with great teammates, and have a lot of fun helping our customers.\\n\\nIn our Global Specialist Practice, you will also have the opportunity to create white papers, write blog posts, build demos and other reusable collateral that can be used by our customers, and you will work closely with our Solution Architects and Service Engineering teams.\\n\\nIf you do not live in a market where we have an open Data Scientist position, please feel free to apply. Our Data Scientists can live in any location where we have a Professional Service office.\\n\\nA successful candidate will be a person who enjoys diving deep into data, doing analysis, discovering root causes, and designing long-term solutions. It will be a person who likes to have fun, loves to learn, and wants to innovate in the world of AI. Major responsibilities include:\\n\\nUnderstand the customer’s business need and guide them to a solution using our AWS AI Services, AWS AI Platforms, AWS AI Frameworks, and AWS AI EC2 Instances .Assist customers by being able to deliver a ML / DL project from beginning to end, including understanding the business need, aggregating data, exploring data, building &amp; validating predictive models, and deploying completed models to deliver business impact to the organization.Work with our Professional Services Big Data/Analytics consultants to analyze, extract, normalize, and label relevant data.Work with our Professional Services consultants and customer teams to help our customers operationalize models after they are built.Assist customers with identifying model drift and retraining models.Research and implement novel ML and DL approaches, including using FPGA.\\n\\nExperience in data modeling, ETL development, and Data warehousing.Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data setsData Warehousing Experience with Oracle, Redshift, etcExperience with software coding practices is a strong plus.Experience using Linux/UNIX to process large data setsMeets/exceeds Amazon’s functional/technical depth and complexity for this roleExperience with AWS technologies like Redshift, S3, EC2, Data Pipeline, &amp; EMRCombination of deep technical skills and business savvy enough to interface with all levels and disciplines within our customer’s organization\\nDemonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment\\nAmazon is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Senior Machine Learning Engineer – Free Mission</td>\n",
       "      <td>New York, NY 10011</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>10011</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>At Spotify, we’re proud of our ambitious mission of having 1 billion fans enjoying music around the world, and are seeking a lead machine learning engineer to join us in pursuit of this goal. Our team leverages machine learning to drive both advertiser outcomes and listener satisfaction in Spotify Free, helping democratize music access globally while positively impacting Spotify’s bottom line. We develop innovative solutions around the core problem of getting the right ad to the right user at the right time, while embodying Spotify’s values and taking our users’ best interest at heart.\\n\\nWhat you’ll do\\n\\nHelp give hands-on technical leadership to one of Spotify’s most important business areas, monetization in our free product of 100+ million monthly active users.\\nDrive collaboration with other engineers, product managers, and designers across our team to make it easier to deliver best-in-class ML-powered listening experiences through shared platforms, tools, and approaches building on our use of Scala/Java and the GCP ecosystem\\nBe a leading voice in an active community of machine learning practitioners across Spotify\\nBuild or improve features that impact our users and make them better utilizing ML\\nTake on complex data-related problems using some of the most diverse datasets available\\nImprove our features through the usage of offline and online tests\\nDevelop individually to continue to grow your impact, and help mentor peers\\nWho you are\\n\\nYou have expertise and excitement about machine learning, including deep familiarity with the state-of-the-art as reflected in research at conferences, e.g. RecSys, ICML, or NeurIPS, and / or in practice at other leading internet companies\\nYou are an expert at architecting data pipelines and are self-sufficient in getting the data you need to build and evaluate your models, using tools like Apache Beam or Spark.\\nYou have 7+ years of professional engineering experience working in a product-driven environment with technologies (Scala, Java, Python, or C++) and cloud platforms (GCP or AWS).\\nYou have 4+ years of machine learning product development experience focused on content generation, personalization, or measurement, leveraging large scale data with broad impact using technologies like TensorFlow or XGBoost.\\nYou care about agile software development and a culture of constant learning and improvement\\nYou have experience and passion for mentoring and encouraging collaborative teams.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Staff Machine Learning Engineer - Search</td>\n",
       "      <td>Hoboken, NJ 07030</td>\n",
       "      <td>Hoboken</td>\n",
       "      <td>NJ</td>\n",
       "      <td>07030</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>The search team at Walmart Labs and Jet is dedicated to the mission of helping millions of customers every day in finding the right products. We are at the forefront of attacking one of the most complex problems of e-commerce. Whenever a user types in a query or browses through product categories on the web site, phone or iPad, our service goes to work. We mine billions of search queries and tens of millions of products to find the most relevant products for our customers. Team members take end-to-end responsibility in analyzing large amounts of data, creating complex models, improving their accuracy and deploying these models to serve customers. E-commerce product search, much like web search, has always been a fertile area of AI innovation. Search algorithm team at Walmart Labs and Jet is working on fascinating AI/ML problems like deep NLP based query understanding, improving relevance ranking of products, semantic matching of query &lt;-&gt; item pairs using embeddings, visual search to enable search by image, etc. As part of this team, you'll solve some of the most challenging and impactful problems in machine learning, information retrieval, natural language processing, computer vision or statistical measurement. Your work will be visible to hundreds of millions of customers and you will have a direct impact on the goals of the Fortune #1 company. If you speak and think machine learning then we want to talk to you. Come join our team and be part of this exciting journey.\\n\\nWhat you will do:\\n\\nBuild advanced machine learning models and improve the accuracy of those models\\nDeploy the models in production where it will serve customers in real time\\nPut on the hacker's hat quickly convert an idea to a demonstration\\nPresent your work to the internal and external community\\nWork alongside senior machine learning researchers and define the right solution to implement\\n\\n\\nWhat you will have:\\n\\n7+ years of experience in Software engineering.\\nAbility to write high performance production quality code. Experience in Python, Scala and other equivalent languages is a plus.\\nFunctional programming experience is a plus.\\nExperience building and productionizing innovative end-to-end Machine Learning systems.\\nGood understanding of common families of models, feature engineering, feature selection and other practical machine learning issues, such as overfitting.\\n\\n\\nBonus Points\\n\\nExperience building and/or maintaining machine learning models and pipelines\\nExperience building and maintaining large scale data pipelines in online advertising, recommender system, ecommerce or relevant areas\\nFamiliarity with Deep Learning.\\n\\nAbout Jet\\n\\nJet is reshaping ecommerce as we know it. Based in Hoboken NJ (just 10 min from Manhattan), we are a shopping site on the relentless pursuit to build the greatest shopping experience in the world. At Jet, we believe in bold. That means taking risks, asking “why not”, looking where no ones looked before and bringing it! Our engineers are utilizing world class technologies, to optimize the supply chain, remove unnecessary costs, sprinkle in some surprise and delight all while saving customers every penny possible and we’re just getting started. At Jet, we have worked hard to build a culture that stresses the importance of learning and sharing knowledge. If you want to be part of the team that is changing the shopping norm and learning a lot along the way, we have a hunch you’d look good in purple.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Senior Lead Machine Learning Engineer/Data Scientist</td>\n",
       "      <td>New York, NY 10020</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>10020</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nLead a team of machine learning engineers, data scientist, data engineers\\nSupport our data modeling efforts to ensure we are capturing the data needed to improve our modeling capabilities.\\nCreate features for our feature store\\nBuild machine learning models\\nUse a variety of techniques including predictive modeling, recommendation engines, revenue management, conversion rate optimization, and site and user experience optimization.</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\n5+ years' experience developing, maintaining, and testing machine learning models.\\nA strong technical advocate with a background in Java, Scala, or Python. Preferably familiar with Jupyter notebook environments and Spark or pySpark.\\nStrong understanding of the machine learning tooling for either Python or Scala (e.g. Pandas, XGBoost, Spark)\\nStrong understanding of machine learning\\nNice to have\\nExperience with CI/CD infrastructure and a strong supporter of unit / integration testing</td>\n",
       "      <td>(We are not sponsoring for this role or in the future)\\nAt Fareportal, we create technology that is driving innovation in the travel industry - one of the world's fastest-growing sectors. Our employees are the core of our organization and together we're revolutionizing the way people book travel.\\nOur portfolio of brands including CheapOair and OneTravel receive over 100 million visitors annually and drive over $4 billion in annual revenue.\\nWe are looking for a Lead Machine Learning Engineer/Data Scientist to join our team. You will be handling hundreds of millions of events per day, responsible for creating and supporting machine learning models that will drive our business.\\nMachine Learning Engineers is at the heart of how Fareportal works and they are part software engineer and part machine learning / data scientist. You will focus on creating and supporting large scale models that we deploy to power our recommendation, pricing or other systems. The ideal candidate will participate in the design and implementation of the entire model pipeline, from project ideation, figuring out which data to capture and store, coming up with features, to creating the final model.\\nWe are passionate about making data-driven decisions and you will have the opportunity to shape the team's direction and create large impact.\\nOur team loves Python and Scala (and is not afraid of Functional Programming) and we strongly encourage DevOps approaches.\\nResponsibilities:\\nLead a team of machine learning engineers, data scientist, data engineers\\nSupport our data modeling efforts to ensure we are capturing the data needed to improve our modeling capabilities.\\nCreate features for our feature store\\nBuild machine learning models\\nUse a variety of techniques including predictive modeling, recommendation engines, revenue management, conversion rate optimization, and site and user experience optimization.\\nOur ideal candidate:\\nWho You Are\\nYou are smart and love to build systems that are well tested as well as flexible\\nYou like being around smart people who will challenge you on a daily basis.\\nYou love to ramp up on new technologies to build awesome things with us!\\nPassionate about working with large unstructured and structured data sets and developing new approaches to relevance problems\\nYou like to share your knowledge and guide other fellow data scientist and engineers\\nRequirements\\n5+ years' experience developing, maintaining, and testing machine learning models.\\nA strong technical advocate with a background in Java, Scala, or Python. Preferably familiar with Jupyter notebook environments and Spark or pySpark.\\nStrong understanding of the machine learning tooling for either Python or Scala (e.g. Pandas, XGBoost, Spark)\\nStrong understanding of machine learning\\nNice to have\\nExperience with CI/CD infrastructure and a strong supporter of unit / integration testing\\nfEvhxhNuhl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Senior Associate, Digital Intelligence – Machine Learning Engineer</td>\n",
       "      <td>New York, NY 10001</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>10001</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>About Chase\\nJPMorgan Chase &amp; Co. (NYSE: JPM) is a leading global financial services firm with assets of $2.6 trillion and operations worldwide. The firm is a leader in investment banking, financial services for consumers and small business, commercial banking, financial transaction processing, and asset management. We serve millions of consumers in the United States and many of the world's most prominent corporate, institutional and government clients under our J.P. Morgan and Chase brands. Information about JPMorgan Chase &amp; Co. is available at www.jpmorganchase.com.\\nChase Consumer &amp; Community Banking serves nearly 66 million consumers and 4 million small businesses with a broad range of financial services, including personal banking, investment advice, small business lending, mortgages, credit cards, payments and auto financing. In recent years, we have undertaken a large-scale digital transformation initiative, building on the success of our current mobile and online service offerings. The Digital team is responsible for building innovative platforms and developing new products that make banking and payment tasks simpler and more personalized for our customers, as well as deepen customer engagement and loyalty with more relevant offers and services. The ambition is to position Chase as the undisputed leader in digital financial services and payments, and to enable highly personalized, real-time experiences that customers increasingly expect. We function similar to a fintech start-up in our brand new offices that inspire collaboration, transparency, agile development, and a fun working environment.\\n\\nDescription:\\nThis role is being offered within JPMorgan Chase Digital Intelligence organization. DI is responsible for creating advanced and intelligent capabilities for our consumer products. We work closely with our Digital Technology engineering team to bring these solutions to market. It is a fast paced and dynamic environment, where we work with many business and product owners in addition to focusing on technical deliveries. Understanding and interacting with the business is a key component to the success of our work where success is defined as bringing value to our customers.\\nThe candidate needs to have significant training and working experience in computer science/software engineering, with large and real-time computational experience. He/she needs to have demonstrated experience in implementing and deployment of large-scale production system certain advanced computational algorithms. Big-Data platform work experience is a must, i.e. worked and maintained HBase, Hadoop, Spark, etc. where the candidate has been a key team player. The candidate needs to have significant software engineering work experience, where he/she has been responsible for bringing a complete system to production end-to-end, working with DevOps and various levels of production engineering teams.\\n\\nQualifications:\\n\\nRequired:\\n\\n3+ years of software engineering/developer and production experience\\n\\n1- 3 years of experience in big-data\\n3+ years of big-Data platform engineering\\n\\n3+ years of parallel computing\\n\\nMinimum Master’s degree in engineering disciplines (candidate’s bachelor degree needs to be engineering focused as well), with the focus in computer science and related extended core training and experience. Candidates with equivalent work experience are also highly desirable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Principal Data Scientist / Applied Machine Learning Engineer</td>\n",
       "      <td>Manhattan, NY</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>NY</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nEstablish project scope and roadmap, including data strategy, needed to develop production-level predictive pipelines that solve large scale problems for clients in the space\\nHelp develop, implement and document rigorous methodology to plan, track and improve accuracy and relevance of models\\nLead internal communication with stakeholders, and ensure delivery of the project per commitment\\nCollaborate with clients and other stakeholders to effectively integrate and communicate findings and use cases\\nProvide guidance and project management support to the Associates on the team\\nExperience building predictive models allows you to clearly determine team size and scope work needed to accomplish business goals\\nKnowledge of databases, data modeling, and data harmonization a must\\nEvaluate emerging technologies and alternative datasets that may contribute value to our existing platforms\\nContribute to the thought leadership of the company by publishing ML research and participating in relevant conferences in the space\\nHealthcare data familiarity, especially around claims and clinical data, is highly desirable</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Role Specification:\\n5+ years of professional experience in Data Science, 3+ years in Healthcare preferred\\nPostgraduate qualification in Computer Science, Biostatistics, or other Quantitative Field from top school (PhD Preferred)\\nHands-on experience on writing production-level machine learning code\\nExposure to standard ML tooling – Python, R, and TensorFlow/Torch libraries\\nExcellent communication skills\\nExcellent critical thinking and problem-solving skills\\nHigh motivation, good work ethic and maturity\\nRole Description\\nWork closely with VP of Data Science and Sales Team to map, execute and track technical AI/ML engagements with large clients in Healthcare, covering Payer, Life Sciences, Medical Technologies, and Provider markets\\nWork in a high growth environment, with the goal of significantly augmenting the capabilities of the data science team, and the implementation of valuable technologies for our partners\\nLead a team or teams of US based / offshore based Data Scientists building ML solutions end-to-end\\nHigh visibility role, interacts with execs from major players in healthcare industry\\nJob Responsibilities\\nEstablish project scope and roadmap, including data strategy, needed to develop production-level predictive pipelines that solve large scale problems for clients in the space\\nHelp develop, implement and document rigorous methodology to plan, track and improve accuracy and relevance of models\\nLead internal communication with stakeholders, and ensure delivery of the project per commitment\\nCollaborate with clients and other stakeholders to effectively integrate and communicate findings and use cases\\nProvide guidance and project management support to the Associates on the team\\nExperience building predictive models allows you to clearly determine team size and scope work needed to accomplish business goals\\nKnowledge of databases, data modeling, and data harmonization a must\\nEvaluate emerging technologies and alternative datasets that may contribute value to our existing platforms\\nContribute to the thought leadership of the company by publishing ML research and participating in relevant conferences in the space\\nHealthcare data familiarity, especially around claims and clinical data, is highly desirable\\n CitiusTech's data science approach is based on 3 focus areas:\\nData Science Consulting - Creation of an end-to-end AI / ML roadmap for healthcare organizations, including use cases and end-state visuals\\nModel Development - Data pre-processing, data quality improvement and data mining for the development of custom AI / ML models\\nModel Operationalization - Validation, deployment and monitoring of selected data science models, to generate actionable insights\\nAbout CitiusTech:\\nCitiusTech is a specialist provider of healthcare technology services and solutions to healthcare technology companies, providers, payers and life sciences organizations. With over 3000 professionals worldwide, CitiusTech enables healthcare organizations to drive clinical value chain excellence, across integration &amp; interoperability, data management (EDW, Big Data), performance management (BI / analytics), predictive analytics &amp; data science, and digital engagement (mobile, IoT). CitiusTech helps customers accelerate innovation in healthcare through specialized solutions, healthcare technology platforms, proficiencies and accelerators. Armed with cutting-edge technology &amp; expertise, world-class service quality and a global resource base, CitiusTech consistently delivers best-in-class solutions along with an unmatched cost advantage to healthcare organizations worldwide.\\n\\nCitiusTech has been recognized as a great place to work by the Great Place to Work Institute® for seven consecutive years (2012 to 2018). CitiusTech has also been listed in the 2018 Healthcare Informatics (HCI) 100, placing it among the top 100 healthcare technology companies in the US, for the third consecutive year. CitiusTech has also been closely associated with key industry organizations, such as HIMSS, HL7, CHIME Foundation and AHIP.\\nmgHoXFUBgS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Location: New York\\nWe are currently seeking outstanding machine learning engineers to join our development team. Developers will work on the enhancement and maintenance of our data pipeline including middle-tier and back-end processes. They will gain and utilize experience in designing and implementing solutions for large scale machine learning systems and application server code on cloud offerings.\\nWe build with open source technology, using a newly created stack built from Tensorflow, gRPC, Elasticsearch, Redis, Kubernetes &amp; GCP – we’re open to trying out new things to find the best tool for the job.\\n\\nSkills and Responsibilities\\n\\nResearch, design and prototype new models and approaches based on machine learning, esp. deep learning, and statistical analysis.\\nImplement and execute machine learning research with reliability and reproducibility.\\nFamiliarity with deep learning CV methods for localization, detection, classification or segmentation a plus.\\nDevelop proof-of-concept systems to demonstrate advanced model performance.\\nCollaborate with the rest of the engineering team to design and launch new features.\\nKeep up with deep learning literature and research publications in order to implement the latest techniques into our networks and pipelines.\\nUnderstanding and implementation of security and data protection.\\nExperienced in mainstream deep learning frameworks, such as PyTorch/Torch, TensorFlow, MxNet, Caffe, etc.\\nTurn models into data products, collaborate with engineering teams, and integrate into process throughout behold.ai.\\nExcellent knowledge of the latest developments in the deep learning field\\nKnowledge of code versioning tools such as Git, Mercurial or SVN\\nA PLUS IF\\n\\nYou have a Doctorate Degree or Master’s Degree in Statistics/Mathematics/Computer Science/Physics or similar with equivalent practical experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>PulsePoint™, a global programmatic advertising platform with specialized healthcare expertise, fuses the science of programmatic targeting, distribution, and optimization with the art of brand engagement. The PulsePoint platform is powered by terabytes of impression-level data, allowing brands to efficiently engage the right audiences at scale while helping publishers increase yield through actionable insights.\\n\\nOur organization has a strong history of utilizing machine learning, contextualization, and targeting to distribute advertising to the right consumers at the right time and create real connections across the internet. We are now taking that knowledge and expertise to solve challenges within healthcare in order to create better health outcomes through Radical Health Personalization™.\\n\\nThe goals of the PulsePoint Data Science team:\\n\\nOptimize and validate targeting mechanisms for specific health conditions\\nImprove and optimize our proprietary contextualization, and recommendation engines that handle hundreds of thousands of transactions per second, billions of times each month\\nCollaborate with internal Health experts to ideate and support rapid assessment, analysis, and prototyping of ideas for achievable commercialization.\\n\\nWhat you will be tasked to do:\\n\\nResearch and develop user profiling models to enhance our clinical trial recommendation engine to leverage both online and offline data.\\nCollaborate with Product teams on data-driven products to support clinical trial platform design and delivery.\\nSupport and enhance the existing work on health user profiling, prediction, and targeting tools.\\nContribute on future project on patient/physician identity for cross-device tracking, profiling and targeting.\\nSupport existing codebases for data integration and production support for our core models.\\n\\nWhat you need to be successful in this role:\\n\\n3+ years of full-time experience working as a Statistician/ Machine Learning Engineer/ Data Scientist\\nAdvanced knowledge of Big Data technologies such as Hadoop, Hive, and Impala\\nAdvanced knowledge of Python using the numpy/scipy/pandas/skilearn stack\\nMS/PhD in Astronomy, Physics, Applied Mathematics, Statistics, Machine Learning, Computer Science; or BS with several years of applied machine learning experience\\n\\n** All applicants must submit a code sample or a GitHub link to be considered **\\n\\nAt PulsePoint™, data is at the core of everything we do and Data Science is a high profile and high impact team, focusing on creating innovative solutions that rely on predictive modeling and big data analytics. We are looking for \"A\" players that have a combination of drive, focus, speed, efficiency and quality to drive statistical modeling, optimization and/or machine learning. You will be given ownership and autonomy over the research and development of your projects and will be expected to execute well and on time. We work on challenging problems that will make ads matter for people with health problems. Your work will directly influence our trajectory as a company.\\n\\nWhat we offer:\\n\\nSane work hours\\nGenerous paid vacation/company holidays\\nVacation reimbursement, sabbatical, pawternity leave, marriage leave, honeymoon bonus\\nComprehensive healthcare with 100%-paid medical, vision, life &amp; disability insurance\\n$2,000 annual training and development budget\\nComplimentary annual memberships to One Medical, NY Citi Bike and SF Ford GoBike\\nMonthly chair massages\\nFree fitness classes (spin, yoga, boxing)\\nGym reimbursement, local gym membership discounts\\nOnsite flu shots, dental cleanings and vision exams\\nAnnual company retreat\\nPaid parental leave and a lot of new parent perks\\nEmergency childcare credits\\n401(k) Match and free access to a financial advisor\\nVolunteer Time Off and Donation Matching, ongoing group volunteer opportunities\\nTeam lunches, Sip &amp; Social Thursdays, Game Nights, Movie Nights\\nHealthy snacks and drinks\\n\\nAnd there's a lot more!\\n\\nWant to peek inside the PulsePoint™ offices? Check it out here: https://www.themuse.com/profiles/pulsepoint ( https://www.themuse.com/profiles/pulsepoint )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>CIMD - Marcus by Goldman Sachs - Machine Learning Engineer</td>\n",
       "      <td>New York, NY 10282</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>10282</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nAt least a Bachelor’s degree, preferably in a quantitative/STEM field - Applied Mathematics, Physics, Engineering, Computer Science etc.\\n2+ years of open source Machine Learning algorithm development experience in Python and AWS\\n2+ years of building data pipelines, feature extractions, Flask/Django APIs and scalable model deployments\\n2+ years of experience with pandas, jupyter notebooks and sklearn\\n2+ years of hands on experience with advanced SQL queries and database knowledge of RDMS, Column based, NoSql, etc.\\n2+ years of experiences in working in AWS or other Cloud computing environments</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Build platforms to accelerate deployment of ML/NLP/AI Models\\nBuild ETL pipelines to derive and store features and insights out of raw datasets\\nBuild orchestration using Airflow or other open sources libraries\\nDocument, design, code and test applications and model outcomes\\nWork on model explainability and governance\\nClosely collaborate with product and marketing teams on delivering new product features, perform exploratory data analysis and/or build data pipelines and APIs\\nBuild measure and report KPIs and explain complex concepts in non-technical terms\\n\\n</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>MORE ABOUT THIS JOB\\nConsumer and Investment Management (CIMD)\\nThe Consumer and Investment Management Division includes Goldman Sachs Asset Management (GSAM), Private Wealth Management (PWM) and our Consumer business (Marcus by Goldman Sachs). We provide asset management, wealth management and banking expertise to consumers and institutions around the world. CIMD partners with various teams across the firm to help individuals and institutions navigate changing markets and take control of their financial lives.\\n\\nConsumer\\nConsumer, externally known as Marcus by Goldman Sachs, is comprised of the firm’s digitally-led consumer businesses, which include our deposits and lending businesses, as well as our personal financial management app, Clarity Money. Consumer combines the strength and heritage of a 150-year-old financial institution with the agility and entrepreneurial spirit of a tech start-up. Through the use of machine learning and intuitive design, we provide customers with powerful tools that are grounded in value, transparency and simplicity to help them make smarter decisions about their money.\\n\\nYour Impact\\nClarity Money is a business recently acquired by Goldman Sachs that offers a revolutionary AI- and machine learning-based product for consumers to improve their financial health. Ushering in a new era of mobile personal finance management apps, Clarity Money uses artificial intelligence and data science to help consumers make smarter financial decisions and get the most from their money. The revolutionary features allow users to cancel bills, get a better credit card and create a savings account, all from within the app, and all at the push of a button.\\n\\nThe Clarity Money team is actively seeking a motivated Data Engineer with proven industry experience in machine learning, data engineering and building robust data pipelines. Strong computer science fundamentals are key to success in this role. The ideal candidate should be an individual contributor, a positive team player and willing to get things done.\\nRESPONSIBILITIES AND QUALIFICATIONS\\nResponsibilities:\\nBuild platforms to accelerate deployment of ML/NLP/AI Models\\nBuild ETL pipelines to derive and store features and insights out of raw datasets\\nBuild orchestration using Airflow or other open sources libraries\\nDocument, design, code and test applications and model outcomes\\nWork on model explainability and governance\\nClosely collaborate with product and marketing teams on delivering new product features, perform exploratory data analysis and/or build data pipelines and APIs\\nBuild measure and report KPIs and explain complex concepts in non-technical terms\\n\\nQualifications:\\nAt least a Bachelor’s degree, preferably in a quantitative/STEM field - Applied Mathematics, Physics, Engineering, Computer Science etc.\\n2+ years of open source Machine Learning algorithm development experience in Python and AWS\\n2+ years of building data pipelines, feature extractions, Flask/Django APIs and scalable model deployments\\n2+ years of experience with pandas, jupyter notebooks and sklearn\\n2+ years of hands on experience with advanced SQL queries and database knowledge of RDMS, Column based, NoSql, etc.\\n2+ years of experiences in working in AWS or other Cloud computing environments\\n\\nPreferred Qualifications\\n\\nMasters in Computer Science, Engineering or Information Systems\\n4+ years of experience in software development using Python, RESTful API, Spark, and ML libraries\\n4+ years of experience in cloud environments like AWS stack or GCP Stack\\nABOUT GOLDMAN SACHS\\nThe Goldman Sachs Group, Inc. is a leading global investment banking, securities and investment management firm that provides a wide range of financial services to a substantial and diversified client base that includes corporations, financial institutions, governments and individuals. Founded in 1869, the firm is headquartered in New York and maintains offices in all major financial centers around the world.\\n\\n© The Goldman Sachs Group, Inc., 2019. All rights reserved Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Vet.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Senior Associate, Digital Intelligence – Machine Learning Engineer</td>\n",
       "      <td>New York, NY 10001</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>10001</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>About Chase\\nJPMorgan Chase &amp; Co. (NYSE: JPM) is a leading global financial services firm with assets of $2.6 trillion and operations worldwide. The firm is a leader in investment banking, financial services for consumers and small business, commercial banking, financial transaction processing, and asset management. We serve millions of consumers in the United States and many of the world's most prominent corporate, institutional and government clients under our J.P. Morgan and Chase brands. Information about JPMorgan Chase &amp; Co. is available at www.jpmorganchase.com.\\nChase Consumer &amp; Community Banking serves nearly 66 million consumers and 4 million small businesses with a broad range of financial services, including personal banking, investment advice, small business lending, mortgages, credit cards, payments and auto financing. In recent years, we have undertaken a large-scale digital transformation initiative, building on the success of our current mobile and online service offerings. The Digital team is responsible for building innovative platforms and developing new products that make banking and payment tasks simpler and more personalized for our customers, as well as deepen customer engagement and loyalty with more relevant offers and services. The ambition is to position Chase as the undisputed leader in digital financial services and payments, and to enable highly personalized, real-time experiences that customers increasingly expect. We function similar to a fintech start-up in our brand new offices that inspire collaboration, transparency, agile development, and a fun working environment.\\n\\nDescription:\\nThis role is being offered within JPMorgan Chase Digital Intelligence organization. DI is responsible for creating advanced and intelligent capabilities for our consumer products. We work closely with our Digital Technology engineering team to bring these solutions to market. It is a fast paced and dynamic environment, where we work with many business and product owners in addition to focusing on technical deliveries. Understanding and interacting with the business is a key component to the success of our work where success is defined as bringing value to our customers.\\nThe candidate needs to have significant training and working experience in computer science/software engineering, with large and real-time computational experience. He/she needs to have demonstrated experience in implementing and deployment of large-scale production system certain advanced computational algorithms. Big-Data platform work experience is a must, i.e. worked and maintained HBase, Hadoop, Spark, etc. where the candidate has been a key team player. The candidate needs to have significant software engineering work experience, where he/she has been responsible for bringing a complete system to production end-to-end, working with DevOps and various levels of production engineering teams.\\n\\nQualifications:\\n\\nRequired:\\n\\n3+ years of software engineering/developer and production experience\\n\\n1- 3 years of experience in big-data\\n3+ years of big-Data platform engineering\\n\\n3+ years of parallel computing\\n\\nMinimum Master’s degree in engineering disciplines (candidate’s bachelor degree needs to be engineering focused as well), with the focus in computer science and related extended core training and experience. Candidates with equivalent work experience are also highly desirable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Python Developer (Financial Sector), Columbia University</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nBachelor's Degree\\nMinimum of 5 years of work experience\\nA positive attitude\\nAbility to deliver our lesson plans that are taught in classrooms across the country to the student body\\nOpenness to share your own professional experiences and industry insight with the students\\nAbility to support our students individually as they go through an emotional roller coaster\\nBe able to infuse empathy, support, encouragement, and fun into the student experience\\n</td>\n",
       "      <td>Trilogy Education partners with universities to offer programs in Web Development, Data Analytics, UX/UI Design, Cybersecurity, and FinTech. Our platform combines a market-driven curriculum, robust career services, and a multinational community of universities, instructors, and employers to prepare adult learners for careers in the digital economy.\\n\\nOur programs have been in existence since 2015, and since then, we've launched an additional 300 classes across the nation. We have hired more than 1,900 Instructors and Teaching Assistants to support our students.\\n\\nThe Job:\\nWe are looking for an experienced Financial Engineer, Python or Machine Learning Engineer with Finance experience, or similar background to teach our part time FinTech class at Columbia University. Our instructors are an essential piece to our students experience with us. You must bring a positive attitude and be able to infuse empathy, support, encouragement and fun into the classroom. As an instructor you will need to have the ability to deliver our lesson plans that are being taught across the country; while at the same time, sharing your own professional experiences and industry insight with the students.\\n\\nOur Financial Technology Program:\\nThere is a parallel economy forming that is upending the financial system. From giant international firms to tiny startups, financial technology is starting to allow a whole new set of players to access financial data, and enabling a whole new generation of financial products and services.\\n\\nWhy teach with us?\\n\\nAre you passionate about education and making an impact? Do you love empowering others to find life-changing opportunities. We'd love to hear from you! If you bring knowledge, strong communication, and a positive energy to the classroom, you're going to help our students along their transformative path to a successful and rewarding career. Prior teaching experience isn't a prerequisite for success as an Instructor or Teaching Assistant within Trilogy.\\n\\nWe'll provide the guidance, training, lesson plans, and tools to support you on your journey of impacting lives in the classroom.\\n\\nWhat You Will Do:\\n\\nLead lectures and share your own personal experiences as an industry professional\\nFacilitate a hands on lab environment for students to gain real world knowledge\\nCoach students through coding activities and in-class projects\\nDistribute Class Materials and Recorded Lectures to set up students for success\\nEnsure a positive learning environment for students by infusing empathy and support into all that you do\\nBe a classroom manager and confirm students are engaged and learning at every turn\\nMake sure students are receiving timely feedback and grades on their assignments from you and your teaching assistants.\\n\\nExperience, or willingness to learn, the following Technologies is required:\\n\\n\\nFinance Fundamentals like Time Series Analysis and Financial Ratios\\nInvestment Principles\\nExcel and VBA\\nPython 3\\nPython Libraries such as Pandas, Matplotlib, NumPy, and more\\nAPIs\\nSQL and NoSQL Databases\\nAWS\\nMachine Learning Applied to Finance with Algorithmic Trading, Scikit-learn, and more\\nCryptocurrency Fundamentals\\nBlockchain technologies like Solidity, Ethereum, and Smart Contracts\\n\\nWhat makes you a great fit (Requirements):\\n\\nBachelor's Degree\\nMinimum of 5 years of work experience\\nA positive attitude\\nAbility to deliver our lesson plans that are taught in classrooms across the country to the student body\\nOpenness to share your own professional experiences and industry insight with the students\\nAbility to support our students individually as they go through an emotional roller coaster\\nBe able to infuse empathy, support, encouragement, and fun into the student experience\\n\\nLogistics:\\n\\n24-week program\\nMon/Wed/Sat OR Tue/Thu/Sat Schedule\\nWeekday Classes: 5:45pm - 10pm (includes office hours and break)\\nSaturday Classes: 9:30am - 2:30pm (includes office hours and lunch break)\\nzr\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Senior Machine Learning Engineer- Data Automation</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>On the Data Automation team, we develop machine learning models and infrastructure to extract key information from all kinds of financial documents such as analyst recommendations, corporate/municipal bond offerings, earnings releases. Our team has built some of the world's most sophisticated neural networks that have beaten the performance of even the best analysts in the market – often demanding 99.9% precision. The models we build enable our clients to get accurate answers fast. The work we do is critical, as a single prediction error can have a market moving effect.\\nAs part of our team, you will lead the research on cutting-edge ML/NLP techniques and design efforts for the most efficient and practical application of those techniques to complex business problems. You will utilize our automated ML suite, equipped with annotation platforms, for collecting training data and hyper-tuning models, as well as deploy your application on our scalable ETL infrastructure. If the idea of applying technology and information retrieval techniques to solve complex data problems excites you, keep reading.\\nIn the upcoming year, you should expect to work on the following:\\n Replace our traditional Seq2Seq and BiLSTM annotation models with modern BERT/ELMO language models\\n Employ weakly supervised learning approaches for understanding structural associations embedded in various document layouts\\n Apply advanced NLP techniques for multi-entity disambiguation and reinforcement learning to replace heuristic-based decision tree\\nYou will also collaborate closely with financial domain experts to gain valuable insights and leverage their business expertise to increase accuracy in annotating training data. A right combination of cross-field ML techniques, deep understanding of the business problem and high quality training data is fundamental to our models beating the precision of most academic and industry standards and presents a challenging opportunity! If this sounds like a challenge you are up for, please apply below.\\nWe'll trust you to:\\n Learn cutting-edge research in advanced ML &amp; NLP topics and devise an efficient application for projects\\n Direct ML strategy for the team and work closely with the ML platform team, ETL infrastructure team as well as guide truth-gathering efforts\\n Drive, design &amp; develop projects as the principal point-of-contact, with the ability to determine suitable ML models, direct feature engineering processes and negotiate KPIs per business needs\\n Participate in technical conferences, publish papers and evaluate new technologies\\nYou’ll need to have:\\n A strong statistical background in ML, NLP, deep learning models along with familiarity in probabilistic information retrieval and optimization methods\\n Professional experience of building and deploying ML apps to production\\n 2+ years of hands-on experience in Python/C/C++ development and knowledge of distributed, scalable architectures and CICD tooling\\n A solid understanding of data structures, algorithms and software design concepts\\n Strong communication skills and interest in learning financial product domains\\n BA, BS, MS, PhD in Computer Science, Data Science or related technology field\\nWe’d love to see:\\n Knowledge of advanced concepts such as weakly supervised learning, reinforcement learning and active learning\\n Familiarity with SQL and NoSQL data modeling and exploratory data visualization\\n Professional experience as a technology lead or architect\\n Authored research publications, participation in ML competitions, working demos/repos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Machine Learning Engineer, Knowledge Platform</td>\n",
       "      <td>New York, NY 10032</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>10032</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Job Description\\n\\nThe knowledge platform team is seeking senior machine learning engineers to join our engineering team. Square is seeking senior machine learning engineers to build a company-wide state-of-the-art knowledge platform. Our goal is to provide tooling, infrastructure, and guidance to unify and level up the 50-100 engineers and data scientists working on ML at Square and work on advanced ML solutions that are applicable across the company. The ideal candidate will have industry experience in solving and optimizing large-scale machine learning problems. We are looking for passionate and self-driven innovators to help us build this V1 platform from the ground up and be part of a fast-paced team. You will be expected to contribute in building ML systems/tooling and building advanced ML models that scale. You will have a wide impact across the company with opportunity to publish papers, contribute to open-source, influence and collaborate with the data science community across Square.\\n\\nQualifications\\n\\nYou have:\\nExperience in many of the following areas is highly desired - AutoML, Knowledge Graphs, recommendation systems, NLP and AI Agents.\\nExperience with cloud computing platforms, such as AWS, Google Cloud or Azure.\\nExperience in designing and productionizing large-scale distributed systems built around machine learned models and big data.\\nExperience or familiarity with interpretable machine learning is a plus.\\nAbility to produce scalable and robust production-quality code incorporating testing, evaluation, and monitoring.\\nAn advanced degree (PhD or MS) in Computer Science\\nTechnologies we use:\\nJava, Python, Google Cloud Platform, AWS, Snowflake\\nPython ML stack (pandas, scikit-learn, etc.)\\nAdditional Information\\n\\nAt Square, our purpose is to empower – within and outside of our walls. In order to build the best tools for the businesses and customers we support all over the world, we have to start at home with a workforce as diverse and empowered as our sellers. To this end, we take great care to evaluate all employees and job applicants equally, based on merit, competence, and qualifications. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any other characteristic protected by law. We encourage candidates from all backgrounds to apply and always consider qualified applicants with arrest and conviction records, in accordance with the San Francisco Fair Chance Ordinance. Applicants in need of special assistance or accommodation during the interview process or in accessing our website may contact us by sending an email to assistance(at)squareup.com. We will treat your request as confidentially as possible. In your email, please include your name and preferred method of contact, and we will respond as soon as possible. Perks At Square, we want you to be well and thrive. Our global benefits package includes: Healthcare coverage, Retirement Plans, Employee Stock Purchase Program, Meal reimbursements, Wellness perks, Paid parental leave, Flexible time off, Learning and Development resources</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>GS Data Scientist</td>\n",
       "      <td>New York, NY 10282</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>10282</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nBachelor’s Degree in a field like computer science, statistics, economics or applied math.\\nStrong knowledge of statistical analysis and exploratory data analysis techniques for prescriptive analytics.\\nProfessional experience in an advance analytics-based data science/ machine learning engineer or stats role.\\nProfessional experience working in cloud environment like AWS.\\nStrong knowledge of machine learning concepts like regression, classification, clustering, heuristics, boosting, feature engineering, etc.\\nStrong Proficiency in SQL, notebooks and Python.\\nUnderstanding of open source libraries for solving orchestration, model deployment, model explainability and management.\\nBasic understanding of new deep learning techniques like GANs, RNNs, CNNs and platforms like keras/tensorflow used to implement these.</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Build machine learning and NLP models to build new product features and improve business metrics.\\nPerform exploratory data analysis and causation/attribution/correlation identifying key insights to help decisions and business strategy.\\nDocument model explainability and decay and deploy models with proper governance.\\nWork with product managers, engineers, marketers and designers, and senior executives to optimize key translate business insights into decisions and action\\nBuild and improve our machine learning deployment and data pipeline platforms.</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>MORE ABOUT THIS JOB\\nWhat We Do\\nAt Goldman Sachs, our Engineers don’t just make things – we make things possible. Change the world by connecting people and capital with ideas. Solve the most challenging and pressing engineering problems for our clients. Join our engineering teams that build massively scalable software and systems, architect low latency infrastructure solutions, proactively guard against cyber threats, and leverage machine learning alongside financial engineering to continuously turn data into action. Create new businesses, transform finance, and explore a world of opportunity at the speed of markets.\\n\\nEngineering, which is comprised of our Technology Division and global strategists groups, is at the critical center of our business, and our dynamic environment requires innovative strategic thinking and immediate, real solutions. Want to push the limit of digital possibilities? Start here.\\n\\nWho We Look For\\nMotivated Data Engineer with proven industry experience in machine learning, data engineering and building robust data pipelines. Strong computer science fundamentals are key to success in this role. The ideal candidate should be an individual contributor, a positive team player and willing to get things done.\\nRESPONSIBILITIES AND QUALIFICATIONS\\nResponsibilities:\\nBuild machine learning and NLP models to build new product features and improve business metrics.\\nPerform exploratory data analysis and causation/attribution/correlation identifying key insights to help decisions and business strategy.\\nDocument model explainability and decay and deploy models with proper governance.\\nWork with product managers, engineers, marketers and designers, and senior executives to optimize key translate business insights into decisions and action\\nBuild and improve our machine learning deployment and data pipeline platforms.\\n\\nQualifications\\nBachelor’s Degree in a field like computer science, statistics, economics or applied math.\\nStrong knowledge of statistical analysis and exploratory data analysis techniques for prescriptive analytics.\\nProfessional experience in an advance analytics-based data science/ machine learning engineer or stats role.\\nProfessional experience working in cloud environment like AWS.\\nStrong knowledge of machine learning concepts like regression, classification, clustering, heuristics, boosting, feature engineering, etc.\\nStrong Proficiency in SQL, notebooks and Python.\\nUnderstanding of open source libraries for solving orchestration, model deployment, model explainability and management.\\nBasic understanding of new deep learning techniques like GANs, RNNs, CNNs and platforms like keras/tensorflow used to implement these.\\n\\nWhy Goldman Sachs\\nUnparalleled responsibility and career opportunity to make a highly visible global impact\\nYou will be part of a large community of like-minded technologists in a flat organization with a culture that promotes collaboration, “can do” mindsets and teamwork\\nResponsibility for requirements gathering, analysis, design and development of funding systems\\nForge strong relationships with our clients across all of our businesses, as well as other technology teams to develop and enhance our systems and processes\\nDevelop solutions that directly impact the bottom line by enabling new investment opportunities for our business partners\\nOpportunity to work on unprecedented projects both at Goldman Sachs &amp; more broadly in the financial services industry\\nABOUT GOLDMAN SACHS\\nThe Goldman Sachs Group, Inc. is a leading global investment banking, securities and investment management firm that provides a wide range of financial services to a substantial and diversified client base that includes corporations, financial institutions, governments and individuals. Founded in 1869, the firm is headquartered in New York and maintains offices in all major financial centers around the world.\\n\\n© The Goldman Sachs Group, Inc., 2019. All rights reserved Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Vet.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Data Science Engineer</td>\n",
       "      <td>New York, NY 10016</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>10016</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Join our team @ Eskalera! A super{set} venture studio company\\nDATA SCIENCE ENGINEER\\nLOCATION: San Francisco or New York City\\nAt Eskalera, our ultimate vision is an environment where every worker, regardless of background, pedigree, race, geography etc, gets a fair shot, and where AI and data-driven methods measurably improve results for progressive businesses that recognize people and talent as their most critical asset. The key to our and our clients’ success is rooted in constructing inclusive cultures.\\nAbout the Role\\nSo, you can query large amounts of data using your favorite big-data toolkits, analyze it using established statistical and machine learning techniques, and communicate the derived insights through clear and concise charts and reports. You are a technologist at heart always seeking to push the current boundaries to process more data and run more sophisticated machine learning algorithms. In your past, you may have doubled as a data scientist, a data engineer, or perhaps a machine learning engineer, but deep inside, all you really care about is building best in class products, applications, and systems that extract knowledge from data at any scale and deliver value to the business.\\nGreat, we are excited to talk to you! We're looking for people who get things done by using their smarts and whatever tools get the job done. Are you at the beginning of your career and this is where you see yourself in the future? Let us know; we love to work with bright people looking to grow.\\nYour Role:\\nR&amp;D of cutting edge algorithmic solutions to real-world problems producing a shippable product as well as intellectual property (papers and patents).\\nUsing statistical and machine learning principles to discover hidden patterns, perform predictive analysis and build models that drive insights.\\nClean, transform and validate data for uniformity and accuracy.\\nDevise and utilize algorithms and statistical approaches to mine data stores, perform data analysis and improve model performance.\\nCommunicate findings internally and externally, generating reports and dashboards, building narratives that resonate with clients and stakeholders.\\nScale efforts to democratize data internally and externally, be an ambassador for data-driven culture.\\nBecome and stay an expert in current and emerging technologies, techniques, and tools.\\nYour Skills and Qualities:*\\n3+ years of professional data science related work\\nUnderstanding of key machine learning and data mining approaches.\\nA bayesian at heart but can report significance if asked.\\nUnderstand the fundamentals of computer science including programming principles, design patterns, database fundamentals, and distributed systems.\\nMake things work and get things done using the programming language of your choice (Python/Scala among others).\\nAre a great communicator, able to articulate complex concepts in easy to understand language.\\nLove to learn new things and can do so quickly.\\nLike working in, and being part of, interdisciplinary teams.\\nAbout Eskalera\\nEskalera enables large and medium-sized companies to transform their HR operations by improving employee engagement, productivity, and growth. Our end-to-end platform arms HR professionals with the most modern applications of AI, data science, and evidence-based findings on implicit bias and D&amp;I. By capturing, processing, and analyzing data from easy-to-use experiences and integrating other available employee data, companies gain a real-time view of the zeitgeist of their employee base to drive measurable business results.\\nEskalera is proud to be an equal opportunity workplace. Individuals seeking employment at Eskalera are considered without regard to race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, veteran status, or sexual orientation.\\nWe do not accept resumes from headhunters, placement agencies, or other suppliers that have not signed a formal agreement with us.\\nThis is Eskalera: https://eskalera.com/about-us/\\nHow we are different?: https://eskalera.com/solutions/\\nJob Type: Full-time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Lead Machine Learning Engineer</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Beeswax is looking for a Lead Machine Learning Engineer to join our growing team. We were recently recognized on the Inc. 5000 list as #46 in the fastest growing companies and #5 in the top software companies. In 2018, we were also named by Business Insider as the \"fastest growing company in AdTech\"\\n\\nBeeswax is an easy to use, massive scale and highly available advertising platform founded by industry veterans who worked together at Google. We're well funded by leading VCs, such as RRE and Foundry Group, and are rapidly expanding our customer list and our engineering team. We offer our customers the most extensible and transparent advertising platform in the world and process millions of transactions per second.\\n\\nOur engineers come from major tech companies such as Amazon and Facebook as well as many other companies with strong software disciplines. We take pride in our mission to build great advertising software.\\n\\nThe Optimization team at Beeswax is simplifying Real Time Bidding for our customers and making it easy for them to train and deploy machine learning models on our platform. To do that, we want to build systems that provide customers easy access to their data, algorithms to train their models and APIs to easily deploy and evaluate the performance of their models. We'll know we're successful when we see our customers actively using our ML workflow and bidding with much higher success and effectiveness rates when using these tools.\\n\\nWe are looking for a Lead Machine Learning Engineer for our Optimization team. The ideal candidate will have experience working on a range of optimization problems in a production environment, such as click-through rate prediction, click-fraud detection, payment fraud, search ranking, text/sentiment classification, viewability prediction, or spam detection.\\n\\nYour primary role will be to lead and grow a machine learning team to support both internal feature development and the creation of a framework our customers can use.\\n\\nResponsibilities\\n\\n\\nWork with customers and the product team to design optimization systems for both off-the-shelf use and customization through APIs\\nBuild and iterate on a workflow that enables our customers to take advantage of our data and ML infrastructure\\nDevelop highly scalable machine learning systems to automatically score and optimize real-time bidding advertising campaigns\\n\\nIdeal candidates will have:\\n\\nA minimum of 5 years experience building ML infrastructure and production models in a product driven driven environment\\nProficiency with statistics and statistical methods\\nExperience with scripting languages such as Python and libraries like Numpy/Pandas.\\nExperience using machine learning libraries or platforms including Tensorflow, Caffe, Scikit-Learn, ML lib in production.\\nExperience with data warehouses such as Snowflake, Redshift or Presto and data processing platforms such as Spark\\nExperience with stream processing such as Kinesis or Kafka is a plus.\\nAdTech experience is a plus\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Data Scientist / Machine Learning Engineer</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Company\\n\\nWell-funded stealth company focused on disrupting healthcare through a differentiated consumer experience and a world-class data &amp; analytics engine to drive engagement and behavior change. The product will sell directly to Fortune 500 CEOs and full risk populations, integrating layers of analytics, digital, concierge services, behavioral health, telemedicine, care management and wellness services to drive sustained engagement, lower costs and improve health.\\n\\nReporting To\\n\\nHead of Data Science and AI with dotted line to Chief Analytics and Marketing Officer\\n\\nPosition Summary\\n\\n\\nThe overall goal is to engage consumers in differentiated ways that will drive better health outcomes. As one of the early hires of the Analytics organization, the primary mission will be to launch the modeling and optimization platform (the \"Health Engine\") to deliver member recommendations that improve health, cost of delivery, and engagement.\\nYou will leverage a wide range of disparate data sources across healthcare (member, payor, employer, provider, partner). Ideal candidates will have a detailed understanding of healthcare data with experience analyzing large longitudinal health datasets.\\nYou will assist in the creation of operational predictive models using current and emerging methodologies in data science. Ideal candidates will possess a deep understanding of statistics, machine learning, causal predictive modeling, and most importantly, a willingness to grow deeper in these areas.\\nYou will collaborate across the organization to drive projects from beginning to end: frame business questions, collect and analyze data, research, prototype, build pipelines, and share insights. You will work with engineering to ensure robust translation to production environments and create solutions that operate effectively at scale.\\n\\nMinimum Qualifications\\n\\n\\n2+ years' industry experience in data science or machine learning focused roles.\\nAdvanced degree (MS or PhD) in a quantitative field such as Statistics, Computer Science, Mathematics, Physics, Engineering, Economics, or similar.\\nDemonstrated experience using Python for data analysis and machine learning (numpy, pandas, scikit-learn, xgboost, spacy, pytorch, stan/pymc3, etc.). Proficiency with SQL and databases. Experience using Unix/OSX from the command line, version control (git), and general software development best practices for contributing to a collaborative code base. Experience configuring and executing analyses in the cloud (GCP, AWS).\\nStrong communication and collaboration skills required. Ability to communicate technical modeling concepts and relevant aspects of modeling platforms to non-technical audiences.\\nWillingness to learn and improve across all technical skill areas and in knowledge of the healthcare domain. Ability to work in a start-up environment that is fast paced and maintain a focus on rapid prototyping of capabilities.\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Senior Machine Learning Engineer</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nMS degree in Computer Science or a related quantitative field\\n5+ years of experience in one or more of the following areas: machine learning (NLP), recommendation systems\\nExperience with machine learning frameworks such as TensorFlow or Keras\\nExperience working in an Agile environment and within a distributed team</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nWork closely with our Data team to extend and improve our Food Genome by applying NLP based methods to this complex domain.\\nBuild models to generate food recommendations and personalized offering based on user behavior\\nDesign, develop, test, deploy, maintain and improve ML models/infrastructure and software that uses these models.\\nManage individual project priorities, deadlines and deliverables.</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>This role is part of the Whisk team within the Samsung NEXT Product organization.\\nWhisk has built a multi-sided marketplace over the past 7 years that delivers value to each member of the network such as Publishers, Retailers, IOT &amp; Health, and Brands. Whisk also has a consumer experience, my.whisk.com for shopping lists, saved recipes, and other potential experiences. Whisk joined Samsung NEXT in March and there are plans to invest more heavily in the platform, to scale the business and grow each aspect of the network (publisher, retailer, IoT, Health, Brands, &amp; B2C). Each investment should not only add value to its own experience but also to the network of partners overall.\\nAbout NEXT Product\\nThe NEXT Product organization is a hyper-growth startup within Samsung NEXT. We’re a globally distributed product development team in search of builders and creators to help conceive, grow and scale new products and categories.\\nSuccessful candidates, at all levels within the organization, will: approach all things team-first, take ownership and “be the change you seek”, have strong written and verbal communication skills, have high EQ, enjoy fast-paced, outcome-driven environments and be inspired to learn and explore daily both inside and outside of your field of expertise.\\nThe Role\\nAs a Senior Machine Learning Engineer, you will build ML-based systems, tools, and services to improve Whisk’s Food Genome (https://whisk.com/cognitive-food-platform/) and to produce highly relevant and personalized recommendations. We are looking for a candidate that has industry experience with a range of Machine Learning disciplines (NLP) and has worked with large data sets, specifically understanding and representing semantics. Experience with the food industry is a plus. This position is located in our New York office.\\nResponsibilities\\nWork closely with our Data team to extend and improve our Food Genome by applying NLP based methods to this complex domain.\\nBuild models to generate food recommendations and personalized offering based on user behavior\\nDesign, develop, test, deploy, maintain and improve ML models/infrastructure and software that uses these models.\\nManage individual project priorities, deadlines and deliverables.\\nRequired Qualifications\\nMS degree in Computer Science or a related quantitative field\\n5+ years of experience in one or more of the following areas: machine learning (NLP), recommendation systems\\nExperience with machine learning frameworks such as TensorFlow or Keras\\nExperience working in an Agile environment and within a distributed team\\nBonus Points\\nPh.D. degree in Computer Science or a related quantitative field\\nResearch experience in Natural Language Processing or Deep Learning.\\nAbout Samsung NEXT\\nWe partner with and build software alongside innovators to develop ideas into products, grow products into businesses and scale businesses globally.\\nFounded in 2012, Samsung NEXT has four key functions in the global software ecosystem:\\nProduct - Building new software and services businesses, at scale.\\nVenture - Investing in early-stage startups to help entrepreneurs build and scale their businesses.\\nPartnerships - Helping startups successfully partner with the variety of businesses within Samsung.\\nM&amp;A - Acquiring startups to connect and scale with our businesses.\\nSamsung is an EEO (Equal Employment Opportunity)/Veterans/Disabled/LGBTQ employer. We welcome and encourage diversity as we strive to create an inclusive workplace.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>DS/ML stack:\\nLanguages: Python, PySpark, SQL\\nData Tools: Spark, AWS RedShift, AWS Athena, pandas, numpy, scipy, parquet\\nModeling Tools: SparkML, scikit-learn, Tensorflow, Tensorflow-Serving, Keras (Tensorflow and Theano backend)\\nAlgorithms: Classifications, Regressions, Neural Networks, Time series, Graphs\\nVisualization: Tableau or similar\\nInfrastructure: AWS (including S3, EMR, EC2, Lambda)\\n\\n\\nWhat will you do?\\nUnderstand business decisions that need to be supported by data e.g. risk of readmission to hospital\\nIdentify relevant internal or external data sources for various business needs\\nResearch the state of a problem and existing solutions then quickly summarize research\\nHelp identify new business opportunities and value propositions from existing data\\nUtilize raw or aggregated data to build predictive models in SPARK, sql, or Python\\nUnderstand quality of models and impact on business problems\\nCommunicate summaries of analyses and predictive modeling efforts to product and business teams\\nCommunicate insights to stakeholders in data engineering, product and clinical teams.\\nBecome expert on projects to help strategize plans of attack in terms of technology and team education.\\nEnsure that all security procedures within their area of responsibility are carried out to achieve compliance with security policies and standards.\\nLeading multiple initiatives across both existing and innovative work\\nProvide continuous mentoring to junior resources\\nWe are looking for someone with:\\n7+ year’s professional experience as a data scientist or machine learning engineer\\n7+ year’s professional experience working in quantitative computational role\\n5+ year’s professional experience working with big data and relational databases\\nVery strong knowledge of advanced applied data science (machine learning, neural networks, etc.), mathematical modeling, computational, statistical, data mining techniques (regression, decision trees, clustering etc.), as well as dimensionality reduction techniques\\nStrong hands-on modeling experience in a business environment with a goal of productionalizing models.\\nStrong experience using machine learning and deep learning packages\\nStrong experience with data manipulation, analysis and visualization\\nProven track record of fully understanding the scope, commitment to quality, and end-to-end ownership to meet upon agreed timelines.\\nQuick learner that can manage multiple projects at the same time successfully\\nDeveloped and designed real-time prediction software\\nStrong experience mentoring junior colleagues\\nExcellent written and verbal communication skills\\nAdvanced degree in physics, applied mathematics, statistics or related field is preferred\\nHealthcare industry experience is a plus\\n\\nAbout Us\\n\\nRemedy Partners delivers software and services that enable payers, employers and at-risk providers to organize and finance healthcare delivery around a patient's episode of care. For healthcare providers, Remedy Partners’ software, analytics and administrative services support bundled payment contracts with Medicare and Commercial Insurers, often through shared-risk partnerships. For payers, Remedy Partners empowers the development of bundled payment contracting programs and guides development of bundled payment networks. Remedy Partners presently delivers its services to partners at more than 1,000 healthcare locations nationwide.\\n\\nPlease note that all Remedy employees are required to adhere to all organizational policies, the Code of Conduct and participate in all compliance-related training and education.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Machine Learning Engineer, Decision Analytics Services (Manager)</td>\n",
       "      <td>Jersey City, NJ</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>NJ</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Proficiency in PySpark, Pandas.\\nProficiency in leveraging CI/CD tools to automate deployment and testing. Experience in Agile methodologies and fast paced DevOps environments\\nProficiency in scripting and GIT workflows\\nGood Knowledge of Hadoop, MapReduce, HDFS\\nGood Knowledge of Big Data querying tools, such as Hive\\nExperience with Big Data ML toolkits – SparkML (alternatively, Scikit Learn in Python)\\nGood Knowledge of Statistical Techniques – Descriptive Statistics, Hypothesis Testing, Tests of Significance, Correlation, Predictive Modeling\\nGood knowledge of SQL, Tableau and MS Excel\\nGood domain knowledge of US Healthcare space</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Capture a 360 degree view of member experience by consolidating disparate data sets\\nPerform descriptive analysis on various aspects of member journey – points of care , claims adjudication, operational processes, appeals mechanism\\nIdentify areas of improvement or friction that might be disrupting member satisfaction\\nMember Profiling – Segment population using advanced clustering techniques for customized targeting and intervention\\nDeploy predictive modeling to design an intervention framework which can navigate the member through his/ her journey with minimum disruption and proactive care</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Overview\\nMachine Learning Engineer, Decision Analytics Services (Manager)\\n\\nEXL (NASDAQ:EXLS) is a leading operations management and analytics company that helps businesses enhance growth and profitability in the face of relentless competition and continuous disruption. Using our proprietary, award-winning Business EXLerator Framework™, which integrates analytics, automation, benchmarking, BPO, consulting, industry best practices and technology platforms, we look deeper to help companies improve global operations, enhance data-driven insights, increase customer satisfaction, and manage risk and compliance. EXL serves the insurance, healthcare, banking and financial services, utilities, travel, transportation and logistics industries. Headquartered in New York, New York, EXL has more than 24,000 professionals in locations throughout the United States, Europe, Asia (primarily India and Philippines), Latin America, Australia and South Africa.\\n\\nEXL Analytics provides data-driven, action-oriented solutions to business problems through statistical data mining, cutting edge analytics techniques and a consultative approach. Leveraging proprietary methodology and best-of-breed technology, EXL Analytics takes an industry-specific approach to transform our clients’ decision making and embed analytics more deeply into their business processes. Our global footprint of nearly 2,000 data scientists and analysts assist client organizations with complex risk minimization methods, advanced marketing, pricing and CRM strategies, internal cost analysis, and cost and resource optimization within the organization. EXL Analytics serves the insurance, healthcare, banking, capital markets, utilities, retail and e-commerce, travel, transportation and logistics industries.\\n\\nPlease visit www.exlservice.com for more information about EXL Analytics.\\n\\nDomain: Healthcare Payer\\n\\nFunctional Area:\\nLeverage huge sets of healthcare payer data to analyze member experience across several dimensions\\nMake recommendations for streamlining underlying processes to enhance member journey, proactive intervention and prompt care delivery\\nResponsibilities\\nCapture a 360 degree view of member experience by consolidating disparate data sets\\nPerform descriptive analysis on various aspects of member journey – points of care , claims adjudication, operational processes, appeals mechanism\\nIdentify areas of improvement or friction that might be disrupting member satisfaction\\nMember Profiling – Segment population using advanced clustering techniques for customized targeting and intervention\\nDeploy predictive modeling to design an intervention framework which can navigate the member through his/ her journey with minimum disruption and proactive care\\nQualifications\\nProficiency in PySpark, Pandas.\\nProficiency in leveraging CI/CD tools to automate deployment and testing. Experience in Agile methodologies and fast paced DevOps environments\\nProficiency in scripting and GIT workflows\\nGood Knowledge of Hadoop, MapReduce, HDFS\\nGood Knowledge of Big Data querying tools, such as Hive\\nExperience with Big Data ML toolkits – SparkML (alternatively, Scikit Learn in Python)\\nGood Knowledge of Statistical Techniques – Descriptive Statistics, Hypothesis Testing, Tests of Significance, Correlation, Predictive Modeling\\nGood knowledge of SQL, Tableau and MS Excel\\nGood domain knowledge of US Healthcare space\\nWhat we offer:\\nEXL Analytics offers an exciting, fast paced and innovative environment, which brings together a group of sharp and entrepreneurial professionals who are eager to influence business decisions. From your very first day, you get an opportunity to work closely with highly experienced, world class analytics consultants.\\nYou can expect to learn many aspects of businesses that our clients engage in. You will also learn effective teamwork and time-management skills - key aspects for personal and professional growth\\nAnalytics requires different skill sets at different levels within the organization. At EXL Analytics, we invest heavily in training you in all aspects of analytics as well as in leading analytical tools and techniques.\\nWe provide guidance/ coaching to every employee through our mentoring program wherein every junior level employee is assigned a senior level professional as advisorsy\\nSky is the limit for our team members. The unique experiences gathered at EXL Analytics sets the stage for further growth and development in our company and beyond.\\n \"EOE/Minorities/Females/Vets/Disabilities\"\\nEEO Statement\\nEEO/Minorities/Females/Vets/Disabilities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Senior, Data Engineer</td>\n",
       "      <td>New York, NY 10011</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>10011</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>11 West 19th Street (22008), United States of America, New York, New York\\n\\nAt Capital One, we’re building a leading information-based technology company. Still founder-led by Chairman and Chief Executive Officer Richard Fairbank, Capital One is on a mission to help our customers succeed by bringing ingenuity, simplicity, and humanity to banking. We measure our efforts by the success our customers enjoy and the advocacy they exhibit. We are succeeding because they are succeeding.\\n\\nGuided by our shared values, we thrive in an environment where collaboration and openness are valued. We believe that innovation is powered by perspective and that teamwork and respect for each other lead to superior results. We elevate each other and obsess about doing the right thing. Our associates serve with humility and a deep respect for their responsibility in helping our customers achieve their goals and realize their dreams. Together, we are on a quest to change banking for good.\\n\\nSenior, Data Engineer\\n\\nAre you a high performing data scientist passionate about cutting edge Machine Learning research or applying the latest advances to production projects? Do you enjoy reading and investigating advancements in applied machine learning architectures and solution white papers? Would you like to participate in the creation of publishable advancements in machine learning? Or does the idea of building enterprise-class ML applications that solve real customer problems excite you? At Capital One’s Center for Machine Learning (C4ML), you'll be part of an elite team setting the example for machine learning research and applied machine learning.\\n\\nAs a Machine Learning Engineer in C4ML, you will build fast data and machine learning solutions to address unique and complex problems in in the financial services industry. Capital One leverages full stack technology solutions including streaming big data, state of the art machine learning, micro-service architecture, distributed computation engines, and intuitive visualizations in the cloud. We work with several cutting-edge technologies and actively develop and contribute to the open source community. You will work alongside highly technical peers, with deep domain expertise (from cyber threat prevention to sophisticated NLP), and partner with product and business teams to deliver game changing solutions for our customers.\\n\\nWho you are:\\nYou have explored the intricacies of a data set to extract insights or have built models that predict or identify patterns used to answer burning business questions\\nYou have contributed to full stack systems built for speed and distributed computing and feel proud to ship code to delighted end users.\\nYou yearn to be part of cutting edge, high profile projects and are motivated by delivering world-class solutions on an aggressive schedule\\nYou love to learn new technologies, keep abreast of the latest technologies within cloud architecture, and drive your organization to adapt to emerging best practices\\nYou are the go-to person to answer deep technical questions about which ML algorithm may improve results or what visualization is best to explore relationships in the data\\nIt would be awesome if you have a robust portfolio on Github or open source contributions you are proud to share\\n\\nBasic Qualifications:\\nBachelor’s Degree or Military Experience\\nAt least 2 years of experience working with Machine Learning, Deep Learning or Artificial Intelligence\\nAt least 2 years of experience programming in Python, Scala or Java\\nAt least 2 years of experience designing and building full stack solutions utilizing distributed computing or multi-node database paradigms\\n\\nPreferred Qualifications:\\nMaster’s Degree or PhD\\nAt least 2 years of experience with cloud software design using microservices or distributed caching\\nA history of publications and conference attendance.\\n\\nAt this time, Capital One will not sponsor a new applicant for employment authorization for this position.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>This role is part of the Core team within the Samsung NEXT Product organization. The Core team is building today a set of large scale products that are directly linked with Samsung world wide and have the potential of capitalizing on Samsung’s massive consumer reach across mobile phones and smart TVs.\\nAbout NEXT Product\\nThe NEXT Product organization is a hyper-growth startup within Samsung NEXT. We’re a globally distributed product development team in search of builders and creators to help conceive, grow and scale new products and categories.\\nSuccessful candidates, at all levels within the organization, will: approach all things team-first, take ownership and “be the change you seek”, have strong written and verbal communication skills, have high EQ, enjoy fast-paced, outcome-driven environments and be inspired to learn and explore daily both inside and outside of your field of expertise.\\n\\nThe Role\\nAs a Machine Learning Engineer, you will build Machine Learning systems fusing and analysing multi-sensory signals to solve real-world challenges in real-time. We are looking for a candidate that has industry experience with Computer Vision (Machine Learning) and has worked with large data sets and in real-time. This position is located in our New York office.\\n\\nRESPONSIBILITIES\\nWork closely with our Engineering and Data teams in NYC, San Francisco and Korea to build real-time solutions for Smart Spaces by applying Computer Vision methods to this complex domain.\\nBuild models for Human Activity Detection and Recognition, Object Detection and tracking and Scene Segmentation in real-time\\nDesign, develop, test, deploy, maintain and improve ML models/infrastructure and software that uses these models.\\nManage individual project priorities, deadlines and deliverables.\\nMINIMUM QUALIFICATIONS\\nMS degree in Computer Science or related quantitative field\\n5+ years of experience in one or more of the following areas: machine learning (CV)\\nExperience with machine learning frameworks\\nExperience working in an Agile environment and within a distributed team\\nPREFERRED QUALIFICATIONS\\nPh.D. degree in Computer Science or related quantitative field\\nResearch experience in Deep Learning.\\nAbout Samsung NEXT\\nWe partner with and build software alongside innovators to develop ideas into products, grow products into businesses and scale businesses globally.\\nFounded in 2012, Samsung NEXT has four key functions in the global software ecosystem:\\nProduct - Building new software and services businesses, at scale.\\nVenture - Investing in early-stage startups to help entrepreneurs build and scale their businesses.\\nPartnerships - Helping startups successfully partner with the variety of businesses within Samsung.\\nM&amp;A - Acquiring startups to connect and scale with our businesses.\\nSamsung is an EEO (Equal Employment Opportunity)/Veterans/Disabled/LGBTQ employer. We welcome and encourage diversity as we strive to create an inclusive workplace.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Staff Backend Engineer, Machine Learning – Free Mission</td>\n",
       "      <td>New York, NY 10011</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>10011</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>We are looking for senior backend engineers to join our team of talented engineers that share a common interest in distributed backend systems, their scalability and continued development. You will build the backend systems that power our application, scale highly distributed systems, and continuously improve our engineering practices. Above all, your work will impact the way the world experiences music.\\n\\nAt Spotify, we’re proud of our ambitious mission of having 1 billion fans enjoying music around the world, and are seeking a lead machine learning engineer to join us in pursuit of this goal. We are looking for a Staff Backend Engineer with a proficiency in Machine Learning to join our team, which uses machine learning to drive advertiser outcomes and listener satisfaction in Spotify Free, helping democratize music access globally while positively impacting Spotify’s bottom line. We develop innovative and scalable solutions around the core problem of getting the right ad to the right user at the right time, while embodying Spotify’s values and taking our users’ best interest at heart.\\n\\nWhat you’ll do\\n\\nBe a technical leader within the team you work with and within Spotify in general.\\nCoordinate technical projects across teams within Spotify.\\nFacilitate collaboration with other engineers to solve interesting and challenging problems around continually improving machine learning models in production\\nHelp build and improve features that impact our users and make them better leveraging machine learning\\nArchitect, design, develop, deploy and operate Java services and systems that serve real-time predictions to millions of users\\nBe a valued member of an autonomous, cross-functional agile team\\nBe a leader of the Spotify-wide backend developer community affecting and driving our architecture across the company\\nWho you are\\n\\nYou are an experienced technical leader.\\nYou have 5+ years of experience in designing and building distributed, high-volume services (Java, PHP, etc)\\nYou are proficient in bare-metal programming languages (Java / C++)\\nYou are experienced with deploying and operating services on Linux.\\nYou have a deep understanding of system design, data structures, and algorithms.\\nYou have 3+ years of experience with machine learning systems, theory, and development workflows\\nYou care about quality and you know what it means to ship high quality code.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Etsy is looking for a Machine Learning Engineer to join our Data Science teams. We are committed to advancing E-commerce related fields by building technologies that help Etsy buyers and sellers discover and celebrate handmade goods from all over the world. This individual is going to design and build machine learning systems that process Internet-scale content. In addition, the individual is going to build and optimize systems, tools, and validation strategies to support new machine learning applications.\\nAbout the Role\\nWhat we're working on:\\nSearch Ranking\\nRecommendation and Personalization\\nNatural Language Processing and Query Understanding\\nDeep Learning\\nImage Processing and Understanding\\nText Understanding\\nFraud and Abuse Detection\\nLarge-scale Machine Learning\\nWe care about curiosity and humility. We are dedicated to learning and constantly improving. We hope you also value things like blameless postmortems and have a natural drive to figure out how everything works. Keeping it real. Etsy’s mission and values are a part of everything we do. We care about how our work affects real people in the community and enjoy opportunities to meet them. We are motivated by this mission every day.\\nAbout You\\nYou have a B.S./M.S./Ph.D. degree in Computer Science or related engineering fields.\\nYou have a solid engineering and coding skills, with ability to write high performance production quality code.\\nExperience in Java, C++, Python, Scala and other equivalent languages is a plus.\\nYou have industry experience building and productionizing innovative end-to-end Machine Learning systems.\\nYou have the ability to quickly prototype ideas and solve complex problems by adapting creative approaches.\\nYou are a strong collaborator and communicator and you make the engineers around you grow and learn.\\nWhat’s Next\\n\\nInterested in working with us? Send us a cover letter and your CV or resume explaining why you’d be great for the job. We value your unique talents and point of view, so feel free to tell us what you are all about. And if you write, draw, craft, or contribute to something you’re proud of, we’d love to hear about it.\\nAt Etsy, we believe that a diverse, equitable and inclusive workplace makes us a more relevant, more competitive, and more resilient company. We welcome people from all backgrounds, ethnicities, cultures, and experiences. Etsy is an equal opportunity employer. We do not discriminate on the basis of race, color, ancestry, religion, national origin, sexual orientation, age, citizenship, marital or family status, disability, gender identity or expression, veteran status, or any other legally protected status.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Senior Machine Learning Engineer / Data Scientist</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>We’re looking for an experienced machine learning engineer or data scientist to join our small team of talented engineers and data scientists and play a major role in shaping an exciting platform.\\n\\nResponsibilities\\n\\nLead development efforts of key features\\n\\nPartner closely with data scientists and product managers to develop algorithms and drive key product or modeling decisions\\n\\nResearch the best metrics and experiment design to measure models performance\\n\\nPresent your research and insights to all levels of the company, clearly and concisely\\n\\nYour profile\\n\\nExpert programming experience with a scripting language such as Python (preferred)\\n\\nDeep understanding of modern machine learning techniques and their mathematical underpinning, such as classification, recommendation systems and natural language processing\\n\\nExperience in deploying and scaling machine learning algorithms into production environments\\n\\nStrong SQL skills\\n\\nProficiency with a statistical analysis tool such as R or Python\\n\\nExperience visualizing data and reporting\\n\\nExperience with ETL (Extract-Transform-Load) systems is a plus\\n\\nDeep product sense &amp; Self-starter\\n\\nProficiency at translating unstructured business problems into an abstract mathematical framework. You are able to make intelligent approximations of mathematical models in order to make them practical and scalable\\n\\nAbility to articulate and execute on your practical vision; you are an effective partner who listens well and incorporates others’ feedback and ideas\\n\\nRequirements\\n\\nDegree in Computer Science, Statistics, Math, Engineering, or related disciplines\\n\\n3+ years of professional experience in engineering, data science, or related\\n\\nProfessional work ethic coupled with sound judgment\\n\\nExperience working in rapid growth environment that requires flexibility and continuous innovation\\n\\nAble to roll up your sleeves to do what is needed in urgent situations while maintaining a big-picture view. You are excited about the idea of working with a small team to get the job done, even if you sometimes need to do things that are outside of your direct job description\\n\\nAbility to prioritize and handle multiple projects with tight deadlines.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Deep technical skills in data engineering, statistics, machine learning, or deep learning and a passion for making these methods more rigorous, robust and scalable\\n\\nStrong programming skills in Python or Java\\n\\nPractical experience working with and conducting experiments on large datasets then turning prototypes into production models in one or more domains</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>The One Amex team at American Express is a core foundational platform that helps drive decisions that impact our customer experience at American Express.\\n\\nThe platform is leveraged by various teams in the company to drive decisions, and customer experience.\\n\\n\\nAs part of the Data Science team, you will be responsible for:\\n\\nDriving requirements for structured data formats from a wide variety of data sources\\nBuild data science products across a wide range of digital data streams (Anomaly Detection, Deep Learning, Information Retrieval)\\nWork with engineering teams to deploy robust, highly available decisioning and alerting pipelines based on your models.\\nPlease note, Salary increases in case of a lateral move are provided only on an exception basis and in line with compensation guidelines.\\n\\nRegularly attend key initiative stand-ups, proactively advising on opportunities to apply the best approach to apply underlying empirically-developed algorithms.\\n\\nQualifications\\nQualifications should include:\\n\\nDeep technical skills in data engineering, statistics, machine learning, or deep learning and a passion for making these methods more rigorous, robust and scalable\\n\\nStrong programming skills in Python or Java\\n\\nPractical experience working with and conducting experiments on large datasets then turning prototypes into production models in one or more domains\\n\\nExperience applying analytical techniques to provide solutions to real business and engineering problems\\n\\nAbility to explain and present analyses and machine learning concepts to a technical audience\\n\\nEmployment eligibility to work with American Express in the U.S. is required as the company will not pursue visa sponsorship for these positions.\\nWhy American Express?\\n\\n\\nThere’s a difference between having a job and making a difference.\\n\\n\\nAmerican Express has been making a difference in people’s lives for over 160 years,\\n\\nbacking them in moments big and small, granting access, tools, and resources to take\\n\\non their biggest challenges and reap the greatest rewards.\\n\\n\\nWe’ve also made a difference in the lives of our people, providing a culture of learning\\n\\nand collaboration, and helping them with what they need to succeed and thrive. We\\n\\nhave their backs as they grow their skills, conquer new challenges, or even take time to\\n\\nspend with their family or community. And when they’re ready to take on a new career\\n\\npath, we’re right there with them, giving them the guidance and momentum into the\\n\\nbest future they envision.\\n\\n\\nBecause we believe that the best way to back our customers is to back our people.\\n\\n\\nThe powerful backing of American Express.\\n\\nDon’t make a difference without it.\\n\\nDon’t live life without it.\\n\\nReqID: 19009478\\nSchedule (Full-Time/Part-Time): Full-time\\nDate Posted: May 23, 2019, 12:07:03 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Our client, a Financial Data and Software company is seeking a Machine Learning Engineer. Comprised of engineers and scientists, the Machine Learning Team develops scalable ML platforms and systems.\\nThe successful candidate will develop new machine learning methods for financial applications, such as intelligent searching and predictive analytics. Machine learning techniques will include supervised, unsupervised, deep learning and time series analysis. In addition to using existing models, you will develop new techniques. The candidate will help in the identification and solution of new problem areas and research technical details to build innovative products and solutions.\\nKey Responsibilities\\nResearch and development of systems with natural language analysis, information retrieval, and financial predictive analytics within a varied technology environment.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Sr. Machine Learning Engineer, ML Research Team</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nMS degree or Ph.D. degree in Computer Science or a related quantitative field.\\n5+ years of machine learning product development experience, using state-of-the-art tooling and have a deep understanding of the best practices for ML systems.\\nFluency in using a neural network framework such as TensorFlow, Keras, Caffe, PyTorch, Theano, or MXNet\\nAbility to architect data pipelines using tools like Apache Beam or Spark. You have experience with setting organization wide best practices for data.\\nAbility to build APIs and libraries for Java, Scala or Python.\\nConcern for agile software processes, data-driven development, reliability, and responsible experimentation.\\nA keen interest in studying the latest publications in the machine learning community.\\nSkilled communication and a proven record of leading work across disciplines.\\n</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>About the team:\\nVideo is 80% of today's global Internet traffic. The Engineering team at Vimeo is building AI-driven tools to help anyone who wants to make a video. Our mission includes modernizing video playback and transcoding technologies with AI, and understanding what makes hundreds of millions of high quality videos on our platform successful. You can help make an impact.\\n\\nWhat you'll do:\\n\\nDesign and build data pipelines and production-level machine learning (ML) infrastructure, using tools such as TensorFlow, Kubernetes, TFX, Kubeflow Pipelines, Apache Beam, Spark and cloud platforms. Leverage your experience to drive best practices in ML systems and data engineering.\\nBring ML research from Notebooks to production. Deploy ML models under the constraints of scalability, correctness, and maintainability, with hardware acceleration techniques. Optimize and give feedback to research-level models to bring them to production level.\\nCollaborate with cross functional agile teams of machine learning engineers, video engineers, data engineers, and others, in building machine learning infrastructure that best supports the ML needs at Vimeo.\\n\\nSkills and knowledge you should possess:\\n\\nMS degree or Ph.D. degree in Computer Science or a related quantitative field.\\n5+ years of machine learning product development experience, using state-of-the-art tooling and have a deep understanding of the best practices for ML systems.\\nFluency in using a neural network framework such as TensorFlow, Keras, Caffe, PyTorch, Theano, or MXNet\\nAbility to architect data pipelines using tools like Apache Beam or Spark. You have experience with setting organization wide best practices for data.\\nAbility to build APIs and libraries for Java, Scala or Python.\\nConcern for agile software processes, data-driven development, reliability, and responsible experimentation.\\nA keen interest in studying the latest publications in the machine learning community.\\nSkilled communication and a proven record of leading work across disciplines.\\n\\nBonus Points (Nice Skills to Have, but Not Needed):\\n\\nExperience with data processing and storage frameworks like Google Cloud Dataflow, Hadoop, Scalding, Spark, Storm, Cassandra, Kafka, etc.\\nExperience with developing insights and models using unstructured data (like clickstreams), experience with search and recommendation systems (learn-to-rank, collaborative filtering, NLP for search, etc.)\\n\\nAbout us:\\nAt Vimeo, our mission is to empower video creators to tell exceptional stories and connect with their audiences and communities. Home to more than 90 million members in over 150 countries, Vimeo is the world's largest ad-free open video platform, providing powerful tools to host, share and sell videos in the highest quality possible.\\n\\nWe work hard to enable creators of all kinds to succeed, and to that end, we prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and creativity. We're committed to building a company and a community where people thrive by being themselves and are inspired to do their best work every day.\\n\\nVimeo is based in New York City, with additional offices in Europe and India. Vimeo is an operating business of IAC (NASDAQ: IAC). Learn more at www.vimeo.com.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Senior Machine Learning Engineer</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Master of Science with 5+ year of experience or Ph.D. with 3+ years of experience in a quantitative discipline such as Computer Sciences.\\nSolid theoretical understanding and hands on experience in developing and deploying classical and deep learning models.\\nProficiency in scalable and object oriented software development preferably Python.\\nHands on experience working with distributed compute platforms using Spark.\\nQuickly generate and updating prototypes from concept to testing while soliciting feedback.</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Why American Express?\\n\\nThere’s a difference between having a job and making a difference.\\n\\nAmerican Express has been making a difference in people’s lives for over 160 years, backing them in moments big and small, granting access, tools, and resources to take on their biggest challenges and reap the greatest rewards.\\n\\nWe’ve also made a difference in the lives of our people, providing a culture of learning and collaboration, and helping them with what they need to succeed and thrive. We have their backs as they grow their skills, conquer new challenges, or even take time to spend with their family or community. And when they’re ready to take on a new career path, we’re right there with them, giving them the guidance and momentum into the best future they envision.\\n\\nBecause we believe that the best way to back our customers is to back our people.\\n\\nThe powerful backing of American Express.\\nDon’t make a difference without it.\\nDon’t live life without it.\\n\\nAs a Machine Learning Engineer on our team you will be responsible for creating and delivering ML solutions to support our organization and clients. You will be challenged with identifying innovative ideas and proof of concepts to deliver against the existing and future needs of our customers. The successful candidate will play a key role in the understanding of product owner strategy and collaborate with peers and technology partners to translate complex user stories into successful AI product releases. If you have the talent and desire to deliver innovative products and services at a rapid pace, this would be the right fit for you!\\n\\nWhat you will be doing:\\nCreating, implementing and deploying production level ML algorithms.\\nSuggesting, collecting and synthesizing requirements.\\nCreating roadmaps towards the deployment of a production-level machine learning application.\\nArchitecting, estimating and planning technical solutions to problems.\\nWho are we looking for:\\nDeep expertise in building scalable Machine Learning powered applications\\nExperience with production grade applications preferred. Ideally with an application that leverages Machine Learning to power its decisions.\\nHighly motivated and can manage relationships in a cross-functional environment. Proven track record of working with multiple stakeholders.\\n\\n\\nQualifications\\nQuantitative and Software Development Skills:\\nMaster of Science with 5+ year of experience or Ph.D. with 3+ years of experience in a quantitative discipline such as Computer Sciences.\\nSolid theoretical understanding and hands on experience in developing and deploying classical and deep learning models.\\nProficiency in scalable and object oriented software development preferably Python.\\nHands on experience working with distributed compute platforms using Spark.\\nQuickly generate and updating prototypes from concept to testing while soliciting feedback.\\nLeadership Skills:\\nExcellent communication skills.\\nDemonstrate self-reliance to achieve goals collaboratively\\nCurious, hardworking and detail-oriented, and motivated by complex analytical problems.\\nThought leadership and innovative thinking.\\nEmployment eligibility to work with American Express in the U.S. is required as the company will not pursue visa sponsorship for these positions.\\nReqID: 19017104\\nSchedule (Full-Time/Part-Time): Full-time\\nDate Posted: Sep 17, 2019, 8:26:35 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>New York, NY 10003</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>10003</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nDevelop highly scalable deep learning models\\nAdapt machine learning methods to make effective use of modern parallel environments, distributed clusters and GPUs\\nDefine performance and scalability requirements for models in production and translate into technical implementation plan and roadmap\\nOwn systems end-to-end including design, code, train, test, deployment and iteration\\n</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nA BS/MS degree in Computer Science or Computer Engineering or equivalent\\n4+ years developing data pipelines with Python with additional experience in Java, Linux, and scripting languages that interact with cloud resources\\nDemonstrated experience developing end-to-end NLP models to derive insights from text data using NLP libraries in Python\\nExperience with building back-end services and APIs in Django or Flask\\nGood grasp of data toolchains and best practices (such as Beam, Dataflow, Airflow, Spark, Kafka)\\nExperience with docker/kubernetes\\nExperience using SQL, NOSQL and search databases (SOLR/Lucene, MySQL, Mongo/Cassandra, SOLR/Lucene, etc.)\\nExperience working with cloud computing (preferably AWS or GCP)\\nExperience with iterative Agile methodology and use of tools like JIRA, Confluence, Git\\nFamiliarity with Deep Learning frameworks like PyTorch and TensorFlow\\nDemonstrated experience in the software development lifecycle, from requirements to design to development and testing\\nStrong communication skills and ability to build pipelines with little guidance in small teams and independently\\nExcellent organizational, problem-solving, debugging and analytical skills\\n</td>\n",
       "      <td>----------------\\nAbout AlphaSense\\n----------------\\n\\nAlphaSense provides an AI-based search engine for market intelligence, used by the largest and fastest-growing firms globally. Our mission is to curate and semantically index the world's market and company information, including the vast high-value content sets that traditional web search engines cannot reach. With 1000+ enterprise clients, AlphaSense helps knowledge professionals become dramatically more productive, and gain an information edge by discovering critical data points and trends that others miss.\\n\\nThe Role:\\nYou will join our team of machine learning engineers developing the cutting edge AI &amp; NLP systems that power AlphaSense Search. You are as excited about scaling these systems for production workloads as you are with developing cutting edge algorithms.\\n\\nResponsibilities:\\n\\nDevelop highly scalable deep learning models\\nAdapt machine learning methods to make effective use of modern parallel environments, distributed clusters and GPUs\\nDefine performance and scalability requirements for models in production and translate into technical implementation plan and roadmap\\nOwn systems end-to-end including design, code, train, test, deployment and iteration\\n\\nRequirements:\\n\\nA BS/MS degree in Computer Science or Computer Engineering or equivalent\\n4+ years developing data pipelines with Python with additional experience in Java, Linux, and scripting languages that interact with cloud resources\\nDemonstrated experience developing end-to-end NLP models to derive insights from text data using NLP libraries in Python\\nExperience with building back-end services and APIs in Django or Flask\\nGood grasp of data toolchains and best practices (such as Beam, Dataflow, Airflow, Spark, Kafka)\\nExperience with docker/kubernetes\\nExperience using SQL, NOSQL and search databases (SOLR/Lucene, MySQL, Mongo/Cassandra, SOLR/Lucene, etc.)\\nExperience working with cloud computing (preferably AWS or GCP)\\nExperience with iterative Agile methodology and use of tools like JIRA, Confluence, Git\\nFamiliarity with Deep Learning frameworks like PyTorch and TensorFlow\\nDemonstrated experience in the software development lifecycle, from requirements to design to development and testing\\nStrong communication skills and ability to build pipelines with little guidance in small teams and independently\\nExcellent organizational, problem-solving, debugging and analytical skills\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Machine Learning Engineer, Decision Analytics Services (Manager)</td>\n",
       "      <td>Jersey City, NJ</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>NJ</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Proficiency in PySpark, Pandas.\\nProficiency in leveraging CI/CD tools to automate deployment and testing. Experience in Agile methodologies and fast paced DevOps environments\\nProficiency in scripting and GIT workflows\\nGood Knowledge of Hadoop, MapReduce, HDFS\\nGood Knowledge of Big Data querying tools, such as Hive\\nExperience with Big Data ML toolkits – SparkML (alternatively, Scikit Learn in Python)\\nGood Knowledge of Statistical Techniques – Descriptive Statistics, Hypothesis Testing, Tests of Significance, Correlation, Predictive Modeling\\nGood knowledge of SQL, Tableau and MS Excel\\nGood domain knowledge of US Healthcare space</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Capture a 360 degree view of member experience by consolidating disparate data sets\\nPerform descriptive analysis on various aspects of member journey – points of care , claims adjudication, operational processes, appeals mechanism\\nIdentify areas of improvement or friction that might be disrupting member satisfaction\\nMember Profiling – Segment population using advanced clustering techniques for customized targeting and intervention\\nDeploy predictive modeling to design an intervention framework which can navigate the member through his/ her journey with minimum disruption and proactive care</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Overview\\nMachine Learning Engineer, Decision Analytics Services (Manager)\\n\\nEXL (NASDAQ:EXLS) is a leading operations management and analytics company that helps businesses enhance growth and profitability in the face of relentless competition and continuous disruption. Using our proprietary, award-winning Business EXLerator Framework™, which integrates analytics, automation, benchmarking, BPO, consulting, industry best practices and technology platforms, we look deeper to help companies improve global operations, enhance data-driven insights, increase customer satisfaction, and manage risk and compliance. EXL serves the insurance, healthcare, banking and financial services, utilities, travel, transportation and logistics industries. Headquartered in New York, New York, EXL has more than 24,000 professionals in locations throughout the United States, Europe, Asia (primarily India and Philippines), Latin America, Australia and South Africa.\\n\\nEXL Analytics provides data-driven, action-oriented solutions to business problems through statistical data mining, cutting edge analytics techniques and a consultative approach. Leveraging proprietary methodology and best-of-breed technology, EXL Analytics takes an industry-specific approach to transform our clients’ decision making and embed analytics more deeply into their business processes. Our global footprint of nearly 2,000 data scientists and analysts assist client organizations with complex risk minimization methods, advanced marketing, pricing and CRM strategies, internal cost analysis, and cost and resource optimization within the organization. EXL Analytics serves the insurance, healthcare, banking, capital markets, utilities, retail and e-commerce, travel, transportation and logistics industries.\\n\\nPlease visit www.exlservice.com for more information about EXL Analytics.\\n\\nDomain: Healthcare Payer\\n\\nFunctional Area:\\nLeverage huge sets of healthcare payer data to analyze member experience across several dimensions\\nMake recommendations for streamlining underlying processes to enhance member journey, proactive intervention and prompt care delivery\\nResponsibilities\\nCapture a 360 degree view of member experience by consolidating disparate data sets\\nPerform descriptive analysis on various aspects of member journey – points of care , claims adjudication, operational processes, appeals mechanism\\nIdentify areas of improvement or friction that might be disrupting member satisfaction\\nMember Profiling – Segment population using advanced clustering techniques for customized targeting and intervention\\nDeploy predictive modeling to design an intervention framework which can navigate the member through his/ her journey with minimum disruption and proactive care\\nQualifications\\nProficiency in PySpark, Pandas.\\nProficiency in leveraging CI/CD tools to automate deployment and testing. Experience in Agile methodologies and fast paced DevOps environments\\nProficiency in scripting and GIT workflows\\nGood Knowledge of Hadoop, MapReduce, HDFS\\nGood Knowledge of Big Data querying tools, such as Hive\\nExperience with Big Data ML toolkits – SparkML (alternatively, Scikit Learn in Python)\\nGood Knowledge of Statistical Techniques – Descriptive Statistics, Hypothesis Testing, Tests of Significance, Correlation, Predictive Modeling\\nGood knowledge of SQL, Tableau and MS Excel\\nGood domain knowledge of US Healthcare space\\nWhat we offer:\\nEXL Analytics offers an exciting, fast paced and innovative environment, which brings together a group of sharp and entrepreneurial professionals who are eager to influence business decisions. From your very first day, you get an opportunity to work closely with highly experienced, world class analytics consultants.\\nYou can expect to learn many aspects of businesses that our clients engage in. You will also learn effective teamwork and time-management skills - key aspects for personal and professional growth\\nAnalytics requires different skill sets at different levels within the organization. At EXL Analytics, we invest heavily in training you in all aspects of analytics as well as in leading analytical tools and techniques.\\nWe provide guidance/ coaching to every employee through our mentoring program wherein every junior level employee is assigned a senior level professional as advisorsy\\nSky is the limit for our team members. The unique experiences gathered at EXL Analytics sets the stage for further growth and development in our company and beyond.\\n \"EOE/Minorities/Females/Vets/Disabilities\"\\nEEO Statement\\nEEO/Minorities/Females/Vets/Disabilities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Machine Learning Engineer – Customer Experience</td>\n",
       "      <td>New York, NY 10011</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>10011</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>We are looking for a Machine Learning Engineer for the team that supplies our close friends in Spotify Customer Support with the software solutions they need. These are customer facing products (e.g. support.spotify.com), internally built systems, and integrations with our vendors. We are about 40 people in total across the development team for Customer Experience, with people in New York, Stockholm and London. This position is based in New York.\\n\\nWhat you’ll learn and do\\nContribute to designing, building, evaluating, shipping, and refining Spotify’s support products by hands-on ML development\\nCollaborate with cross functional agile teams spanning user research, design, data science, product management, and engineering to build new product features that advance our mission to support artists and fans in personalized and relevant ways\\nPrototype new approaches and production-ize solutions at scale for our hundreds of millions of active users\\nHelp drive optimization, testing, and tooling to improve quality\\nBe part of an active group of machine learning practitioners in New York (and across Spotify) collaborating with one another\\nWho you are\\nYou have a strong background in machine learning, with experience in personalization and Natural Language Processing.\\nYou have hands-on experience implementing production machine learning systems at scale in Java, Scala, Python, or similar languages. Experience with XGBoost, TensorFlow is also a plus.\\nYou preferably have experience with data pipeline tools like Apache Beam or even our open source API for it, Scio and cloud platforms like GCP or AWS.\\nYou care about agile software processes, data-driven development, reliability, and disciplined experimentation\\nYou love your customers even more than your code</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      Title  \\\n",
       "0   Senior Machine Learning Engineer                                                          \n",
       "1   Senior Machine Learning Engineer - Natural Language Processing (NLP)                      \n",
       "2   Human Resources – Workforce Analytics – Lead Machine Learning Engineer - Vice President   \n",
       "3   Senior Data Scientist                                                                     \n",
       "4   Data Scientist- Machine Learning Engineer                                                 \n",
       "5   Senior Machine Learning Engineer                                                          \n",
       "6   ML Software Engineer - Event Detection                                                    \n",
       "7   Senior Machine Learning Engineer - Search                                                 \n",
       "8   Machine Learning Engineer - Health ML                                                     \n",
       "9   Senior Data Scientist / Senior Machine Learning Engineer                                  \n",
       "10  Machine Learning Engineer                                                                 \n",
       "11  Machine Learning Engineer                                                                 \n",
       "12  Machine Learning Engineer                                                                 \n",
       "13  Staff Machine Learning Engineer - Search                                                  \n",
       "14  Associate Cloud Developer, A2C Relaunch                                                   \n",
       "15  Machine Learning Engineer, Sustainability                                                 \n",
       "16  Senior Machine Learning Engineer - Search                                                 \n",
       "17  Senior Machine Learning Engineer                                                          \n",
       "18  Machine Learning Engineer                                                                 \n",
       "19  Senior Machine Learning Engineer – Free Mission                                           \n",
       "20  Staff Machine Learning Engineer - Search                                                  \n",
       "21  Senior Lead Machine Learning Engineer/Data Scientist                                      \n",
       "22  Senior Associate, Digital Intelligence – Machine Learning Engineer                        \n",
       "23  Principal Data Scientist / Applied Machine Learning Engineer                              \n",
       "24  Machine Learning Engineer                                                                 \n",
       "25  Machine Learning Engineer                                                                 \n",
       "26  CIMD - Marcus by Goldman Sachs - Machine Learning Engineer                                \n",
       "27  Senior Associate, Digital Intelligence – Machine Learning Engineer                        \n",
       "28  Python Developer (Financial Sector), Columbia University                                  \n",
       "29  Senior Machine Learning Engineer- Data Automation                                         \n",
       "30  Machine Learning Engineer, Knowledge Platform                                             \n",
       "31  GS Data Scientist                                                                         \n",
       "32  Data Science Engineer                                                                     \n",
       "33  Lead Machine Learning Engineer                                                            \n",
       "34  Data Scientist / Machine Learning Engineer                                                \n",
       "35  Senior Machine Learning Engineer                                                          \n",
       "36  Senior Data Scientist                                                                     \n",
       "37  Machine Learning Engineer, Decision Analytics Services (Manager)                          \n",
       "38  Senior, Data Engineer                                                                     \n",
       "39  Machine Learning Engineer                                                                 \n",
       "40  Staff Backend Engineer, Machine Learning – Free Mission                                   \n",
       "41  Machine Learning Engineer                                                                 \n",
       "42  Senior Machine Learning Engineer / Data Scientist                                         \n",
       "43  Machine Learning Engineer                                                                 \n",
       "44  Machine Learning Engineer                                                                 \n",
       "45  Sr. Machine Learning Engineer, ML Research Team                                           \n",
       "46  Senior Machine Learning Engineer                                                          \n",
       "47  Machine Learning Engineer                                                                 \n",
       "48  Machine Learning Engineer, Decision Analytics Services (Manager)                          \n",
       "49  Machine Learning Engineer – Customer Experience                                           \n",
       "\n",
       "                 Location         City State         Zip     Country  \\\n",
       "0   New York, NY 10121     New York     NY    10121       None Found   \n",
       "1   New York, NY 10018     New York     NY    10018       None Found   \n",
       "2   Jersey City, NJ 07310  Jersey City  NJ    07310       None Found   \n",
       "3   New York, NY           New York     NY    None Found  None Found   \n",
       "4   New York, NY           New York     NY    None Found  None Found   \n",
       "5   New York, NY           New York     NY    None Found  None Found   \n",
       "6   New York, NY           New York     NY    None Found  None Found   \n",
       "7   Hoboken, NJ 07030      Hoboken      NJ    07030       None Found   \n",
       "8   New York, NY           New York     NY    None Found  None Found   \n",
       "9   New York, NY           New York     NY    None Found  None Found   \n",
       "10  New York, NY 10010     New York     NY    10010       None Found   \n",
       "11  New York, NY           New York     NY    None Found  None Found   \n",
       "12  New York, NY 10011     New York     NY    10011       None Found   \n",
       "13  Hoboken, NJ            Hoboken      NJ    None Found  None Found   \n",
       "14  New York, NY           New York     NY    None Found  None Found   \n",
       "15  New York, NY           New York     NY    None Found  None Found   \n",
       "16  Hoboken, NJ            Hoboken      NJ    None Found  None Found   \n",
       "17  New York, NY 10012     New York     NY    10012       None Found   \n",
       "18  New York, NY           New York     NY    None Found  None Found   \n",
       "19  New York, NY 10011     New York     NY    10011       None Found   \n",
       "20  Hoboken, NJ 07030      Hoboken      NJ    07030       None Found   \n",
       "21  New York, NY 10020     New York     NY    10020       None Found   \n",
       "22  New York, NY 10001     New York     NY    10001       None Found   \n",
       "23  Manhattan, NY          Manhattan    NY    None Found  None Found   \n",
       "24  New York, NY           New York     NY    None Found  None Found   \n",
       "25  New York, NY           New York     NY    None Found  None Found   \n",
       "26  New York, NY 10282     New York     NY    10282       None Found   \n",
       "27  New York, NY 10001     New York     NY    10001       None Found   \n",
       "28  New York, NY           New York     NY    None Found  None Found   \n",
       "29  New York, NY           New York     NY    None Found  None Found   \n",
       "30  New York, NY 10032     New York     NY    10032       None Found   \n",
       "31  New York, NY 10282     New York     NY    10282       None Found   \n",
       "32  New York, NY 10016     New York     NY    10016       None Found   \n",
       "33  New York, NY           New York     NY    None Found  None Found   \n",
       "34  New York, NY           New York     NY    None Found  None Found   \n",
       "35  New York, NY           New York     NY    None Found  None Found   \n",
       "36  New York, NY           New York     NY    None Found  None Found   \n",
       "37  Jersey City, NJ        Jersey City  NJ    None Found  None Found   \n",
       "38  New York, NY 10011     New York     NY    10011       None Found   \n",
       "39  New York, NY           New York     NY    None Found  None Found   \n",
       "40  New York, NY 10011     New York     NY    10011       None Found   \n",
       "41  New York, NY           New York     NY    None Found  None Found   \n",
       "42  New York, NY           New York     NY    None Found  None Found   \n",
       "43  New York, NY           New York     NY    None Found  None Found   \n",
       "44  New York, NY           New York     NY    None Found  None Found   \n",
       "45  New York, NY           New York     NY    None Found  None Found   \n",
       "46  New York, NY           New York     NY    None Found  None Found   \n",
       "47  New York, NY 10003     New York     NY    10003       None Found   \n",
       "48  Jersey City, NJ        Jersey City  NJ    None Found  None Found   \n",
       "49  New York, NY 10011     New York     NY    10011       None Found   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Qualifications  \\\n",
       "0   BS/MS degree in Computer Science, Computer Engineering, or a related subject.\\n5+ years of demonstrated experience in Python.\\nIn-depth knowledge of Python data processing and machine learning libraries.\\nExperience with and understanding of the Python ML frameworks such as TensorFlow and PyTorch\\nExperience with API design & development\\nUnderstanding of the data layer integration (both SQL and no-SQL)\\nExperience with cloud deployments is a plus\\nUnderstanding AWS / Azure / GCP data ETL capabilities is a plus\\nExperience with C/C++, Java and/or Scala plus.\\nPassion for writing well structured, testable code with a focus on readability and maintainability.\\nExperience with open source CI tools is a plus.\\nData modeling experience is a plus.\\nExcellent communication skills.\\n                                          \n",
       "1   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "2   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "3   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "4   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "5   \\nDeep understanding of ML problems such as classification, clustering, anomaly detection, association rules, deep learning, and recommendation\\nDeep understanding of test analysis\\nPrevious work with Spark MLlib\\nPrevious work with TensorFlow\\nB.S. or M.S in Computer Science\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "6   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "7   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "8   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "9   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "10  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "11  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "12  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "13  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "14  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "15  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "16  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "17  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "18  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "19  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "20  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "21  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "22  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "23  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "24  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "25  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "26  \\nAt least a Bachelor’s degree, preferably in a quantitative/STEM field - Applied Mathematics, Physics, Engineering, Computer Science etc.\\n2+ years of open source Machine Learning algorithm development experience in Python and AWS\\n2+ years of building data pipelines, feature extractions, Flask/Django APIs and scalable model deployments\\n2+ years of experience with pandas, jupyter notebooks and sklearn\\n2+ years of hands on experience with advanced SQL queries and database knowledge of RDMS, Column based, NoSql, etc.\\n2+ years of experiences in working in AWS or other Cloud computing environments                                                                                                                                                                                                                                \n",
       "27  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "28  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "29  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "30  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "31  \\nBachelor’s Degree in a field like computer science, statistics, economics or applied math.\\nStrong knowledge of statistical analysis and exploratory data analysis techniques for prescriptive analytics.\\nProfessional experience in an advance analytics-based data science/ machine learning engineer or stats role.\\nProfessional experience working in cloud environment like AWS.\\nStrong knowledge of machine learning concepts like regression, classification, clustering, heuristics, boosting, feature engineering, etc.\\nStrong Proficiency in SQL, notebooks and Python.\\nUnderstanding of open source libraries for solving orchestration, model deployment, model explainability and management.\\nBasic understanding of new deep learning techniques like GANs, RNNs, CNNs and platforms like keras/tensorflow used to implement these.   \n",
       "32  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "33  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "34  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "35  \\nMS degree in Computer Science or a related quantitative field\\n5+ years of experience in one or more of the following areas: machine learning (NLP), recommendation systems\\nExperience with machine learning frameworks such as TensorFlow or Keras\\nExperience working in an Agile environment and within a distributed team                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "36  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "37  Proficiency in PySpark, Pandas.\\nProficiency in leveraging CI/CD tools to automate deployment and testing. Experience in Agile methodologies and fast paced DevOps environments\\nProficiency in scripting and GIT workflows\\nGood Knowledge of Hadoop, MapReduce, HDFS\\nGood Knowledge of Big Data querying tools, such as Hive\\nExperience with Big Data ML toolkits – SparkML (alternatively, Scikit Learn in Python)\\nGood Knowledge of Statistical Techniques – Descriptive Statistics, Hypothesis Testing, Tests of Significance, Correlation, Predictive Modeling\\nGood knowledge of SQL, Tableau and MS Excel\\nGood domain knowledge of US Healthcare space                                                                                                                                                                                          \n",
       "38  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "39  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "40  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "41  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "42  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "43  Deep technical skills in data engineering, statistics, machine learning, or deep learning and a passion for making these methods more rigorous, robust and scalable\\n\\nStrong programming skills in Python or Java\\n\\nPractical experience working with and conducting experiments on large datasets then turning prototypes into production models in one or more domains                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "44  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "45  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "46  Master of Science with 5+ year of experience or Ph.D. with 3+ years of experience in a quantitative discipline such as Computer Sciences.\\nSolid theoretical understanding and hands on experience in developing and deploying classical and deep learning models.\\nProficiency in scalable and object oriented software development preferably Python.\\nHands on experience working with distributed compute platforms using Spark.\\nQuickly generate and updating prototypes from concept to testing while soliciting feedback.                                                                                                                                                                                                                                                                                                                           \n",
       "47  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "48  Proficiency in PySpark, Pandas.\\nProficiency in leveraging CI/CD tools to automate deployment and testing. Experience in Agile methodologies and fast paced DevOps environments\\nProficiency in scripting and GIT workflows\\nGood Knowledge of Hadoop, MapReduce, HDFS\\nGood Knowledge of Big Data querying tools, such as Hive\\nExperience with Big Data ML toolkits – SparkML (alternatively, Scikit Learn in Python)\\nGood Knowledge of Statistical Techniques – Descriptive Statistics, Hypothesis Testing, Tests of Significance, Correlation, Predictive Modeling\\nGood knowledge of SQL, Tableau and MS Excel\\nGood domain knowledge of US Healthcare space                                                                                                                                                                                          \n",
       "49  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Skills  \\\n",
       "0   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "1   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "2   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "3   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "4   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "5   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "6   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "7   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "8   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "9   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "10  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "11  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "12  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "13  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "14  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "15  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "16  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "17  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "18  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "19  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "20  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "21  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "22  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "23  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "24  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "25  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "26  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "27  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "28  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "29  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "30  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "31  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "32  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "33  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "34  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "35  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "36  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "37  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "38  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "39  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "40  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "41  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "42  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "43  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "44  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "45  \\nMS degree or Ph.D. degree in Computer Science or a related quantitative field.\\n5+ years of machine learning product development experience, using state-of-the-art tooling and have a deep understanding of the best practices for ML systems.\\nFluency in using a neural network framework such as TensorFlow, Keras, Caffe, PyTorch, Theano, or MXNet\\nAbility to architect data pipelines using tools like Apache Beam or Spark. You have experience with setting organization wide best practices for data.\\nAbility to build APIs and libraries for Java, Scala or Python.\\nConcern for agile software processes, data-driven development, reliability, and responsible experimentation.\\nA keen interest in studying the latest publications in the machine learning community.\\nSkilled communication and a proven record of leading work across disciplines.\\n   \n",
       "46  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "47  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "48  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "49  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Responsibilities  \\\n",
       "0   Collaborate with the product owner, technical lead, product designer, and other stakeholders to design, prototype and develop enterprise-class data intensive applications.\\nMaintain existing code and make improvements to increase maintainability, performance, and scalability.\\nSupport software rollouts to production.\\nConstantly improve code quality and test coverage.\\nUnderstand full-stack dependencies to minimize regressions and attain improved designs.\\nGuide and mentor junior engineers. Serve as team lead if appropriate.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "1   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "2   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "3   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "4   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "5   \\nBuild & maintain production ready ML pipelines\\nBuild & maintain a production-ready experimentation platform to run models in parallel and A/B test\\nPrepare and preprocess data in collaboration with the data engineering team\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "6   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "7   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "8   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "9   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "10  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "11  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "12  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "13  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "14  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "15  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "16  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "17  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "18  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "19  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "20  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "21  \\nLead a team of machine learning engineers, data scientist, data engineers\\nSupport our data modeling efforts to ensure we are capturing the data needed to improve our modeling capabilities.\\nCreate features for our feature store\\nBuild machine learning models\\nUse a variety of techniques including predictive modeling, recommendation engines, revenue management, conversion rate optimization, and site and user experience optimization.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "22  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "23  \\nEstablish project scope and roadmap, including data strategy, needed to develop production-level predictive pipelines that solve large scale problems for clients in the space\\nHelp develop, implement and document rigorous methodology to plan, track and improve accuracy and relevance of models\\nLead internal communication with stakeholders, and ensure delivery of the project per commitment\\nCollaborate with clients and other stakeholders to effectively integrate and communicate findings and use cases\\nProvide guidance and project management support to the Associates on the team\\nExperience building predictive models allows you to clearly determine team size and scope work needed to accomplish business goals\\nKnowledge of databases, data modeling, and data harmonization a must\\nEvaluate emerging technologies and alternative datasets that may contribute value to our existing platforms\\nContribute to the thought leadership of the company by publishing ML research and participating in relevant conferences in the space\\nHealthcare data familiarity, especially around claims and clinical data, is highly desirable   \n",
       "24  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "25  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "26  Build platforms to accelerate deployment of ML/NLP/AI Models\\nBuild ETL pipelines to derive and store features and insights out of raw datasets\\nBuild orchestration using Airflow or other open sources libraries\\nDocument, design, code and test applications and model outcomes\\nWork on model explainability and governance\\nClosely collaborate with product and marketing teams on delivering new product features, perform exploratory data analysis and/or build data pipelines and APIs\\nBuild measure and report KPIs and explain complex concepts in non-technical terms\\n\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "27  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "28  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "29  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "30  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "31  Build machine learning and NLP models to build new product features and improve business metrics.\\nPerform exploratory data analysis and causation/attribution/correlation identifying key insights to help decisions and business strategy.\\nDocument model explainability and decay and deploy models with proper governance.\\nWork with product managers, engineers, marketers and designers, and senior executives to optimize key translate business insights into decisions and action\\nBuild and improve our machine learning deployment and data pipeline platforms.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "32  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "33  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "34  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "35  \\nWork closely with our Data team to extend and improve our Food Genome by applying NLP based methods to this complex domain.\\nBuild models to generate food recommendations and personalized offering based on user behavior\\nDesign, develop, test, deploy, maintain and improve ML models/infrastructure and software that uses these models.\\nManage individual project priorities, deadlines and deliverables.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "36  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "37  Capture a 360 degree view of member experience by consolidating disparate data sets\\nPerform descriptive analysis on various aspects of member journey – points of care , claims adjudication, operational processes, appeals mechanism\\nIdentify areas of improvement or friction that might be disrupting member satisfaction\\nMember Profiling – Segment population using advanced clustering techniques for customized targeting and intervention\\nDeploy predictive modeling to design an intervention framework which can navigate the member through his/ her journey with minimum disruption and proactive care                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "38  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "39  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "40  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "41  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "42  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "43  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "44  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "45  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "46  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "47  \\nDevelop highly scalable deep learning models\\nAdapt machine learning methods to make effective use of modern parallel environments, distributed clusters and GPUs\\nDefine performance and scalability requirements for models in production and translate into technical implementation plan and roadmap\\nOwn systems end-to-end including design, code, train, test, deployment and iteration\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "48  Capture a 360 degree view of member experience by consolidating disparate data sets\\nPerform descriptive analysis on various aspects of member journey – points of care , claims adjudication, operational processes, appeals mechanism\\nIdentify areas of improvement or friction that might be disrupting member satisfaction\\nMember Profiling – Segment population using advanced clustering techniques for customized targeting and intervention\\nDeploy predictive modeling to design an intervention framework which can navigate the member through his/ her journey with minimum disruption and proactive care                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "49  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "\n",
       "     Education  \\\n",
       "0   None Found   \n",
       "1   None Found   \n",
       "2   None Found   \n",
       "3   None Found   \n",
       "4   None Found   \n",
       "5   None Found   \n",
       "6   None Found   \n",
       "7   None Found   \n",
       "8   None Found   \n",
       "9   None Found   \n",
       "10  None Found   \n",
       "11  None Found   \n",
       "12  None Found   \n",
       "13  None Found   \n",
       "14  None Found   \n",
       "15  None Found   \n",
       "16  None Found   \n",
       "17  None Found   \n",
       "18  None Found   \n",
       "19  None Found   \n",
       "20  None Found   \n",
       "21  None Found   \n",
       "22  None Found   \n",
       "23  None Found   \n",
       "24  None Found   \n",
       "25  None Found   \n",
       "26  None Found   \n",
       "27  None Found   \n",
       "28  None Found   \n",
       "29  None Found   \n",
       "30  None Found   \n",
       "31  None Found   \n",
       "32  None Found   \n",
       "33  None Found   \n",
       "34  None Found   \n",
       "35  None Found   \n",
       "36  None Found   \n",
       "37  None Found   \n",
       "38  None Found   \n",
       "39  None Found   \n",
       "40  None Found   \n",
       "41  None Found   \n",
       "42  None Found   \n",
       "43  None Found   \n",
       "44  None Found   \n",
       "45  None Found   \n",
       "46  None Found   \n",
       "47  None Found   \n",
       "48  None Found   \n",
       "49  None Found   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Requirement  \\\n",
       "0   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "1   \\nMSc or PhD in Computer Science, Machine Learning, Maths, Stats (or related field).\\nExperience with Machine Learning techniques for supervised & unsupervised learning e.g. CNN's, DNN's & RNN's.\\nStrong knowledge of Machine Learning frameworks such as Tensorflow & Keras.\\nExperience with Natural Language Processing.\\nExcellent programming skills preferably with Python.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "2   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "3   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "4   \\nMS/PhD preferred\\n2+ years experience in data science/machine learning preferred\\nExperience with making predictions from both structured and unstructured data\\nPractical knowledge of Python and its scientific libraries SciPy, Scikit, Pandas, and NumPy, with extensive knowledge of programming best practices\\nSolid foundation in machine learning models, processes, and theories, with the ability to evaluate different algorithmic approaches\\nWorking knowledge of statistics and probability (statistical inference, Bayesian statistics)\\nEmbodiment of our core company values of motivation, positivity, curiosity, humility and integrity, and buy-in for our company mission of eliminating bias in hiring\\nWillingness to relocate or regularly travel to the NYC metro area\\n                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "5   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "6   \\nBS, MS, or PhD in computer science or a related quantitative field with 4+ years of software engineering experience\\nExperience with software engineering best practices (e.g. unit testing, code reviews, design documentation)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "7   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "8   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "9   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "10  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "11  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "12  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "13  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "14  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "15  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "16  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "17  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "18  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "19  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "20  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "21  \\n5+ years' experience developing, maintaining, and testing machine learning models.\\nA strong technical advocate with a background in Java, Scala, or Python. Preferably familiar with Jupyter notebook environments and Spark or pySpark.\\nStrong understanding of the machine learning tooling for either Python or Scala (e.g. Pandas, XGBoost, Spark)\\nStrong understanding of machine learning\\nNice to have\\nExperience with CI/CD infrastructure and a strong supporter of unit / integration testing                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "22  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "23  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "24  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "25  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "26  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "27  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "28  \\nBachelor's Degree\\nMinimum of 5 years of work experience\\nA positive attitude\\nAbility to deliver our lesson plans that are taught in classrooms across the country to the student body\\nOpenness to share your own professional experiences and industry insight with the students\\nAbility to support our students individually as they go through an emotional roller coaster\\nBe able to infuse empathy, support, encouragement, and fun into the student experience\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "29  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "30  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "31  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "32  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "33  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "34  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "35  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "36  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "37  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "38  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "39  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "40  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "41  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "42  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "43  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "44  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "45  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "46  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "47  \\nA BS/MS degree in Computer Science or Computer Engineering or equivalent\\n4+ years developing data pipelines with Python with additional experience in Java, Linux, and scripting languages that interact with cloud resources\\nDemonstrated experience developing end-to-end NLP models to derive insights from text data using NLP libraries in Python\\nExperience with building back-end services and APIs in Django or Flask\\nGood grasp of data toolchains and best practices (such as Beam, Dataflow, Airflow, Spark, Kafka)\\nExperience with docker/kubernetes\\nExperience using SQL, NOSQL and search databases (SOLR/Lucene, MySQL, Mongo/Cassandra, SOLR/Lucene, etc.)\\nExperience working with cloud computing (preferably AWS or GCP)\\nExperience with iterative Agile methodology and use of tools like JIRA, Confluence, Git\\nFamiliarity with Deep Learning frameworks like PyTorch and TensorFlow\\nDemonstrated experience in the software development lifecycle, from requirements to design to development and testing\\nStrong communication skills and ability to build pipelines with little guidance in small teams and independently\\nExcellent organizational, problem-solving, debugging and analytical skills\\n   \n",
       "48  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "49  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        FullDescriptions  \n",
       "0   We are seeking a highly-experienced Senior Backend / ML Engineer to join our team building advanced Business Intelligence, Machine Learning, and Data Processing applications.\\nYour Impact\\nAs a Backend Engineer, you will develop advanced tools that allow our customers to build highly-sophisticated Business Intelligence applications for their stakeholders. You will work as a member of an engineering “feature team,” responsible for delivering value to our customers. In this role, you will design, implement, and deliver enterprise-grade machine learning applications for both internal- and external-facing consumers. You will be part of a dynamic team of engineers who are developing cutting edge technology that fuels the premier BI platform in the industry. Your work will be deployed to production and used by dozens of major corporations such as FedEx, US Bank, and Mastercard to help drive their business goals and service their customers.\\nWhile mostly focusing in ML models productizing and data processing you will be expected to contribute to the model development. You believe that good design is the key to good coding - “measure twice, cut once.” You write excellent-quality code (if you do say so yourself), and understand how to best practices of SW architecture, development and testing.\\n Responsibilities\\nCollaborate with the product owner, technical lead, product designer, and other stakeholders to design, prototype and develop enterprise-class data intensive applications.\\nMaintain existing code and make improvements to increase maintainability, performance, and scalability.\\nSupport software rollouts to production.\\nConstantly improve code quality and test coverage.\\nUnderstand full-stack dependencies to minimize regressions and attain improved designs.\\nGuide and mentor junior engineers. Serve as team lead if appropriate.\\nQualifications\\nBS/MS degree in Computer Science, Computer Engineering, or a related subject.\\n5+ years of demonstrated experience in Python.\\nIn-depth knowledge of Python data processing and machine learning libraries.\\nExperience with and understanding of the Python ML frameworks such as TensorFlow and PyTorch\\nExperience with API design & development\\nUnderstanding of the data layer integration (both SQL and no-SQL)\\nExperience with cloud deployments is a plus\\nUnderstanding AWS / Azure / GCP data ETL capabilities is a plus\\nExperience with C/C++, Java and/or Scala plus.\\nPassion for writing well structured, testable code with a focus on readability and maintainability.\\nExperience with open source CI tools is a plus.\\nData modeling experience is a plus.\\nExcellent communication skills.\\nInformation Builders helps organizations transform data into business value. Our software solutions for business intelligence and analytics, integration, and data integrity empower people to make smarter decisions, strengthen customer relationships, and drive growth. Our dedication to customer success is unmatched in the industry. That’s why thousands of leading organizations rely on Information Builders to be their trusted partner. Founded in 1975, Information Builders is headquartered in New York City, with offices around the world, and remains one of the largest independent, privately held companies in the industry.\\nInformation Builders, Inc. is an Equal Opportunity Employer: All qualified applicants will receive consideration for employment and will not be discriminated against based on their race, gender, disability, veteran status, or other protected classification.\\n#LI-LO1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "1   Why join LYNK?\\nLYNK is a VC-backed, product-driven startup working with leading institutional clients, top level experts and thought leaders globally\\nWe operate in a high-octane environment where our people think about the big picture and always strive to “make it happen”\\nOur team, spread across four countries today (and growing!), is multinational, multilingual and multicultural. Our clients have likened us to a mini United Nations.\\nYou will be constantly challenged with new problems to solve every day.\\nWe are here to realize big dreams and have a firm belief in our core mission – to democratize access to knowledge.\\n\\nWhat You’ll Do:\\nJoin us, and tackle some of the most challenging problems in natural language processing and large scale applied machine learning. You will build cutting edge natural language understanding technologies and deploy them on a global scale.\\n\\nBuild data pipelines that clean, transform and aggregate data into databases and adopt data warehouse solutions in AWS Redshift\\nGather and process raw data at scale (including writing scripts, web scraping, calling APIs, write SQL queries, writing applications, etc.).\\nDevelop data pipelines that unify various data sources into one cohesive platform for data access.\\nDesign and Develop NLP engine and applications.\\nDevelop sourcing, cleansing, structuring and ingesting new data sources.\\nApply machine learning and predictive modelling techniques.\\nDevelop creative solutions to business problems using mathematical algorithms.\\nEvaluate different NLP technology and tools.\\nWork on very large text-based data sets, applying the latest techniques for entity recognition and sentiment extraction, with the goal of identifying features of real-time text feeds\\nRequirements\\nWhat Expertise You’ll Add To The Team:\\nMSc or PhD in Computer Science, Machine Learning, Maths, Stats (or related field).\\nExperience with Machine Learning techniques for supervised & unsupervised learning e.g. CNN's, DNN's & RNN's.\\nStrong knowledge of Machine Learning frameworks such as Tensorflow & Keras.\\nExperience with Natural Language Processing.\\nExcellent programming skills preferably with Python.\\n\\nBonus Attributes:\\nStrong passion for creative content curation and building brand awareness\\nPassion for business and enthusiastic about taking part in shaping LYNK’s growth\\nFunction well in a very fast-paced startup environment\\nTrack record of excelling in small teams\\nTeam players who thrive in uncertainty and like to “make things happen”!\\nBenefits\\nWhat We Commit To You\\nCompetitive remuneration package in a rapidly-expanding startup\\nWork in a collaborative, co-creation hub in the heart of the city - with amazing facilities\\nComprehensive medical insurance coverage, including dental\\nGenerous leave policy, including a ‘work remote policy’\\nThe opportunity to travel and work around the globe with our international clients and growing number of offices (Hong Kong, Singapore, Mumbai, New York City)\\nThe opportunity to be a part of something impactful\\n\\nVisit http://lynk.global for more info.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "2   JPMorgan Chase & Co. (NYSE: JPM) is a leading global financial services firm with assets of $2.6 trillion and operations worldwide. The firm is a leader in investment banking, financial services for consumers and small business, commercial banking, financial transaction processing, and asset management. A component of the Dow Jones Industrial Average, JPMorgan Chase & Co. serves millions of consumers in the United States and many of the world's most prominent corporate, institutional and government clients under its J.P. Morgan and Chase brands. Information about JPMorgan Chase & Co. is available at www.jpmorganchase.com.\\n\\nHuman Resources plays an integral role in designing, implementing, and managing global initiatives across the firm. The functional areas within HR include global Recruiting, Training, Talent and Development, Diversity, Compensation, Benefits, Employee Relations, Technology, Finance, HR Service Delivery, and the Chief Data & Analytics Office.\\nWorkforce Analytics (WFA) is the firm’s centralized global HR analytics function, positioned within the HR Chief Data & Analytics Office. WFA applies quantitative methods, technology, and research to people data and people decisions across the firm.\\nPosition Overview & Responsibilities:\\nThe Lead ML Engineer will be responsible for designing, building, and deploying data products that integrate ML and NLP with other internal applications and platforms. This individual will report to the Head of Data Science and join a cross-functional data science team that leads some of the most critical projects in HR.\\nCandidate Profile\\nThe ideal candidate will be skilled, innovative, self-motivated, and inclined to create genuine business value through the alignment of technology, data, and business interests. He or she will have hands-on experience with the development of data products, from data ingestion to deployment. Additionally, excellent communication skills and a collaborative attitude will be crucial to success, as this role will partner closely with aligned Technology teams in addition to the immediate data science team.\\nKey Responsibilities\\nLead the redevelopment of Python-based monolithic ML & NLP products as RESTful microservices\\nDeploy data science products using standard CI/CD workflows into the firm’s cloud and Hadoop platforms\\nCollaborate with a team of data scientists and engineers on a variety of innovative machine learning and natural language processing projects\\nPrototype and build data pipelines. Support configuration and management of ETL and scheduling jobs/software. Perform ad-hoc ingestion of data from varied sources into HDFS.\\nRequirements\\nBachelor’s Degree in Computer Science or a related field desired\\n3+ years of experience in software engineering, preferably in a data-driven domain\\nExperience leading an engineering team is preferred\\nFamiliarity with Python, Flask, SQL, API or web service development, and Hadoop is preferred\\nExperience with Docker, Kubernetes, the SDLC process & tools, and ML model management is desired\\nProfessional maturity and the ability to work/deliver with limited supervision\\nExcellent verbal and written communication skills and a team-oriented attitude                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "3   Description\\nDS/ML stack:\\nLanguages: Python, PySpark, SQL\\nData Tools: Spark, AWS RedShift, AWS Athena, pandas, numpy, scipy, parquet\\nModeling Tools: SparkML, scikit-learn, Tensorflow, Tensorflow-Serving, Keras (Tensorflow and Theano backend)\\nAlgorithms: Classifications, Regressions, Neural Networks, Time series, Graphs\\nVisualization: Tableau or similar\\nInfrastructure: AWS (including S3, EMR, EC2, Lambda)\\n\\n\\nWhat will you do?\\nUnderstand business decisions that need to be supported by data e.g. risk of readmission to hospital\\nIdentify relevant internal or external data sources for various business needs\\nResearch the state of a problem and existing solutions then quickly summarize research\\nHelp identify new business opportunities and value propositions from existing data\\nUtilize raw or aggregated data to build predictive models in SPARK, sql, or Python\\nUnderstand quality of models and impact on business problems\\nCommunicate summaries of analyses and predictive modeling efforts to product and business teams\\nCommunicate insights to stakeholders in data engineering, product and clinical teams.\\nBecome expert on projects to help strategize plans of attack in terms of technology and team education.\\nEnsure that all security procedures within their area of responsibility are carried out to achieve compliance with security policies and standards.\\nLeading multiple initiatives across both existing and innovative work\\nProvide continuous mentoring to junior resources\\nWe are looking for someone with:\\n7+ year’s professional experience as a data scientist or machine learning engineer\\n7+ year’s professional experience working in quantitative computational role\\n5+ year’s professional experience working with big data and relational databases\\nVery strong knowledge of advanced applied data science (machine learning, neural networks, etc.), mathematical modeling, computational, statistical, data mining techniques (regression, decision trees, clustering etc.), as well as dimensionality reduction techniques\\nStrong hands-on modeling experience in a business environment with a goal of productionalizing models.\\nStrong experience using machine learning and deep learning packages\\nStrong experience with data manipulation, analysis and visualization\\nProven track record of fully understanding the scope, commitment to quality, and end-to-end ownership to meet upon agreed timelines.\\nQuick learner that can manage multiple projects at the same time successfully\\nDeveloped and designed real-time prediction software\\nStrong experience mentoring junior colleagues\\nExcellent written and verbal communication skills\\nAdvanced degree in physics, applied mathematics, statistics or related field is preferred\\nHealthcare industry experience is a plus\\n\\nAbout Us\\n\\nRemedy Partners delivers software and services that enable payers, employers and at-risk providers to organize and finance healthcare delivery around a patient's episode of care. For healthcare providers, Remedy Partners’ software, analytics and administrative services support bundled payment contracts with Medicare and Commercial Insurers, often through shared-risk partnerships. For payers, Remedy Partners empowers the development of bundled payment contracting programs and guides development of bundled payment networks. Remedy Partners presently delivers its services to partners at more than 1,000 healthcare locations nationwide.\\n\\nPlease note that all Remedy employees are required to adhere to all organizational policies, the Code of Conduct and participate in all compliance-related training and education.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "4   Using neuroscience-based assessments and machine learning algorithms, pymetrics is reinventing the recruiting industry by matching candidates to jobs where they are most likely to succeed. We are leading the charge in an evolving industry and growing our amazing team to support the mission of using data to unleash one's full potential.\\nWe are looking for a talented data scientist with strong machine learning experience to join our core product development team. Data scientists on the core team contribute to the predictive modeling used throughout pymetrics to match job candidates to roles, audit algorithms for potential bias, and optimize solutions for faster, more robust analyses. You will work on an academically diverse team (with backgrounds in machine learning, statistics, behavioral science, and computer science) to test new methods and optimize existing solutions.\\nThe ideal candidate would bring experience building scalable predictive algorithms in a production environment. We value an ability to communicate with a bright team from diverse backgrounds, and the initiative to tackle interesting problems independently and with scientific rigor.\\nResponsibilities include:\\nDevelop machine learning solutions for new and existing data products relating to hiring\\nWrite production level code for practical application of data products\\nApply statistical and machine learning techniques to identify trends in data\\nWork with clients to apply custom data science solutions to unique problems\\nCollaborate with and train other members of the data science team\\nInteract with data scientists, analysts, engineers and product managers on other data products implemented at pymetrics, including language analysis, psychometric assessment, statistical analysis and data visualization\\n\\nRequirements\\nAbout you:\\nMS/PhD preferred\\n2+ years experience in data science/machine learning preferred\\nExperience with making predictions from both structured and unstructured data\\nPractical knowledge of Python and its scientific libraries SciPy, Scikit, Pandas, and NumPy, with extensive knowledge of programming best practices\\nSolid foundation in machine learning models, processes, and theories, with the ability to evaluate different algorithmic approaches\\nWorking knowledge of statistics and probability (statistical inference, Bayesian statistics)\\nEmbodiment of our core company values of motivation, positivity, curiosity, humility and integrity, and buy-in for our company mission of eliminating bias in hiring\\nWillingness to relocate or regularly travel to the NYC metro area\\nNice to Haves:\\n1+ years experience in deep learning, including familiarity with Keras, TensorFlow and/or PyTorch\\nComfort with SQL\\nKnowledge of psych/cogsci/neuroscience research\\nInterest in issues of transparency and fairness in AI\\nEye for data visualization and presentation of data-driven insights\\nWe are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\\nBenefits\\nHealth care plan (medical, dental & vision)\\nFlexible paid time off\\nFamily leave (maternity, paternity)\\n401k\\nTeam budget for training & development\\nStock option plan\\nCommuter transportation reimbursement\\nDog-friendly workplace\\nFun, diverse and intellectually eager coworkers                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "5   The machine learning engineering team is developing the brain of the BounceX communication and personalization platform. As a Senior Machine Learning Engineer, you will be working with a team of Data Engineers and Data Scientists in order to build out our next-generation platform. You will be utilizing cutting edge technologies such as Spark MLLib, Tensorflow, Google AI Platform, and Cloud Dataproc to build the required ML pipelines to enhance our customer's experience.\\n\\nResponsibilities:\\n\\nBuild & maintain production ready ML pipelines\\nBuild & maintain a production-ready experimentation platform to run models in parallel and A/B test\\nPrepare and preprocess data in collaboration with the data engineering team\\n\\nQualifications:\\n\\nDeep understanding of ML problems such as classification, clustering, anomaly detection, association rules, deep learning, and recommendation\\nDeep understanding of test analysis\\nPrevious work with Spark MLlib\\nPrevious work with TensorFlow\\nB.S. or M.S in Computer Science\\n\\nNice to have:\\n\\nExperience with Google Cloud BigQuery\\nExperience with Google Cloud BigTable\\n\\nBounceX is proud to be an equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.\\n\\nJOIN US ON OUR MISSION\\n\\nBounceX is a global marketing technology company that has been recognized as a best place to work by Glassdoor and Crain's, and one of America's fastest-growing SaaS companies.\\n\\nMore than 300 companies including JetBlue, Uniqlo, HelloFresh, and Comcast use BounceX to orchestrate real-time, multichannel marketing programs customized for every individual web visitor.\\n\\nWith offices in New York City and London, BounceX is built on the belief that the success of a company is rooted in the strength of its team, so we've created a collaborative, inclusive environment where people love coming to work.\\n\\nWe provide career coaching, growth and development opportunities, and benefits that are in the 95th percentile of all technology companies. Some highlights include excellent healthcare that starts day one, best-in-class fully paid family leave, 401(k) match, flexible work hours, and more.\\n\\nWhat bonds our community together is our commitment to 5 Core Values:\\n\\n\\nCome Hungry\\nCarry Each Other\\nDrive Undeniable Performance\\nRespect People, Privacy, Ideas\\nBounce Back\\n\\nCome join us on our mission.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "6   Who We Are:\\n\\n\\nWhen an event occurs in the real-world, it often breaks out on Twitter. The Event Detection team builds, scales and maintains the software services that power the discovery of interesting and eventful conversation across the product. We detect and surface what’s happening, contextualizing by finding the most interesting content around events, including Trends, Moments, and Live Videos for users. We are a tightly knit and passionate group that loves working together, and we are looking for exceptional additions to our flock.\\n\\n\\nWhat You'll Do:\\nEvents are one of the central use-cases for Twitter and millions of people are informed about their world through our work. The team’s purpose is to automatically detect such Events on Twitter. As an ML engineer on our team, you will apply machine learning and data science techniques to a modeling and relevance problems related to automatic Event detection. You will participate in the engineering life-cycle at Twitter, including building and analyzing datasets, working with offline data pipelines, writing production code, conducting code reviews, and working alongside our systems engineers. Although you will work on cutting-edge problems, please note that this is not a research position. You will work directly with multiple teams across the company who are innovating on the product and refining Twitter to make it the best place to see and talk about what's happening in the world.\\n\\n\\nWho You Are:\\n\\n\\nYou have a passion for machine learning and improving the ways people consume what’s happening in the world. You are a relevance engineer, applied data scientist or machine-learning engineer who wants to work on exciting algorithmic and infrastructure issues. You are experienced solving large scale relevance problems and comfortable building brand new systems to enable future quality improvements.\\n\\n\\nKnowledgeable in one or more of the following: machine-learning, information retrieval, recommendation systems, social network analysis\\nA strong technical advocate with a background in Java, Scala, or Python. Preferably familiar with Jupyter notebook environments and Spark or pySpark.\\nPassionate about working with large unstructured and structured data sets and developing new approaches to relevance problems.\\nExperienced in collaborating across multiple teams including analytics, product management, and operations.\\nRequirements:\\n\\nBS, MS, or PhD in computer science or a related quantitative field with 4+ years of software engineering experience\\nExperience with software engineering best practices (e.g. unit testing, code reviews, design documentation)\\n\\n\\nWe are committed to an inclusive and diverse Twitter. Twitter is an equal opportunity employer. We do not discriminate based on race, ethnicity, color, ancestry, national origin, religion, sex, sexual orientation, gender identity, age, disability, veteran status, genetic information, marital status or any other legally protected status.\\n\\nSan Francisco applicants: Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "7   The search team at Walmart Labs and Jet is dedicated to the mission of helping millions of customers every day in finding the right products. We are at the forefront of attacking one of the most complex problems of e-commerce. Whenever a user types in a query or browses through product categories on the web site, phone or iPad, our service goes to work. We mine billions of search queries and tens of millions of products to find the most relevant products for our customers. Team members take end-to-end responsibility in analyzing large amounts of data, creating complex models, improving their accuracy and deploying these models to serve customers. E-commerce product search, much like web search, has always been a fertile area of AI innovation. Search algorithm team at Walmart Labs and Jet is working on fascinating AI/ML problems like deep NLP based query understanding, improving relevance ranking of products, semantic matching of query <-> item pairs using embeddings, visual search to enable search by image, etc. As part of this team, you'll solve some of the most challenging and impactful problems in machine learning, information retrieval, natural language processing, computer vision or statistical measurement. Your work will be visible to hundreds of millions of customers and you will have a direct impact on the goals of the Fortune #1 company. If you speak and think machine learning then we want to talk to you. Come join our team and be part of this exciting journey.\\n\\nWhat you will do:\\n\\nBuild advanced machine learning models and improve the accuracy of those models\\nDeploy the models in production where it will serve customers in real time\\nPut on the hacker's hat quickly convert an idea to a demonstration\\nPresent your work to the internal and external community\\nWork alongside senior machine learning researchers and define the right solution to implement\\n\\n\\nWhat you will have:\\n\\n4+ years of experience in Software engineering.\\nAbility to write high performance production quality code. Experience in Python, Scala and other equivalent languages is a plus.\\nExperience building and productionizing innovative end-to-end Machine Learning systems.\\nGood understanding of common families of models, feature engineering, feature selection and other practical machine learning issues, such as overfitting.\\n\\n\\nBonus Points\\n\\nExperience building and/or maintaining machine learning models and pipelines\\nFunctional programming experience is a plus.\\nExperience building and maintaining large scale data pipelines in online advertising, recommender system, ecommerce or relevant areas\\nFamiliarity with Deep Learning.\\n\\nAbout Jet\\n\\nJet is reshaping ecommerce as we know it. Based in Hoboken NJ (just 10 min from Manhattan), we are a shopping site on the relentless pursuit to build the greatest shopping experience in the world. At Jet, we believe in bold. That means taking risks, asking “why not”, looking where no ones looked before and bringing it! Our engineers are utilizing world class technologies, to optimize the supply chain, remove unnecessary costs, sprinkle in some surprise and delight all while saving customers every penny possible and we’re just getting started. At Jet, we have worked hard to build a culture that stresses the importance of learning and sharing knowledge. If you want to be part of the team that is changing the shopping norm and learning a lot along the way, we have a hunch you’d look good in purple.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "8   Are you an engineer who’s interested in tackling very challenging adversarial problems and passionate about defending online users against abuse, spam, and manipulation? Do you love working on challenging problems that require a multi-disciplinary approach, creative solutions, and rapid product iterations? Will you be proud to work on a real-time, scalable system that serves millions of users daily? If so, you should join us.\\n\\nWho We Are\\n\\nThe Health ML engineering team is responsible for building scalable detection systems that keep spam, manipulation, and abuse at bay. We use ML and relevance techniques to make Twitter safer and to limit the spread of misinformation on the platform. Our team works across the product to detect abusive and spammy users and content, increase action on bad actors, drive changes in user behavior, and detect and remediate accounts that are violating the terms of service on Twitter.\\n\\nWe develop, maintain, and contribute to several machine learning models and systems, including:\\n\\nModels that detect unwanted interactions\\nModels to prioritize human review of accounts violating Twitter's policies to more quickly take action and limit their damage\\nDetection of bots that misuse the platform or spread misinformation\\nDetection of repeat abusive offenders who create new accounts after being suspended\\nReal-time rule engines and clustering systems to identify and action on clusters of bad actors at scale\\nWhat You’ll Do\\n\\nAlthough you will work on cutting-edge problems, this position is not a pure research position. You will participate in the engineering life-cycle at Twitter, including designing distributed systems, writing production code and data pipelines, conducting code reviews and working alongside our infrastructure and reliability teams. You’ll apply data science, machine learning, and/or graph analysis techniques to a variety of modeling and relevance problems involving users, their social graph, their tweets, and their behavior.\\n\\nWho You Are\\n\\nYou’re a relevance engineer, applied data scientist, or machine-learning engineer who wants to work on exciting algorithmic and deep infrastructure issues to improve the health of the public conversation on Twitter. You’re experienced at solving large scale relevance problems and comfortable doing incremental quality work while building brand new systems to enable future improvements.\\n\\nYou are knowledgeable in one or more of the following: machine learning (including deep learning), information retrieval, recommendation systems, social network analysis.\\nYou are a strong technical advocate with a background in Java, C++, or Scala, and Python.\\nYou strive to find the right balance between moving fast to deliver quality improvements to users and accumulating technical debt that drags down productivity.\\nYou have a collaborative working style with a strong focus on disciplined execution and results.\\nYou like to ground decisions in data and reasoning and solve root causes of problems rather than surface issues.\\nYou are adept at communicating relevant information clearly and concisely.\\nYou look ahead to identify opportunities and thrive in a culture of innovation.\\n\\n\\nHere’s all the legal good stuff:\\n\\nWe are committed to an inclusive and diverse Twitter. Twitter is an equal opportunity employer. We do not discriminate based on race, ethnicity, color, ancestry, national origin, religion, sex, sexual orientation, gender identity, age, disability, veteran, genetic information, marital status or any other legally protected status.\\n\\nSan Francisco applicants: Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "9   Company\\n\\nWell-funded stealth company focused on disrupting healthcare through a differentiated consumer experience and a world-class data & analytics engine to drive engagement and behavior change. The product will sell directly to Fortune 500 CEOs and full risk populations, integrating layers of analytics, digital, concierge services, behavioral health, telemedicine, care management and wellness services to drive sustained engagement, lower costs and improve health.\\n\\nReporting To\\n\\nHead of Data Science and AI with dotted line to Chief Analytics and Marketing Officer\\n\\nPosition Summary\\n\\n\\nThe overall goal is to engage consumers in differentiated ways that will drive better health outcomes. As one of the early hires of the Analytics organization, the primary mission will be to launch the modeling and optimization platform (the \"Health Engine\") to deliver member recommendations that improve health, cost of delivery, and engagement.\\nYou will leverage a wide range of disparate data sources across healthcare (member, payor, employer, provider, partner). Ideal candidates will have a detailed understanding of healthcare data with experience analyzing large longitudinal health datasets.\\nYou will lead in the creation of operational predictive models using current and emerging methodologies in data science. Ideal candidates will possess a deep understanding of statistics, machine learning, causal predictive modeling, and most importantly, a willingness to teach and mentor others in these areas.\\nYou will collaborate across the organization to drive projects from beginning to end: frame business questions, collect and analyze data, research, prototype, build pipelines, and share insights. You will work with engineering to ensure robust translation to production environments and create solutions that operate effectively at scale.\\n\\nMinimum Qualifications\\n\\n\\n5+ years' industry experience in data science or machine learning focused roles.\\nAdvanced degree (MS or PhD) in a quantitative field such as Statistics, Computer Science, Mathematics, Physics, Engineering, Economics, or similar.\\nDemonstrated experience using Python for data analysis and machine learning (numpy, pandas, scikit-learn, xgboost, spacy, pytorch, stan/pymc3, etc.). Proficiency with SQL and databases. Experience using Unix/OSX from the command line, version control (git), and general software development best practices for contributing to a collaborative code base. Experience configuring and executing analyses in the cloud (GCP, AWS).\\nStrong communication and collaboration skills required. Ability to communicate technical modeling concepts and relevant aspects of modeling platforms to non-technical audiences.\\nWillingness to teach and mentor others across all technical skill areas and in knowledge of the healthcare domain. Ability to work in a start-up environment that is fast paced and maintain a focus on rapid prototyping of capabilities.\\n\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "10  Machine Learning Engineer – New York, NY\\n\\nKasisto enables financial institutions to service, engage and acquire customers via human-like, intelligent conversations – anytime, anywhere. Kasisto’s Conversational AI platform, KAI, powers omni-channel virtual assistants and chatbots who are fluent in banking across mobile apps, websites, messaging platforms, and voice-enabled devices.\\n\\nKAI is the leading Conversational AI platform for the finance industry. Kasisto’s customers include J.P. Morgan, Mastercard, TD Bank, Standard Chartered, DBS Bank, among others. They chose KAI Banking for its proven track record to drive business results while improving customer experiences. The platform is engaging with millions of consumers around the world, across multiple channels, in different languages, and is optimized for performance, scalability, security, and compliance.\\n\\nBuilt with the deepest AI portfolio in the industry, KAI includes Platform Tools and Services to customize and continually improve consumer experiences as well as seamlessly add new features, channels, and markets.\\n\\nThis position\\n\\nWe are looking for an experienced Machine Learning Engineer. This position’s primary focus will be our platform’s core natural language understanding (NLU) engine, including accuracy improvements, performance evaluation, and the development of new features. The ideal candidate will have experience with machine learning-based approaches to text classification, named entity recognition, parameter extraction, and/or representation learning, as well as with the creation and evaluation of annotated training corpora. As Kasisto has an international customer-base, we welcome candidates with experience in languages besides English.\\n\\nYou should have the ability to work independently within a small, creative, deadline-driven environment. This is an excellent opportunity for someone looking to grow professionally within a fast-moving tech startup with a global reach.\\n\\nWhat you will be doing\\n\\nBuild machine learning models to understand documents and drive insights.\\nDesign and implement efficient pipelines for data manipulation, processing and delivery to our end users\\nCreate tools for automated quality assurance and anomaly detection to alert stakeholders of changes in the quality of machine learning models and analytics\\nDevelop quality software through code reviews, automated testing and design reviews\\nBuilding better-annotated training corpora by assessing data collection and annotation processes\\nAssisting in the implementation of new features and tools for both internal and external consumption\\nWhat you need in this position\\n\\n3+ years professional experience with machine learning\\nStrong proficiency in Java; Python or Scala experience a plus\\nExperience with deploying machine learning-based systems in production environments\\nExperience with multilingual NLP systems a plus\\nFamiliarity with a major machine learning/deep learning framework a plus (Keras, Tensorflow, Torch, Spark-ML, h2o.ai, etc.)\\nLocation – New York City, Flatiron District\\n\\nApplicants must be authorized to work in the US as we are unable to sponsor. Kasisto is an equal opportunity employer.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "11  Functional Area:\\nFA - Finance\\nEstimated Travel Percentage (%): No Travel\\nRelocation Provided: No\\nAIG Europe (Services) Limited\\nJob ID: JR1903962 Machine Learning Engineer\\nYour Future Team\\n\\nAbout Investments AI at AIG:\\nAIG is an insurance company that’s helped people solve important problems for almost a century. We’ve long been known for our technical expertise, and creating innovative solutions for new and developing areas of risk that our clients may face.\\nThe Investments AI team at AIG supports this ethos by developing AI-first products – that is, apps and services that use machine learning to inform and assist their users – for AIG’s insurance and investments businesses.\\nOur mission to create a safer world through the power of AI is achieved mainly through:\\nThe incubation of disruptive innovation via our diverse team of scientists, engineers, and designers who work collaboratively.\\nAI, ML and NLP R&D contribution, including publications in top conferences and journals.\\nThe provision of machine learning advisory and consulting to AIG’s global businesses.\\nOur solutions and innovations aim to reinvent AIG’s internal processes, improve AIG’s offerings, and ultimately disrupt the industry.\\nAs a critical role in Investment AI’s success, we’re looking to hire machine learning engineers to join our team and contribute to the development of the algorithmic core of a series of exciting new products and projects.\\nYour Contribution at AIG\\nBased from our New York office, this is an exceptional opportunity for those who want to enjoy state-of-the-art R&D and be challenged and grow as a machine learning engineer. Along the way, this role will contribute to game-changing products that use AIG’s global network to deliver impact and change.\\nResponsibilities and Performance Objectives\\nTake ownership of a significant part of the team’s solution development\\nDemonstrate end-to-end understanding of applications being created\\nPartner with ML Researchers to push the boundaries on the performance of the latest methods applied to big problems across the investments domain\\nContribute to peer review process to ensure code quality\\nWhat we are looking for\\nAbility to formalize learning problems with mathematical notation\\nHands-on experience solving Machine Learning problems\\nSolid understanding of algorithms and data structures\\nDetailed knowledge of Machine Learning evaluation metrics and best-practice\\nUp to date knowledge of Machine Learning literature and libraries (e.g. Tensorflow, Pytorch)\\nFamiliarity with build automation and continuous integration (e.g., Gulp, Grunt, Jenkins, CodePipeline)\\nAdvanced degree in a related field such as Machine Learning or Statistics (highly preferred)\\nGood communicator and a team player\\nAn ideal candidate (is not required to, but) will also have:\\nLinux SysAdmin skills\\nEngineering for scale using cloud platforms (e.g. Amazon Web Services)\\nInfrastructure-as-Code (e.g. Terraform, Cloudformation, etc.)\\nIt has been and will continue to be the policy of American International Group, Inc., its subsidiaries and affiliates to be an Equal Opportunity Employer. We provide equal opportunity to all qualified individuals regardless of race, color, religion, age, gender, gender expression, national origin, veteran status, disability or any other legally protected categories.\\nAt AIG, we believe that diversity and inclusion are critical to our future and our mission – creating a foundation for a creative workplace that leads to innovation, growth, and profitability. Through a wide variety of programs and initiatives, we invest in each employee, seeking to ensure that our people are not only respected as individuals, but also truly valued for their unique perspectives.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "12  Explore the possibilities across our global house of brands.\\nDefined by inclusivity rather than exclusivity, Tapestry embraces the exploration of individuality and invests in helping you grow personally and professionally. Every individual in our global house has the opportunity to make an impact, learn and be part of our growing and unique story.\\nAt Tapestry, we have the freedom to express ourselves and run with our best ideas across Coach, Kate Spade New York, and Stuart Weitzman. We share a profound belief in both our individual and collective potential, and know that with hard work and dedication, anything is possible.\\n\\nPurpose\\nRetail as an industry is changing. With an increasing amount of shopping done online, traditional retailers must innovate to stay relevant. The Data Labs Team (https://datalabs.tapestry.com) at Tapestry is tackling these challenges by leveraging our deep data assets to provide a best in class, worldwide capability to drive actionable customer understanding across all of our brands: Coach, Kate Spade and Stuart Weitzman. We are looking for individuals with a passion for discovery, innovation, and the power of advanced analytics to drive financial results and improve customer experiences. We work collaboratively with business partners across the organization to define the questions to ask, pursue the best opportunities, share insights, and develop practical business recommendations.\\nThe optimal candidate will have the opportunity to work on innovative projects with the goal of enabling Tapestry to execute on the bleeding edge in the applications of machine learning and artificial intelligence within the fashion retail industry. The candidate will leverage both internal and external data along with a suite of machine learning algorithms to develop and deploy pipelines that allow both the data and the models to provide actionable insights that produce value across the organization.\\nWe are looking for team player to support with guiding and implementing in production application of data science and machine learning methods with an eye and passion for software engineering, and the ability to connect analytics to business impact. The ideal person will lead and potentially grow the existing team to amplify impact through the combination of analytical and tooling innovation, scaled execution, science leadership, data partnership, and high pace of execution.\\n\\nThe successful individual will leverage their proficiency in Engineering and Advanced Analytics to…\\nInvestigate areas of the business that could benefit from machine learning solutions, engaging with technology and operational leaders to understand the problems they are looking to solve, as well as educating them on what is an achievable outcome.\\nAct as the ML Engineering Lead to manage the production, delivery, and integration of the solution within the business.\\nImplement in production machine learning systems using Python, R, and AWS.\\nSolutions will include but will not be limited to: inventory allocation, supply chain optimization, pricing models, targeting models, customer segmentation, customer loyalty and retention, competitive benchmarking, recommendation systems, computer vision applications.\\nSolution and develop architecture for model evaluation and model serving infrastructure.\\nWork with a team of world class data scientists, business analysts, statisticians, and creative technologists.\\nAsk not, “What is the best algorithm?”, but instead, “What is the best system?” to solve a problem.\\nWork closely with different business units (Strategy, Marketing, e-Commerce, Retail, Outlet, Pricing, Supply Chain among others) to identify business needs and challenges that can be addressed through data-driven advanced analytics.\\n\\nThe accomplished individual will possess…\\nMaster’s degree in a quantitative field or the work experience equivalent\\n2+ years of software or data engineering experience\\n2+ years of experience or exposure to applications of machine learning\\nStrong background of creating data processing and model deployment pipelines (Apache Airflow, Apache Beam, PySpark, Amazon Pipeline)\\nAdvanced knowledge of Linux (bash), Python, and SQL (MySQL, PostgreSQL)\\nExperience building and maintaining model monitoring frameworks.\\nExperience leveraging Amazon Web Services to build software microservices.\\nKnowledge of software development principles including but not limited to, software development lifecycle, agile methodologies, code reviews\\nKnowledge of data management and storage principles\\nWorking understanding of core ML/Statistics principles.\\nExcellent written and verbal communication skills\\n\\nThe accomplished individual will also be…\\nAn achiever that maintains a high standard but understands that perfection is the enemy of progress\\nAn innovator who can execute as an individual and is proactive in solving problems\\nAn autodidact, with a passion for both the acquisition and application of knowledge\\nA catalyst who can deliver from ideas and inspires others towards that shared vision\\nA collaborator who recognizes the value of and can action on not only managing junior resources but of managing up to influence executives while collaborating laterally\\nA believer in the spirit of entrepreneurship that understands the power of perseverance\\n\\nTapestry, Inc. is an equal opportunity and affirmative action employer and we pride ourselves on hiring and developing the best people. All employment decisions (including recruitment, hiring, promotion, compensation, transfer, training, discipline and termination) are based on the applicant’s or employee’s qualifications as they relate to the requirements of the position under consideration. These decisions are made without regard to age, sex, sexual orientation, gender identity, genetic characteristics, race, color, creed, religion, ethnicity, national origin, alienage, citizenship, disability, marital status, military status, pregnancy, or any other legally-recognized protected basis prohibited by applicable law. Visit Tapestry, Inc. at http://www.tapestry.com/                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "13  The search team at Walmart Labs and Jet is dedicated to the mission of helping millions of customers every day in finding the right products. We are at the forefront of attacking one of the most complex problems of e-commerce. Whenever a user types in a query or browses through product categories on the web site, phone or iPad, our service goes to work. We mine billions of search queries and tens of millions of products to find the most relevant products for our customers. Team members take end-to-end responsibility in analyzing large amounts of data, creating complex models, improving their accuracy and deploying these models to serve customers. E-commerce product search, much like web search, has always been a fertile area of AI innovation. Search algorithm team at Walmart Labs and Jet is working on fascinating AI/ML problems like deep NLP based query understanding, improving relevance ranking of products, semantic matching of query item pairs using embeddings, visual search to enable search by image, etc. As part of this team, you'll solve some of the most challenging and impactful problems in machine learning, information retrieval, natural language processing, computer vision or statistical measurement. Your work will be visible to hundreds of millions of customers and you will have a direct impact on the goals of the Fortune #1 company. If you speak and think machine learning then we want to talk to you. Come join our team and be part of this exciting journey.\\n\\nWhat you will do:\\n\\nBuild advanced machine learning models and improve the accuracy of those models\\nDeploy the models in production where it will serve customers in real time\\nPut on the hacker's hat quickly convert an idea to a demonstration\\nPresent your work to the internal and external community\\nWork alongside senior machine learning researchers and define the right solution to implement\\n\\nWhat you will have:\\n\\n7+ years of experience in Software engineering.\\nAbility to write high performance production quality code. Experience in Python, Scala and other equivalent languages is a plus.\\nFunctional programming experience is a plus.\\nExperience building and productionizing innovative end-to-end Machine Learning systems.\\nGood understanding of common families of models, feature engineering, feature selection and other practical machine learning issues, such as overfitting.\\n\\nBonus Points\\n\\n\\nExperience building and/or maintaining machine learning models and pipelines\\nExperience building and maintaining large scale data pipelines in online advertising, recommender system, ecommerce or relevant areas\\nFamiliarity with Deep Learning.\\n\\nAbout Jet\\n\\nJet is reshaping ecommerce as we know it. Based in Hoboken NJ (just 10 min from Manhattan), we are a shopping site on the relentless pursuit to build the greatest shopping experience in the world. At Jet, we believe in bold. That means taking risks, asking \"why not\", looking where no ones looked before and bringing it! Our engineers are utilizing world class technologies, to optimize the supply chain, remove unnecessary costs, sprinkle in some surprise and delight all while saving customers every penny possible and we're just getting started. At Jet, we have worked hard to build a culture that stresses the importance of learning and sharing knowledge. If you want to be part of the team that is changing the shopping norm and learning a lot along the way, we have a hunch you'd look good in purple.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "14  BS level technical degree or equivalent experience; Computer Science or Engineering background preferred; Masters Degree desired.Experience with one of the following programming languages: Java, Python, Ruby, Node.js, C#, or C++Experience with Networking fundamentals, Security, Databases (Relational and/or NoSQL), Operating Systems (Unix, Linux, and/or Windows)Exposure to Agile development methodologies\\n\\nReturner Program Details:\\nReturn to work and come build the future of cloud computing with Amazon Web Services.The AWS Returners Program offers individuals who have been on a career break an opportunity to return to full time employment within a breadth of different roles. The program is designed to support Returners back into a permanent position, setting them up with the skills and knowledge needed for success at AWS!\\n\\nAmazon aims to be the most customer centric company on earth. Amazon Web Services (AWS) provides a highly reliable, scalable, low-cost infrastructure platform in the cloud that powers critical applications for hundreds of thousands of businesses in 190 countries around the world.\\n\\nWhat are we looking for?\\nIf you have been out of the workforce for longer than two years, and want to restart your career, the AWS Returners Program could be for you. As a Returner:\\nYou will bring your voice. At AWS we value individual expression, respect different opinions, and work together to create a culture where each of us is able to contribute fully.You will accelerate your growth. The scope and scale of what we do for our customers drive us to experiment with new possibilities, take risks and learn quickly.You will chart your own path. The possibilities you explore, the opportunities you take advantage of, and the impact you have is driven by your ideas and initiative.You will embrace the challenge. At AWS building the future is inspiring and fun and we embrace the challenge that comes with inventing and delivering things that were never thought possible.\\nYou will use our Leadership Principles every day. Whether discussing ideas for new projects or deciding on the best approach to solving a problem our Leadership Principles is just one of the things that makes Amazon peculiar. Learn more about our Leadership principles here.\\nWhat does the AWS Returners Program Offer?\\nIn Amazon Web Services, we don't mind being called \"peculiar.\" We have our own way of doing things. We're obsessed with customers, we see beauty in simplifying the complex, and we're comfortable with being misunderstood. That might sound unorthodox, but our unusual approach and our culture - focused on removing obstacles so builders can build - are part of why our employees enjoy working in AWS.\\n\\nAWS is helping over a million customers in 190 countries leverage the power of cloud computing. Being a global company isn’t just about worldwide availability or working with international customers; we also see the value in building global teams. Here are some of the great benefits that you’ll get from joining us on our program.\\n\\nFor more information please visit.\\nhttps://www.amazon.jobs/en/landing_pages/awsreturners\\n\\nProfessional Services:\\n\\nWe are looking for motivated technologists who possess a unique balance of technical depth, business knowledge, and strong interpersonal skills who have been on a career break an opportunity to return. This program is designed to help and support you back into a full-time permanent role. Our goal is to set you up with the skills and knowledge you need for success.\\n\\nDuring your first 6 months as a Returner, you will receive instruction and on-the-job training on a range of AWS services and solutions. By the end of the first year, you will choose a specialty track suited to your strengths and preferences (subject to business availability). These tracks include:\\n\\nApplication Developer – AppDev resources are specialists in designing applications that run natively in the cloud. They are experts in building programs that run on any number of platforms including virtualized instances, containers, or serverless architecture.\\nCloud Infrastructure Architect – An expert in cloud-based networking and system rollouts. CIAs specialize in network performance, infrastructure provisioning, and building Application Programming Interfaces (APIs).\\nDevOps Specialist – A leader in building advanced computing systems that harness continuous integration/continuous deployment pipelines and utilize the strengths of cloud computing to build scalable and economical systems for customers.\\nData Lake & Analytics Specialist – This role will specifically focus on data processing capabilities and helping our customers and partners to remove the constraints that prevent our customers from leveraging their data to develop business insights. Engagements will include migration of existing applications and development of new applications using AWS cloud services.\\nData Warehouse & Massive Parallel Processing Specialist – This role will specifically focus on large scale data warehousing and database migration capabilities. Engagements will include Redshift implementations and helping customers to migrate from their existing on-premises data warehouses using other databases to Amazon Redshift.\\nData & Machine Learning Engineer – In this role, you will work with our partners and customers with a focus on our AWS Analytics and ML services offering such Amazon Kinesis, AWS Glue, Amazon Redshift, Amazon EMR, Athena, Amazon SageMaker, and more. You will help our customers and partners to remove the constraints that prevent them from leveraging their data to develop business insights.\\n\\nOur consultants deliver proof-of-concept projects, topical workshops, and lead implementation projects. These professional services engagements focus on key customer solutions such as, web applications, enterprise applications, HPC, batch processing and big data, archiving and disaster recovery, education and government.\\n\\nResponsibilities include:\\nExpertise - Collaborate with AWS field sales, pre-sales, training and support teams to help partners and customers learn and use AWS services such as Amazon Elastic Compute Cloud (EC2), Amazon Simple Storage Service (S3), Amazon SimpleDB/RDS databases, AWS Identity and Access Management (IAM), etc.Solutions - Define and deliver on-site technical engagements with partners and customers. This includes participating in pre-sales on-site visits, understanding customer requirements, and proposing and delivering packaged offerings, and delivering custom solution engagements.Delivery - Engagements include short on-site projects proving the use of AWS services to support new distributed computing solutions that often span private cloud and public cloud services. Engagements will include migration of existing applications and development of new applications using AWS cloud services.Insights - Work with AWS engineering and support teams to convey partner and customer needs and feedback as input to technology roadmaps. Share real world implementation challenges and recommend new capabilities that would simplify adoption and drive greater value from use of AWS cloud services.\\n\\nTroubleshooting: Experience with QA, testing, helpdesk, IT support, or any technician or quality assurance type workCloud Awareness: Experience implementing a cloud-based technology solutionExperience with systems administration (Linux/Windows) or network administration (DNS, IPsec, BGP, VPN, Load Balancing)Scripting skills (e.g. Powershell, Python, Bash, Ruby, Perl, etc.)Passion for experiencing new technologies, cultures, and locations in the US and around the world\\nAmazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation/Age\\n\\nPursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.\\n\\nPursuant to the Los Angeles Fair Chance Ordinance, we will consider for employment\\nqualified applicants with arrest and conviction records.  \n",
       "15  Who are we?\\n\\nSidewalk Labs is an Alphabet company tackling the challenges of urban growth. Our vision for cities is rooted in a cross-disciplinary approach that is reflected in our team, composed of experts from real estate, government, finance, technology, engineering and more. Since its founding in 2015, Sidewalk Labs has evolved into an organization of over 100 employees based primarily in New York and Toronto.\\n\\nWe are currently designing a new kind of mixed-use, complete community on Toronto's waterfront in partnership with the tripartite agency Waterfront Toronto and the local community. This joint effort, called Sidewalk Toronto, will combine forward-thinking urban design and new digital technology to create a people-centered neighborhood that achieves precedent-setting levels of sustainability, affordability, mobility, and economic opportunity.\\n\\nWe are working to achieve something unprecedented — help us build it.\\n\\nWhat is the role?\\n\\nTo improve sustainability in cities, Sidewalk Labs is developing new technology that will drastically reduce greenhouse gas emissions compared to the status quo, empower smarter management of resources, and reduce the cost of future upgrades and maintenance. We plan for a 75%-85% reduction in greenhouse gas emissions compared to similar projects, aiming for Climate Positive.\\n\\nTo achieve our sustainability goals in Quayside, we plan to pilot and scale different kinds of innovation to tackle the thorniest problems in building environment performance. Success requires bold innovation around electricity and thermal systems.\\n\\nWe are looking for a machine learning engineer to join our team in our New York City office. In your first project you will build models and programs that reduce energy use in buildings and cut greenhouse gas emissions through analysis of building management system (BMS) data and other similar systems.\\n\\nIt's a bonus (but not a requirement) if you are familiar with building systems and IoT sensors, their data, and analysis of it (e.g., HVAC, occupancy, temperature, lighting, etc.).\\n\\nWhat is required is passion for sustainability and the desire to create a climate positive community.\\n\\nWhat you have you achieve:\\nWithin your first 6 months, you will:\\n\\nBuild from scratch our initial models for studying and reducing energy usage.\\nModel energy use and reductions, including creating regression-based energy baselines.\\nBuild and refine recommendation engines and predictive models (e.g. time to reach set point, monthly energy consumption).\\nCreate dashboards and interactive visualizations to share ongoing data.\\nDesign communication models catered to cohorts.\\nDesign and build data pipelines and processes for optimal and secure processing of complex data sets.\\nDevelop methods and naming schemas to unify (messy) data from building systems, sensors, APIs, and other sources, enabling a streamlined way to analyze data and prototype use cases.\\nBuild in security and privacy by design.\\n\\nWhat we expect:\\n\\nKnow your computer science.\\nHave a CS background to choose the right algorithms, systems approaches and patterns to solve problems without reinventing the wheel.\\nCandidates must be able to hit the ground running. Therefore, we generally look for 3+ years of industry experience in a world-class engineering organization.\\nExperience with Python and at least one systems programming language (C++, Java, or Go). Experience with Google Cloud Platform and/or Kubernetes a plus\\nHave in-depth experience delivering algorithms and implementing end-to-end data processing pipelines.\\nBe a technologist.\\nBias towards action and shipping. Once you've sketched out an idea, you find the fastest path to a prototype to prove the concept.\\nYou are obsessed with privacy and constantly ask how we can build privacy into product design.\\nBe comfortable with a range of languages and open source tools and frameworks, and make good decisions about which to use to solve a problem. You are excited to learn something new when the need arises.\\nBe creative: you'll come up with new ideas based on your broad understanding of technological possibilities and city domain knowledge.\\nSolve problems, together.\\nCome up with novel solutions, working well with technologists and non-technologists alike.\\nAsk hard questions and challenge assumptions to ensure that we're solving the right problems.\\nHave flexibility to work on the team's most pressing problems.\\nPassionate about cities.\\nYou have thought about the urban environment and care deeply about improving the lives of urban citizens.\\n\\nWe are very excited to hear from you.\\n\\nThe community of the future is a place for everyone, and Sidewalk Labs is proud to be an equal opportunity employer. We encourage members of underrepresented communities to apply. All employment is based on merit and business need.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "16  The search team at Walmart Labs and Jet is dedicated to the mission of helping millions of customers every day in finding the right products. We are at the forefront of attacking one of the most complex problems of e-commerce. Whenever a user types in a query or browses through product categories on the web site, phone or iPad, our service goes to work. We mine billions of search queries and tens of millions of products to find the most relevant products for our customers. Team members take end-to-end responsibility in analyzing large amounts of data, creating complex models, improving their accuracy and deploying these models to serve customers. E-commerce product search, much like web search, has always been a fertile area of AI innovation. Search algorithm team at Walmart Labs and Jet is working on fascinating AI/ML problems like deep NLP based query understanding, improving relevance ranking of products, semantic matching of query item pairs using embeddings, visual search to enable search by image, etc. As part of this team, you'll solve some of the most challenging and impactful problems in machine learning, information retrieval, natural language processing, computer vision or statistical measurement. Your work will be visible to hundreds of millions of customers and you will have a direct impact on the goals of the Fortune #1 company. If you speak and think machine learning then we want to talk to you. Come join our team and be part of this exciting journey.\\n\\nWhat you will do:\\n\\nBuild advanced machine learning models and improve the accuracy of those models\\nDeploy the models in production where it will serve customers in real time\\nPut on the hacker's hat quickly convert an idea to a demonstration\\nPresent your work to the internal and external community\\nWork alongside senior machine learning researchers and define the right solution to implement\\n\\nWhat you will have:\\n\\n4+ years of experience in Software engineering.\\nAbility to write high performance production quality code. Experience in Python, Scala and other equivalent languages is a plus.\\nExperience building and productionizing innovative end-to-end Machine Learning systems.\\nGood understanding of common families of models, feature engineering, feature selection and other practical machine learning issues, such as overfitting.\\n\\nBonus Points\\n\\n\\nExperience building and/or maintaining machine learning models and pipelines\\nFunctional programming experience is a plus.\\nExperience building and maintaining large scale data pipelines in online advertising, recommender system, ecommerce or relevant areas\\nFamiliarity with Deep Learning.\\n\\nAbout Jet\\n\\nJet is reshaping ecommerce as we know it. Based in Hoboken NJ (just 10 min from Manhattan), we are a shopping site on the relentless pursuit to build the greatest shopping experience in the world. At Jet, we believe in bold. That means taking risks, asking \"why not\", looking where no ones looked before and bringing it! Our engineers are utilizing world class technologies, to optimize the supply chain, remove unnecessary costs, sprinkle in some surprise and delight all while saving customers every penny possible and we're just getting started. At Jet, we have worked hard to build a culture that stresses the importance of learning and sharing knowledge. If you want to be part of the team that is changing the shopping norm and learning a lot along the way, we have a hunch you'd look good in purple.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "17  Getting together with real people in real life makes powerful things happen. Side hustles become careers, ideas become movements, and chance encounters become lifelong connections. Meetup brings people together to build thriving communities. Show up. Change lives.\\n\\nEvery year, millions of people RSVP to an eclectic variety of Meetups around the world. Activity on Meetup is growing faster than ever and by studying it, we're learning how to help members discover the groups and events that are right for them -- sparking new ways to make their worlds come alive than ever before. We are a collaborative and dedicated team seeking machine learning engineers to join us in designing and building the future vision of Meetup.\\n\\nRole and responsibilities\\n\\nYou imagine a world more easily connected, where people come together in real life, meet, and do more of the things that empower personal growth through real human connections. We are looking to add engineers to our machine learning team to:\\n\\n\\nUse machine learning to improve Meetup's recommendation, search and notification systems\\nDesign, build, and own every aspect of our low-latency personalization platform\\nDevelop your leadership skills while mentoring other specialists\\nCollaborate with product and design to leverage data and algorithms to improve user experience\\nRecruit and present on behalf of Meetup at technical conferences and Meetup events\\n\\nPreferred qualifications:\\n\\nBS+ degree in Computer Science, Engineering, Statistics or related STEM field\\n5+ years work/educational experience with recommendations, predictions, or NLP\\nContributed to a large codebase in Scala (most of our codebase), Java or Python\\nHands-on experience using machine learning frameworks to robustly build, validate, test, and monitor statistical models\\nImplement machine learning algorithms in cloud (AWS) and horizontally scalable environments (MapReduce, Hadoop, Spark)\\nExperience with both relational and NoSQL (DynamoDB, Redis) databases and RESTful APIs\\n\\nOur values:\\nMeetup employees are bold, supportive, and passionate about enabling people coming together and creating the future of real community; a future where people embrace their differences and similarities, show up, do things, and turn to each other to improve their lives. We care about moving fast, real-world change, and proud to be an equal opportunity employer committed to hiring and developing diverse, dynamic teams in a safe and inclusive environment.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "18  B.S. degree in mathematics, statistics, computer science or a similar quantitative field5+ years work experience in relevant fieldExperience in using SQL to analyze data in a database or data warehouse and be able to use a major programming (e.g. Java/C) and/or a scripting language (Perl, Unix shell, Python) to process data for modelingExperience working with a wide range of predictive and decision models and data mining techniques, as well as tools for developing such models\\n\\nExcited by using massive amounts of data to develop Machine Learning (ML) and Deep Learning (DL) models? Want to help the largest global enterprises derive business value through the adoption of Artificial Intelligence (AI)? Eager to learn from many different enterprise’s use cases of AWS ML and DL? Thrilled to be key part of Amazon, who has been investing in Machine Learning for decades, pioneering and shaping the world’s AI technology?\\n\\nAt Amazon Web Services (AWS), we are helping large enterprises build ML and DL models on the AWS Cloud. We are applying predictive technology to large volumes of data and against a wide spectrum of problems. Our Professional Services organization works together with our AWS customers to address their business needs using AI.\\n\\nAWS Professional Services is a unique consulting team. We pride ourselves on being customer obsessed and highly focused on the AI enablement of our customers. If you have experience with AI, including building ML or DL models, we’d like to have you join our team. You will get to work with an innovative company, with great teammates, and have a lot of fun helping our customers.\\n\\nIn our Global Specialist Practice, you will also have the opportunity to create white papers, write blog posts, build demos and other reusable collateral that can be used by our customers, and you will work closely with our Solution Architects and Service Engineering teams.\\n\\nIf you do not live in a market where we have an open Data Scientist position, please feel free to apply. Our Data Scientists can live in any location where we have a Professional Service office.\\n\\nA successful candidate will be a person who enjoys diving deep into data, doing analysis, discovering root causes, and designing long-term solutions. It will be a person who likes to have fun, loves to learn, and wants to innovate in the world of AI. Major responsibilities include:\\n\\nUnderstand the customer’s business need and guide them to a solution using our AWS AI Services, AWS AI Platforms, AWS AI Frameworks, and AWS AI EC2 Instances .Assist customers by being able to deliver a ML / DL project from beginning to end, including understanding the business need, aggregating data, exploring data, building & validating predictive models, and deploying completed models to deliver business impact to the organization.Work with our Professional Services Big Data/Analytics consultants to analyze, extract, normalize, and label relevant data.Work with our Professional Services consultants and customer teams to help our customers operationalize models after they are built.Assist customers with identifying model drift and retraining models.Research and implement novel ML and DL approaches, including using FPGA.\\n\\nExperience in data modeling, ETL development, and Data warehousing.Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data setsData Warehousing Experience with Oracle, Redshift, etcExperience with software coding practices is a strong plus.Experience using Linux/UNIX to process large data setsMeets/exceeds Amazon’s functional/technical depth and complexity for this roleExperience with AWS technologies like Redshift, S3, EC2, Data Pipeline, & EMRCombination of deep technical skills and business savvy enough to interface with all levels and disciplines within our customer’s organization\\nDemonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment\\nAmazon is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "19  At Spotify, we’re proud of our ambitious mission of having 1 billion fans enjoying music around the world, and are seeking a lead machine learning engineer to join us in pursuit of this goal. Our team leverages machine learning to drive both advertiser outcomes and listener satisfaction in Spotify Free, helping democratize music access globally while positively impacting Spotify’s bottom line. We develop innovative solutions around the core problem of getting the right ad to the right user at the right time, while embodying Spotify’s values and taking our users’ best interest at heart.\\n\\nWhat you’ll do\\n\\nHelp give hands-on technical leadership to one of Spotify’s most important business areas, monetization in our free product of 100+ million monthly active users.\\nDrive collaboration with other engineers, product managers, and designers across our team to make it easier to deliver best-in-class ML-powered listening experiences through shared platforms, tools, and approaches building on our use of Scala/Java and the GCP ecosystem\\nBe a leading voice in an active community of machine learning practitioners across Spotify\\nBuild or improve features that impact our users and make them better utilizing ML\\nTake on complex data-related problems using some of the most diverse datasets available\\nImprove our features through the usage of offline and online tests\\nDevelop individually to continue to grow your impact, and help mentor peers\\nWho you are\\n\\nYou have expertise and excitement about machine learning, including deep familiarity with the state-of-the-art as reflected in research at conferences, e.g. RecSys, ICML, or NeurIPS, and / or in practice at other leading internet companies\\nYou are an expert at architecting data pipelines and are self-sufficient in getting the data you need to build and evaluate your models, using tools like Apache Beam or Spark.\\nYou have 7+ years of professional engineering experience working in a product-driven environment with technologies (Scala, Java, Python, or C++) and cloud platforms (GCP or AWS).\\nYou have 4+ years of machine learning product development experience focused on content generation, personalization, or measurement, leveraging large scale data with broad impact using technologies like TensorFlow or XGBoost.\\nYou care about agile software development and a culture of constant learning and improvement\\nYou have experience and passion for mentoring and encouraging collaborative teams.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "20  The search team at Walmart Labs and Jet is dedicated to the mission of helping millions of customers every day in finding the right products. We are at the forefront of attacking one of the most complex problems of e-commerce. Whenever a user types in a query or browses through product categories on the web site, phone or iPad, our service goes to work. We mine billions of search queries and tens of millions of products to find the most relevant products for our customers. Team members take end-to-end responsibility in analyzing large amounts of data, creating complex models, improving their accuracy and deploying these models to serve customers. E-commerce product search, much like web search, has always been a fertile area of AI innovation. Search algorithm team at Walmart Labs and Jet is working on fascinating AI/ML problems like deep NLP based query understanding, improving relevance ranking of products, semantic matching of query <-> item pairs using embeddings, visual search to enable search by image, etc. As part of this team, you'll solve some of the most challenging and impactful problems in machine learning, information retrieval, natural language processing, computer vision or statistical measurement. Your work will be visible to hundreds of millions of customers and you will have a direct impact on the goals of the Fortune #1 company. If you speak and think machine learning then we want to talk to you. Come join our team and be part of this exciting journey.\\n\\nWhat you will do:\\n\\nBuild advanced machine learning models and improve the accuracy of those models\\nDeploy the models in production where it will serve customers in real time\\nPut on the hacker's hat quickly convert an idea to a demonstration\\nPresent your work to the internal and external community\\nWork alongside senior machine learning researchers and define the right solution to implement\\n\\n\\nWhat you will have:\\n\\n7+ years of experience in Software engineering.\\nAbility to write high performance production quality code. Experience in Python, Scala and other equivalent languages is a plus.\\nFunctional programming experience is a plus.\\nExperience building and productionizing innovative end-to-end Machine Learning systems.\\nGood understanding of common families of models, feature engineering, feature selection and other practical machine learning issues, such as overfitting.\\n\\n\\nBonus Points\\n\\nExperience building and/or maintaining machine learning models and pipelines\\nExperience building and maintaining large scale data pipelines in online advertising, recommender system, ecommerce or relevant areas\\nFamiliarity with Deep Learning.\\n\\nAbout Jet\\n\\nJet is reshaping ecommerce as we know it. Based in Hoboken NJ (just 10 min from Manhattan), we are a shopping site on the relentless pursuit to build the greatest shopping experience in the world. At Jet, we believe in bold. That means taking risks, asking “why not”, looking where no ones looked before and bringing it! Our engineers are utilizing world class technologies, to optimize the supply chain, remove unnecessary costs, sprinkle in some surprise and delight all while saving customers every penny possible and we’re just getting started. At Jet, we have worked hard to build a culture that stresses the importance of learning and sharing knowledge. If you want to be part of the team that is changing the shopping norm and learning a lot along the way, we have a hunch you’d look good in purple.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "21  (We are not sponsoring for this role or in the future)\\nAt Fareportal, we create technology that is driving innovation in the travel industry - one of the world's fastest-growing sectors. Our employees are the core of our organization and together we're revolutionizing the way people book travel.\\nOur portfolio of brands including CheapOair and OneTravel receive over 100 million visitors annually and drive over $4 billion in annual revenue.\\nWe are looking for a Lead Machine Learning Engineer/Data Scientist to join our team. You will be handling hundreds of millions of events per day, responsible for creating and supporting machine learning models that will drive our business.\\nMachine Learning Engineers is at the heart of how Fareportal works and they are part software engineer and part machine learning / data scientist. You will focus on creating and supporting large scale models that we deploy to power our recommendation, pricing or other systems. The ideal candidate will participate in the design and implementation of the entire model pipeline, from project ideation, figuring out which data to capture and store, coming up with features, to creating the final model.\\nWe are passionate about making data-driven decisions and you will have the opportunity to shape the team's direction and create large impact.\\nOur team loves Python and Scala (and is not afraid of Functional Programming) and we strongly encourage DevOps approaches.\\nResponsibilities:\\nLead a team of machine learning engineers, data scientist, data engineers\\nSupport our data modeling efforts to ensure we are capturing the data needed to improve our modeling capabilities.\\nCreate features for our feature store\\nBuild machine learning models\\nUse a variety of techniques including predictive modeling, recommendation engines, revenue management, conversion rate optimization, and site and user experience optimization.\\nOur ideal candidate:\\nWho You Are\\nYou are smart and love to build systems that are well tested as well as flexible\\nYou like being around smart people who will challenge you on a daily basis.\\nYou love to ramp up on new technologies to build awesome things with us!\\nPassionate about working with large unstructured and structured data sets and developing new approaches to relevance problems\\nYou like to share your knowledge and guide other fellow data scientist and engineers\\nRequirements\\n5+ years' experience developing, maintaining, and testing machine learning models.\\nA strong technical advocate with a background in Java, Scala, or Python. Preferably familiar with Jupyter notebook environments and Spark or pySpark.\\nStrong understanding of the machine learning tooling for either Python or Scala (e.g. Pandas, XGBoost, Spark)\\nStrong understanding of machine learning\\nNice to have\\nExperience with CI/CD infrastructure and a strong supporter of unit / integration testing\\nfEvhxhNuhl                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "22  About Chase\\nJPMorgan Chase & Co. (NYSE: JPM) is a leading global financial services firm with assets of $2.6 trillion and operations worldwide. The firm is a leader in investment banking, financial services for consumers and small business, commercial banking, financial transaction processing, and asset management. We serve millions of consumers in the United States and many of the world's most prominent corporate, institutional and government clients under our J.P. Morgan and Chase brands. Information about JPMorgan Chase & Co. is available at www.jpmorganchase.com.\\nChase Consumer & Community Banking serves nearly 66 million consumers and 4 million small businesses with a broad range of financial services, including personal banking, investment advice, small business lending, mortgages, credit cards, payments and auto financing. In recent years, we have undertaken a large-scale digital transformation initiative, building on the success of our current mobile and online service offerings. The Digital team is responsible for building innovative platforms and developing new products that make banking and payment tasks simpler and more personalized for our customers, as well as deepen customer engagement and loyalty with more relevant offers and services. The ambition is to position Chase as the undisputed leader in digital financial services and payments, and to enable highly personalized, real-time experiences that customers increasingly expect. We function similar to a fintech start-up in our brand new offices that inspire collaboration, transparency, agile development, and a fun working environment.\\n\\nDescription:\\nThis role is being offered within JPMorgan Chase Digital Intelligence organization. DI is responsible for creating advanced and intelligent capabilities for our consumer products. We work closely with our Digital Technology engineering team to bring these solutions to market. It is a fast paced and dynamic environment, where we work with many business and product owners in addition to focusing on technical deliveries. Understanding and interacting with the business is a key component to the success of our work where success is defined as bringing value to our customers.\\nThe candidate needs to have significant training and working experience in computer science/software engineering, with large and real-time computational experience. He/she needs to have demonstrated experience in implementing and deployment of large-scale production system certain advanced computational algorithms. Big-Data platform work experience is a must, i.e. worked and maintained HBase, Hadoop, Spark, etc. where the candidate has been a key team player. The candidate needs to have significant software engineering work experience, where he/she has been responsible for bringing a complete system to production end-to-end, working with DevOps and various levels of production engineering teams.\\n\\nQualifications:\\n\\nRequired:\\n\\n3+ years of software engineering/developer and production experience\\n\\n1- 3 years of experience in big-data\\n3+ years of big-Data platform engineering\\n\\n3+ years of parallel computing\\n\\nMinimum Master’s degree in engineering disciplines (candidate’s bachelor degree needs to be engineering focused as well), with the focus in computer science and related extended core training and experience. Candidates with equivalent work experience are also highly desirable.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "23  Role Specification:\\n5+ years of professional experience in Data Science, 3+ years in Healthcare preferred\\nPostgraduate qualification in Computer Science, Biostatistics, or other Quantitative Field from top school (PhD Preferred)\\nHands-on experience on writing production-level machine learning code\\nExposure to standard ML tooling – Python, R, and TensorFlow/Torch libraries\\nExcellent communication skills\\nExcellent critical thinking and problem-solving skills\\nHigh motivation, good work ethic and maturity\\nRole Description\\nWork closely with VP of Data Science and Sales Team to map, execute and track technical AI/ML engagements with large clients in Healthcare, covering Payer, Life Sciences, Medical Technologies, and Provider markets\\nWork in a high growth environment, with the goal of significantly augmenting the capabilities of the data science team, and the implementation of valuable technologies for our partners\\nLead a team or teams of US based / offshore based Data Scientists building ML solutions end-to-end\\nHigh visibility role, interacts with execs from major players in healthcare industry\\nJob Responsibilities\\nEstablish project scope and roadmap, including data strategy, needed to develop production-level predictive pipelines that solve large scale problems for clients in the space\\nHelp develop, implement and document rigorous methodology to plan, track and improve accuracy and relevance of models\\nLead internal communication with stakeholders, and ensure delivery of the project per commitment\\nCollaborate with clients and other stakeholders to effectively integrate and communicate findings and use cases\\nProvide guidance and project management support to the Associates on the team\\nExperience building predictive models allows you to clearly determine team size and scope work needed to accomplish business goals\\nKnowledge of databases, data modeling, and data harmonization a must\\nEvaluate emerging technologies and alternative datasets that may contribute value to our existing platforms\\nContribute to the thought leadership of the company by publishing ML research and participating in relevant conferences in the space\\nHealthcare data familiarity, especially around claims and clinical data, is highly desirable\\n CitiusTech's data science approach is based on 3 focus areas:\\nData Science Consulting - Creation of an end-to-end AI / ML roadmap for healthcare organizations, including use cases and end-state visuals\\nModel Development - Data pre-processing, data quality improvement and data mining for the development of custom AI / ML models\\nModel Operationalization - Validation, deployment and monitoring of selected data science models, to generate actionable insights\\nAbout CitiusTech:\\nCitiusTech is a specialist provider of healthcare technology services and solutions to healthcare technology companies, providers, payers and life sciences organizations. With over 3000 professionals worldwide, CitiusTech enables healthcare organizations to drive clinical value chain excellence, across integration & interoperability, data management (EDW, Big Data), performance management (BI / analytics), predictive analytics & data science, and digital engagement (mobile, IoT). CitiusTech helps customers accelerate innovation in healthcare through specialized solutions, healthcare technology platforms, proficiencies and accelerators. Armed with cutting-edge technology & expertise, world-class service quality and a global resource base, CitiusTech consistently delivers best-in-class solutions along with an unmatched cost advantage to healthcare organizations worldwide.\\n\\nCitiusTech has been recognized as a great place to work by the Great Place to Work Institute® for seven consecutive years (2012 to 2018). CitiusTech has also been listed in the 2018 Healthcare Informatics (HCI) 100, placing it among the top 100 healthcare technology companies in the US, for the third consecutive year. CitiusTech has also been closely associated with key industry organizations, such as HIMSS, HL7, CHIME Foundation and AHIP.\\nmgHoXFUBgS                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "24  Location: New York\\nWe are currently seeking outstanding machine learning engineers to join our development team. Developers will work on the enhancement and maintenance of our data pipeline including middle-tier and back-end processes. They will gain and utilize experience in designing and implementing solutions for large scale machine learning systems and application server code on cloud offerings.\\nWe build with open source technology, using a newly created stack built from Tensorflow, gRPC, Elasticsearch, Redis, Kubernetes & GCP – we’re open to trying out new things to find the best tool for the job.\\n\\nSkills and Responsibilities\\n\\nResearch, design and prototype new models and approaches based on machine learning, esp. deep learning, and statistical analysis.\\nImplement and execute machine learning research with reliability and reproducibility.\\nFamiliarity with deep learning CV methods for localization, detection, classification or segmentation a plus.\\nDevelop proof-of-concept systems to demonstrate advanced model performance.\\nCollaborate with the rest of the engineering team to design and launch new features.\\nKeep up with deep learning literature and research publications in order to implement the latest techniques into our networks and pipelines.\\nUnderstanding and implementation of security and data protection.\\nExperienced in mainstream deep learning frameworks, such as PyTorch/Torch, TensorFlow, MxNet, Caffe, etc.\\nTurn models into data products, collaborate with engineering teams, and integrate into process throughout behold.ai.\\nExcellent knowledge of the latest developments in the deep learning field\\nKnowledge of code versioning tools such as Git, Mercurial or SVN\\nA PLUS IF\\n\\nYou have a Doctorate Degree or Master’s Degree in Statistics/Mathematics/Computer Science/Physics or similar with equivalent practical experience                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "25  PulsePoint™, a global programmatic advertising platform with specialized healthcare expertise, fuses the science of programmatic targeting, distribution, and optimization with the art of brand engagement. The PulsePoint platform is powered by terabytes of impression-level data, allowing brands to efficiently engage the right audiences at scale while helping publishers increase yield through actionable insights.\\n\\nOur organization has a strong history of utilizing machine learning, contextualization, and targeting to distribute advertising to the right consumers at the right time and create real connections across the internet. We are now taking that knowledge and expertise to solve challenges within healthcare in order to create better health outcomes through Radical Health Personalization™.\\n\\nThe goals of the PulsePoint Data Science team:\\n\\nOptimize and validate targeting mechanisms for specific health conditions\\nImprove and optimize our proprietary contextualization, and recommendation engines that handle hundreds of thousands of transactions per second, billions of times each month\\nCollaborate with internal Health experts to ideate and support rapid assessment, analysis, and prototyping of ideas for achievable commercialization.\\n\\nWhat you will be tasked to do:\\n\\nResearch and develop user profiling models to enhance our clinical trial recommendation engine to leverage both online and offline data.\\nCollaborate with Product teams on data-driven products to support clinical trial platform design and delivery.\\nSupport and enhance the existing work on health user profiling, prediction, and targeting tools.\\nContribute on future project on patient/physician identity for cross-device tracking, profiling and targeting.\\nSupport existing codebases for data integration and production support for our core models.\\n\\nWhat you need to be successful in this role:\\n\\n3+ years of full-time experience working as a Statistician/ Machine Learning Engineer/ Data Scientist\\nAdvanced knowledge of Big Data technologies such as Hadoop, Hive, and Impala\\nAdvanced knowledge of Python using the numpy/scipy/pandas/skilearn stack\\nMS/PhD in Astronomy, Physics, Applied Mathematics, Statistics, Machine Learning, Computer Science; or BS with several years of applied machine learning experience\\n\\n** All applicants must submit a code sample or a GitHub link to be considered **\\n\\nAt PulsePoint™, data is at the core of everything we do and Data Science is a high profile and high impact team, focusing on creating innovative solutions that rely on predictive modeling and big data analytics. We are looking for \"A\" players that have a combination of drive, focus, speed, efficiency and quality to drive statistical modeling, optimization and/or machine learning. You will be given ownership and autonomy over the research and development of your projects and will be expected to execute well and on time. We work on challenging problems that will make ads matter for people with health problems. Your work will directly influence our trajectory as a company.\\n\\nWhat we offer:\\n\\nSane work hours\\nGenerous paid vacation/company holidays\\nVacation reimbursement, sabbatical, pawternity leave, marriage leave, honeymoon bonus\\nComprehensive healthcare with 100%-paid medical, vision, life & disability insurance\\n$2,000 annual training and development budget\\nComplimentary annual memberships to One Medical, NY Citi Bike and SF Ford GoBike\\nMonthly chair massages\\nFree fitness classes (spin, yoga, boxing)\\nGym reimbursement, local gym membership discounts\\nOnsite flu shots, dental cleanings and vision exams\\nAnnual company retreat\\nPaid parental leave and a lot of new parent perks\\nEmergency childcare credits\\n401(k) Match and free access to a financial advisor\\nVolunteer Time Off and Donation Matching, ongoing group volunteer opportunities\\nTeam lunches, Sip & Social Thursdays, Game Nights, Movie Nights\\nHealthy snacks and drinks\\n\\nAnd there's a lot more!\\n\\nWant to peek inside the PulsePoint™ offices? Check it out here: https://www.themuse.com/profiles/pulsepoint ( https://www.themuse.com/profiles/pulsepoint )                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "26  MORE ABOUT THIS JOB\\nConsumer and Investment Management (CIMD)\\nThe Consumer and Investment Management Division includes Goldman Sachs Asset Management (GSAM), Private Wealth Management (PWM) and our Consumer business (Marcus by Goldman Sachs). We provide asset management, wealth management and banking expertise to consumers and institutions around the world. CIMD partners with various teams across the firm to help individuals and institutions navigate changing markets and take control of their financial lives.\\n\\nConsumer\\nConsumer, externally known as Marcus by Goldman Sachs, is comprised of the firm’s digitally-led consumer businesses, which include our deposits and lending businesses, as well as our personal financial management app, Clarity Money. Consumer combines the strength and heritage of a 150-year-old financial institution with the agility and entrepreneurial spirit of a tech start-up. Through the use of machine learning and intuitive design, we provide customers with powerful tools that are grounded in value, transparency and simplicity to help them make smarter decisions about their money.\\n\\nYour Impact\\nClarity Money is a business recently acquired by Goldman Sachs that offers a revolutionary AI- and machine learning-based product for consumers to improve their financial health. Ushering in a new era of mobile personal finance management apps, Clarity Money uses artificial intelligence and data science to help consumers make smarter financial decisions and get the most from their money. The revolutionary features allow users to cancel bills, get a better credit card and create a savings account, all from within the app, and all at the push of a button.\\n\\nThe Clarity Money team is actively seeking a motivated Data Engineer with proven industry experience in machine learning, data engineering and building robust data pipelines. Strong computer science fundamentals are key to success in this role. The ideal candidate should be an individual contributor, a positive team player and willing to get things done.\\nRESPONSIBILITIES AND QUALIFICATIONS\\nResponsibilities:\\nBuild platforms to accelerate deployment of ML/NLP/AI Models\\nBuild ETL pipelines to derive and store features and insights out of raw datasets\\nBuild orchestration using Airflow or other open sources libraries\\nDocument, design, code and test applications and model outcomes\\nWork on model explainability and governance\\nClosely collaborate with product and marketing teams on delivering new product features, perform exploratory data analysis and/or build data pipelines and APIs\\nBuild measure and report KPIs and explain complex concepts in non-technical terms\\n\\nQualifications:\\nAt least a Bachelor’s degree, preferably in a quantitative/STEM field - Applied Mathematics, Physics, Engineering, Computer Science etc.\\n2+ years of open source Machine Learning algorithm development experience in Python and AWS\\n2+ years of building data pipelines, feature extractions, Flask/Django APIs and scalable model deployments\\n2+ years of experience with pandas, jupyter notebooks and sklearn\\n2+ years of hands on experience with advanced SQL queries and database knowledge of RDMS, Column based, NoSql, etc.\\n2+ years of experiences in working in AWS or other Cloud computing environments\\n\\nPreferred Qualifications\\n\\nMasters in Computer Science, Engineering or Information Systems\\n4+ years of experience in software development using Python, RESTful API, Spark, and ML libraries\\n4+ years of experience in cloud environments like AWS stack or GCP Stack\\nABOUT GOLDMAN SACHS\\nThe Goldman Sachs Group, Inc. is a leading global investment banking, securities and investment management firm that provides a wide range of financial services to a substantial and diversified client base that includes corporations, financial institutions, governments and individuals. Founded in 1869, the firm is headquartered in New York and maintains offices in all major financial centers around the world.\\n\\n© The Goldman Sachs Group, Inc., 2019. All rights reserved Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Vet.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "27  About Chase\\nJPMorgan Chase & Co. (NYSE: JPM) is a leading global financial services firm with assets of $2.6 trillion and operations worldwide. The firm is a leader in investment banking, financial services for consumers and small business, commercial banking, financial transaction processing, and asset management. We serve millions of consumers in the United States and many of the world's most prominent corporate, institutional and government clients under our J.P. Morgan and Chase brands. Information about JPMorgan Chase & Co. is available at www.jpmorganchase.com.\\nChase Consumer & Community Banking serves nearly 66 million consumers and 4 million small businesses with a broad range of financial services, including personal banking, investment advice, small business lending, mortgages, credit cards, payments and auto financing. In recent years, we have undertaken a large-scale digital transformation initiative, building on the success of our current mobile and online service offerings. The Digital team is responsible for building innovative platforms and developing new products that make banking and payment tasks simpler and more personalized for our customers, as well as deepen customer engagement and loyalty with more relevant offers and services. The ambition is to position Chase as the undisputed leader in digital financial services and payments, and to enable highly personalized, real-time experiences that customers increasingly expect. We function similar to a fintech start-up in our brand new offices that inspire collaboration, transparency, agile development, and a fun working environment.\\n\\nDescription:\\nThis role is being offered within JPMorgan Chase Digital Intelligence organization. DI is responsible for creating advanced and intelligent capabilities for our consumer products. We work closely with our Digital Technology engineering team to bring these solutions to market. It is a fast paced and dynamic environment, where we work with many business and product owners in addition to focusing on technical deliveries. Understanding and interacting with the business is a key component to the success of our work where success is defined as bringing value to our customers.\\nThe candidate needs to have significant training and working experience in computer science/software engineering, with large and real-time computational experience. He/she needs to have demonstrated experience in implementing and deployment of large-scale production system certain advanced computational algorithms. Big-Data platform work experience is a must, i.e. worked and maintained HBase, Hadoop, Spark, etc. where the candidate has been a key team player. The candidate needs to have significant software engineering work experience, where he/she has been responsible for bringing a complete system to production end-to-end, working with DevOps and various levels of production engineering teams.\\n\\nQualifications:\\n\\nRequired:\\n\\n3+ years of software engineering/developer and production experience\\n\\n1- 3 years of experience in big-data\\n3+ years of big-Data platform engineering\\n\\n3+ years of parallel computing\\n\\nMinimum Master’s degree in engineering disciplines (candidate’s bachelor degree needs to be engineering focused as well), with the focus in computer science and related extended core training and experience. Candidates with equivalent work experience are also highly desirable.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "28  Trilogy Education partners with universities to offer programs in Web Development, Data Analytics, UX/UI Design, Cybersecurity, and FinTech. Our platform combines a market-driven curriculum, robust career services, and a multinational community of universities, instructors, and employers to prepare adult learners for careers in the digital economy.\\n\\nOur programs have been in existence since 2015, and since then, we've launched an additional 300 classes across the nation. We have hired more than 1,900 Instructors and Teaching Assistants to support our students.\\n\\nThe Job:\\nWe are looking for an experienced Financial Engineer, Python or Machine Learning Engineer with Finance experience, or similar background to teach our part time FinTech class at Columbia University. Our instructors are an essential piece to our students experience with us. You must bring a positive attitude and be able to infuse empathy, support, encouragement and fun into the classroom. As an instructor you will need to have the ability to deliver our lesson plans that are being taught across the country; while at the same time, sharing your own professional experiences and industry insight with the students.\\n\\nOur Financial Technology Program:\\nThere is a parallel economy forming that is upending the financial system. From giant international firms to tiny startups, financial technology is starting to allow a whole new set of players to access financial data, and enabling a whole new generation of financial products and services.\\n\\nWhy teach with us?\\n\\nAre you passionate about education and making an impact? Do you love empowering others to find life-changing opportunities. We'd love to hear from you! If you bring knowledge, strong communication, and a positive energy to the classroom, you're going to help our students along their transformative path to a successful and rewarding career. Prior teaching experience isn't a prerequisite for success as an Instructor or Teaching Assistant within Trilogy.\\n\\nWe'll provide the guidance, training, lesson plans, and tools to support you on your journey of impacting lives in the classroom.\\n\\nWhat You Will Do:\\n\\nLead lectures and share your own personal experiences as an industry professional\\nFacilitate a hands on lab environment for students to gain real world knowledge\\nCoach students through coding activities and in-class projects\\nDistribute Class Materials and Recorded Lectures to set up students for success\\nEnsure a positive learning environment for students by infusing empathy and support into all that you do\\nBe a classroom manager and confirm students are engaged and learning at every turn\\nMake sure students are receiving timely feedback and grades on their assignments from you and your teaching assistants.\\n\\nExperience, or willingness to learn, the following Technologies is required:\\n\\n\\nFinance Fundamentals like Time Series Analysis and Financial Ratios\\nInvestment Principles\\nExcel and VBA\\nPython 3\\nPython Libraries such as Pandas, Matplotlib, NumPy, and more\\nAPIs\\nSQL and NoSQL Databases\\nAWS\\nMachine Learning Applied to Finance with Algorithmic Trading, Scikit-learn, and more\\nCryptocurrency Fundamentals\\nBlockchain technologies like Solidity, Ethereum, and Smart Contracts\\n\\nWhat makes you a great fit (Requirements):\\n\\nBachelor's Degree\\nMinimum of 5 years of work experience\\nA positive attitude\\nAbility to deliver our lesson plans that are taught in classrooms across the country to the student body\\nOpenness to share your own professional experiences and industry insight with the students\\nAbility to support our students individually as they go through an emotional roller coaster\\nBe able to infuse empathy, support, encouragement, and fun into the student experience\\n\\nLogistics:\\n\\n24-week program\\nMon/Wed/Sat OR Tue/Thu/Sat Schedule\\nWeekday Classes: 5:45pm - 10pm (includes office hours and break)\\nSaturday Classes: 9:30am - 2:30pm (includes office hours and lunch break)\\nzr\\n\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "29  On the Data Automation team, we develop machine learning models and infrastructure to extract key information from all kinds of financial documents such as analyst recommendations, corporate/municipal bond offerings, earnings releases. Our team has built some of the world's most sophisticated neural networks that have beaten the performance of even the best analysts in the market – often demanding 99.9% precision. The models we build enable our clients to get accurate answers fast. The work we do is critical, as a single prediction error can have a market moving effect.\\nAs part of our team, you will lead the research on cutting-edge ML/NLP techniques and design efforts for the most efficient and practical application of those techniques to complex business problems. You will utilize our automated ML suite, equipped with annotation platforms, for collecting training data and hyper-tuning models, as well as deploy your application on our scalable ETL infrastructure. If the idea of applying technology and information retrieval techniques to solve complex data problems excites you, keep reading.\\nIn the upcoming year, you should expect to work on the following:\\n Replace our traditional Seq2Seq and BiLSTM annotation models with modern BERT/ELMO language models\\n Employ weakly supervised learning approaches for understanding structural associations embedded in various document layouts\\n Apply advanced NLP techniques for multi-entity disambiguation and reinforcement learning to replace heuristic-based decision tree\\nYou will also collaborate closely with financial domain experts to gain valuable insights and leverage their business expertise to increase accuracy in annotating training data. A right combination of cross-field ML techniques, deep understanding of the business problem and high quality training data is fundamental to our models beating the precision of most academic and industry standards and presents a challenging opportunity! If this sounds like a challenge you are up for, please apply below.\\nWe'll trust you to:\\n Learn cutting-edge research in advanced ML & NLP topics and devise an efficient application for projects\\n Direct ML strategy for the team and work closely with the ML platform team, ETL infrastructure team as well as guide truth-gathering efforts\\n Drive, design & develop projects as the principal point-of-contact, with the ability to determine suitable ML models, direct feature engineering processes and negotiate KPIs per business needs\\n Participate in technical conferences, publish papers and evaluate new technologies\\nYou’ll need to have:\\n A strong statistical background in ML, NLP, deep learning models along with familiarity in probabilistic information retrieval and optimization methods\\n Professional experience of building and deploying ML apps to production\\n 2+ years of hands-on experience in Python/C/C++ development and knowledge of distributed, scalable architectures and CICD tooling\\n A solid understanding of data structures, algorithms and software design concepts\\n Strong communication skills and interest in learning financial product domains\\n BA, BS, MS, PhD in Computer Science, Data Science or related technology field\\nWe’d love to see:\\n Knowledge of advanced concepts such as weakly supervised learning, reinforcement learning and active learning\\n Familiarity with SQL and NoSQL data modeling and exploratory data visualization\\n Professional experience as a technology lead or architect\\n Authored research publications, participation in ML competitions, working demos/repos                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "30  Job Description\\n\\nThe knowledge platform team is seeking senior machine learning engineers to join our engineering team. Square is seeking senior machine learning engineers to build a company-wide state-of-the-art knowledge platform. Our goal is to provide tooling, infrastructure, and guidance to unify and level up the 50-100 engineers and data scientists working on ML at Square and work on advanced ML solutions that are applicable across the company. The ideal candidate will have industry experience in solving and optimizing large-scale machine learning problems. We are looking for passionate and self-driven innovators to help us build this V1 platform from the ground up and be part of a fast-paced team. You will be expected to contribute in building ML systems/tooling and building advanced ML models that scale. You will have a wide impact across the company with opportunity to publish papers, contribute to open-source, influence and collaborate with the data science community across Square.\\n\\nQualifications\\n\\nYou have:\\nExperience in many of the following areas is highly desired - AutoML, Knowledge Graphs, recommendation systems, NLP and AI Agents.\\nExperience with cloud computing platforms, such as AWS, Google Cloud or Azure.\\nExperience in designing and productionizing large-scale distributed systems built around machine learned models and big data.\\nExperience or familiarity with interpretable machine learning is a plus.\\nAbility to produce scalable and robust production-quality code incorporating testing, evaluation, and monitoring.\\nAn advanced degree (PhD or MS) in Computer Science\\nTechnologies we use:\\nJava, Python, Google Cloud Platform, AWS, Snowflake\\nPython ML stack (pandas, scikit-learn, etc.)\\nAdditional Information\\n\\nAt Square, our purpose is to empower – within and outside of our walls. In order to build the best tools for the businesses and customers we support all over the world, we have to start at home with a workforce as diverse and empowered as our sellers. To this end, we take great care to evaluate all employees and job applicants equally, based on merit, competence, and qualifications. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any other characteristic protected by law. We encourage candidates from all backgrounds to apply and always consider qualified applicants with arrest and conviction records, in accordance with the San Francisco Fair Chance Ordinance. Applicants in need of special assistance or accommodation during the interview process or in accessing our website may contact us by sending an email to assistance(at)squareup.com. We will treat your request as confidentially as possible. In your email, please include your name and preferred method of contact, and we will respond as soon as possible. Perks At Square, we want you to be well and thrive. Our global benefits package includes: Healthcare coverage, Retirement Plans, Employee Stock Purchase Program, Meal reimbursements, Wellness perks, Paid parental leave, Flexible time off, Learning and Development resources                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "31  MORE ABOUT THIS JOB\\nWhat We Do\\nAt Goldman Sachs, our Engineers don’t just make things – we make things possible. Change the world by connecting people and capital with ideas. Solve the most challenging and pressing engineering problems for our clients. Join our engineering teams that build massively scalable software and systems, architect low latency infrastructure solutions, proactively guard against cyber threats, and leverage machine learning alongside financial engineering to continuously turn data into action. Create new businesses, transform finance, and explore a world of opportunity at the speed of markets.\\n\\nEngineering, which is comprised of our Technology Division and global strategists groups, is at the critical center of our business, and our dynamic environment requires innovative strategic thinking and immediate, real solutions. Want to push the limit of digital possibilities? Start here.\\n\\nWho We Look For\\nMotivated Data Engineer with proven industry experience in machine learning, data engineering and building robust data pipelines. Strong computer science fundamentals are key to success in this role. The ideal candidate should be an individual contributor, a positive team player and willing to get things done.\\nRESPONSIBILITIES AND QUALIFICATIONS\\nResponsibilities:\\nBuild machine learning and NLP models to build new product features and improve business metrics.\\nPerform exploratory data analysis and causation/attribution/correlation identifying key insights to help decisions and business strategy.\\nDocument model explainability and decay and deploy models with proper governance.\\nWork with product managers, engineers, marketers and designers, and senior executives to optimize key translate business insights into decisions and action\\nBuild and improve our machine learning deployment and data pipeline platforms.\\n\\nQualifications\\nBachelor’s Degree in a field like computer science, statistics, economics or applied math.\\nStrong knowledge of statistical analysis and exploratory data analysis techniques for prescriptive analytics.\\nProfessional experience in an advance analytics-based data science/ machine learning engineer or stats role.\\nProfessional experience working in cloud environment like AWS.\\nStrong knowledge of machine learning concepts like regression, classification, clustering, heuristics, boosting, feature engineering, etc.\\nStrong Proficiency in SQL, notebooks and Python.\\nUnderstanding of open source libraries for solving orchestration, model deployment, model explainability and management.\\nBasic understanding of new deep learning techniques like GANs, RNNs, CNNs and platforms like keras/tensorflow used to implement these.\\n\\nWhy Goldman Sachs\\nUnparalleled responsibility and career opportunity to make a highly visible global impact\\nYou will be part of a large community of like-minded technologists in a flat organization with a culture that promotes collaboration, “can do” mindsets and teamwork\\nResponsibility for requirements gathering, analysis, design and development of funding systems\\nForge strong relationships with our clients across all of our businesses, as well as other technology teams to develop and enhance our systems and processes\\nDevelop solutions that directly impact the bottom line by enabling new investment opportunities for our business partners\\nOpportunity to work on unprecedented projects both at Goldman Sachs & more broadly in the financial services industry\\nABOUT GOLDMAN SACHS\\nThe Goldman Sachs Group, Inc. is a leading global investment banking, securities and investment management firm that provides a wide range of financial services to a substantial and diversified client base that includes corporations, financial institutions, governments and individuals. Founded in 1869, the firm is headquartered in New York and maintains offices in all major financial centers around the world.\\n\\n© The Goldman Sachs Group, Inc., 2019. All rights reserved Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Vet.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "32  Join our team @ Eskalera! A super{set} venture studio company\\nDATA SCIENCE ENGINEER\\nLOCATION: San Francisco or New York City\\nAt Eskalera, our ultimate vision is an environment where every worker, regardless of background, pedigree, race, geography etc, gets a fair shot, and where AI and data-driven methods measurably improve results for progressive businesses that recognize people and talent as their most critical asset. The key to our and our clients’ success is rooted in constructing inclusive cultures.\\nAbout the Role\\nSo, you can query large amounts of data using your favorite big-data toolkits, analyze it using established statistical and machine learning techniques, and communicate the derived insights through clear and concise charts and reports. You are a technologist at heart always seeking to push the current boundaries to process more data and run more sophisticated machine learning algorithms. In your past, you may have doubled as a data scientist, a data engineer, or perhaps a machine learning engineer, but deep inside, all you really care about is building best in class products, applications, and systems that extract knowledge from data at any scale and deliver value to the business.\\nGreat, we are excited to talk to you! We're looking for people who get things done by using their smarts and whatever tools get the job done. Are you at the beginning of your career and this is where you see yourself in the future? Let us know; we love to work with bright people looking to grow.\\nYour Role:\\nR&D of cutting edge algorithmic solutions to real-world problems producing a shippable product as well as intellectual property (papers and patents).\\nUsing statistical and machine learning principles to discover hidden patterns, perform predictive analysis and build models that drive insights.\\nClean, transform and validate data for uniformity and accuracy.\\nDevise and utilize algorithms and statistical approaches to mine data stores, perform data analysis and improve model performance.\\nCommunicate findings internally and externally, generating reports and dashboards, building narratives that resonate with clients and stakeholders.\\nScale efforts to democratize data internally and externally, be an ambassador for data-driven culture.\\nBecome and stay an expert in current and emerging technologies, techniques, and tools.\\nYour Skills and Qualities:*\\n3+ years of professional data science related work\\nUnderstanding of key machine learning and data mining approaches.\\nA bayesian at heart but can report significance if asked.\\nUnderstand the fundamentals of computer science including programming principles, design patterns, database fundamentals, and distributed systems.\\nMake things work and get things done using the programming language of your choice (Python/Scala among others).\\nAre a great communicator, able to articulate complex concepts in easy to understand language.\\nLove to learn new things and can do so quickly.\\nLike working in, and being part of, interdisciplinary teams.\\nAbout Eskalera\\nEskalera enables large and medium-sized companies to transform their HR operations by improving employee engagement, productivity, and growth. Our end-to-end platform arms HR professionals with the most modern applications of AI, data science, and evidence-based findings on implicit bias and D&I. By capturing, processing, and analyzing data from easy-to-use experiences and integrating other available employee data, companies gain a real-time view of the zeitgeist of their employee base to drive measurable business results.\\nEskalera is proud to be an equal opportunity workplace. Individuals seeking employment at Eskalera are considered without regard to race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, veteran status, or sexual orientation.\\nWe do not accept resumes from headhunters, placement agencies, or other suppliers that have not signed a formal agreement with us.\\nThis is Eskalera: https://eskalera.com/about-us/\\nHow we are different?: https://eskalera.com/solutions/\\nJob Type: Full-time                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "33  Beeswax is looking for a Lead Machine Learning Engineer to join our growing team. We were recently recognized on the Inc. 5000 list as #46 in the fastest growing companies and #5 in the top software companies. In 2018, we were also named by Business Insider as the \"fastest growing company in AdTech\"\\n\\nBeeswax is an easy to use, massive scale and highly available advertising platform founded by industry veterans who worked together at Google. We're well funded by leading VCs, such as RRE and Foundry Group, and are rapidly expanding our customer list and our engineering team. We offer our customers the most extensible and transparent advertising platform in the world and process millions of transactions per second.\\n\\nOur engineers come from major tech companies such as Amazon and Facebook as well as many other companies with strong software disciplines. We take pride in our mission to build great advertising software.\\n\\nThe Optimization team at Beeswax is simplifying Real Time Bidding for our customers and making it easy for them to train and deploy machine learning models on our platform. To do that, we want to build systems that provide customers easy access to their data, algorithms to train their models and APIs to easily deploy and evaluate the performance of their models. We'll know we're successful when we see our customers actively using our ML workflow and bidding with much higher success and effectiveness rates when using these tools.\\n\\nWe are looking for a Lead Machine Learning Engineer for our Optimization team. The ideal candidate will have experience working on a range of optimization problems in a production environment, such as click-through rate prediction, click-fraud detection, payment fraud, search ranking, text/sentiment classification, viewability prediction, or spam detection.\\n\\nYour primary role will be to lead and grow a machine learning team to support both internal feature development and the creation of a framework our customers can use.\\n\\nResponsibilities\\n\\n\\nWork with customers and the product team to design optimization systems for both off-the-shelf use and customization through APIs\\nBuild and iterate on a workflow that enables our customers to take advantage of our data and ML infrastructure\\nDevelop highly scalable machine learning systems to automatically score and optimize real-time bidding advertising campaigns\\n\\nIdeal candidates will have:\\n\\nA minimum of 5 years experience building ML infrastructure and production models in a product driven driven environment\\nProficiency with statistics and statistical methods\\nExperience with scripting languages such as Python and libraries like Numpy/Pandas.\\nExperience using machine learning libraries or platforms including Tensorflow, Caffe, Scikit-Learn, ML lib in production.\\nExperience with data warehouses such as Snowflake, Redshift or Presto and data processing platforms such as Spark\\nExperience with stream processing such as Kinesis or Kafka is a plus.\\nAdTech experience is a plus\\n\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "34  Company\\n\\nWell-funded stealth company focused on disrupting healthcare through a differentiated consumer experience and a world-class data & analytics engine to drive engagement and behavior change. The product will sell directly to Fortune 500 CEOs and full risk populations, integrating layers of analytics, digital, concierge services, behavioral health, telemedicine, care management and wellness services to drive sustained engagement, lower costs and improve health.\\n\\nReporting To\\n\\nHead of Data Science and AI with dotted line to Chief Analytics and Marketing Officer\\n\\nPosition Summary\\n\\n\\nThe overall goal is to engage consumers in differentiated ways that will drive better health outcomes. As one of the early hires of the Analytics organization, the primary mission will be to launch the modeling and optimization platform (the \"Health Engine\") to deliver member recommendations that improve health, cost of delivery, and engagement.\\nYou will leverage a wide range of disparate data sources across healthcare (member, payor, employer, provider, partner). Ideal candidates will have a detailed understanding of healthcare data with experience analyzing large longitudinal health datasets.\\nYou will assist in the creation of operational predictive models using current and emerging methodologies in data science. Ideal candidates will possess a deep understanding of statistics, machine learning, causal predictive modeling, and most importantly, a willingness to grow deeper in these areas.\\nYou will collaborate across the organization to drive projects from beginning to end: frame business questions, collect and analyze data, research, prototype, build pipelines, and share insights. You will work with engineering to ensure robust translation to production environments and create solutions that operate effectively at scale.\\n\\nMinimum Qualifications\\n\\n\\n2+ years' industry experience in data science or machine learning focused roles.\\nAdvanced degree (MS or PhD) in a quantitative field such as Statistics, Computer Science, Mathematics, Physics, Engineering, Economics, or similar.\\nDemonstrated experience using Python for data analysis and machine learning (numpy, pandas, scikit-learn, xgboost, spacy, pytorch, stan/pymc3, etc.). Proficiency with SQL and databases. Experience using Unix/OSX from the command line, version control (git), and general software development best practices for contributing to a collaborative code base. Experience configuring and executing analyses in the cloud (GCP, AWS).\\nStrong communication and collaboration skills required. Ability to communicate technical modeling concepts and relevant aspects of modeling platforms to non-technical audiences.\\nWillingness to learn and improve across all technical skill areas and in knowledge of the healthcare domain. Ability to work in a start-up environment that is fast paced and maintain a focus on rapid prototyping of capabilities.\\n\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "35  This role is part of the Whisk team within the Samsung NEXT Product organization.\\nWhisk has built a multi-sided marketplace over the past 7 years that delivers value to each member of the network such as Publishers, Retailers, IOT & Health, and Brands. Whisk also has a consumer experience, my.whisk.com for shopping lists, saved recipes, and other potential experiences. Whisk joined Samsung NEXT in March and there are plans to invest more heavily in the platform, to scale the business and grow each aspect of the network (publisher, retailer, IoT, Health, Brands, & B2C). Each investment should not only add value to its own experience but also to the network of partners overall.\\nAbout NEXT Product\\nThe NEXT Product organization is a hyper-growth startup within Samsung NEXT. We’re a globally distributed product development team in search of builders and creators to help conceive, grow and scale new products and categories.\\nSuccessful candidates, at all levels within the organization, will: approach all things team-first, take ownership and “be the change you seek”, have strong written and verbal communication skills, have high EQ, enjoy fast-paced, outcome-driven environments and be inspired to learn and explore daily both inside and outside of your field of expertise.\\nThe Role\\nAs a Senior Machine Learning Engineer, you will build ML-based systems, tools, and services to improve Whisk’s Food Genome (https://whisk.com/cognitive-food-platform/) and to produce highly relevant and personalized recommendations. We are looking for a candidate that has industry experience with a range of Machine Learning disciplines (NLP) and has worked with large data sets, specifically understanding and representing semantics. Experience with the food industry is a plus. This position is located in our New York office.\\nResponsibilities\\nWork closely with our Data team to extend and improve our Food Genome by applying NLP based methods to this complex domain.\\nBuild models to generate food recommendations and personalized offering based on user behavior\\nDesign, develop, test, deploy, maintain and improve ML models/infrastructure and software that uses these models.\\nManage individual project priorities, deadlines and deliverables.\\nRequired Qualifications\\nMS degree in Computer Science or a related quantitative field\\n5+ years of experience in one or more of the following areas: machine learning (NLP), recommendation systems\\nExperience with machine learning frameworks such as TensorFlow or Keras\\nExperience working in an Agile environment and within a distributed team\\nBonus Points\\nPh.D. degree in Computer Science or a related quantitative field\\nResearch experience in Natural Language Processing or Deep Learning.\\nAbout Samsung NEXT\\nWe partner with and build software alongside innovators to develop ideas into products, grow products into businesses and scale businesses globally.\\nFounded in 2012, Samsung NEXT has four key functions in the global software ecosystem:\\nProduct - Building new software and services businesses, at scale.\\nVenture - Investing in early-stage startups to help entrepreneurs build and scale their businesses.\\nPartnerships - Helping startups successfully partner with the variety of businesses within Samsung.\\nM&A - Acquiring startups to connect and scale with our businesses.\\nSamsung is an EEO (Equal Employment Opportunity)/Veterans/Disabled/LGBTQ employer. We welcome and encourage diversity as we strive to create an inclusive workplace.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "36  DS/ML stack:\\nLanguages: Python, PySpark, SQL\\nData Tools: Spark, AWS RedShift, AWS Athena, pandas, numpy, scipy, parquet\\nModeling Tools: SparkML, scikit-learn, Tensorflow, Tensorflow-Serving, Keras (Tensorflow and Theano backend)\\nAlgorithms: Classifications, Regressions, Neural Networks, Time series, Graphs\\nVisualization: Tableau or similar\\nInfrastructure: AWS (including S3, EMR, EC2, Lambda)\\n\\n\\nWhat will you do?\\nUnderstand business decisions that need to be supported by data e.g. risk of readmission to hospital\\nIdentify relevant internal or external data sources for various business needs\\nResearch the state of a problem and existing solutions then quickly summarize research\\nHelp identify new business opportunities and value propositions from existing data\\nUtilize raw or aggregated data to build predictive models in SPARK, sql, or Python\\nUnderstand quality of models and impact on business problems\\nCommunicate summaries of analyses and predictive modeling efforts to product and business teams\\nCommunicate insights to stakeholders in data engineering, product and clinical teams.\\nBecome expert on projects to help strategize plans of attack in terms of technology and team education.\\nEnsure that all security procedures within their area of responsibility are carried out to achieve compliance with security policies and standards.\\nLeading multiple initiatives across both existing and innovative work\\nProvide continuous mentoring to junior resources\\nWe are looking for someone with:\\n7+ year’s professional experience as a data scientist or machine learning engineer\\n7+ year’s professional experience working in quantitative computational role\\n5+ year’s professional experience working with big data and relational databases\\nVery strong knowledge of advanced applied data science (machine learning, neural networks, etc.), mathematical modeling, computational, statistical, data mining techniques (regression, decision trees, clustering etc.), as well as dimensionality reduction techniques\\nStrong hands-on modeling experience in a business environment with a goal of productionalizing models.\\nStrong experience using machine learning and deep learning packages\\nStrong experience with data manipulation, analysis and visualization\\nProven track record of fully understanding the scope, commitment to quality, and end-to-end ownership to meet upon agreed timelines.\\nQuick learner that can manage multiple projects at the same time successfully\\nDeveloped and designed real-time prediction software\\nStrong experience mentoring junior colleagues\\nExcellent written and verbal communication skills\\nAdvanced degree in physics, applied mathematics, statistics or related field is preferred\\nHealthcare industry experience is a plus\\n\\nAbout Us\\n\\nRemedy Partners delivers software and services that enable payers, employers and at-risk providers to organize and finance healthcare delivery around a patient's episode of care. For healthcare providers, Remedy Partners’ software, analytics and administrative services support bundled payment contracts with Medicare and Commercial Insurers, often through shared-risk partnerships. For payers, Remedy Partners empowers the development of bundled payment contracting programs and guides development of bundled payment networks. Remedy Partners presently delivers its services to partners at more than 1,000 healthcare locations nationwide.\\n\\nPlease note that all Remedy employees are required to adhere to all organizational policies, the Code of Conduct and participate in all compliance-related training and education.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "37  Overview\\nMachine Learning Engineer, Decision Analytics Services (Manager)\\n\\nEXL (NASDAQ:EXLS) is a leading operations management and analytics company that helps businesses enhance growth and profitability in the face of relentless competition and continuous disruption. Using our proprietary, award-winning Business EXLerator Framework™, which integrates analytics, automation, benchmarking, BPO, consulting, industry best practices and technology platforms, we look deeper to help companies improve global operations, enhance data-driven insights, increase customer satisfaction, and manage risk and compliance. EXL serves the insurance, healthcare, banking and financial services, utilities, travel, transportation and logistics industries. Headquartered in New York, New York, EXL has more than 24,000 professionals in locations throughout the United States, Europe, Asia (primarily India and Philippines), Latin America, Australia and South Africa.\\n\\nEXL Analytics provides data-driven, action-oriented solutions to business problems through statistical data mining, cutting edge analytics techniques and a consultative approach. Leveraging proprietary methodology and best-of-breed technology, EXL Analytics takes an industry-specific approach to transform our clients’ decision making and embed analytics more deeply into their business processes. Our global footprint of nearly 2,000 data scientists and analysts assist client organizations with complex risk minimization methods, advanced marketing, pricing and CRM strategies, internal cost analysis, and cost and resource optimization within the organization. EXL Analytics serves the insurance, healthcare, banking, capital markets, utilities, retail and e-commerce, travel, transportation and logistics industries.\\n\\nPlease visit www.exlservice.com for more information about EXL Analytics.\\n\\nDomain: Healthcare Payer\\n\\nFunctional Area:\\nLeverage huge sets of healthcare payer data to analyze member experience across several dimensions\\nMake recommendations for streamlining underlying processes to enhance member journey, proactive intervention and prompt care delivery\\nResponsibilities\\nCapture a 360 degree view of member experience by consolidating disparate data sets\\nPerform descriptive analysis on various aspects of member journey – points of care , claims adjudication, operational processes, appeals mechanism\\nIdentify areas of improvement or friction that might be disrupting member satisfaction\\nMember Profiling – Segment population using advanced clustering techniques for customized targeting and intervention\\nDeploy predictive modeling to design an intervention framework which can navigate the member through his/ her journey with minimum disruption and proactive care\\nQualifications\\nProficiency in PySpark, Pandas.\\nProficiency in leveraging CI/CD tools to automate deployment and testing. Experience in Agile methodologies and fast paced DevOps environments\\nProficiency in scripting and GIT workflows\\nGood Knowledge of Hadoop, MapReduce, HDFS\\nGood Knowledge of Big Data querying tools, such as Hive\\nExperience with Big Data ML toolkits – SparkML (alternatively, Scikit Learn in Python)\\nGood Knowledge of Statistical Techniques – Descriptive Statistics, Hypothesis Testing, Tests of Significance, Correlation, Predictive Modeling\\nGood knowledge of SQL, Tableau and MS Excel\\nGood domain knowledge of US Healthcare space\\nWhat we offer:\\nEXL Analytics offers an exciting, fast paced and innovative environment, which brings together a group of sharp and entrepreneurial professionals who are eager to influence business decisions. From your very first day, you get an opportunity to work closely with highly experienced, world class analytics consultants.\\nYou can expect to learn many aspects of businesses that our clients engage in. You will also learn effective teamwork and time-management skills - key aspects for personal and professional growth\\nAnalytics requires different skill sets at different levels within the organization. At EXL Analytics, we invest heavily in training you in all aspects of analytics as well as in leading analytical tools and techniques.\\nWe provide guidance/ coaching to every employee through our mentoring program wherein every junior level employee is assigned a senior level professional as advisorsy\\nSky is the limit for our team members. The unique experiences gathered at EXL Analytics sets the stage for further growth and development in our company and beyond.\\n \"EOE/Minorities/Females/Vets/Disabilities\"\\nEEO Statement\\nEEO/Minorities/Females/Vets/Disabilities                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "38  11 West 19th Street (22008), United States of America, New York, New York\\n\\nAt Capital One, we’re building a leading information-based technology company. Still founder-led by Chairman and Chief Executive Officer Richard Fairbank, Capital One is on a mission to help our customers succeed by bringing ingenuity, simplicity, and humanity to banking. We measure our efforts by the success our customers enjoy and the advocacy they exhibit. We are succeeding because they are succeeding.\\n\\nGuided by our shared values, we thrive in an environment where collaboration and openness are valued. We believe that innovation is powered by perspective and that teamwork and respect for each other lead to superior results. We elevate each other and obsess about doing the right thing. Our associates serve with humility and a deep respect for their responsibility in helping our customers achieve their goals and realize their dreams. Together, we are on a quest to change banking for good.\\n\\nSenior, Data Engineer\\n\\nAre you a high performing data scientist passionate about cutting edge Machine Learning research or applying the latest advances to production projects? Do you enjoy reading and investigating advancements in applied machine learning architectures and solution white papers? Would you like to participate in the creation of publishable advancements in machine learning? Or does the idea of building enterprise-class ML applications that solve real customer problems excite you? At Capital One’s Center for Machine Learning (C4ML), you'll be part of an elite team setting the example for machine learning research and applied machine learning.\\n\\nAs a Machine Learning Engineer in C4ML, you will build fast data and machine learning solutions to address unique and complex problems in in the financial services industry. Capital One leverages full stack technology solutions including streaming big data, state of the art machine learning, micro-service architecture, distributed computation engines, and intuitive visualizations in the cloud. We work with several cutting-edge technologies and actively develop and contribute to the open source community. You will work alongside highly technical peers, with deep domain expertise (from cyber threat prevention to sophisticated NLP), and partner with product and business teams to deliver game changing solutions for our customers.\\n\\nWho you are:\\nYou have explored the intricacies of a data set to extract insights or have built models that predict or identify patterns used to answer burning business questions\\nYou have contributed to full stack systems built for speed and distributed computing and feel proud to ship code to delighted end users.\\nYou yearn to be part of cutting edge, high profile projects and are motivated by delivering world-class solutions on an aggressive schedule\\nYou love to learn new technologies, keep abreast of the latest technologies within cloud architecture, and drive your organization to adapt to emerging best practices\\nYou are the go-to person to answer deep technical questions about which ML algorithm may improve results or what visualization is best to explore relationships in the data\\nIt would be awesome if you have a robust portfolio on Github or open source contributions you are proud to share\\n\\nBasic Qualifications:\\nBachelor’s Degree or Military Experience\\nAt least 2 years of experience working with Machine Learning, Deep Learning or Artificial Intelligence\\nAt least 2 years of experience programming in Python, Scala or Java\\nAt least 2 years of experience designing and building full stack solutions utilizing distributed computing or multi-node database paradigms\\n\\nPreferred Qualifications:\\nMaster’s Degree or PhD\\nAt least 2 years of experience with cloud software design using microservices or distributed caching\\nA history of publications and conference attendance.\\n\\nAt this time, Capital One will not sponsor a new applicant for employment authorization for this position.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "39  This role is part of the Core team within the Samsung NEXT Product organization. The Core team is building today a set of large scale products that are directly linked with Samsung world wide and have the potential of capitalizing on Samsung’s massive consumer reach across mobile phones and smart TVs.\\nAbout NEXT Product\\nThe NEXT Product organization is a hyper-growth startup within Samsung NEXT. We’re a globally distributed product development team in search of builders and creators to help conceive, grow and scale new products and categories.\\nSuccessful candidates, at all levels within the organization, will: approach all things team-first, take ownership and “be the change you seek”, have strong written and verbal communication skills, have high EQ, enjoy fast-paced, outcome-driven environments and be inspired to learn and explore daily both inside and outside of your field of expertise.\\n\\nThe Role\\nAs a Machine Learning Engineer, you will build Machine Learning systems fusing and analysing multi-sensory signals to solve real-world challenges in real-time. We are looking for a candidate that has industry experience with Computer Vision (Machine Learning) and has worked with large data sets and in real-time. This position is located in our New York office.\\n\\nRESPONSIBILITIES\\nWork closely with our Engineering and Data teams in NYC, San Francisco and Korea to build real-time solutions for Smart Spaces by applying Computer Vision methods to this complex domain.\\nBuild models for Human Activity Detection and Recognition, Object Detection and tracking and Scene Segmentation in real-time\\nDesign, develop, test, deploy, maintain and improve ML models/infrastructure and software that uses these models.\\nManage individual project priorities, deadlines and deliverables.\\nMINIMUM QUALIFICATIONS\\nMS degree in Computer Science or related quantitative field\\n5+ years of experience in one or more of the following areas: machine learning (CV)\\nExperience with machine learning frameworks\\nExperience working in an Agile environment and within a distributed team\\nPREFERRED QUALIFICATIONS\\nPh.D. degree in Computer Science or related quantitative field\\nResearch experience in Deep Learning.\\nAbout Samsung NEXT\\nWe partner with and build software alongside innovators to develop ideas into products, grow products into businesses and scale businesses globally.\\nFounded in 2012, Samsung NEXT has four key functions in the global software ecosystem:\\nProduct - Building new software and services businesses, at scale.\\nVenture - Investing in early-stage startups to help entrepreneurs build and scale their businesses.\\nPartnerships - Helping startups successfully partner with the variety of businesses within Samsung.\\nM&A - Acquiring startups to connect and scale with our businesses.\\nSamsung is an EEO (Equal Employment Opportunity)/Veterans/Disabled/LGBTQ employer. We welcome and encourage diversity as we strive to create an inclusive workplace.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "40  We are looking for senior backend engineers to join our team of talented engineers that share a common interest in distributed backend systems, their scalability and continued development. You will build the backend systems that power our application, scale highly distributed systems, and continuously improve our engineering practices. Above all, your work will impact the way the world experiences music.\\n\\nAt Spotify, we’re proud of our ambitious mission of having 1 billion fans enjoying music around the world, and are seeking a lead machine learning engineer to join us in pursuit of this goal. We are looking for a Staff Backend Engineer with a proficiency in Machine Learning to join our team, which uses machine learning to drive advertiser outcomes and listener satisfaction in Spotify Free, helping democratize music access globally while positively impacting Spotify’s bottom line. We develop innovative and scalable solutions around the core problem of getting the right ad to the right user at the right time, while embodying Spotify’s values and taking our users’ best interest at heart.\\n\\nWhat you’ll do\\n\\nBe a technical leader within the team you work with and within Spotify in general.\\nCoordinate technical projects across teams within Spotify.\\nFacilitate collaboration with other engineers to solve interesting and challenging problems around continually improving machine learning models in production\\nHelp build and improve features that impact our users and make them better leveraging machine learning\\nArchitect, design, develop, deploy and operate Java services and systems that serve real-time predictions to millions of users\\nBe a valued member of an autonomous, cross-functional agile team\\nBe a leader of the Spotify-wide backend developer community affecting and driving our architecture across the company\\nWho you are\\n\\nYou are an experienced technical leader.\\nYou have 5+ years of experience in designing and building distributed, high-volume services (Java, PHP, etc)\\nYou are proficient in bare-metal programming languages (Java / C++)\\nYou are experienced with deploying and operating services on Linux.\\nYou have a deep understanding of system design, data structures, and algorithms.\\nYou have 3+ years of experience with machine learning systems, theory, and development workflows\\nYou care about quality and you know what it means to ship high quality code.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "41  Etsy is looking for a Machine Learning Engineer to join our Data Science teams. We are committed to advancing E-commerce related fields by building technologies that help Etsy buyers and sellers discover and celebrate handmade goods from all over the world. This individual is going to design and build machine learning systems that process Internet-scale content. In addition, the individual is going to build and optimize systems, tools, and validation strategies to support new machine learning applications.\\nAbout the Role\\nWhat we're working on:\\nSearch Ranking\\nRecommendation and Personalization\\nNatural Language Processing and Query Understanding\\nDeep Learning\\nImage Processing and Understanding\\nText Understanding\\nFraud and Abuse Detection\\nLarge-scale Machine Learning\\nWe care about curiosity and humility. We are dedicated to learning and constantly improving. We hope you also value things like blameless postmortems and have a natural drive to figure out how everything works. Keeping it real. Etsy’s mission and values are a part of everything we do. We care about how our work affects real people in the community and enjoy opportunities to meet them. We are motivated by this mission every day.\\nAbout You\\nYou have a B.S./M.S./Ph.D. degree in Computer Science or related engineering fields.\\nYou have a solid engineering and coding skills, with ability to write high performance production quality code.\\nExperience in Java, C++, Python, Scala and other equivalent languages is a plus.\\nYou have industry experience building and productionizing innovative end-to-end Machine Learning systems.\\nYou have the ability to quickly prototype ideas and solve complex problems by adapting creative approaches.\\nYou are a strong collaborator and communicator and you make the engineers around you grow and learn.\\nWhat’s Next\\n\\nInterested in working with us? Send us a cover letter and your CV or resume explaining why you’d be great for the job. We value your unique talents and point of view, so feel free to tell us what you are all about. And if you write, draw, craft, or contribute to something you’re proud of, we’d love to hear about it.\\nAt Etsy, we believe that a diverse, equitable and inclusive workplace makes us a more relevant, more competitive, and more resilient company. We welcome people from all backgrounds, ethnicities, cultures, and experiences. Etsy is an equal opportunity employer. We do not discriminate on the basis of race, color, ancestry, religion, national origin, sexual orientation, age, citizenship, marital or family status, disability, gender identity or expression, veteran status, or any other legally protected status.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "42  We’re looking for an experienced machine learning engineer or data scientist to join our small team of talented engineers and data scientists and play a major role in shaping an exciting platform.\\n\\nResponsibilities\\n\\nLead development efforts of key features\\n\\nPartner closely with data scientists and product managers to develop algorithms and drive key product or modeling decisions\\n\\nResearch the best metrics and experiment design to measure models performance\\n\\nPresent your research and insights to all levels of the company, clearly and concisely\\n\\nYour profile\\n\\nExpert programming experience with a scripting language such as Python (preferred)\\n\\nDeep understanding of modern machine learning techniques and their mathematical underpinning, such as classification, recommendation systems and natural language processing\\n\\nExperience in deploying and scaling machine learning algorithms into production environments\\n\\nStrong SQL skills\\n\\nProficiency with a statistical analysis tool such as R or Python\\n\\nExperience visualizing data and reporting\\n\\nExperience with ETL (Extract-Transform-Load) systems is a plus\\n\\nDeep product sense & Self-starter\\n\\nProficiency at translating unstructured business problems into an abstract mathematical framework. You are able to make intelligent approximations of mathematical models in order to make them practical and scalable\\n\\nAbility to articulate and execute on your practical vision; you are an effective partner who listens well and incorporates others’ feedback and ideas\\n\\nRequirements\\n\\nDegree in Computer Science, Statistics, Math, Engineering, or related disciplines\\n\\n3+ years of professional experience in engineering, data science, or related\\n\\nProfessional work ethic coupled with sound judgment\\n\\nExperience working in rapid growth environment that requires flexibility and continuous innovation\\n\\nAble to roll up your sleeves to do what is needed in urgent situations while maintaining a big-picture view. You are excited about the idea of working with a small team to get the job done, even if you sometimes need to do things that are outside of your direct job description\\n\\nAbility to prioritize and handle multiple projects with tight deadlines.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "43  The One Amex team at American Express is a core foundational platform that helps drive decisions that impact our customer experience at American Express.\\n\\nThe platform is leveraged by various teams in the company to drive decisions, and customer experience.\\n\\n\\nAs part of the Data Science team, you will be responsible for:\\n\\nDriving requirements for structured data formats from a wide variety of data sources\\nBuild data science products across a wide range of digital data streams (Anomaly Detection, Deep Learning, Information Retrieval)\\nWork with engineering teams to deploy robust, highly available decisioning and alerting pipelines based on your models.\\nPlease note, Salary increases in case of a lateral move are provided only on an exception basis and in line with compensation guidelines.\\n\\nRegularly attend key initiative stand-ups, proactively advising on opportunities to apply the best approach to apply underlying empirically-developed algorithms.\\n\\nQualifications\\nQualifications should include:\\n\\nDeep technical skills in data engineering, statistics, machine learning, or deep learning and a passion for making these methods more rigorous, robust and scalable\\n\\nStrong programming skills in Python or Java\\n\\nPractical experience working with and conducting experiments on large datasets then turning prototypes into production models in one or more domains\\n\\nExperience applying analytical techniques to provide solutions to real business and engineering problems\\n\\nAbility to explain and present analyses and machine learning concepts to a technical audience\\n\\nEmployment eligibility to work with American Express in the U.S. is required as the company will not pursue visa sponsorship for these positions.\\nWhy American Express?\\n\\n\\nThere’s a difference between having a job and making a difference.\\n\\n\\nAmerican Express has been making a difference in people’s lives for over 160 years,\\n\\nbacking them in moments big and small, granting access, tools, and resources to take\\n\\non their biggest challenges and reap the greatest rewards.\\n\\n\\nWe’ve also made a difference in the lives of our people, providing a culture of learning\\n\\nand collaboration, and helping them with what they need to succeed and thrive. We\\n\\nhave their backs as they grow their skills, conquer new challenges, or even take time to\\n\\nspend with their family or community. And when they’re ready to take on a new career\\n\\npath, we’re right there with them, giving them the guidance and momentum into the\\n\\nbest future they envision.\\n\\n\\nBecause we believe that the best way to back our customers is to back our people.\\n\\n\\nThe powerful backing of American Express.\\n\\nDon’t make a difference without it.\\n\\nDon’t live life without it.\\n\\nReqID: 19009478\\nSchedule (Full-Time/Part-Time): Full-time\\nDate Posted: May 23, 2019, 12:07:03 AM                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "44  Our client, a Financial Data and Software company is seeking a Machine Learning Engineer. Comprised of engineers and scientists, the Machine Learning Team develops scalable ML platforms and systems.\\nThe successful candidate will develop new machine learning methods for financial applications, such as intelligent searching and predictive analytics. Machine learning techniques will include supervised, unsupervised, deep learning and time series analysis. In addition to using existing models, you will develop new techniques. The candidate will help in the identification and solution of new problem areas and research technical details to build innovative products and solutions.\\nKey Responsibilities\\nResearch and development of systems with natural language analysis, information retrieval, and financial predictive analytics within a varied technology environment.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "45  About the team:\\nVideo is 80% of today's global Internet traffic. The Engineering team at Vimeo is building AI-driven tools to help anyone who wants to make a video. Our mission includes modernizing video playback and transcoding technologies with AI, and understanding what makes hundreds of millions of high quality videos on our platform successful. You can help make an impact.\\n\\nWhat you'll do:\\n\\nDesign and build data pipelines and production-level machine learning (ML) infrastructure, using tools such as TensorFlow, Kubernetes, TFX, Kubeflow Pipelines, Apache Beam, Spark and cloud platforms. Leverage your experience to drive best practices in ML systems and data engineering.\\nBring ML research from Notebooks to production. Deploy ML models under the constraints of scalability, correctness, and maintainability, with hardware acceleration techniques. Optimize and give feedback to research-level models to bring them to production level.\\nCollaborate with cross functional agile teams of machine learning engineers, video engineers, data engineers, and others, in building machine learning infrastructure that best supports the ML needs at Vimeo.\\n\\nSkills and knowledge you should possess:\\n\\nMS degree or Ph.D. degree in Computer Science or a related quantitative field.\\n5+ years of machine learning product development experience, using state-of-the-art tooling and have a deep understanding of the best practices for ML systems.\\nFluency in using a neural network framework such as TensorFlow, Keras, Caffe, PyTorch, Theano, or MXNet\\nAbility to architect data pipelines using tools like Apache Beam or Spark. You have experience with setting organization wide best practices for data.\\nAbility to build APIs and libraries for Java, Scala or Python.\\nConcern for agile software processes, data-driven development, reliability, and responsible experimentation.\\nA keen interest in studying the latest publications in the machine learning community.\\nSkilled communication and a proven record of leading work across disciplines.\\n\\nBonus Points (Nice Skills to Have, but Not Needed):\\n\\nExperience with data processing and storage frameworks like Google Cloud Dataflow, Hadoop, Scalding, Spark, Storm, Cassandra, Kafka, etc.\\nExperience with developing insights and models using unstructured data (like clickstreams), experience with search and recommendation systems (learn-to-rank, collaborative filtering, NLP for search, etc.)\\n\\nAbout us:\\nAt Vimeo, our mission is to empower video creators to tell exceptional stories and connect with their audiences and communities. Home to more than 90 million members in over 150 countries, Vimeo is the world's largest ad-free open video platform, providing powerful tools to host, share and sell videos in the highest quality possible.\\n\\nWe work hard to enable creators of all kinds to succeed, and to that end, we prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and creativity. We're committed to building a company and a community where people thrive by being themselves and are inspired to do their best work every day.\\n\\nVimeo is based in New York City, with additional offices in Europe and India. Vimeo is an operating business of IAC (NASDAQ: IAC). Learn more at www.vimeo.com.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "46  Why American Express?\\n\\nThere’s a difference between having a job and making a difference.\\n\\nAmerican Express has been making a difference in people’s lives for over 160 years, backing them in moments big and small, granting access, tools, and resources to take on their biggest challenges and reap the greatest rewards.\\n\\nWe’ve also made a difference in the lives of our people, providing a culture of learning and collaboration, and helping them with what they need to succeed and thrive. We have their backs as they grow their skills, conquer new challenges, or even take time to spend with their family or community. And when they’re ready to take on a new career path, we’re right there with them, giving them the guidance and momentum into the best future they envision.\\n\\nBecause we believe that the best way to back our customers is to back our people.\\n\\nThe powerful backing of American Express.\\nDon’t make a difference without it.\\nDon’t live life without it.\\n\\nAs a Machine Learning Engineer on our team you will be responsible for creating and delivering ML solutions to support our organization and clients. You will be challenged with identifying innovative ideas and proof of concepts to deliver against the existing and future needs of our customers. The successful candidate will play a key role in the understanding of product owner strategy and collaborate with peers and technology partners to translate complex user stories into successful AI product releases. If you have the talent and desire to deliver innovative products and services at a rapid pace, this would be the right fit for you!\\n\\nWhat you will be doing:\\nCreating, implementing and deploying production level ML algorithms.\\nSuggesting, collecting and synthesizing requirements.\\nCreating roadmaps towards the deployment of a production-level machine learning application.\\nArchitecting, estimating and planning technical solutions to problems.\\nWho are we looking for:\\nDeep expertise in building scalable Machine Learning powered applications\\nExperience with production grade applications preferred. Ideally with an application that leverages Machine Learning to power its decisions.\\nHighly motivated and can manage relationships in a cross-functional environment. Proven track record of working with multiple stakeholders.\\n\\n\\nQualifications\\nQuantitative and Software Development Skills:\\nMaster of Science with 5+ year of experience or Ph.D. with 3+ years of experience in a quantitative discipline such as Computer Sciences.\\nSolid theoretical understanding and hands on experience in developing and deploying classical and deep learning models.\\nProficiency in scalable and object oriented software development preferably Python.\\nHands on experience working with distributed compute platforms using Spark.\\nQuickly generate and updating prototypes from concept to testing while soliciting feedback.\\nLeadership Skills:\\nExcellent communication skills.\\nDemonstrate self-reliance to achieve goals collaboratively\\nCurious, hardworking and detail-oriented, and motivated by complex analytical problems.\\nThought leadership and innovative thinking.\\nEmployment eligibility to work with American Express in the U.S. is required as the company will not pursue visa sponsorship for these positions.\\nReqID: 19017104\\nSchedule (Full-Time/Part-Time): Full-time\\nDate Posted: Sep 17, 2019, 8:26:35 AM                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "47  ----------------\\nAbout AlphaSense\\n----------------\\n\\nAlphaSense provides an AI-based search engine for market intelligence, used by the largest and fastest-growing firms globally. Our mission is to curate and semantically index the world's market and company information, including the vast high-value content sets that traditional web search engines cannot reach. With 1000+ enterprise clients, AlphaSense helps knowledge professionals become dramatically more productive, and gain an information edge by discovering critical data points and trends that others miss.\\n\\nThe Role:\\nYou will join our team of machine learning engineers developing the cutting edge AI & NLP systems that power AlphaSense Search. You are as excited about scaling these systems for production workloads as you are with developing cutting edge algorithms.\\n\\nResponsibilities:\\n\\nDevelop highly scalable deep learning models\\nAdapt machine learning methods to make effective use of modern parallel environments, distributed clusters and GPUs\\nDefine performance and scalability requirements for models in production and translate into technical implementation plan and roadmap\\nOwn systems end-to-end including design, code, train, test, deployment and iteration\\n\\nRequirements:\\n\\nA BS/MS degree in Computer Science or Computer Engineering or equivalent\\n4+ years developing data pipelines with Python with additional experience in Java, Linux, and scripting languages that interact with cloud resources\\nDemonstrated experience developing end-to-end NLP models to derive insights from text data using NLP libraries in Python\\nExperience with building back-end services and APIs in Django or Flask\\nGood grasp of data toolchains and best practices (such as Beam, Dataflow, Airflow, Spark, Kafka)\\nExperience with docker/kubernetes\\nExperience using SQL, NOSQL and search databases (SOLR/Lucene, MySQL, Mongo/Cassandra, SOLR/Lucene, etc.)\\nExperience working with cloud computing (preferably AWS or GCP)\\nExperience with iterative Agile methodology and use of tools like JIRA, Confluence, Git\\nFamiliarity with Deep Learning frameworks like PyTorch and TensorFlow\\nDemonstrated experience in the software development lifecycle, from requirements to design to development and testing\\nStrong communication skills and ability to build pipelines with little guidance in small teams and independently\\nExcellent organizational, problem-solving, debugging and analytical skills\\n\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "48  Overview\\nMachine Learning Engineer, Decision Analytics Services (Manager)\\n\\nEXL (NASDAQ:EXLS) is a leading operations management and analytics company that helps businesses enhance growth and profitability in the face of relentless competition and continuous disruption. Using our proprietary, award-winning Business EXLerator Framework™, which integrates analytics, automation, benchmarking, BPO, consulting, industry best practices and technology platforms, we look deeper to help companies improve global operations, enhance data-driven insights, increase customer satisfaction, and manage risk and compliance. EXL serves the insurance, healthcare, banking and financial services, utilities, travel, transportation and logistics industries. Headquartered in New York, New York, EXL has more than 24,000 professionals in locations throughout the United States, Europe, Asia (primarily India and Philippines), Latin America, Australia and South Africa.\\n\\nEXL Analytics provides data-driven, action-oriented solutions to business problems through statistical data mining, cutting edge analytics techniques and a consultative approach. Leveraging proprietary methodology and best-of-breed technology, EXL Analytics takes an industry-specific approach to transform our clients’ decision making and embed analytics more deeply into their business processes. Our global footprint of nearly 2,000 data scientists and analysts assist client organizations with complex risk minimization methods, advanced marketing, pricing and CRM strategies, internal cost analysis, and cost and resource optimization within the organization. EXL Analytics serves the insurance, healthcare, banking, capital markets, utilities, retail and e-commerce, travel, transportation and logistics industries.\\n\\nPlease visit www.exlservice.com for more information about EXL Analytics.\\n\\nDomain: Healthcare Payer\\n\\nFunctional Area:\\nLeverage huge sets of healthcare payer data to analyze member experience across several dimensions\\nMake recommendations for streamlining underlying processes to enhance member journey, proactive intervention and prompt care delivery\\nResponsibilities\\nCapture a 360 degree view of member experience by consolidating disparate data sets\\nPerform descriptive analysis on various aspects of member journey – points of care , claims adjudication, operational processes, appeals mechanism\\nIdentify areas of improvement or friction that might be disrupting member satisfaction\\nMember Profiling – Segment population using advanced clustering techniques for customized targeting and intervention\\nDeploy predictive modeling to design an intervention framework which can navigate the member through his/ her journey with minimum disruption and proactive care\\nQualifications\\nProficiency in PySpark, Pandas.\\nProficiency in leveraging CI/CD tools to automate deployment and testing. Experience in Agile methodologies and fast paced DevOps environments\\nProficiency in scripting and GIT workflows\\nGood Knowledge of Hadoop, MapReduce, HDFS\\nGood Knowledge of Big Data querying tools, such as Hive\\nExperience with Big Data ML toolkits – SparkML (alternatively, Scikit Learn in Python)\\nGood Knowledge of Statistical Techniques – Descriptive Statistics, Hypothesis Testing, Tests of Significance, Correlation, Predictive Modeling\\nGood knowledge of SQL, Tableau and MS Excel\\nGood domain knowledge of US Healthcare space\\nWhat we offer:\\nEXL Analytics offers an exciting, fast paced and innovative environment, which brings together a group of sharp and entrepreneurial professionals who are eager to influence business decisions. From your very first day, you get an opportunity to work closely with highly experienced, world class analytics consultants.\\nYou can expect to learn many aspects of businesses that our clients engage in. You will also learn effective teamwork and time-management skills - key aspects for personal and professional growth\\nAnalytics requires different skill sets at different levels within the organization. At EXL Analytics, we invest heavily in training you in all aspects of analytics as well as in leading analytical tools and techniques.\\nWe provide guidance/ coaching to every employee through our mentoring program wherein every junior level employee is assigned a senior level professional as advisorsy\\nSky is the limit for our team members. The unique experiences gathered at EXL Analytics sets the stage for further growth and development in our company and beyond.\\n \"EOE/Minorities/Females/Vets/Disabilities\"\\nEEO Statement\\nEEO/Minorities/Females/Vets/Disabilities                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "49  We are looking for a Machine Learning Engineer for the team that supplies our close friends in Spotify Customer Support with the software solutions they need. These are customer facing products (e.g. support.spotify.com), internally built systems, and integrations with our vendors. We are about 40 people in total across the development team for Customer Experience, with people in New York, Stockholm and London. This position is based in New York.\\n\\nWhat you’ll learn and do\\nContribute to designing, building, evaluating, shipping, and refining Spotify’s support products by hands-on ML development\\nCollaborate with cross functional agile teams spanning user research, design, data science, product management, and engineering to build new product features that advance our mission to support artists and fans in personalized and relevant ways\\nPrototype new approaches and production-ize solutions at scale for our hundreds of millions of active users\\nHelp drive optimization, testing, and tooling to improve quality\\nBe part of an active group of machine learning practitioners in New York (and across Spotify) collaborating with one another\\nWho you are\\nYou have a strong background in machine learning, with experience in personalization and Natural Language Processing.\\nYou have hands-on experience implementing production machine learning systems at scale in Java, Scala, Python, or similar languages. Experience with XGBoost, TensorFlow is also a plus.\\nYou preferably have experience with data pipeline tools like Apache Beam or even our open source API for it, Scio and cloud platforms like GCP or AWS.\\nYou care about agile software processes, data-driven development, reliability, and disciplined experimentation\\nYou love your customers even more than your code                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Descriptions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Descriptions_df.to_csv('Descriptions_df_MLE_NYC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
