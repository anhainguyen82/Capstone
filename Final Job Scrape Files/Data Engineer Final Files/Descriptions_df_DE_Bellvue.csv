,Title,Location,City,State,Zip,Country,Qualifications,Skills,Responsibilities,Education,Requirement,FullDescriptions
0,Big Data Engineer,"Bellevue, WA",Bellevue,WA,None Found,None Found,"
4+ years of relevant technical experience, including 2+ years with noSQL databases (MongoDB preferred) as well as experience with SQL
Strong Python coding skills
Experience developing and implementing ETL architectures with large, complex data sets
Understanding of database architecture and data lakes
Distributing computing (parallel processing, multi-threading) – Hadoop, MapReduce, Spark
Hands-on experience with web crawling/web scraping required (6+ months)
Experience developing APIs
Experience with Node.js and familiarity with Machine Learning are pluses
Strong quantitative data analysis skills
Beyond the technical, strong business thinking is required, including experience or interest in consumer apps/consumer tech
Curiosity about anomalies in the data and the ability to identify the business opportunities they represent.
Strong communication skills and excitement around championing your great ideas and insights to stakeholders at all levels
Azure experience is a plus
",None Found,None Found,None Found,"
4+ years of relevant technical experience, including 2+ years with noSQL databases (MongoDB preferred) as well as experience with SQL
Strong Python coding skills
Experience developing and implementing ETL architectures with large, complex data sets
Understanding of database architecture and data lakes
Distributing computing (parallel processing, multi-threading) – Hadoop, MapReduce, Spark
Hands-on experience with web crawling/web scraping required (6+ months)
Experience developing APIs
Experience with Node.js and familiarity with Machine Learning are pluses
Strong quantitative data analysis skills
Beyond the technical, strong business thinking is required, including experience or interest in consumer apps/consumer tech
Curiosity about anomalies in the data and the ability to identify the business opportunities they represent.
Strong communication skills and excitement around championing your great ideas and insights to stakeholders at all levels
Azure experience is a plus
","About us

Launched in October 2018, the Likewise app is the fun, social and incredibly useful way for people to discover, curate, and share recommendations on TV shows, movies, books, podcasts, restaurants, travel and more. Best of all, Likewise helps people quickly find recommendations from their friends, family, and other trusted sources.
Imagined and backed by Bill Gates’ private office, Likewise is a rare early-stage startup that is thinking big, playing to win, and investing to continue its rapid growth trajectory. If you are passionate about what you do, and want to be a core part of creating a household consumer name, then come talk to us about getting in on the fun!
Here's a link to a Geekwire article about us: https://bit.ly/2RuxBlx. And Built In Seattle named us one of Seattle’s 50 Startups to Watch in 2019! https://bit.ly/2VXup3o
Role
With the Likewise app launched, we have a lot of fun and creative work ahead of us in making Likewise’s AI into the end-all-be-all for determining the best recommendations to consumers across any category – movies, podcasts, books, restaurants, travel, and more! The work you will be doing is the foundation to making Likewise AI real, and it won’t happen without you. You’ll redefine how AI makes recommendations, and in doing so, change people’s lives for the better. We expect to grow the team as the company grows, and the right candidate will have the potential to lead that growth.
Objectives
Create a process that handles our disparate internal and external data sources and automatically converts that unstructured data into structured data to be consumed by machine learning and our product, marketing, and executive teams
Build data process pipelines for new and existing data sources
Glean insights and business opportunities from the data, and champion ideas for improvement based on those insights to the product team
Lead the external data sources collection effort, and creatively identify new, relevant data sources that will positively impact our products and users
Work closely with the Data Science team to complete all data needs
Find the handful of outliers in massive data sets and define processes to handle them
Requirements
Qualifications
4+ years of relevant technical experience, including 2+ years with noSQL databases (MongoDB preferred) as well as experience with SQL
Strong Python coding skills
Experience developing and implementing ETL architectures with large, complex data sets
Understanding of database architecture and data lakes
Distributing computing (parallel processing, multi-threading) – Hadoop, MapReduce, Spark
Hands-on experience with web crawling/web scraping required (6+ months)
Experience developing APIs
Experience with Node.js and familiarity with Machine Learning are pluses
Strong quantitative data analysis skills
Beyond the technical, strong business thinking is required, including experience or interest in consumer apps/consumer tech
Curiosity about anomalies in the data and the ability to identify the business opportunities they represent.
Strong communication skills and excitement around championing your great ideas and insights to stakeholders at all levels
Azure experience is a plus
Benefits
Working here
Located in downtown Bellevue, close to restaurants, shopping, parks and transit, we are proud to offer a competitive benefits package including stock options, health care where we pay 100% of employee premiums, 401(k) plan, commuter benefits, flexible paid time off, and a culture that’s team-based, open, casual and fun. If you’re looking for a rare opportunity to be a part of an innovative, exciting company and become a key member on our team, join us!
We support workplace diversity and do not discriminate on the basis of race, color, religion, gender identity or expression, national origin, age, military service eligibility, veteran status, sexual orientation, marital status, physical or mental disability, or any other protected class."
1,"Data Engineer I, Amazon Payment Products","Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"We are looking for Data Engineer who has a passion for their customers and a passion for working with data. You like working with your customers, understanding their challenges, and partnering with them to invent great solutions. You like working with large data sets, and bringing data together from multiple systems to answer critical business questions and drive change. You are analytical and creative. You should also have the following skills or experiences:Bachelor’s degree in Computer Science, Mathematics, Statistics, Finance or related technical field.
3+ years developing end-to-end Business Intelligence solutions: data modeling, ETL and reporting3+ years in relational database concepts with a solid knowledge of star schema, Oracle, SQL, PL/SQL, SQL Tuning, OLAP, Big Data technologiesExperience with coding languages like Python/Java/ScalaExperience in working with business customers to drive requirements analysisHave analytical skills and be creativeExperience with Big Data solutions: Hadoop, Hive or other frameworksExposure to large databases, BI applications, data quality and performance tuningExcellent written and spoken communication skill

Hundreds of millions of customers, billions of transactions, petabytes of data… How to use the world’s richest collection of e-commerce data to provide superior value and better paying experience to customers ? The Amazon Payments Team manages all Amazon branded payment offerings globally. These offerings are growing rapidly and we are continuously adding new market-leading features and launching new products. Amazon.com has a culture of data-driven decision-making and demands business intelligence that is timely, accurate, and actionable. This team provides a fast-paced environment where every day brings new challenges and new opportunities.

Our team of high caliber software developers, data scientists, statisticians and product managers use rigorous quantitative approaches to ensure that we target the right product to the right customer at the right moment, managing tradeoffs between click through rate, approval rates and lifetime value. In order to accomplish this we leverage the wealth of Amazon’s information to build a wide range of probabilistic models, set up experiments that ensure that we are thriving to reach global optimums and leverage Amazon’s technological infrastructure to display the right offerings in real time.

As a Data Engineer you will be working in one of the world's largest and most complex data warehouse environments. You should be passionate about working with huge data sets and be someone who loves to bring datasets together to answer business questions. You should have deep expertise in creation and management of datasets. You will build data analytical solutions that will address increasingly complex business questions.

You should be expert at implementing and operating stable, scalable data flow solutions from production systems into end-user facing applications/reports. These solutions will be fault tolerant, self-healing and adaptive. You will be working on developing solutions that provide some of the unique challenges of space, size and speed. You will implement data analytics using cutting edge analytics patterns and technologies that are inclusive of but not limited to various AWS Offerings -EMR, Lambda, Kinesis, and Spectrum. You will extract huge volumes of structured and unstructured data from various sources (Relational /Non-relational/No-SQL database) and message streams and construct complex analyses. You will write scalable code and tune performance running over billion of rows of data. You will implement data flow solutions that process data on Spark ,Redshift and store in Redshift ,Filebased system (S3) for reporting and adhoc analysis.

You should be detail-oriented and must have an aptitude for solving unstructured problems. You should work in a self-directed environment, own tasks and drive them to completion.

You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions and to build data sets that answer those questions. You own customer relationship about data and execute tasks that are manifestations of such ownership, like ensuring high data availability, low latency, documenting data details and transformations and handling user notifications and training.

Experience partnering with business owners directly to understand their requirements and provide data which can help them observe patterns and spot anomalies.Experience with web technology to develop dashboards.Practical Knowledge of Linux or Unix shell scriptingExperience in processing large volume of data.Strong troubleshooting and problem solving skillsDemonstrated experience in dealing with Senior Management on addressing their reporting and metrics requirements"
2,HR Finance Data Engineer III,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelor's degree or higher in a quantitative/technical field (e.g. Computer Science, Statistics, Engineering).5+ years of relevant experience in one of the following areas: Data engineering, database engineering, business intelligence or business analytics.5+ years of hands-on experience in writing complex, highly-optimized SQL queries across large data sets.5+ years of experience in scripting languages like Python, Scala, etc.Demonstrated strength in data modeling, ETL development, and Data warehousing. Data WarehousingExperience with Redshift, Oracle, NoSQL etc.Experience with AWS services including S3, Redshift, EMR, Kinesis and RDS.Experience with Big Data Technologies (Hadoop, Hive, Hbase, Pig, Spark, etc.)Experience in working and delivering end-to-end projects independently.Knowledge of distributed systems as it pertains to data storage and computing.

The Human Resources Finance Technology team within Amazon's Financial Planning & Analysis organization is seeking a highly skilled and motivated Data Engineer to join our team in Seattle. You will be building world class big data applications to support Amazon Human Resources. If you enjoy innovating, thinking big and want to contribute directly to the success of a growing team, you may be a prime candidate for this position.

As a Sr. Data Engineer on the HR Finance Tech team, you will
Build robust and scalable data integration (ETL) pipelines using SQL, EMR, Python, Spark, Redshift, Lambda, and MatillionBuild and deliver high quality data architecture to support business intelligence engineer and program managers’ reporting needs.Interface with other technology teams to extract, transform, and load data from a wide variety of data sources.Drive both business and technology solutions to improve visibility into key Amazon HR metrics.Continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers.Translate data into actionable insights for the stakeholders.

Proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategyExperience providing technical leadership and mentoring other engineers for best practices on data engineeringKnowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operationsMasters in computer science, mathematics, statistics, economics, or other quantitative field
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation/Age"
3,Business Intelligence Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelors in engineering, science, math, statistics or computer science3+ years of work experience as a business intelligence engineer, data engineer or data scientist role3+ years of experience in SQL programming3+ years of experience in building data warehouses and dimensional modeling3+ years of experience with business intelligence and data visualization tools (e.g. Tableau)3+ years of experience with a modern programming language (e.g. Python, R, Scala etc.)Experience with AWS Suite

Amazon Lab126 is an inventive research and development company that designs and engineers high-profile consumer electronics. Lab126 began in 2004 as a subsidiary of Amazon.com, Inc., originally creating the best-selling Kindle family of products. Since then, we have produced groundbreaking devices like Fire tablets, Fire TV, Amazon Echo and Amazon Show. The Amazon Devices group delivers delightfully unique Amazon experiences, giving customers instant access to everything, digital or physical.

Are you interested in a fast-paced, high-growth environment with the opportunity to work on business-critical decisions? Amazon Device Accessories is looking for an outstanding Business Intelligence Engineer to join our Operational Excellence Team. We’re looking for someone who can provide insight on KPI’s, understand inferential statistics and advise business teams on how to optimize for profit.

As an engineer on the team, you'll leverage tools and services including Amazon Redshift, Tableau, AWS Glue, AWS Athena, Spark, EMR, Machine Learning and Time Series models to build solutions that deliver data-driven reports, dashboards, and recommendations to high level leadership.

You'll work directly with business leaders and stakeholders to understand different business problems and use cases. You'll work with Finance, Tech and Business teams to identify and consume data sources, transform the data, and build the reports and visualizations needed to meet the requirements. You’ll have the opportunity to get hands on experience with Machine Learning, Time Series Modelling and high impact business analysis.

Developing this capability will provide insights that are used to lead decision making around product allocation, product effectiveness, productivity analysis and business impact. Consumers of these insights will include Directors, VP’s and SVP’s.

Our tenets for analytics team members are as follows:
Utilizing the Scientific Method to make tangible business impactMetrics before Messes
o Ensuring we’re measuring the right business metrics to guide the business
Forecast or be Last
o Developing state of the art predictive models for ensuring we’re moving in the right direction

Roles and Responsibilities:
Build data solutions using AWS services that deliver data-driven reports, dashboards, and tools.Develop and implement Time Series and Machine Learning Forecast ModelsManage marketing and sales data for the organizationManage ETL pipelines using AWS EMR and SparkDistill problem definitions, models, and constraints from informal business requirements.Provide innovative self-service tools to our customers to self-serve and scale dataFollow established engineering best practices and define new best practices where required.Identify critical metrics/reports that measure product performance, efficiency/effectiveness and create client facing dashboards to facilitate decision making.Collaborate on the design, development, maintenance, and delivery/presentation of forecasting models, metrics, reports, analyses, tools, and dashboardsPerform proactive diagnostic analysis on the various product measures and surface meaningful insights to the leadership team.Collaborate with Data Scientists, Data Engineers and Economists to develop Product Insights on Marketing and Sales data.

Masters in engineering, science, math, statistics or computer scienceExperience using AWS services for data analytics (i.e., Athena, Glue, Redshift, EMR, etc.)Experience developing custom ETL solutions using Python and SQLExperience with Tableau Desktop and Tableau ServerStrong written and verbal communications skills. Having the ability to translate scientific findings into business recommendations and outputs.The ability to influence stakeholders through delivering results and earning trustBasic statistical tests (but not limited to) t-tests, chi-square and regressionExpert SQLProficiency in PythonExperience delivering the best Products to customers
Amazon is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age."
4,"Data Engineer, Global Specialty Fulfillment","Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"BS in Computer Science, Math, Physics, or Engineering6+ years relevant work experience in software development or related data-driven fieldKnowledge of data management fundamentals and data storage principlesKnowledge of distributed systems as it pertains to data storage and computingDemonstrated experience in relational database concepts with an expert knowledge of SQLDemonstrated ability in data modeling, ETL development, and Data warehousing

Love food? We do! The AmazonFresh and Prime Now operations finance team is seeking an experienced and innovative Data Engineer to build tools that support Operations teams in AmazonFresh and Prime Now. We are an analytics team responsible for building tools, analysis, and reporting to support internal leaders within fulfillment, last mile, and supply chain operations. This is a unique opportunity for someone interested in Amazon’s start-up consumables-focused environment. AmazonFresh and Prime Now experiment, fail fast, learn, and scale rapidly.

Ultra-fast delivery delights Amazon customers by delivering what they want quickly: medication for a sick kid, lunch at work when you forgot, food and drinks for a party, last minute gifts, dinner from a local restaurant, and so many more uses.

The business model of ultra-fast delivery is attractive, and offers our Engineering team the opportunity to work on any number of complex technical problems. Our team designs, builds and owns our end-to-end services from the ground up and works on large scale back-end systems to support the entirety of our order and inventory pipelines.

We are seeking Data Engineer. In this role you will:

You help build the infrastructure to answer questions with data, using software engineering best practices, data management fundamentals, data storage principles, and recent advances in distributed systems
You manage AWS resources.
You collaborate with Business Intelligence Engineers (BIEs) to recognize and help adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation
You help drive the architecture and technology choices that enable a world-class user experience
You develop expertise in a broad range of Amazon’s data resources and know when, how, and which to use and which not to use
You encourage the organization to adopt next-generation data architecture strategies, proposing both data flows and storage solutions
You are comfortable with a degree of ambiguity and willing to develop quick proof of concepts, iterate and improve
You create extensible designs and easy to maintain solutions with the long term vision in mind
You have an understanding and empathy for business objectives, and continually align your work with those objectives and seek to deliver business value. You listen effectively.
You are comfortable presenting your findings to large groups

We have a very flat team structure, and offer a unique opportunity for technical leaders who want to work closely with the business in defining, designing, building and operating products that are in the early stage of fast expansion.

Experience working with AWS Big Data TechnologiesExperience working with Open Source Big Data toolsProven track record of delivering a big data solutionExperience developing tools for data engineers and machine learningExperience working with both Batch and Real Time data processing systems
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Vet / Gender Identity / Sexual Orientation / Age"
5,Business Intel Engineer III,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"BA/BS in Computer Science, Engineering, Statistics, Mathematics, Finance or related field.5+ years’ experience as a BIE, data scientist, data engineer or similar job function with a technology company.Demonstrated strength in SQL, data modeling, ETL development, and data warehousing.Advanced skills in Excel as well as any data visualization tools like Quicksight, Tableau or similar BI tools.Experience of working in very large data warehouse environment and multi data sources.Familiarity with AWS solutions such as Redshift, S3.Advanced ability to draw insights from data and clearly communicate them to the stakeholders and senior management.Have ability to influence and drive program from end to end.

Amazon seeks an experienced Business Intelligence Engineer (BIE) to join Enterprise Risk Management and Compliance (ERMC) team. Our mission is to prevent denied parties from transacting with Amazon businesses, including AWS, customers, vendors, sellers, subsidiaries etc. We screen events in billion every day.

You efficiently and routinely deliver the right things. You are seasoned BI. You have broad knowledge on Amazon businesses, data, systems and tools. You have a department-wide view of the analytical solutions that you build, and you consistently think in terms of automating or expanding the results beyond our business. You are a key influencer in your team’s strategy and contribute significantly to team projects. You will drive reporting/analytics projects from end-to-end. You supervise the creation and implementation of BI projects, provide mentor and guidance to team members, help them to achieve their goals.

This role has opportunity to grow to a BI manager in the future.

Duties & responsibilities for this role will include:

Interface with business customers to gather requirements, drive reporting or analytic projects to help solve complex challenges.
Design, implement, and support datasets that provide structured data for reporting and analysis.
Develop Tableau/QuickSight dashboards across various business teams to drive adoption and increase visibility into key measures of business performance.
Analyze billions of rows of data to find the root causes behind variances and drive business insights.
Investigate and implement new big data technologies to provide automatic resolutions to address business needs.
Mentor junior team members and help them grow.
The successful candidate will demonstrate good business acumen, experience in developing reports and conducting analysis, strong communication skills, an ability to work effectively with cross functional teams, and an ability to work in an ever-changing environment.

MBA or Master’s in Computer Science, Engineering, Statistics, Mathematics, Finance or related field.Experience in projects involving complex data sets and high variability.Working knowledge of statistical methodologies.Experience to conduct complex data analysis and use ML models.A history of teamwork and willingness to roll up one’s sleeves to get the job done.Excellent communication (verbal and written) and interpersonal skills and an ability to effectively communicate with both business and technical teams.Experience to handle confidential and sensitive data.Design and develop data infrastructure to support business growth."
6,"Manager III, Data Engineer","Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Experience mentoring and managing other Data Engineers or Software Development Engineers, ensuring data engineering best practices are being followedA desire to work in a collaborative, intellectually curious environment.Bachelors degree in Computer Science, Mathematics, Physical Sciences or a related STEM field5+ Years of Data Warehouse Experience with Oracle, Redshift, PostgreSQL, etc.Experience in maintaining data warehouse systems and working on large scale data transformation using EMR, Hadoop, Hive, or other Big Data technologiesDemonstrated strength in SQL, data modeling, ETL development, and data warehousingExperience with administering and supporting multiple relational and non relational DBs managing data at peta byte scaleExperience with hardware provisioning, forecasting hardware usage, and managing to a budget

The S3C Compliance team owns the end-to-end compliance experience for over two million active Selling Partners. We own innovation in food and product safety, compliance for global trade, and accuracy for dangerous goods classifications. We support worldwide product, program, data science, and analytics teams. We provide scalable technology to improve safety and compliance in throughout the supply chain.

We are looking for an experienced Data Engineering Manager to lead the Risk Data Technologies team, manage existing data resources, implement new technologies and tooling to further enable science and analytics, as well as help drive scalable data sharing practices. In this role you will split your time between hands on development and managerial activities. You will own data environments, integrate with new technologies, and oversee the development of new processes that support teams across the global compliance organization. You will gather requirements through direct interaction with business, science, as well as software development teams. You will track the performance of our resources and related capabilities, constantly evolving our offering in order to scale our capability set with the growth of the business and needs of our customers.

The ideal candidate will have outstanding communication skills, proven data infrastructure design and implementation capabilities, strong business acumen, and an innate drive to deliver results. He/she will be a self-starter, comfortable with ambiguity and will enjoy working in a fast-paced dynamic environment.

Extensive experience working with AWS with a strong understanding of Redshift, EMR, Athena, Aurora, DynamoDB, Kinesis, Lambda, S3, EC2, etc.Extensive Experience with Big Data Technologies (Hadoop, Hive, Hbase, Pig, Spark, etc.)Strong interpersonal skills and the ability to communicate complex technology solutions to senior leadership, gain alignment, and drive progress
Amazon is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age."
7,"Data Engineer, Talent Assessment","Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Degree in Computer Science, Engineering, Mathematics, or a related field, or substantial industry experience5+ years of experience data warehousingExpertise in Redshift, Netezza, Teradata or other MPP databasesExperience with data modeling and ETL (load/transform) developmentExceptional command of SQLHands on experience with a business intelligence tool such as Tableau, OBIEE, Cognos, SSRS/SSAS, or QuickSightKnowledge of a programming or scripting language (Python, Perl, or Javascript)

Amazon’s Talent Assessment team designs and implements groundbreaking hiring solutions for one of the world’s fastest growing companies. We work in a fast-paced, global environment where we must solve complex problems (ranging from research-based to technical) and deliver solutions that have impact.

We are seeking a Data Engineer who can lead the development and support of the analytic technologies as we use data-based solutions to design and experiment with new hiring solutions that predict success for highly complex roles (technical and non-technical). Be part of a global team that helps select for roles having great impact on Amazon globally (for example, AWS, Kindle, Retail, and Business & Development). You will enable flexible and structured access to our global candidate data to support our strategies. This includes implementation of a BI platform, promotion of scalability through automation and reporting tools, and adherence to the highest data quality and governance standards. The candidate will also drive the design and implementation of world class big data infrastructure to support machine learning and econometric analysis. This role is based in Seattle, WA.

Master’s degree in Information Systems or a related fieldExperience with Java and Map Reduce frameworks such as Hive/Hadoop.Familiarity with EMR, NoSql, Dynamo DBStrong organizational and multitasking skills with ability to balance competing priorities.Exceptional written communication skills"
8,Big Data Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"A desire to work in a collaborative, intellectually curious environment.Degree in Computer Science, Engineering, Mathematics, Physics, or a related field and at least 4 years work experienceIndustry experience as a Data Engineer or related specialty (e.g., Software Engineer, Business Intelligence Engineer, Data Scientist) with a track record of manipulating, processing, and extracting value from large datasets.Demonstrated ability in data modeling, ETL development, and data warehousing.Experience with Oracle, Redshift, Teradata, etc.Experience with Big Data Technologies (Hadoop, Hive, Hbase, Pig, Spark, etc.)Coding proficiency in at least one modern programming language (Python, Ruby, Java, etc)

Machine Learning is changing the way new products, programs and services are created and intelligently marketed to customers to increase customer engagement. The Consumer Analytics team is uniquely organized with SDEs, DEs, BIEs and Research Scientists to solve challenging predictive analytics problems at Amazon scale. Are you passionate about Big Data (Amazon scale), Machine Learning and Predictive Analytics software?

Big Data Processing
We are responsible for the production, processing, and analysis of several TB’s of customer grain data on a daily basis. We analyze data coming from various traffic channels such as onsite, free search, paid search, social, paid social email, associates etc. We heavily use AWS services such as AWS Flow, S3, EC2, EMR (Hadoop/Spark), Kinesis, DynamoDb to manage our data workflows.

Machine Learning
We build various Machine Learning solutions that learn and become better with time by the addition of new data and validation methodologies. We work with both supervised and unsupervised machine learning approaches not limited to regression, classification, clustering etc.

Our products have become Amazon wide programs and are accelerating in adoption across businesses. We have services that provide predictions from our models to influence Amazon customer experience. However, as we look forward our rate of innovation is dependent on the quality and breadth of data we input to these models. As Amazon is pivoting towards worldwide simultaneous launches of programs like Prime and Amazon Video our fundamental data models need to be re-engineered. We also need serious engineering behind the data pipelines to establish and support stronger SLAs as businesses take dependency on our outputs.

We are looking for an outstanding individual who combines superb technical, communication, and analytical capabilities with a demonstrated ability to get the right things done quickly and effectively. This person must be comfortable working with a team of software development engineers to raise the bar of the data pipelines we build and maintain. Given the cross Amazon nature of our products, the individual should be highly self-directed having good cross-team collaboration skills.

The ideal candidate for our team is a thinker and a doer: someone who loves sophisticated algorithms and mathematical precision, but at the same time enjoys implementing real systems, and is motivated by the prospect of spectacular business returns.

Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data setsExperience building data products incrementally and integrating and managing datasets from multiple sourcesExperience leading large-scale data warehousing and analytics projects, including using AWS technologies – Redshift, S3, EC2, Data-pipeline and other big data technologiesExperience providing technical leadership and mentor other engineers for the best practices on the data engineering spaceExperience using machine learning and statistical tools such as Python/Pandas, R etc .Linux/UNIX including to process large data sets.
Amazon.com is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation."
9,Data Engineer I,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"A desire to work in a collaborative, intellectually curious environment.Degree in Computer Science, Engineering, Mathematics, or a related field and 4-5+ years industry experienceOne year of experience in the following skill(s):Developing and operating large-scale data structures for business intelligence analytics using: ETL/ELT processes; OLAP technologies; data modeling; SQL;Experience with at least one relational database technology such as Redshift, Oracle, MySQL or MS SQLExperience with at least one massively parallel processing data technology such as Redshift, Teradata, Netezza, Spark, or Hadoop based big data solution

Health, Safety, Security, and Compliance (HS3C) is responsible for keeping our Customers and partners safe, and ensuring we maintain WW compliance. We build scalable solutions that grow with the Amazon business. HS3C-Compliance team collects petabytes of data from thousands of data sources inside and outside Amazon including the Amazon catalog system, inventory system, customer order system, and page views on the website. We provide interfaces for our internal customers to access and query the data hundreds of thousands of times per day, using Amazon Web Service’s (AWS) Redshift, Hive, and Spark.

HS3C-Compliance is growing, and the data processing landscape is shifting. Our data is consumed by teams across HS3C including Research Scientists, Machine Learning Specialists, Business Analysts, and Data Engineers. We are seeking an outstanding Data Engineer to join the HS3C-Compliance data technologies team. The HS3C-Compliance data technologies team manages the core HS3C business data from hundreds of source systems. Amazon has culture of data-driven decision-making, and demands business intelligence that is timely, accurate, and actionable. If you join the HS3C-Compliance data technologies team, your work will have an immediate influence on day-to-day decision making at Amazon.

As an Amazon Data Engineer II, you will be working in one of the world's largest cloud-based data lakes. You should be skilled in the architecture of data warehouse solutions for the Enterprise using multiple platforms (EMR, RDBMS, Columnar, Cloud). You should have extensive experience in the design, creation, management, and business use of extremely large datasets. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions, and to build data sets that answer those questions. Above all you should be passionate about working with huge data sets and someone who loves to bring datasets together to answer business questions and drive change.
As a Data Engineer II on the HS3C-Compliance data technologies team, you will design, develop, implement, test, document, and operate large-scale, high-volume, high-performance data structures for analytics and deep learning. Implement data ingestion routines both real time and batch using best practices in data modeling, ETL/ELT processes leveraging AWS technologies and Big data tools. Gather business and functional requirements and translate these requirements into robust, scalable, operable solutions that work well within the overall data architecture. Analyze source data systems and drive best practices in source teams. Participate in the full development life cycle, end-to-end, from design, implementation and testing, to documentation, delivery, support, and maintenance. Produce comprehensive, usable dataset documentation and metadata. Evaluate and make decisions around dataset implementations designed and proposed by peer data engineers. Evaluate and make decisions around the use of new or existing software products and tools. Mentor junior data engineers.

Industry experience as a Data Engineer or related specialty (e.g., Software Engineer, Business Intelligence Engineer, Data Scientist) with a track record of manipulating, processing, and extracting value from large datasets.Coding proficiency in at least one modern programming language (Python, Ruby, Java, etc)Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data setsExperience building data products incrementally and integrating and managing datasets from multiple sourcesQuery performance tuning skills using Unix profiling tools and SQLExperience leading large-scale data warehousing and analytics projects, including using AWS technologies – Redshift, S3, EC2, Data-pipeline and other big data technologiesExperience providing technical leadership and mentor other engineers for the best practices on the data engineering spaceLinux/UNIX including to process large data sets.Experience with AWS
Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age."
10,AWS Data Engineer,"Seattle, WA 98104",Seattle,WA,98104,None Found,"At least 5 years of Consulting or client service delivery experience on Amazon AWS (AWS)At least 5 years of experience in developing data ingestion, data processing and analytical pipelines for big data, relational databases, NoSQL and data warehouse solutionsExtensive experience providing practical direction within the AWS Native and HadoopExperience with private and public cloud architectures, pros/cons, and migration considerations.Minimum of 5 years of hands-on experience in AWS and Big Data technologies such as Java, Node.js, C##, Python, SQL, EC2, S3, Lambda, Spark/SparkSQL, Hive/MR, Pig, Oozie and streaming technologies such as Kafka, Kinesis, NiFI etc.Extensive hands-on experience implementing data migration and data processing using AWS services: VPC/SG, EC2, S3, AutoScaling, CloudFormation, LakeFormation, DMS, Kinesis, Kafka, Nifi, CDC processing Redshift, Snowflake, RDS, Aurora, Neptune, DynamoDB, Hive, NoSQL, Cloudtrail, CloudWatch, Docker, Lambda, Spark,Glue, Sage Maker, AI/ML, API GW, etc.5+ years of hands on experience in programming languages such as Java, c#, node.js, python, pyspark, spark, SQL, Unix shell/Perl scripting etc.Minimum of 5 years of RDBMS experienceExperience in using Hadoop File Formats and compression techniquesExperience working with DevOps tools such as GitLabs, Jenkins, CodeBuild, CoePipeline CodeDeploy, etc.Bachelors or higher degree in Computer Science or a related discipline.","DevOps on an AWS platform. Multi-cloud experience a plus.Experience developing and deploying ETL solutions on AWS using tools like Talend, Informatica, MatillionStrong in Java, C##, Spark, PySpark, Unix shell/Perl scriptingIoT, event-driven, microservices, containers/Kubernetes in the cloud",None Found,None Found," Proven ability to build, manage and foster a team-oriented environment Proven ability to work creatively and analytically in a problem-solving environment Desire to work in an information systems environment Excellent communication (written and oral) and interpersonal skills Excellent leadership and management skills","Are you ready to step up to the New and take your technology expertise to the next level?

Join Accenture and help transform leading organizations and communities around the world. The sheer scale of our capabilities and client engagements, in conjunction with the way we collaborate, operate and deliver value, provides an unparalleled opportunity to grow and advance. Choose Accenture and make delivering innovative work part of your extraordinary career.

People in our Client Delivery & Operations career track drive delivery and capability excellence through the design, development and/ or delivery of a solution, service, capability or offering. They grow into delivery-focused roles, and can progress within their current role, laterally or upward. We partner with our clients to help transform their data into an ‘Appreciating Business Asset.’

As part of our Data Business Group, you will lead technology innovation for our clients through robust delivery of world-class solutions. You will build better software better! There will never be a typical day and that’s why people love it here. The opportunities to make a difference within exciting client initiatives are unlimited in the ever-changing technology landscape. You will be part of a highly collaborative and growing network of technology and data experts, who are taking on today’s biggest, most complex business challenges using the latest data and analytics technologies. We will nurture your talent in an inclusive culture that values diversity. You will have an opportunity to work in roles such as Data Scientist, Data Engineer, or Chief Data Officer covering all aspects of Data including Data Management, Data Governance, Data Intelligence, Knowledge Graphs, and IoT. Come grow your career in Technology at Accenture!

The Amazon AWS Data Engineer is responsible for delivering Data On Cloud projects for Amazon AWS based deals. The ideal candidate would be responsible for developing and delivering AWS cloud solutions to meet today’s high demand in areas such as AIML, IoT, advanced analytics, open source, enterprise collaboration, microservices, serverless, etc. The AWS Data Engineer is a highly performant engineer responsible for delivering Cloud based Big Data and Analytical Solutions at our clients. Responsibilities include building data on cloud solutions at customers, leading Business and IT stakeholders through designing a robust, secure and optimized AWS solutions and ability to be hands-on delivering the target solution. This role will work with customers and leading internal engineering teams in delivering big data soltuions on cloud. Using Amazon AWS public cloud technologies, our AWS Data Engineer professionals implement state of the art, scalable, high performance Data On Cloud solutions that meet the need of today’s corporate and emerging digital applications.

Role & Responsibilities:
Provide subject matter expertise and hands on delivery of data capture, curation and consumption pipelines on AWS and HadoopAbility to build cloud data solutions and provide domain perspective on storage, big data platform services, serverless architectures, hadoop ecosystem, RDBMS, DW/DM, NoSQL databases and security.Participate in deep architectural discussions to build confidence and ensure customer success when building new solutions and migrating existing data applications on the AWS platform.
- Build full technology stack of services required including PaaS (Platform as-a-service), IaaS (Infrastructure as-a-service), SaaS (software as-a-service), operations, management and automation.Apply Accenture methodology, Accenture reusable assets, and previous work experience to delivery consistently high-quality work.Stay educated on new and emerging technologies/patterns/methodologies and market offerings that may be of interest to our clients.Understand the strategic direction set by senior management as it relates to team goals.Use considerable judgment to define solution and seeks guidance on complex problems.Primary upward interaction is with direct supervisor. May interact with peers and/or management levels at a client and/or within Accenture. Establish methods and procedures
on new assignments with guidance.Manage small teams of delivery engineers successfully delivering work efforts (if in an independent contributor role) at a client or within Accenture.Able to travel up to 100% (M-TH)

Basic QualificationsAt least 5 years of Consulting or client service delivery experience on Amazon AWS (AWS)At least 5 years of experience in developing data ingestion, data processing and analytical pipelines for big data, relational databases, NoSQL and data warehouse solutionsExtensive experience providing practical direction within the AWS Native and HadoopExperience with private and public cloud architectures, pros/cons, and migration considerations.Minimum of 5 years of hands-on experience in AWS and Big Data technologies such as Java, Node.js, C##, Python, SQL, EC2, S3, Lambda, Spark/SparkSQL, Hive/MR, Pig, Oozie and streaming technologies such as Kafka, Kinesis, NiFI etc.Extensive hands-on experience implementing data migration and data processing using AWS services: VPC/SG, EC2, S3, AutoScaling, CloudFormation, LakeFormation, DMS, Kinesis, Kafka, Nifi, CDC processing Redshift, Snowflake, RDS, Aurora, Neptune, DynamoDB, Hive, NoSQL, Cloudtrail, CloudWatch, Docker, Lambda, Spark,Glue, Sage Maker, AI/ML, API GW, etc.5+ years of hands on experience in programming languages such as Java, c#, node.js, python, pyspark, spark, SQL, Unix shell/Perl scripting etc.Minimum of 5 years of RDBMS experienceExperience in using Hadoop File Formats and compression techniquesExperience working with DevOps tools such as GitLabs, Jenkins, CodeBuild, CoePipeline CodeDeploy, etc.Bachelors or higher degree in Computer Science or a related discipline.

Candidate Must Have Completed The Following Certifications
§ Certified AWS Developer - Associate
§ Certified AWS DevOps – Professional (Nice to have)
§ Certified AWS Big Data Specialty (Nice to have)

Nice-to-Have Skills/Qualifications:DevOps on an AWS platform. Multi-cloud experience a plus.Experience developing and deploying ETL solutions on AWS using tools like Talend, Informatica, MatillionStrong in Java, C##, Spark, PySpark, Unix shell/Perl scriptingIoT, event-driven, microservices, containers/Kubernetes in the cloud
Experience in Apache Maven a plusUnderstanding and implementation of Data Lake architecturesUnderstanding NoSQL technologies such as MongoDB, Cassandra, Hbase is a plusUnderstanding Solr, Elasticsearch is a plus

Professional Skill Requirements Proven ability to build, manage and foster a team-oriented environment Proven ability to work creatively and analytically in a problem-solving environment Desire to work in an information systems environment Excellent communication (written and oral) and interpersonal skills Excellent leadership and management skills

All of our professionals receive comprehensive training covering business acumen, technical and professional skills development. You'll also have opportunities to hone your functional skills and expertise in an area of specialization. We offer a variety of formal and informal training programs at every level to help you acquire and build specialized skills faster. Learning takes place both on the job and through formal training conducted online, in the classroom, or in collaboration with teammates. The sheer variety of work we do, and the experience it offers, provide an unbeatable platform from which to build a career.

Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status).

Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.

Accenture is a Federal Contractor and an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities.

Equal Employment Opportunity

All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.

Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.

Accenture is committed to providing veteran employment opportunities to our service men and women."
11,Data Engineer,"Bellevue, WA 98004",Bellevue,WA,98004,None Found,"
Bachelor’s degree required
3-5 years of experience in database technologies
Minimum 3 years of experience in Data Warehousing
Experience with AWS tools (S3/EC2/Athena/Redshift Spectrum/IAM)
Experience with Python
Familiarity with Tableau or other data visualization tools.
Experienced with Linux administration and scripting
Deep experience with data modeling, data pipelines, SQL, AWS, and distributed compute platforms
Experience building effective relationships with a broad range of partners
Ability to communicate well with partners, both technical and non-technical",None Found,"
Collect, transform, analyze, and refine operational and customer data.
Build-out data structures designed to efficiently answer business questions.
Assist in evolving data structures from a MSSQL Server footprint into a data lake environment.
Develop, implement and tune current ETL processes.
Assist with ad hoc report generation and analysis for merchandise and customers.
Create pipelines from internal and external data sources to AWS using custom python scripts.
Assist in managing our Tableau ecosystem and provide technical support.","
Bachelor’s degree required
3-5 years of experience in database technologies
Minimum 3 years of experience in Data Warehousing
Experience with AWS tools (S3/EC2/Athena/Redshift Spectrum/IAM)
Experience with Python
Familiarity with Tableau or other data visualization tools.
Experienced with Linux administration and scripting
Deep experience with data modeling, data pipelines, SQL, AWS, and distributed compute platforms
Experience building effective relationships with a broad range of partners
Ability to communicate well with partners, both technical and non-technical","
While performing the duties of this job, the associate is regularly required to talk or hear. The associate is frequently required to sit; stand; walk; use hands to finger, handle or feel; as well as reach with hands and arms.
The associate must frequently lift and/or move up to 15 pounds and occasionally lift and/or move up to 35 pounds. Specific vision abilities required by this job include close vision, distance vision, depth perception and ability to adjust focus.
Ability to work in open environment with fluctuating temperatures and standard lighting
Ability to work on computer and mobile phone for multiple hours; with frequent interruptions
Required to travel in elevator or stairwells to attend meetings and engage with associates on multiple floors throughout building
Hotel, Airplane, and Car Travel Required","Overview
Responsible for unlocking the value in our ever growing data by creating new and improved techniques and solutions for data collection, management, usage and reporting.
Responsibilities
Core Accountabilities:
Collect, transform, analyze, and refine operational and customer data.
Build-out data structures designed to efficiently answer business questions.
Assist in evolving data structures from a MSSQL Server footprint into a data lake environment.
Develop, implement and tune current ETL processes.
Assist with ad hoc report generation and analysis for merchandise and customers.
Create pipelines from internal and external data sources to AWS using custom python scripts.
Assist in managing our Tableau ecosystem and provide technical support.
Qualifications
Education/Experience Required:
Bachelor’s degree required
3-5 years of experience in database technologies
Minimum 3 years of experience in Data Warehousing
Experience with AWS tools (S3/EC2/Athena/Redshift Spectrum/IAM)
Experience with Python
Familiarity with Tableau or other data visualization tools.
Experienced with Linux administration and scripting
Deep experience with data modeling, data pipelines, SQL, AWS, and distributed compute platforms
Experience building effective relationships with a broad range of partners
Ability to communicate well with partners, both technical and non-technical

Physical Requirements:
The physical demands described here are representative of those that are required by an associate to successfully perform the essential functions of this job.
While performing the duties of this job, the associate is regularly required to talk or hear. The associate is frequently required to sit; stand; walk; use hands to finger, handle or feel; as well as reach with hands and arms.
The associate must frequently lift and/or move up to 15 pounds and occasionally lift and/or move up to 35 pounds. Specific vision abilities required by this job include close vision, distance vision, depth perception and ability to adjust focus.
Ability to work in open environment with fluctuating temperatures and standard lighting
Ability to work on computer and mobile phone for multiple hours; with frequent interruptions
Required to travel in elevator or stairwells to attend meetings and engage with associates on multiple floors throughout building
Hotel, Airplane, and Car Travel Required

Position Type/Expected Hours of Work:
This is a full-time position. As an International Retailer, occasional evening and/or weekend work may be required during periods of high volume. This role operates in a professional office environment and routinely uses standard office equipment.

Other Considerations:
Please note this job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the associate for this job. Duties, responsibilities and activities may change at any time with or without notice. Reasonable accommodations may be made to qualified individuals with disabilities to enable them to perform the essential functions of the role."
12,Senior Data Engineer - Turn 10 Studios,"Redmond, WA",Redmond,WA,None Found,None Found,"
Enthusiasm for cars and/or gaming - Our priority is making amazing racing games. The ideal candidate must have enthusiasm for our products and empathy for our customers.
Enthusaism for cloud data technology - Our pipelines are fully supported by Azure leveraging things like Data Explorer (Kusto), Data Warehouse, Data Factory, Data Lake, SQL and Power BI. The ideal candidate has a passion for cloud technology and a minimum of 5 years' experience.
A drive to develop data insights - Collecting data is the easy part. Helping business leaders and game designers ask the right questions and answering these questions with a relentless attention to details (accuracy) is where the fun begins. The ideal candidate is a meticulous gatekeeper for data and code quality, passionate about generating insights from data, and a strong communicator and collaborator.
Enthusiasm for AI/ML or an interest to learn - We don't do science projects, but we have an aspiration to build AI/ML capabilities that generate customer value.",None Found,"
Evolving our big data pipelines to streamline data collection (measure things) and democratize the consumption of data (generate information).
Working with business leaders and game designers to answer the key questions that enable the team to drive franchise growth and create experiences that thrill customers.",None Found,None Found,"Games. Xbox. Big data. AI/ML. Turn 10 Studios, makers of the award winning, billion-dollar Forza franchise, is searching for a senior engineer to help build our next generation data pipelines. You would be joining a small team of awesome people that move fast, innovate daily, and have fun (we make games!).

Analytics is a crucial part of the business at Turn 10. Understanding user motivations and behaviors enables the team to build fun, engaging racing experiences on PC, Xbox and mobile. The gaming industry is evolving to a GaaS model (Games as a Service) where the most successful studios will learn continuously from data and respond rapidly to customer's needs. This is our challenge. As a leader on the data engineering team, you will be front and center building the platform that will enable the entire studio to quickly learn, adapt and transform our games.
Responsibilities
You'll focus on:

Evolving our big data pipelines to streamline data collection (measure things) and democratize the consumption of data (generate information).
Working with business leaders and game designers to answer the key questions that enable the team to drive franchise growth and create experiences that thrill customers.

Expanding the studios capabilities in AI/ML, building an intelligent cloud for Forza.
Qualifications
We only have a few requirements:

Enthusiasm for cars and/or gaming - Our priority is making amazing racing games. The ideal candidate must have enthusiasm for our products and empathy for our customers.
Enthusaism for cloud data technology - Our pipelines are fully supported by Azure leveraging things like Data Explorer (Kusto), Data Warehouse, Data Factory, Data Lake, SQL and Power BI. The ideal candidate has a passion for cloud technology and a minimum of 5 years' experience.
A drive to develop data insights - Collecting data is the easy part. Helping business leaders and game designers ask the right questions and answering these questions with a relentless attention to details (accuracy) is where the fun begins. The ideal candidate is a meticulous gatekeeper for data and code quality, passionate about generating insights from data, and a strong communicator and collaborator.
Enthusiasm for AI/ML or an interest to learn - We don't do science projects, but we have an aspiration to build AI/ML capabilities that generate customer value.

Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.

Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work."
13,Data Engineer- Python,"Seattle, WA 98104",Seattle,WA,98104,None Found, 5+ years of experience in core JAVA and SQL,None Found,None Found,None Found,None Found,"As a Senior Consultant, you will focus on managing the information supply chain from acquisition to ingestion, storage and the provisioning of data to points of impact by modernizing and enabling new capabilities. Information value is enhanced through enterprise-scale applications that enable visualization, consumption and monetization of both structured and unstructured data. Big data is becoming one of the most important technology trends that has the potential for dramatically changing the way organizations use information to enhance the customer experience and transform their business models.
Work you'll do

Senior Consultants work within an engagement team. Key responsibilities will include:
 Function as integrators between business needs and technology solutions, helping to create technology solutions to meet clients’ business needs.
 Identifying business requirements, requirements management, functional design, prototyping, process design (including scenario design, flow mapping), testing, training, defining support procedures and supporting implementations.

The Team

Analytics & Cognitive

In this age of disruption, organizations need to navigate the future with confidence, embracing decision making with clear, data-driven choices that deliver enterprise value in a dynamic business environment.


The Analytics & Cognitive team leverages the power of data, analytics, robotics, science and cognitive technologies to uncover hidden relationships from vast troves of data, generate insights, and inform decision-making. Together with the Strategy practice, our Strategy & Analytics portfolio helps clients transform their business by architecting organizational intelligence programs and differentiated strategies to win in their chosen markets.


Analytics & Cognitive will work with our clients to:
 Implement large-scale data ecosystems including data management, governance and the integration of structured and unstructured data to generate insights leveraging cloud-based platforms
 Leverage automation, cognitive and science-based techniques to manage data, predict scenarios and prescribe actions
 Drive operational efficiency by maintaining their data ecosystems, sourcing analytics expertise and providing As-a-Service offerings for continuous insights and improvements


Qualifications

Required:

 5+ years of experience in core JAVA and SQL
 3+ years of experience in Python& Unix Shell Scripting
 3+ years of experience in building scalable and high performance data pipelines using Apache Hadoop, Map Reduce, Pig & Hive
 Experience with bigdata cross platform compatible file formats like Apache Avro & Apache Parquet
 Experience in Apache Spark is a plus
 1+ years of experience with data lake implementations, core modernizations and data ingestion

 1 or more years of hands on experience designing and implementing data ingestion techniques for real time and batch processes for video, voice, weblog, sensor, machine and social media data into Hadoop ecosystems and HDFS clusters.
 2+ years of experience leading workstreams or small teams
 Willingness for weekly client-based travel, up to 80-100% (Monday — Thursday/Friday)
 Bachelor’s Degree or equivalent professional experience

 Preferred:

AWS Certification, Hadoop Certification or Spark Certification
Experience with Cloud using Amazon Web Services (AWS), Microsoft Azure, or Google Cloud Platform (GCP)
Experience with data integration products like Informatica Power Center Big Data Edition (BDE), IBM BigInsights, Talend etc.
Experience designing and implementing reporting and visualization for unstructured and structured data sets
Experience in designing and implementing scalable, distributed systems leveraging cloud computing technologies like AWS EC2, AWS Elastic Map Reduce and Microsoft Azure
Experience designing and developing data cleansing routines utilizing typical data quality functions involving standardization, transformation, rationalization, linking and matching
Knowledge of data, master data and metadata related standards, processes and technology
Experience working with multi-Terabyte data sets
Experience with Data Integration on traditional and Hadoop environments
Ability to work independently, manage small engagements or parts of large engagements.
Strong oral and written communication skills, including presentation skills (MS Visio, MS PowerPoint).
Strong problem solving and troubleshooting skills with the ability to exercise mature judgment.
Eagerness to mentor junior staff.
An advanced degree in the area of specialization is preferred.

How you’ll grow

At Deloitte, our professional development plan focuses on helping people at every level of their career to identify and use their strengths to do their best work every day. From entry-level employees to senior leaders, we believe there’s always room to learn. We offer opportunities to help sharpen skills in addition to hands-on experience in the global, fast-changing business world. From on-the-job learning experiences to formal development programs at Deloitte University, our professionals have a variety of opportunities to continue to grow throughout their career. Explore Deloitte University, The Leadership Center.


Benefits

At Deloitte, we know that great people make a great organization. We value our people and offer employees a broad range of benefits. Learn more about what working at Deloitte can mean for you.
Deloitte’s culture

Our positive and supportive culture encourages our people to do their best work every day. We celebrate individuals by recognizing their uniqueness and offering them the flexibility to make daily choices that can help them to be healthy, centered, confident, and aware. We offer well-being programs and are continuously looking for new ways to maintain a culture where our people excel and lead healthy, happy lives. Learn more about Life at Deloitte.


Corporate citizenship

Deloitte is led by a purpose: to make an impact that matters. This purpose defines who we are and extends to relationships with our clients, our people and our communities. We believe that business has the power to inspire and transform. We focus on education, giving, skill-based volunteerism, and leadership to help drive positive social impact in our communities. Learn more about Deloitte’s impact on the world.


Recruiter tips

We want job seekers exploring opportunities at Deloitte to feel prepared and confident. To help you with your interview, we suggest that you do your research: know some background about the organization and the business area you’re applying to. Check out recruiting tips from Deloitte professionals.

#LI:PTY
#IND:PTY"
14,Senior Data Engineer- Enterprise Data Platform,"Seattle, WA 98101",Seattle,WA,98101,None Found,None Found,None Found,"
Design, implement, and support a platform providing secured access to large datasets.
Collaborate with customers from Finance, HR and other shared service functions understanding their requirements and delivering data solutions they need.
Understand the data sources, develop an ETL strategy with these sources, perform data modeling to meet customers’ data needs.
Continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for datasets.
Recognize and adopt best practices in reporting and analysis: data integrity, data security, analysis, validation, and documentation.
Monitor, manage and administer the Enterprise Applications Data Warehouse and ensure optimal performance at scale.
Design, implement and manage the access to the datasets based on the Zillow’s data access policies.",None Found,None Found,"About the team
Are you passionate about data? Does the prospect of dealing with massive volumes of data excite you? Do you want to create the next-generation tools for intuitive data access?

Zillow Group's Enterprise Applications organization is seeking a savvy Data Engineer to join our team and shape the future of our Enterprise data platform. This data platform serves Analytics and reporting needs of Zillow's Finance, HR and other organizational functions. You will be responsible for building data collection, transformation and processing pipeline automation for Zillow’s Enterprise function data to support Zillow’s rapidly growing and dynamic businesses, and use it to deliver the BI and Insights critical for success of these functions.

Our team enjoys a good challenge and we celebrate our successes together. If you enjoy working in a supportive environment that encourages creativity and promotes ownership and career growth, come and join us.
About the role
The right candidate has experience in building and maintaining data warehouses and BI systems for Enterprise functions and shared services, and is excited at the opportunity to build and optimize our data systems from the ground up.
Key Responsibilities:
Design, implement, and support a platform providing secured access to large datasets.
Collaborate with customers from Finance, HR and other shared service functions understanding their requirements and delivering data solutions they need.
Understand the data sources, develop an ETL strategy with these sources, perform data modeling to meet customers’ data needs.
Continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for datasets.
Recognize and adopt best practices in reporting and analysis: data integrity, data security, analysis, validation, and documentation.
Monitor, manage and administer the Enterprise Applications Data Warehouse and ensure optimal performance at scale.
Design, implement and manage the access to the datasets based on the Zillow’s data access policies.
Who you are
As a Data Engineer, you should be an expert with data warehousing components (e.g. Data Modeling, ETL and Reporting) and integrations. You should have a deep understanding of the architecture for enterprise level data warehouse solutions using multiple platforms (RDBMS, Columnar, Cloud). You should be an expert in the design, creation, management of large datasets. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions, and to build data sets that answer those questions. You should have strong analytical Skills.
Qualifications:
BS in CS or similar and 8+ years professional experience, or MS with 5+ years of Professional experience.
Solid Experience in dimensional data modeling, ETL development, and Data Warehousing.
Hands on experience building and supporting Enterprise level Data warehouses by sourcing data from SaaS applications like Workday, Anaplan, Zuora or other ERPs.
Solid experience with data modelling, SQL, writing, debugging and performance tuning.
Experience with any BI reporting tools like Tableau, Domo.
Basic database administration.
System monitoring and alerting, dashboarding experience.
Experience with Snowflake is a plus.
Experience with middleware tools such as Boomi, Workato or Mulesoft.
You know how to work with high volume of rapidly changing data.
Get to know us
Zillow Group houses the largest portfolio of real estate brands on mobile and the web. We are on a mission to rewire the real estate transaction and are building transformational tools and services that make it easier for everyone to find and get into a home they love. We are working to create an on-demand real estate transaction experience for every stage of the home lifecycle - for buyers, sellers, renters and borrowers - and we're well on our way. No matter what job you're in, you will play a critical role in making this vision a reality for millions of people.
At Zillow Group, we're powered by our inclusive work culture, where everyone has the support and resources to do the best work of their careers. Our efforts to streamline the real estate transaction is supported by our passion to empower people and enrich lives around everything home, a deep-rooted culture of innovation, a fundamental commitment to Equity and Belonging, and world-class benefits. But, don't just take our word for it. Read our reviews on Glassdoor and recent recognition from multiple organizations, including: Fortune 100 Best Companies to Work For (#69), Fortune Best Workplaces for Diversity (#38), Fortune Best Workplaces for Parents (#31), Fortune Best Workplaces for Women (#20), Fatherly's Best Workplaces for New Dads (#37), JUST Capital 100 Company (#69), Bloomberg Gender Equality Index constituent.
Zillow Group is an equal opportunity employer committed to fostering an inclusive, innovative environment with the best employees. Therefore, we provide employment opportunities without regard to age, race, color, ancestry, national origin, religion, disability, sex, gender identity or expression, sexual orientation, or any other protected status in accordance with applicable law. If there are preparations we can make to help ensure you have a comfortable and positive interview experience, please let us know."
15,Sr. Data Engineer - Worldwide Operations Talent Management,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelor's degree in a quantitative/technical discipline such as Computer Science, Engineering, Statistics5+ years of relevant experience in one of the following areas: Data engineering, database engineering, business intelligence or business analyticsDemonstrable skills and experience writing complex, highly-optimized SQL queries across large data setsExperience in scripting languages such as PythonExperience with AWS technologies such as Redshift, EMR, S3Experience in building reporting solutions using BI tools

At WW Operations (WWOps) Talent Management, we use data to drive all our decision making. The Talent Analytics team acts as an internal provider of analytical solutions, using quantitative approaches to uncover insight to drive changes and inform decisions. As the Data Engineer, you will work on a team transforming massive, complex data into quantifiable relationships, trends and actionable insights. We are looking for a strong problem-solver, who is skilled using data and technologies to implement solutions.

In this role, you will design, implement and manage an analytical data infrastructure. You will collaborate closely with other engineers and scientists across the organization to create robust and scalable solutions to flow data from various source systems into the data warehouse and into end-user facing applications.

This role also requires a significant understanding of data mining and analytical techniques. You will be expected to deliver at a high level against ambiguous problems with minimal technical supervision. The successful candidate will have strong technical and analytical capabilities, business acumen, effective communication skills, and the ability to work effectively with cross-functional teams in a fast paced environment.

Experience working with Open Source Big Data tools (Parquet, Spark, Hadoop)Advanced knowledge in AWS technologiesFamiliarity with statistical modeling and machine learning techniquesStrong verbal and written communication skills and ability to build rapport with cross-functional partners
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation"
16,Business Intelligence Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Own the design, development, and maintenance of scalable solutions for ongoing metrics, reports, analyses, dashboards, etc. to support analytical and business needs.Translate basic business problem statements into analysis requirements. Work with internal customers to define best output based on expressed stakeholder needs.Review and audit existing ETL jobs and SQL queries.Experience using Python, Ruby, or other scripting languages to automate data retrieval, manipulation, and analysis.Experience using R, SAS, or other statistical packages.

As we strive to be Earth's most customer-centric company, Amazon has reinvented how hundreds of millions of people shop online – providing customers with the opportunity to find and discover virtually anything they want to buy and providing millions of sellers with a platform for growing successful businesses. We are looking for an exceptional business analyst to help us develop new ways to build trust and loyalty with sellers, a crucial component of our flywheel

Sellers’ trust in Amazon is our top priority and in this role, you will be tasked with building that trust over time by diving deep into how we measure our progress and helping to identify and prioritize key areas of focus. Amazon’s growth requires leaders who move fast, have an entrepreneurial spirit to create new solutions, have an unrelenting tenacity to get things done, and are capable of breaking down and solving complex problems.

The successful candidate will be a self-starter, comfortable with ambiguity and be able to create and maintain efficient & automated processes. They will set the vision, strategy, and roadmap, and work alongside with stakeholders in the organization to make it happen. They know and love working with business intelligence tools, can model multidimensional datasets, and can partner effectively with business leaders to answer key business questions. They are analytical and creative, and don’t quit. This is a role with high visibility to senior leadership and with high opportunity for impact for those willing to roll up their sleeves and dive deep to achieve results.

Advanced degree in data science, statistics, or a related field.5+ years in the analysis space as a Business Intelligence Engineer, Business Analyst, Data Engineer, or similar roles.
Amazon is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age."
17,Data Engineer I,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"A desire to work in a collaborative, intellectually curious environment.Degree in Computer Science, Engineering, Mathematics, or a related field and 4-5+ years industry experienceOne year of experience in the following skill(s):Developing and operating large-scale data structures for business intelligence analytics using: ETL/ELT processes; OLAP technologies; data modeling; SQL;Experience with at least one relational database technology such as Redshift, Oracle, MySQL or MS SQLExperience with at least one massively parallel processing data technology such as Redshift, Teradata, Netezza, Spark, or Hadoop based big data solution

Health, Safety, Sustainability, Security, and Compliance (HS3C) is responsible for keeping our Customers and partners safe, and ensuring we maintain WW compliance. We build scalable solutions that grow with the Amazon business. HS3C-Compliance team collects petabytes of data from thousands of data sources inside and outside Amazon including the Amazon catalog system, inventory system, customer order system, and page views on the website. We provide interfaces for our internal customers to access and query the data hundreds of thousands of times per day, using Amazon Web Service’s (AWS) Redshift, Hive, and Spark.
HS3C-Compliance is growing, and the data processing landscape is shifting. Our data is consumed by teams across HS3C including Research Scientists, Machine Learning Specialists, Business Analysts, and Data Engineers. We are seeking an outstanding Data Engineer to join the HS3C-Compliance data technologies team. The HS3C-Compliance data technologies team manages the core HS3C business data from hundreds of source systems. Amazon has culture of data-driven decision-making, and demands business intelligence that is timely, accurate, and actionable. If you join the HS3C-Compliance data technologies team, your work will have an immediate influence on day-to-day decision making at Amazon.

As an Amazon Data Engineer II, you will be working in one of the world's largest cloud-based data lakes. You should be skilled in the architecture of data warehouse solutions for the Enterprise using multiple platforms (EMR, RDBMS, Columnar, Cloud). You should have extensive experience in the design, creation, management, and business use of extremely large datasets. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions, and to build data sets that answer those questions. Above all you should be passionate about working with huge data sets and someone who loves to bring datasets together to answer business questions and drive change.

As a Data Engineer II on the HS3C-Compliance data technologies team, you will design, develop, implement, test, document, and operate large-scale, high-volume, high-performance data structures for analytics and deep learning. Implement data ingestion routines both real time and batch using best practices in data modeling, ETL/ELT processes leveraging AWS technologies and Big data tools. Gather business and functional requirements and translate these requirements into robust, scalable, operable solutions that work well within the overall data architecture. Analyze source data systems and drive best practices in source teams. Participate in the full development life cycle, end-to-end, from design, implementation and testing, to documentation, delivery, support, and maintenance. Produce comprehensive, usable dataset documentation and metadata. Evaluate and make decisions around dataset implementations designed and proposed by peer data engineers. Evaluate and make decisions around the use of new or existing software products and tools. Mentor junior data engineers.

Industry experience as a Data Engineer or related specialty (e.g., Software Engineer, Business Intelligence Engineer, Data Scientist) with a track record of manipulating, processing, and extracting value from large datasets.Coding proficiency in at least one modern programming language (Python, Ruby, Java, etc)Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data setsExperience building data products incrementally and integrating and managing datasets from multiple sourcesQuery performance tuning skills using Unix profiling tools and SQLExperience leading large-scale data warehousing and analytics projects, including using AWS technologies – Redshift, S3, EC2, Data-pipeline and other big data technologiesExperience providing technical leadership and mentor other engineers for the best practices on the data engineering spaceLinux/UNIX including to process large data sets.Experience with AWS
Amazon is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age."
18,"Staff Software Engineer, Data Engineering","Seattle, WA 98107",Seattle,WA,98107,None Found,None Found,None Found,None Found,None Found,None Found,"What you’ll be doing…
Are you a senior Data Engineer with experience in cloud technologies and a passion for data? As a Staff Software Engineer in the Office of the CTO Data Science & Engineering team, you will be drive solutions to wide-ranging data engineering and infrastructure challenges for product and internal operations. You will partner with world-class developers, engineers, architects, and data scientists to drive thinking, provide technical leadership, and collaborate in defining best practices around data engineering. You will also work alongside local product management, engineering, and research teams to develop innovative solutions that will influence our product line.

Some of your responsibilities include…
Provide technical leadership to efforts around tooling and infrastructure that enable teams to efficiently complete and maintain data science projects
Partner with teams on modeling and analysis problems – from transforming problem statements into analysis problems, to working through data modeling and engineering, to analysis and communication of results
Lead code reviews, design, and best practices
Coach and mentor senior engineers
Participate in the evolution of overall approach to Data Engineering at Tableau
Build up and share best practices for the development and deployment of ML based solutions
Use experience gained in the above and expertise in this space to influence our product roadmap, potentially working with prototype engineering team to add additional capabilities to our products to solve more of these problems

Who you are...
Experienced . 10+ years of experience in a Data Engineer role with a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.
Technically Savvy. A background in some specific technologies is preferred: AWS (EC2, EMR, RDS, Redshift), Python (including DS packages), SQLServer, Cassandra, Snowflake, and Data pipeline/streaming tools (Airflow, NiFi, Kafka)
Data Rockstar. Experience building and optimizing data pipelines, architectures and data sets. A successful history of manipulating, processing and extracting value from large disconnected datasets. Deep knowledge of stream processing, and highly scalable ‘big data’ data stores. Demonstrated experience in designing or implementing enterprise-wide data strategy.
Team Player. Experience supporting and working with cross-functional teams in a dynamic environment. Strong oral and written communication skills.
You are a Recruiter! Tableau hires company builders and, in this role, you will be asked to be on the constant lookout for the best talent to bring onboard to help us continue to build one of the best companies in the world!
#LI-EF1
Tableau Software is an Equal Opportunity Employer.
Tableau Software is a company on a mission. We help people see and understand their data. After a highly successful IPO in 2013, Tableau has become a market-defining company in the business intelligence industry. Our culture is casual and high-energy. We are passionate about our product and our mission and we are loyal to each other and our company. We value work/life balance, efficiency, simplicity, freakishly friendly customer service, and making a difference in the world!"
19,Business Analyst Manager,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelor's Degree, preferably in an analytical field - e.g. Economics, Operations, Business, Mathematics, Statistics, Finance or an in applicable social sciences field such as Criminal Justice or Law.At least four years of experience working in Analytics/Business Intelligence environmentExperience in working with databases and relational data set solutions in a business or government environmentDemonstrated use of commercial and proprietary analytical software solutions as well as query languages such as SAS, SPSS and SQL.Prior experience in design and execution of analytical projectsWorked extensively in large scale data bases and data warehousesExcellent oral/written communication and presentation skills, including an ability to effectively communicate with both internal and external stakeholders.

Each day, hundreds of thousands of developers make billions of transactions worldwide on our cloud. They are harnessing the power of Amazon Web Services (AWS) to enable innovative applications, websites, and businesses. However, there are always a few people that try to take unfair advantage of a good thing...

Are you interested in taking your skills and career to the next level, while having fun and fighting fraud in the cloud? How would you like to be the driving force for developing the data and insights strategy for our global AWS Investigations Fraud Team? You will be leading our Analytics Team that is central in shaping the definition and execution of the long-term data and insights strategy for AWS Investigations.

As the BA Manager, you will oversee a highly skilled team (Data Engineer; Business Intelligence Engineer; Business Analysts) who will design, develop, and evaluate highly innovative business intelligence tools. Your team will partner with business stakeholders to develop automated reports for AWS Investigations. Your team will constantly be seeking out new data that is useful in improving AWS Investigations, while maintaining data integrity of existing data. Your team will have the opportunity to Think Big on ways to evolve measuring, reporting, evaluating the AWS Investigator group.

Responsibilities Include:
Interfacing with business customers, gathering requirements and developing new datasets in data warehouseOptimizing the performance of business-critical queries and dealing with ETL job related issuesIdentifying the data integrity issues to address them immediately to provide great user experienceExtracting and combining data from various heterogeneous data sourcesCreate, update, maintain, data visualization dashboards used by internal stakeholdersModelling data and metadata to support ad-hoc and pre-built reportingWorking with customers to fulfill their data requirement using DW tables & maintain metadata for all DW TablesLead the effort to shape the definition and execution of the long-term data and insights strategy for AWS Investigations

Experience in e-commerce/on-line companies in fraud / risk control functionsExperience in leading strategic and analytical projects related to; Fraud or Cyber Crime or Financial Crimes or White Collar Crimes or Financial Risk ManagementExposure to software development life cycle (SDLC) processHistory of constructing operational dashboards utilized by global teamsExperience working with teams across regions (U.S.; EMEA; APAC)Someone who is keen to leverage their existing skills while trying new approaches"
20,SQL Developer,"Renton, WA 98057",Renton,WA,98057,None Found,None Found,None Found,None Found,None Found,None Found,"Company Information
PACCAR is a Fortune 500 company established in 1905. PACCAR Inc is recognized as a global leader in the commercial vehicle, financial, and customer service fields with internationally recognized brands such as Kenworth, Peterbilt, and DAF trucks. PACCAR is a global technology leader in the design, manufacture and customer support of premium light-, medium- and heavy-duty trucks under the Kenworth, Peterbilt and DAF nameplates and also provides customized financial services, information technology and truck parts related to its principal business.
Whether you want to design the transportation technology of tomorrow, support the staff functions of a dynamic, international leader, or build our excellent products and services, you can develop the career you desire with PACCAR. Get started!
Division Information
PACCAR's Information Division (ITD), located in Renton, WA utilizes cutting-edge technology to provide systems development, consulting, voice and data communications services to the entire Corporation, which has high visibility in the technology sector.
Requisition Summary
Does empowering teams to make data driven decisions excite you? Do you wake up in the morning wondering what possibilities could be unlocked with more data? PACCAR is looking for a seasoned data engineer with AWS experience to join the team. Data Engineering focuses on making possible fast, accurate, and reliable access to data. We build data pipelines, manage a data warehouse, and support the production use of our data. We advocate for good data practices and make sure that our business users are able to make good data driven decisions.
Job Functions / Responsibilities
Does empowering teams to make data driven decisions excite you? Do you wake up in the morning wondering what possibilities could be unlocked with more data? PACCAR is looking for a seasoned data engineer to join the team. Data Engineering focuses on understanding and modeling business and application data requirements and designing data structures and pipelines that ensure fast, accurate, and reliable access to high-quality data. We advocate for sound data practices and make sure that our business users are able to make good data driven decisions.
Work with business users and application architects to understand data requirements, definitions and business rules
Create conceptual and logical data models that accurately reflect these requirements in a way easily understood by business users and development teams
Work with dev teams to create sound physical data designs that reflect the project architecture and choice of data/database technology
Implement data structures on a variety of database platforms, including SQL Server, Oracle, Teradata and Snowflake
Work with dev teams to create database objects (views, functions, stored procedures) that improve application performance, functionality and scalability
Build data pipelines (including data migration from legacy data sources, cleansing and transformation), data validation frameworks, job schedules with emphasis on automation and scale
Contribute to overall architecture, framework, and design patterns to store and process high data volumes
Ensure product and technical features are delivered to spec and on-time
Design and implement features in collaboration with product owners, reporting analysts / data analysts, and business partners within an Agile / Scrum methodology
Proactively support product health by building solutions that are automated, scalable, and sustainable – be relentlessly focused on minimizing defects and technical debt
Qualifications
Masters’ or Bachelors' degree in Software Engineering or a related field
5+ years of experience in large-scale software development (preferably Agile) with emphasis on data modeling and database development
5+ years of experience with data modeling tools (Erwin, ER/Studio, PowerDesigner)
5+ years of experience with relational DBMSs and SQL coding (SQL Server, Oracle, Teradata, Snowflake)
Ability to communicate effectively (both orally and in writing) with business users, project team leaders and application developers
Proficiency with ETL tools and techniques (SSIS, Attunity, Informatica)
2+ years experience with AWS and related services (EC2, S3, DynamoDB, ElasticSearch, SQS, SNS, Lambda, Airflow, Snowflake, etc.)
Education
5+ years exerience or Bachelors' degree in Computer Science
Additional Job Board Information
PACCAR is an Equal Opportunity Employer/Protected Veteran/Disability."
21,Data Engineer,"Bellevue, WA",Bellevue,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Rational Consulting is growing, and we need amazing talent to join our team. If you have an entrepreneurial attitude with a deep spirit of service and killer subject expertise, we want to talk to you. We are always looking for the next great consultant to raise the bar and push Rational Consulting to be better than we were yesterday. Staying hungry, curious, and looking forward to what's next is part of our DNA.

We are currently seeking a Data Engineer to join our tech client in Bellevue, WA. Our client drives a very progressive approach to retail technology sales. A world where passionate innovators come to collaborate and empower. This team is reinventing the way we all work, play, learn and do business. Bring your vision to their mission!

What You'll Do:

Create and edit reports and dashboards in Power BI
Support the client in identifying how to get access to required data to drive desired insights
Help the client and other Rational team members identify new insights that might be available from available data
Uphold data integrity standards
Support making sure data is secured and shared with only the appropriate audiences
Asses new data sources and how they can enhance and augment current reporting

What You'll Bring:

2-3 years of enterprise level experience working with Power BI
Experience writing queries in DAX, SQL, M, and Power Query
Knowledge Azure SQL DB, SSIS, and Logic Apps/Flow
An understanding of:
Data modeling
Data cleansing
Data visualization
Working knowledge of the Smartsheets platform

Who You Are:

Well-rounded Professional. You have amazing communication and organizational skills along with high EQ.
Self-sufficient. You get stuff done, you are able to work with little direct supervision but know when to ask for help.
Collaborative to the Core. Demonstrated ability to work in a team environment, as a leader and member.
Data Lover. You know your numbers and value the metrics behind the consumer story.

Rational is a results-oriented CX Solutions firm designing premium customer experiences. Each of our business practices are deeply rooted in delivering client success. We see ourselves as partners to our clients, and we invest in each of their business goals, ensuring that our work helps deliver on these goals. Client success is our ultimate metric, and what drives our mindset, skillset, and company culture.

Rational wants to make sure that all candidates have an equal opportunity to be considered for employment. Please let us know if you need any reasonable accommodation to participate in the job application or interview process."
22,Data Engineer,"Renton, WA",Renton,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"COMPANY OVERVIEW
Founded in 2009, Cyborg Mobile is a human-centered consultancy providing Technology and Management Consulting Services. Cyborg Mobile provides solutions in Experience Design, Program Leadership, Organizational Change, Product Innovation, Digital Strategy, and Consumer Mobile Technology.
At Cyborg Mobile, we use our combined expertise and empathetic approach to build products that delight customers. Our team members are passionate about growth, innovation and collaboration. We enjoy learning for fun and staying curious. If you have growth and ownership mindset and can work cohesively with a team, you are probably a great fit for our team!
THE POSITION
Cyborg Mobile seeks a Data Engineer to support its growing consultancy firm. This is a contract position for a public sector client of ours, with opportunity to extend into a full-time role. The key project is a data modernization effort that will help the client collect, manage, process and extract insights from data to better serve internal stakeholders and the public. This role will be part of the Data Services IT team and work closely with business analysts and SMEs.
POSITION RESPONSIBILITIES
As a Data Engineer, you will be responsible for all aspects of the software development lifecycle, including design, coding, integration testing, deployment and documentation. You will work in an Agile team setting to create and maintain new data applications relying heavily on experience and judgment to plan and accomplish goals.
Specific breakdown of responsibilities:
Analyze and resolve complex challenges around data and tools. Optimize analytical workflows by identifying opportunities and automating them
Collaborate with members of your team (eg, business analysts, data architect, subject matter experts) on the project's goals to understand and document business requirements
Translate customer requirements into unambiguous, scalable, robust and flexible technical solutions for implementation
Create and maintain architecture diagrams, data models, mapping documents, business rules, data flow diagrams and other design related artifacts
Assist the data warehouse team in designing efficient processes to load and manage data, including assessment of data quality in the source systems and implement appropriate business rules, data mappings, and transformation rules
Actively participate in code reviews, unit testing, system integration testing and remedy solution defects
Analyze and troubleshoot production issues quickly to ensure system uptime meets service level agreements
QUALIFICATIONS/REQUIREMENTS
Working knowledge in data migration/integration with off-premise/cloud services such as Azure and/or AWS
Proven handling of cost-conscious, enterprise-grade data movements and current on cloud/hybrid analytical technologies (big data, lakes, stream analytics, NoSQL, DWH, ETL/ELT)
5+ years of experience building, administering and managing scalable analytical platforms containing both structured and unstructured data
Exposure to full-stack engineering (application, data, infrastructure and platform administration) and technology trends / best practices
Strong coder in any object-oriented language: Java, C#, Python, Javascript, etc.
Experience building infrastructure required for optimal ETL/ELT process for large data sets in a variety of structured and unstructured formats
Knowledge of big data ecosystem using tools like Hadoop, MapReduce, HBase, oozie, Flume, MongoDB, Cassandra and Pig
Experience working with NoSQL databases and DevOps tools: ADO, Git, Jenkins, Docker, etc.
Knowledge of machine learning, including pattern recognition clustering, text mining, etc.
Ability to work in version control and change/release management processes, alongside experience with source control mediums such as Team Foundation Server (TFS), Visual Studio Team Services (VSTS) or Git (preferred)
Solid understanding of data warehouse principles and multi-dimensional data modeling concepts, source to target mapping and data integration architecture. Foundational knowledge of traditional end-end ETL/OLAP solutions, preferably but not required, on the Microsoft SSIS/SSAS stack
Excellent written and verbal communication skills with the ability to communicate to non-technical audiences"
23,Senior Data Engineer,"Seattle, WA 98103",Seattle,WA,98103,None Found,"
Bachelor CS degree and 7+ years of experience in software engineering.
Track record of developing and maintaining reliable, highly available, secure, high throughput web-scale data systems (e.g. Social, AdTech, MarTech, Heathcare, FinTech, etc.).
Experience with big data pipelines and processing (e.g. MapReduce, Hadoop, Big Query, Hive, Tez, Spark, etc.).
Experience with realtime streaming event logs (e.g. Kafka, GCP Cloud Pub/Sub, SNS/SQS).
You influence your peers, advise senior leaders, coach and mentor junior team members.
You facilitate cross-team collaboration among engineers and contribute to the broader community of senior engineers.
Must pass a Criminal Justice Information Services (CJIS) background check and maintain confidential and highly sensitive information.",None Found,None Found,None Found,None Found,"Our mission is to protect life.
We’re out to make the world a safer place by solving big problems and taking on the public safety challenges of our time. From our company's inception building the TASER device to a full suite of hardware and software solutions, we are focused on providing police agencies with the state-of-the-art devices and services they need to successfully serve and protect us. In the next few years, we're going to eliminate the burden of paperwork in policing, so officers can increase the time they spend building relationships and serving in their communities. We’ll put video at the heart of the police record so our justice system can get to the truth faster. And we won't stop innovating until the bullet is rendered obsolete.

It’s a big mission, but it’s one we’ll pursue relentlessly every single day.

Your Impact

You are a Senior Full Stack Software Engineer with experience building large-scale software applications. At Axon, you’ll create and maintain a data architecture that is the connective tissue between Axon products and public safety systems. Successfully completing this work means that you are:
Protecting life by surfacing key information to ensure Officer and Jail SafetyEnabling Crime Analysts to unlock that missing piece of data to solve crimeAllowing justice to be swift and accurate by giving Prosecutors and Courts accurate informationAllowing Investigators and Forensic Technicians easy access to crime scene evidence

When you are successful, you will equip public safety professionals at all levels with the information they need to protect life and truth.

Your Day to Day
Help build one of the largest cloud solutions on the planet. What you build will accelerate product innovation and help scale our platform to meet the ever-expanding needs of our growing customer base.
Partner with internal teams and agencies to make law enforcement data highly accessible and actionable.
Develop the core platform capabilities that support Axon's product development and evolution - at scale.
Solve challenging problems of scale, latency, reliability, and availability. Our team will draw from your experience in these areas and support your continued growth.
Write performant, maintainable code that is easy to read and well-documented.
Basic Qualifications
Bachelor CS degree and 7+ years of experience in software engineering.
Track record of developing and maintaining reliable, highly available, secure, high throughput web-scale data systems (e.g. Social, AdTech, MarTech, Heathcare, FinTech, etc.).
Experience with big data pipelines and processing (e.g. MapReduce, Hadoop, Big Query, Hive, Tez, Spark, etc.).
Experience with realtime streaming event logs (e.g. Kafka, GCP Cloud Pub/Sub, SNS/SQS).
You influence your peers, advise senior leaders, coach and mentor junior team members.
You facilitate cross-team collaboration among engineers and contribute to the broader community of senior engineers.
Must pass a Criminal Justice Information Services (CJIS) background check and maintain confidential and highly sensitive information.
Preferred Qualifications
Experience with Azure cloud components and .NET.
Experience creating and maintaining containerized web applications and serverless components.
Familiarity with build and CI tools/processes like Kubernetes, TeamCity, Azure DevOps, etc.
ETL Development for Business Intelligence.
Experience using statistical programming languages (e.g. Python, R) and to deliver results for real-world problems.
Compensation and Benefits
Competitive salary and 401K with employer match
Discretionary paid time off
Robust parental leave policy
An award-winning office/working environment
Ride along with real police officers in real life situations, see them use technology, get inspired
And more...
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status."
24,"Software Development Engineer, Big Data","Seattle, WA 98101",Seattle,WA,98101,None Found,None Found,None Found,None Found,None Found,None Found,"About the team
Job Description Summary
We build the pipelines and processes responsible for daily ingestion of terabytes of data. We productionalize intelligent, data-driven systems to help Zillow capture strategic opportunities in the market. Our work enriches Zillow's unparalleled living database of all homes and hundreds of millions of customers and empowers teams downstream to build analytics tools and products to delight our users.

Small team = big impact. Engineering teams are highly decentralized in order to create the small team speed and autonomy of a start-up environment but backed by big company resources.Fast-moving, developer driven organization full of brilliant and ambitious people.Learn more about what we are doing at www.zillow.com/engineering and www.zillow.com/data-science
About the role
We are looking for a strong technical contributor with a background in software development to create intelligent data driven systems and pipelines. As a Data Engineer, you will be responsible for all phases of the development cycle: design, implementation, testing, and release. You will leverage your deep knowledge and experience to provide technical leadership for the team, take ideas from zero to completion, and provide the bridge between raw data and actionable business insights. You will:
Build and maintain highly-scalable ETL pipelines and data-driven systems
Work closely with business stake holders, data analysts and machine learning engineers to productionalize analytic solutions
Design and implement new data pipelines to support business analysts and data scientists
Design and build infrastructure to support our petabyte scale data lake
Who you are
Data engineer with experience with building and shipping highly scalable distributed systems on cloud platforms (AWS/Azure/GCP) and database technologies (SQL/NoSQL/column-orienteddatastores/distributed databases)
Experience with the Big Data ecosystem (Hadoop/Hive/Spark/Presto/Airflow)
Proven track record of leading and delivering large projects independently
Proven ability to learn new technologies quickly
A degree (BS/MS+) in Computer Science or a related technical discipline
Experience with Hive, Spark, Presto, Airflow and or Python a plus
Get to know us
Zillow Group houses the largest portfolio of real estate brands on mobile and the web. We are on a mission to rewire the real estate transaction and are building transformational tools and services that make it easier for everyone to find and get into a home they love. We are working to create an on-demand real estate transaction experience for every stage of the home lifecycle - for buyers, sellers, renters and borrowers - and we're well on our way. No matter what job you're in, you will play a critical role in making this vision a reality for millions of people.
At Zillow Group, we're powered by our inclusive work culture, where everyone has the support and resources to do the best work of their careers. Our efforts to streamline the real estate transaction is supported by our passion to empower people and enrich lives around everything home, a deep-rooted culture of innovation, a fundamental commitment to Equity and Belonging, and world-class benefits. But, don't just take our word for it. Read our reviews on Glassdoor and recent recognition from multiple organizations, including: Fortune 100 Best Companies to Work For (#69), Fortune Best Workplaces for Diversity (#38), Fortune Best Workplaces for Parents (#31), Fortune Best Workplaces for Women (#20), Fatherly's Best Workplaces for New Dads (#37), JUST Capital 100 Company (#69), Bloomberg Gender Equality Index constituent.
Zillow Group is an equal opportunity employer committed to fostering an inclusive, innovative environment with the best employees. Therefore, we provide employment opportunities without regard to age, race, color, ancestry, national origin, religion, disability, sex, gender identity or expression, sexual orientation, or any other protected status in accordance with applicable law. If there are preparations we can make to help ensure you have a comfortable and positive interview experience, please let us know."
25,"Principal Engineer, Software","Bellevue, WA",Bellevue,WA,None Found,None Found,"One or more of the following: SQL, Hive, Pig, R, Matlab, SAS, Python, Java, Ruby, C++, Perl, MDX, DAX",None Found,"Technical System Expertise: Understands system protocols, how systems operate, and data flows. Aware of current technology benefits and trends. Understand the building blocks, interactions, dependencies and tools required to complete software and automation work. In-depth understanding of enterprise data warehouse patterns and technologies. Have experience with ""Big Data"" model paradigms such as MapReduce in order to build a scale out data processing solutions.",None Found,None Found,"This role is tasked with developing, constructing, testing and maintaining architectures and software in support of data transfer between systems. This is done by aligning architectural capabilities with requirements from the business to engineer data pipelines from data sourcing, ingestion, enrichment, and modeling. The Principal Data Engineer also optimizes existing ETL/ELT processes, builds APIs for data access, and analyzes source systems for optimization. They do this by partnering with Technical Product Managers, Data Scientists, Data Architects, and Business Functional Analysts, to build and deliver analytics solutions with a product mindset. Their experience and knowledge allows them to apply DevOps principals to data engineering processes to ensure reliable, accurate, and complete data pipelines.

Responsibilities
Technical System Expertise: Understands system protocols, how systems operate, and data flows. Aware of current technology benefits and trends. Understand the building blocks, interactions, dependencies and tools required to complete software and automation work. In-depth understanding of enterprise data warehouse patterns and technologies. Have experience with ""Big Data"" model paradigms such as MapReduce in order to build a scale out data processing solutions.
Technical Engineering Services: Supports engineering projects by developing software solutions for data and analytics; conducting tests and inspections; preparing reports and calculations. Expected to supervise engineering teams on occasion.
Innovation: Presents new ideas which improve an existing system/process/service. Presents new ideas which utilize new frameworks to improve an existing system/process/services. Express new perspectives based on independent study of the industry. Review current company processes to highlight questions that may drive process refinement.
Technical Writing: Maintains knowledge of existing technology documents. Writes basic documentation on how technology works. Contributes clear documentation for new code and systems used. Documenting systems designs, presentations, and business requirements for consumption at the VP level.
Technical Leadership: Collaborates with technical teams and utilizes system experience to deliver technical solutions. Continuously learns new technologies.
Technology Strategy: Understand current technology that supports business goals. Understand technology trends and how technical investments may be affected by changes within those trends. Identifies risks and mitigation strategies from a technical perspective as it relates to this field.
Also responsible for other Duties/Projects as assigned by business management as needed.

Qualifications
One or more of the following: SQL, Hive, Pig, R, Matlab, SAS, Python, Java, Ruby, C++, Perl, MDX, DAX
SQL and SSAS Expert
Proficient in BI/Analytics and Data Prep tools such as Tableau, PowerBI, CLIQ, Alteryx, SAP Data Hub Modeler, etc.
Expert in ETL/ELT Deployment Environments such as on-prem (SSIS, Nifi, etc), cloud-based (Azure Data Factory, AWS Glue, etc) & containerized (Kubernetes)
Working knowledge of TCP/IP, Firewalls, SSH, SSL, SFTP, port forwarding, NTFS Security, ACLs, Least Privilege, Active Directory, LDAP
Data Warehouse Virtualization Platforms (eg: Denodo)

Minimum Qualifications
Bachelors Degree in Computer Science, Engineering or similar.
5-8 years of Technical Experience Required.
Master of Science, MBA or Engineering Preferred




Company Profile
As America's Un-carrier, T-Mobile USA, Inc. (NASDAQ: ""TMUS"") is redefining the way consumers and businesses buy wireless services through leading product and service innovation. The company's advanced nationwide 4G and 4G LTE network delivers outstanding wireless experiences for customers who are unwilling to compromise on quality and value. Based in Bellevue, Washington, T-Mobile USA. Inc. provides services through its subsidiaries and operates its flagship brands, T-Mobile and Metro by T-Mobile. For more information, please visit http://www.t-mobile.com

EOE Statement
We Take Equal Opportunity Seriously - By Choice. T-Mobile USA, Inc. is an Equal Opportunity Employer. All decisions concerning the employment relationship will be made without regard to age, race, ethnicity, color, religion, creed, sex, sexual orientation, gender identity or expression, national origin, marital status, citizenship status, veteran status, the presence of any physical or mental disability, or any other status or characteristic protected by federal, state, or local law. Discrimination or harassment based upon any of these factors is wholly inconsistent with our Company values and will not be tolerated. Furthermore, such discrimination or harassment may violate federal, state, or local law."
26,Data Engineer - Internal Audit,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelor's degree in computer science, engineering, mathematics, or a related technical discipline.Proficiency in SQL & Python.Experience working with AWS big data technologies (Redshift, S3, DynamoDB) and moving data between different accounts & technology.2+ years of industry experience in software development, data engineering, business intelligence, data science, or related field with a track record of manipulating, processing, and extracting value from large datasets.Demonstrated strength in data modeling and ETL development for optimal performance.

Internal Audit’s mission is to help our businesses improve controllership, operational efficiency, and customer experience.

Amazon is seeking a Data Engineer for our Internal Audit Data Analytics team that provides data analytics services and solutions to enable our audit programs to scale with Amazon’s growth and complexity. This is a highly visible opportunity to provide custom-build solutions and services that will increase the productivity of Amazon’s audit function using data.

In this role, you will be a technical expert with massive impact. You work tightly with the Business Intelligence Engineers (BIEs) on our team to onboard data and construct data models that will be designed for optimal analysis. You will be an expert in collecting data from different types of sources and normalizing them into a consumable data models that are accessible to less technical users. Our team will maintain an ever changing infrastructure which will require data engineering problem solving, building unique high quality reliable, accurate, consistent, and architecturally sound data sets that are aligned with our business needs.

Tasks include, but are not limited to:
Managing AWS resources including S3, Glue, Redshift, Lambda etc.Design, implement and support an analytical data infrastructure and recommending complimentary technology additions.Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using internally built and AWS technologies.Explore and learn the latest AWS technologies to provide new capabilities and increase efficiency.Collaborate with Data Scientists and Business Intelligence Engineers (BIEs) to recognize and help adopt best practices in analysis: data integrity, test design, analysis, validation, and documentation.Lend domain knowledge of datasets and practices to BIE’s.Help continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers.

Masters in computer science, mathematics, statistics, economics, or other quantitative fields.Experience working with bigger AWS big data technologies (EMR, Neptune, Athena).Proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategy.Experience providing technical leadership and educating other engineers for best practices on data engineering.Familiarity with statistical models and data mining algorithms.
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation"
27,Principal Data Engineer,"Renton, WA 98057",Renton,WA,98057,None Found,"Bachelor’s Degree in computer science, engineering, mathematics, MIS or similar field.

10 years in technology roles.

Must have experience with the following technologies:

C#

ASP.net

T-SQL

HTML/CSS

JavaScript

Nodejs

Demonstrated analytical skills

Demonstrated problem solving skills

Promotes information sharing

Ability to work within tight timeframes and meet strict deadlines.

Possesses strong technical Aptitude.
",None Found,None Found,None Found,None Found,"Providence St. Joseph Health is calling a Principal Data Engineer to one of our following locations: Renton, WA (preferred), Spokane, WA, Richland, WA, Everett, WA, Olympia, WA, Anchorage, AK, Missoula, MT, Portland, OR, Beaverton, OR, Anaheim, CA, Burbank, CA or Lubbock, TX. This position is 1 year-long in duration with full medical, dental, vision and vacation benefits. We are open to the possibility of working remotely within our 7 state region of operation: AK, WA, OR, MT, CA, NM and TX.
We are seeking a Principal Data Engineer to design and build modern data-centric software applications to support clinical and operational processes across all parts of the health system. These applications leverage cloud computing, big data, mobile, data science, and modern software development methodologies and frameworks. Data Engineers build data pipelines, enrichment processes, provisioning layers, APIs and user interfaces to meet the requirements of key initiatives. The Principal Data Engineer will take point on development of best practices and standards across the engineering team and participate in research and development of new technologies. A Principal Data Engineer should be able to and emphasize mentoring less experienced Data Engineers and training the team, as needed, to develop a robust skillset among the entire team. Strongly encourages and places a priority on collaboration with meticulous source control and documentation. An emphasis on simple solutions to complex problems through the use of modern and emerging methods and tools is critical. This position will works closely with the Product, Platform, and Architecture teams to deliver on joint efforts.
In this position you will have the following responsibilities:
Design, build and deliver quantitative applications that improve operations and generate value

Participate in DevOps, Agile, and continuous integration frameworks

Stay abreast of emerging technologies, open source projects, and best practices in the field

Data warehousing, big data, enterprise search, business intelligence, analytics, modern and mobile applications

Build processes that are fault-tolerant, self-healing, reliable, resilient and secure

Work effectively and in real-time with other developers, product managers, and customers to deliver on collective goals

Actively participate in code reviews, support the overall code base, and support the establishment of standard processes and frameworks. Take a lead role in the development of standard practices and enforce following standard processes.

Qualifications:
Required qualifications for this position include:
Bachelor’s Degree in computer science, engineering, mathematics, MIS or similar field.

10 years in technology roles.

Must have experience with the following technologies:

C#

ASP.net

T-SQL

HTML/CSS

JavaScript

Nodejs

Demonstrated analytical skills

Demonstrated problem solving skills

Promotes information sharing

Ability to work within tight timeframes and meet strict deadlines.

Possesses strong technical Aptitude.

Preferred qualifications for this position include:
Master’s Degree.

Cloud computing, Linux, Hadoop, MapReduce, Spark, Hbase, Kudu and NoSQL platforms in general; Apache Solr and Lucene

Java, Scala, C#, Python, shell scripting and/or similar languages

Relational database platforms, database design, and SQL

APIs, JSON, REST and other relevant W3C open standards

Modern application development frameworks

Familiarity with commercial or open source ETL tools

About the department you will serve.
Providence Strategic and Management Services provides a variety of functional and system support services for all eight regions of Providence Health & Services from Alaska to California. We are focused on supporting our Mission by delivering a robust foundation of services and sharing of specialized expertise.
We offer a full comprehensive range of benefits - see our website for details
http://www.providenceiscalling.jobs/rewards-benefits/
Our Mission
As expressions of God’s healing love, witnessed through the ministry of Jesus, we are steadfast in serving all, especially those who are poor and vulnerable.
About Us
Providence Health & Services is a not-for-profit Catholic network of hospitals, care centers, health plans, physicians, clinics, home health care and services guided by a Mission of caring the Sisters of Providence began over 160 years ago. Providence is proud to be an Equal Opportunity Employer. Providence does not discriminate on the basis of race, color, gender, disability, veteran, military status, religion, age, creed, national origin, sexual identity or expression, sexual orientation, marital status, genetic information, or any other basis prohibited by local, state, or federal law.
Schedule: Full-time
Shift: Day
Job Category: Information Technology
Location: Alaska-Anchorage
Other Location(s): Oregon-Portland, Oregon-Beaverton, Montana-Missoula, Washington-Everett, Washington-Renton, Washington-Richland, Washington-Spokane, California-Anaheim
Req ID: 234029"
28,BI Engineer - Alexa Engagement,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelor’s degree in math, statistics, computer science, or finance or equivalent experience.5+ years of experience as a Data Engineer, BI Engineer, Business/Financial Analyst or Systems AnalystSQL writing experience and experience with ETLRedshift experience

Come help us shape the future of the best voice controlled computer in the cloud. Alexa and Echo are shaping the future of voice recognition and cloud-based content/services. Alexa is the name of the Amazon cloud-based voice service and the brain that powers Echo, the award-winning and groundbreaking Amazon device designed around your voice. Echo connects to Alexa, to provide information, answer questions, play music, read the news, check sports scores or the weather, and more—instantly. It's hands-free, and always ready. All you have to do is ask.

To achieve this, we blend of a variety of disciplines (such as NLP, data mining, machine learning, big data, semantic web, graph stores, cloud computing) in an effort to understand our customers and the things they're excited about. To complement our complex algorithms and extensive data analyses, we create elevated and inspirational mobile and web features across the entire communication experience. We use artificial intelligence, data mining and usability studies to develop new features, and we test them through hundreds of R & D experiments a year. We are also incredibly intent on solving some of the most complex computing problems to be found in industry and academia, and we get to test our solutions in the real world every day. And most importantly, we relentlessly ask: ""What haven't we thought of yet?""

The business intelligence engineer will work closely with data scientists, software engineers, and product managers to build out reporting to inform key stakeholders and decision-makers. In this role, you’ll design, execute and iterate on high visibility business intelligence reporting for the teams of people that are actively building out Alexa's capabilities. If you love working with huge data sets and delivering the insights you discover through business intelligence reporting and automated systems, then this is the job for you.

Key Responsibilities
Collect, analyze and share data to help product teams drive improvement in key business metrics and customer experiencePropose and prioritize changes to reporting and create additional metrics and processes based on program changes and customer requirementsWork closely with Alexa program teams to create ad-hoc reports to support timely business decisions and project workIdentify and implement new capabilities and best practices to develop and improve automated data analysis processesLearn and understand a growing range of Amazon data resources and discover how, and when to use which datasets

Expert understanding of best practices to handle extremely large volume of dataAbility to create extensible and scalable data schema that lay the foundation for downstream analysisA clear passion for learning new BI skills and techniques independently and continuouslyAbility to prioritize multiple concurrent projects while still delivering timely and accurate resultsExperience working in a lean, successful start-up or on a new product team where continuous innovation is desired and ambiguity is the normExperience mentoring others in SQL, modeling, forecasting and the use of large datasetsProficiency with scripting languages and Unix systems (Python, perl, bash, etc.)Experience with the following is a plus: Looker, Tableau, MicrostrategyExperience in an internet-based company with large, complex data sources.
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation."
29,Business Intelligence Engineer II,"Bellevue, WA 98004",Bellevue,WA,98004,None Found,"
Exposure to Web Analytics such as standard Clickstream analysis tools (e.g. Omniture) and Multivariate test software a plus
Experience with Tableau, SAS, SPSS or similar a plus
Experience with Hadoop development a plus
Travel industry and/or e-Commerce experience a plus",None Found,None Found,None Found,None Found,"Expedia
Business Intelligence Engineer/ Data Engineer (Partner Marketing)
At Expedia Group, the data landscape is defined by complexity. As a lodging marketplace, we connect customers with our millions of hotel partners; displaying a multitude of rates, promotions and content to facilitate the best possible purchase decisions. All of this results in an abundance of data ready to be transformed and interpreted into something meaningful. At Expedia Group we have a large Analytics function focused on delivering these insights, within which the Business Intelligence team has a critical role to play.
The Business Intelligence team is focused on building reliable data structures, analytical tools, and process automation applications to support our Partner Marketing group as they become more scientific and efficient in engagement with our hotel suppliers. As engineers are directly integrated with the business analyst and data scientist communities across the organization, the team shares in the ownership of key projects and deliverables. Working with platform teams, we utilize advanced technology to optimize a complex Big Data ecosystem and enable better accessibility to data. As a Business Intelligence Engineer, you will serve as an expert in our systems and processes and be positioned to provide guidance to various teams to ensure that deliverables exceed expectations.
What You’ll Do:
Serve as an expert on Expedia’s datamarts/warehouses – with a deep understanding of the architecture and how to map and consolidate information across various sources
Be creative by developing automated solutions and improving existing features for business process efficiency
Be ready and willing to go extra miles for business needs.
Run ad-hoc reports for financial modeling, business intelligence, and project level data analysis
Build and maintain business intelligence reports and dashboards
Administrate reporting databases and delivery systems to support the ongoing reporting operations
Create monitoring tools to track the quality and performance of solutions
Work with global teams, including database developers, product managers and business partners to construct appropriate BI framework for projects/programs
Work with other developers to maintain and enhance our custom-built applications which will encompass both database and user interface modules
Who You Are:
Do you have good experience working with AWS cloud-based services: S3, EC2, RDS?
Have you been working with Hadoop, Hive, Presto, Spark, Qubole, Snowflake?
Do you love working with Marketing data, Google Analytics, Facebook APIs etc…?
Are you familiar with building APIs and authentications services?
You have background in Dotnet development (MVC, ASP.Net; C#, etc.) and web technologies (Javascript; HTML; CSS, etc.)
Minimum of 3 years’ experience as a developer in a Business Intelligence/data mining/report writing role. Solid foundation in SQL, particularly Business Intelligence and Analytics solutions
Possess strong scripting skills to perform data/file manipulation
Solid background in Data Warehousing and Business Analytics environment
You have ability to read and interpret data schemas as well as develop reporting and visualizations
You have excellent problem solving skills with experience identifying and solving data quality issues
You are flexible and motivated working in a dynamic environment
Have excellent verbal and written communication skills (English)
Experience with data mining methodologies and statistical methods
Ability to logically translate and disseminate analytical insights to non-analytical business partners
You have strong emphasis on testing, validating and overall data quality
A MS/BS degree in Computer Science or related technical field preferred. Additional education in business or statistics a plus
Other Qualifications:
Exposure to Web Analytics such as standard Clickstream analysis tools (e.g. Omniture) and Multivariate test software a plus
Experience with Tableau, SAS, SPSS or similar a plus
Experience with Hadoop development a plus
Travel industry and/or e-Commerce experience a plus
Why Join Us:
Expedia Group recognizes our success is dependent on the success of our people. We are the world's travel platform, made up of the most knowledgeable, passionate, and creative people in our business. Our brands recognize the power of travel to break down barriers and make people's lives better – that responsibility inspires us to be the place where exceptional people want to do their best work, and to provide them to tools to do so.
Whether you're applying to work in engineering or customer support, marketing or lodging supply, at Expedia Group we act as one team, working towards a common goal; to bring the world within reach. We relentlessly strive for better, but not at the cost of the customer. We act with humility and optimism, respecting ideas big and small. We value diversity and voices of all volumes. We are a global organization but keep our feet on the ground so we can act fast and stay simple. Our teams also have the chance to give back on a local level and make a difference through our corporate social responsibility program, Expedia Cares.
Our family of travel brands includes: Brand Expedia®, Hotels.com®, Expedia® Partner Solutions, Egencia®, trivago®, HomeAway®, Orbitz®, Travelocity®, Wotif®, lastminute.com.au®, ebookers®, CheapTickets®, Hotwire®, Classic Vacations®, Expedia® Media Solutions, CarRentals.com™, Expedia Local Expert®, Expedia® CruiseShipCenters®, SilverRail Technologies, Inc., ALICE and Traveldoo®.LI-BSTEWARD
Expedia is committed to creating an inclusive work environment with a diverse workforce. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. This employer participates in E-Verify. The employer will provide the Social Security Administration (SSA) and, if necessary, the Department of Homeland Security (DHS) with information from each new employee's I-9 to confirm work authorization."
30,Sr. BI Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"BA/BS in Analytics, MIS, Computer Science, Engineering, Statistics, Mathematics or related field.5+ years’ experience as a BIE, data scientist, data engineer or similar job function with a technology company.A history of teamwork and willingness to roll up one’s sleeves to get the job done.Demonstrated strength in SQL, data modeling, ETL development, and data warehousing.Advanced skills in data visualization tools like Quicksight, Tableau or Cognos Solutions.Understanding of Finance concepts is a plus.Working knowledge of Python/Java or similar coding languages is a plus.Familiarity with AWS solutions such as Redshift, S3, EC2, Quicksight is a plus but not required.Ability to draw insights from data and clearly communicate them to the stakeholders and senior management.Have ability to independently influence and drive outputs, meet deadlines, and set clear expectations and road-maps.

Amazon Web Services seeks an experienced Sr. Business Intelligence Engineer (BIE) to join the AWS Finance BI(FinBI) team. The team is made of up Data Engineers, BIEs and tool developers. This team is building several platform solutions for all of AWS Finance to help invent and simplify on behalf of the customers. In this organization every day is Day 1 and no projects are the same. In this role you'll own solution designing, customer engagement and full end to end development on products. Some technologies used in the roll will be S3,Redshift, ETL, ETL automation, ad-hoc reporting with tools like QuickSight and IBM Cognos Analytics, and long term analytical projects that will affect the effectiveness of the FinBI team and the customer. You'll work with multiple AWS Finance Stakeholders and Functions, and will work with multiple sources on a wide range of data technologies developing the next generation of reporting solutions.

The successful candidate will be a self-starter comfortable with ambiguity, with strong attention to detail, and the ability to work in a fast-paced environment. You will consult, design, build and manage analytical projects with your customer in mind. You should have a strong expertise and proven success in the design, creation, management, and business use of extremely large datasets. You should be experienced at designing, implementing, and operating stable, scalable, low cost solutions to flow data from production systems into the data warehouse and into end-user facing applications or reports. Above all you should be passionate about inventing on behalf of your customers while learning new solutions to answer business questions to drive tangible change.

Duties & responsibilities for this role will include:
The successful candidate will demonstrate good business acumen, experience in developing reports and conducting analysis, strong communication skills, an ability to work effectively with cross functional teams, and an ability to work in an ever-changing environment.Interfacing with business customers to gather data and metrics requirements, then driving analytic projects which will help solve complex challenges.Design, implement, and support key datasets that provide structured and timely access to actionable business information.Perform deep-dives to find the root causes behind variances of key parameters.Experience working in a very large data warehouse environment and multi data sources.Analyzing data and driving insights related to operation and compliance.Build data pipelines for the customers to self-serve very seamlessly.Investigate and implement new big data technologies to provide automatic resolutions to address stakeholder needs.

Advanced Degrees in Analytical, MIS, Computer Science, Engineering, Statistics, Mathematics or 8+ years in related experience.Experience in end to end projects involving complex data sets and high variability.Excellent communication (verbal and written) and interpersonal skills and an ability to effectively communicate with both business and technical teams.Experience handling confidential and sensitive data.Design and develop data infrastructure to support business growth.Ability to coach and grow team-members is a plus.
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation"
31,Data Engineering Manager,"Seattle, WA",Seattle,WA,None Found,None Found,"
Experience leading, managing and hiring a team of talented engineers
Expertise in at least one of the following engineering domain areas: * Data warehouse modernization: building complete data warehouse solutions, including technical architectures, star/snowflake schema designs, infrastructure components, ETL/ELT pipelines, and reporting/analytic tools. Must have hands-on experience working with batch or streaming data processing software (such as Beam, Airflow, Hadoop, Spark, Hive).
Data migration: migrating data stores to reliable and scalable cloud-based stores, including strategies for near zero-downtime.
Backup, restore & disaster recovery: building production-grade data backup and restore, and disaster recovery solutions. Up to petabytes in scale.
Expertise in at least one of the following data domains: * Predictive analytics (e.g., recommendation systems, predictive maintenance)
Natural language processing (e.g., conversational chatbots)
Document understanding
Image classification
Marketing analytics
IoT systems
Experience writing software in one or more languages such as Python or Java/Scala
Experience in technical consulting or customer-facing role
Excellent critical thinking, problem-solving and analytical skills
",None Found,None Found,None Found,None Found,"Join SADA as a Data Engineering Manager!

Your Mission

As a Data Engineering Manager at SADA, you will build and lead a growing Data Engineering team as we deliver robust data solutions for our clients on Google Cloud Platform (GCP). You will be responsible for managing a blended team of data engineers and data scientists, so a broad background in Big Data, data warehouse modernization, analytics, disaster recovery, data science, and machine learning is highly advantageous.

The diversity of customers that SADA works with ensures a steady flow of challenging data work. Be prepared to tackle real-world data problems that our customers find too difficult or time-consuming to solve themselves. Engagements vary from being purely consultative to requiring heavy hands-on work and cover a diverse array of data domain areas. Management here at SADA also means developing people and being a leader.

In this role, you will:

Be comfortable working with customer executives to align business outcomes with technical vision and goals.
Guide the day-to-day activities of a geographically distributed team, including hiring world-class talent, reviewing work and setting goals.
Provide technical and professional leadership and mentorship on a diverse range of subject matter areas, such as Big Data pipelines and data warehouses to statistics and machine learning.
Develop and codify best practices for your team that can be replicated across multiple customer engagements.
Partner with your team to develop services and offerings that scale and are repeatable.
Participate in key technical and design discussions with technical leads as a hands-on manager.
Partner with other practice leads, architects, project managers, executives and sales personnel to develop statements of work, and then oversee execution by your team with high levels of agility and quality.

Pathway to Success

#BeOneStepAhead: At SADA we are in the business of change. We are focused on leading-edge technology that is ever-evolving. We embrace change enthusiastically and encourage agility. This means that not only do our employees know that change is inevitable, but they embrace this change to continuously expand their skills, preparing for future customer needs.

Your success starts by positively impacting the direction of a fast-growing data practice area with vision and passion. You will be measured by your team’s performance on customer engagements, how well your team achieves internal organizational goals, how well you collaborate with and support your team and peers, and the consultative polish you bring to customer interactions.

As you continue to execute successfully, we will build a customized development plan together that leads you through the management growth track.

Expectations


Required Travel - 15-25% travel to customer sites, conferences, and other related events
Customer Facing - You will interact with customers on a regular basis, sometimes daily, other times weekly/bi-weekly. Common touchpoints occur when qualifying potential opportunities, at project kickoff, throughout the engagement as progress is communicated, and at project close. You can expect to interact with a range of customer stakeholders, including engineers, technical project managers, and executives.
Training - Ongoing with first-week orientation at HQ followed by a 90-day onboarding schedule. Details of the timeline can be shared.

Job Requirements

Required Credentials:

Google Professional Data Engineer Certified

[https://cloud.google.com/certification/data-engineer] or able to complete within the first 45 days of employment

Required Qualifications:

Experience leading, managing and hiring a team of talented engineers
Expertise in at least one of the following engineering domain areas: * Data warehouse modernization: building complete data warehouse solutions, including technical architectures, star/snowflake schema designs, infrastructure components, ETL/ELT pipelines, and reporting/analytic tools. Must have hands-on experience working with batch or streaming data processing software (such as Beam, Airflow, Hadoop, Spark, Hive).
Data migration: migrating data stores to reliable and scalable cloud-based stores, including strategies for near zero-downtime.
Backup, restore & disaster recovery: building production-grade data backup and restore, and disaster recovery solutions. Up to petabytes in scale.
Expertise in at least one of the following data domains: * Predictive analytics (e.g., recommendation systems, predictive maintenance)
Natural language processing (e.g., conversational chatbots)
Document understanding
Image classification
Marketing analytics
IoT systems
Experience writing software in one or more languages such as Python or Java/Scala
Experience in technical consulting or customer-facing role
Excellent critical thinking, problem-solving and analytical skills

Useful Qualifications:

Experience working with Google Cloud data products (CloudSQL, Spanner, Cloud Storage, Pub/Sub, Dataflow, Dataproc, Bigtable, BigQuery, Dataprep, Composer, etc)
Experience in a large scale, high-volume data warehouse environment
Experience operationalizing machine learning models on large datasets
Demonstrated skills in selecting the right statistical tools given a data analysis problem

About SADA

Values: We built our core values
[https://sadasystems.com/about/company-overview/] on themes that internally compel us to deliver our best to our partners, our customers and to each other. Ensuring a diverse and inclusive workplace where we learn from each other is core to SADA’s values. We welcome people of different backgrounds, experiences, abilities and perspectives. We are an equal opportunity employer.

1. Make them rave
2. Be data driven
3. Be one step ahead
4. Be a change agent
5. Do the right thing

Work with the best : SADA has been the largest partner in North America for GCP since 2016 and recently announced, at Google NEXT, as the
2018 Global Partner of the Year
[https://sadasystems.com/blog/google-cloud/gcp/sada-wins-2018-google-cloud-partner-award/]. SADA has also been awarded
Best Place to Work
[https://sadasystems.com/blog/news/sada-systems-best-places-work-2019/] by Inc. as well as LA Business Journal!

Benefits : Unlimited PTO
[https://sadasystems.com/blog/news/blogannouncementsblogannouncementsunlimited-pto-yes-unlimited-why-sada-is-the-best-place-to-work/], competitive and attractive compensation, performance-based bonuses, paid holidays, rich medical, dental, vision plans, life, short and long-term disability insurance, 401K with match,
professional development reimbursement program
[https://sadasystems.com/blog/news/blogannouncementsprofessional-development-how-we-do-it-why-it-matters/] as well as Google Certified training programs.

Business Performance: SADA has been named to the INC 5000 Fastest-Growing Private Companies list for 12 years in a row garnering Honoree status. CRN has also named SADA on the Top 500 Global Solutions Providers for the past 5 years. The overall culture continues to evolve with engineering at its core: 3200+ projects completed, 3000+ customers served, 10K+ workloads and 25M+ users migrated to the cloud."
32,"Sr. Data Engineer - BI, Analyst, Cloud","Seattle, WA 98115",Seattle,WA,98115,None Found,"
8+ years of BI development experience with 4+ of cloud analytics experience
Cloud solution implementation experience with some of the following technologies:
Jenkins
Sqoop
Hadoop including Hive and Pig
Spark and SparkSQL
AWS S3, Redshift, Dinamo DB
Azure Data Lake Store, HDInsight, U-SQL
Python, JSON, Java",None Found,None Found,None Found,None Found,"Developer – Big Data
Seattle, WA

About the Role. . .
Very strong cloud analytics development skills are vital to Logic 20/20’s success. In order to continue and accelerate our growth, we are looking for Big Data Developers to add to our Seattle, Washington-based team. Big Data Developers are responsible for delivering client value and ensuring high client satisfaction. They are expected to be adept at recognizing, subscribing, and applying best practices, methodology, tools, and techniques to meet client requirements, timelines, and budgets.
You like to . . .
Develop end-to-end cloud analytics solutions
Lead small teams of developers on BI projects on client projects in the greater Seattle region
Communicate project status to internal and external stakeholders
Translate client user requirements into data flows, data mapping, etc.
Ensure that the design system runs efficiently and accurately
Create and deliver technical and project documentation as required throughout the project lifecycle
Deliver projects and solve problems within small, medium and large organizations utilizing disparate tools and methodologies
Deliver high quality projects on time and budget in adverse environments
Qualifications
8+ years of BI development experience with 4+ of cloud analytics experience
Cloud solution implementation experience with some of the following technologies:
Jenkins
Sqoop
Hadoop including Hive and Pig
Spark and SparkSQL
AWS S3, Redshift, Dinamo DB
Azure Data Lake Store, HDInsight, U-SQL
Python, JSON, Java
Advanced data analysis skills including advanced SQL query capabilities
Deep experience in data modeling, data analysis and relational database design
Demonstrated ability to identify business and technical impacts of user requirements and incorporate them into the project schedule
Ability to work both independently and as part of a team
Ability to work under pressure and to independently handle multiple projects and deadlines
Experience working with large datasets (over 100M rows)
Experience with Talend / Informatica is a plus
Experience building real time or near real time BI solutions for PROD
An undergraduate degree in technology or business is required
Cloud certification (AWS or GCE) is a plus

About Logic20/20. . .
Logic20/20 is one of Seattle’s fastest growing full-service consulting firms. Our core competency is creating simplicity and efficiency in complex solutions. Although we make it look like magic, we succeed by combining methodical and structured approaches with our substantial experience to design elegant solutions for even the most intricate challenges. Our rapid growth is in response to our ability to deliver consistently for our clients, which is directly related to the quality of the people we hire.
The past four years, we’ve been in the top 10 “Best Companies to Work For” ….. why? Our team members are highly self-motivated, comfortable conceiving strategies on the fly, and enjoy working both individually and as part of a team. Our environment is very high-energy and demanding, and individuals with remarkable enthusiasm and a can-do attitude are joining our team. We have lots of fun, focus on our employees and our clients, and work to bring our best to every opportunity."
33,"Strategic Customer Engagements, Product Manager - Pricing Analytics","Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelor's degree8+ years of work experienceAbility to drive project success in an ambiguous environmentStrong ability to build trust with stakeholdersAbility to communicate with both technical and non-technical partnersExperience building financial models

Are you an entrepreneur that thrives in a fast-paced ambiguous environment? Do you want to be involved in strategic deals come to life?

If so, we are looking for a Sr. Product Manager to join the Strategic Customer Engagements team to build scalable tools to support complex deals. The Strategic Customer Engagements Deal Team works with our customers on commercial private opportunities to meet their desired business outcomes while ensuring alignment with AWS business objectives.

In this role, you be responsible for understanding and modeling customer usage patterns, the competitive environment, and the strategy for our largest AWS service. You will work with a data engineer to identify the data sources and metrics needed to support our largest customer facing deals. You will work cross-functionally with our competitive insights team and with technical partners to understand business tradeoffs and develop tools for our team to quickly analyze deals. You will also provide strategic support to model large deals and be a voice in the room during the deal process.

The ideal candidate will be able to work independently in an ambiguous environment. They will understand financial modelling and be able to communicate complex relationships to senior leaders.

MBA5+ years of product management experienceExperience working with data engineersExperience working with AWS services"
34,Senior Data Engineer – Marketing,"Seattle, WA 98107",Seattle,WA,98107,None Found,None Found,None Found,None Found,None Found,None Found,"What you’ll be doing…
The Senior Marketing Data Engineer contributes in technical solutions on behalf of Tableau’s Marketing Data Engineering team. This team is responsible for building and operating our cloud-based Marketing data platform that enables self-service Marketing analytics. The Senior Data Engineer role will help solve challenging data integration problems by participating in development, architecture and operations work, related to building the Marketing data platform. The role will collaborate with product managers, engineers, and internal customers to scope and define implementation plans that meet business requirements. In addition to that this role will collaborate with other managers across Tableau to help develop our standards and practices while serving as a mentor to other Data Engineers. The Senior Data Engineer supports Tableau’s core value commitments to delight our customers and work as a team.
Some of the things you’ll be doing include…
Help build and architect the Marketing Data Platform
Build robust scalable data processing and data integration pipelines using Python, Kafka, Spark, REST API endpoints and microservices to ingest data from variety of external data sources to Snowflake, and use Airflow to build workflow DAGs and schedule jobs.
Develop data quality automations and unit tests to ensure the accuracy of the data delivered to the Analysts and Business Customers
Build solutions that scale gracefully as our data volumes grow exponentially
Define and implement monitoring and alerting policies for data solutions
Help modernize our SDLC for CI/CD automation and the Cloud
Develop data models that support analytical models used by Tableau
Participate in code reviews and related processes
Help our Data Engineers grow by providing “humble smart” mentorship
Work with product managers, engineers, and internal customers to identify and scope of the requests and define implementation plans
Lead knowledge-sharing sessions to train team members on new skills or technologies
Who you are…
Passionate . You have a passion for data, building data platforms, and enjoy solving complex data integration problems with modern, cloud-based technologies. You are naturally curious, enjoy learning new technologies and seek out efficient solutions without producing complicated code. You understand the value of delivering value to the customer quickly and welcome incremental feedback. You maintain a high personal standard for delivering quality software, with a sense of urgency to our users that performs at scale and is easily maintained by other team members. You enjoy collaboration and are comfortable working in an agile and iterative development environment.
Experienced. BA/BS in Computer Science or equivalent. 5-7+ years professional experience in software engineering role. 2-3+ years ETL development experience. AWS Certifications on either a Developer or Architect track handy but not required. Experience with containers and container orchestration tools such as Docker and Kubernetes are handy but not required. Experience with CI/CD pipelines is handy but not required.
Technically Savvy. A technical background in data architecture, ETL development, data pipeline architecture & development, data warehousing concepts including database management.
Demonstrated experience in the following areas:
Writing Python code
Writing complex highly-optimized SQL queries across large data sets
AWS services such as EC2, S3, IAM roles, ECS, CloudWatch, etc.
Snowflake
Airflow and Kafka
Git
Cross-Cultural Leadership . Deep experience working with a team of cross-functional disciplines
Entrepreneurial . Strong Entrepreneurial drive. The ability to finish tasks start to finish.
Go-Getter . Tableau Product knowledge or the ability to learn it quickly. Enthusiasm for a fast-growing, fast-changing environment.
Detail oriented. Nothing gets overlooked when it comes to you.
You are a Recruiter! Tableau hires company builders and, in this role, you will be asked to be on the constant lookout for the best talent to bring on board to help us continue to build one of the best companies in the world!
#LI-SC2
Tableau Software is an Equal Opportunity Employer.
Tableau Software is a company on a mission. We help people see and understand their data. After a highly successful IPO in 2013, Tableau has become a market-defining company in the business intelligence industry. Our culture is casual and high-energy. We are passionate about our product and our mission and we are loyal to each other and our company. We value work/life balance, efficiency, simplicity, freakishly friendly customer service, and making a difference in the world!"
35,Software Engineer 2 (Data Engineer),"Redmond, WA",Redmond,WA,None Found,None Found,"
BS or MS Degree in Computer Science or Data Science.
Experience developing with cloud-based technologies, including relational databases, data warehouse, big data (i.e. Hadoop, Spark), orchestration/data pipeline tools.
Experience with telemetry and data mining eg: Azure Data Lake, Kusto, Hadoop and related big data systems
Software Programming experience with C#
Knowledge of an analysis tools such as R and Python
Proficiency in Power BI
Experience with Agile software development using the scrum methodology.",None Found,"
Lead the development of our data pipeline and reporting infrastructure including developing solutions for data collection, management and usage.
Help strategize and extend this system to handle Data Science models in platforms like Azure ML and/or DataBricks
Working on a system that speaks natively to various data platforms, enabling individual users to rapidly explore their data and author insightful visualizations.
Partner with our extended team of PMs, service engineers, support delivery managers and engineers to ensure reporting requirements, delivery plans, engineering execution, risks and issues and support scenarios are well-understood and communicated.
Become a SME on multiple business processes and how related solutions are expressed in our services and technology and mentor other engineers.",None Found,None Found,"While you’ve heard about Microsoft’s Digital Transformation and how it’s leading our industry to the cloud, have you ever thought of becoming a key member of the team that powers the core Infrastructure services for this strategic effort in our company?
Core Platform Engineering is part of the Core Services Engineering (CSE) team - our goal is to boldly pursue big ideas that power transformational advancements at Microsoft, while helping Microsoft employees work smarter, faster, and more securely every day. We are technology leaders with deep technical experts, focused on digital transformation and enabling our stakeholders.

As part of CPE, the Enterprise Infrastructure Service (EIS) team has a very broad Infrastructure portfolio which includes:

Providing network connectivity services (Core routing & WAN, wireless, wired, VPN, firewalls, load balancers, DNS, etc.) for 580 sites globally, including Microsoft's large corporate campuses.
Managing 90 contact centers, ensuring that 36 million calls to Microsoft are delivered, and driving new capabilities, like speech to text translations for these calls.
Moving line-of-business workloads to Azure and partnering with the Azure team on the features and functionalities required for a modern enterprise, with a focus on customer experience and security.
Providing shared lab services for more than 40 labs and 4 legacy datacenters, while driving these workloads to Azure.
Playing a significant part in driving the strategic vision and implementation of new and existing prioritized investments across Microsoft to increase our capabilities to function as modern enterprise and continue our digital transformation.
We have exciting opportunities for you to innovate, influence, transform, inspire and grow within our organization and we encourage you to apply to learn more!

Are you someone with a passion for data, analytics, insights and technology? Do you want to be part of a team lighting up actionable insights to help the organization make business decisions and improve customer experience? Do you want to be at the forefront of driving company-wide impact using Big Data?

The Customer Engagement Solutions (CES) Data Engineering (DE) team is transforming the customer support infrastructure and executing against modern engineering and customer first strategy.

The Data Engineering team builds and operates an extensive data platform that associates telemetry and customer contact data. By connecting data across different product/service telemetry and contact routing systems, the DE platform provides Microsoft with visibility and insights into our customer and support agent interaction. Our scope is currently expanding to include, data ingestion and management, live site and scorecard reporting, deep data analysis and application development for entire telecom contact support space within Microsoft.
We are hiring a Data Engineer with a combination of programming and data skills to lead the evolution and development of our internal tools, reporting and analytics infrastructure. This position is a technical role with operational accountability.

Come be a core member of this exciting space and join an amazing, growing team!
Responsibilities
Lead the development of our data pipeline and reporting infrastructure including developing solutions for data collection, management and usage.
Help strategize and extend this system to handle Data Science models in platforms like Azure ML and/or DataBricks
Working on a system that speaks natively to various data platforms, enabling individual users to rapidly explore their data and author insightful visualizations.
Partner with our extended team of PMs, service engineers, support delivery managers and engineers to ensure reporting requirements, delivery plans, engineering execution, risks and issues and support scenarios are well-understood and communicated.
Become a SME on multiple business processes and how related solutions are expressed in our services and technology and mentor other engineers.
Qualifications
BS or MS Degree in Computer Science or Data Science.
Experience developing with cloud-based technologies, including relational databases, data warehouse, big data (i.e. Hadoop, Spark), orchestration/data pipeline tools.
Experience with telemetry and data mining eg: Azure Data Lake, Kusto, Hadoop and related big data systems
Software Programming experience with C#
Knowledge of an analysis tools such as R and Python
Proficiency in Power BI
Experience with Agile software development using the scrum methodology.
Preferred, not required:
Experience in Machine Learning systems
#CSEO

Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.

Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work."
36,"Sr. Program Manager, Transportation Network Optimization","Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelor degree or higher in Supply Chain, Engineering, Transportation, Business Analytics or other technical discipline5+ years of experience conducting quantitative analysisExperience with supply chain management concepts - forecasting, planning, optimization, and logistics - gained through work experience or graduate level educationDemonstrated ability leading projects with multiple stakeholdersExperience presenting and communicating across all levels of the organization; ability to speak effectively before the appropriate audienceEffective time management, prioritization, and organizational skills

The North America Sort Centers are experiencing explosive growth and looking for a skilled, highly motivated and experienced Sr. Program Manager with leadership experience and a strong delivery record to join the Network Optimization Team. Sort Center network is the critical Middle-mile solution in the Amazon Transportation Services (ATS) group that links the fulfillment centers to the last mile solutions. The experience of our customers is dependent upon our ability efficiently execute new programs and manage volume flow through the middle-mile network.

The successful candidate will have strong quantitative and analytical skills. This candidate needs to be comfortable facilitating ideation and working from concept through to execution. This position will partner and drive operational excellence with Engineering, Field Operations, Transportation, Last Mile Delivery, Topology, Finance and Technology teams to determine root cause of operational challenges, drive process improvements, build KPIs (Key Performance Indicators) and metrics, un-earth opportunities and present findings and recommendations to business partners and management.

A qualified candidate must be self-motivated and have demonstrated ability to manage medium to large-scale projects that are innovative or complex and at the same time delivered as quickly, accurately, and as cost effectively as possible. In addition, this candidate needs to possess strong written and verbal communication skills, strong focus on internal customers, high intellectual curiosity to learn new concepts and methodologies and ability to adapt and thrive in the fast-paced, high change environment.

Responsibilities:
Work with teams across NA Operations to identify opportunities and provide data driven recommendations to improve the cross-dock program through the Sort Center network.Work on programs with a focus on improving speed of delivery and continuous flow to our last mile delivery partners.Communicate network changes, programs and events that will impact future short term and long term sort and delivery operations.Identify and analyze opportunities to service new initiatives/programs.Own the design and development of ongoing metrics, reports, dashboards, etc. to drive key business decisions.Provide analytical network support to improve quality and standard work results.Root cause research to identify process breakdowns within departments and providing data through use of various skill sets to find solutions to process failuresCollaborate with BI/Data Engineer teams and drive the collection of new data and the refinement of existing data sources to continually improve data qualityFoster culture of continuous improvement through mentoring, feedback, and metrics.
#NASC

Intermediate to advanced knowledge of Excel and SQL.MBA or Master’s degree or higher in Supply Chain, Engineering, Transportation, Business Analytics or other technical or Operations discipline.Extensive experience in transportation/supply chain.Experience with Amazon Quality operations and/or Standard WorkFamiliarity with the processes used in Amazon fulfillment networkCross functional project management experiences
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation/ Age"
37,ES Tech Data Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Experience with AWS services including S3, Redshift, EMR and Kinesis.Build robust and scalable data integration (ETL) pipelines using SQL, EMR, Python and Spark.Experience with Big Data Technologies (Hadoop, Hive, Hbase, Pig, Spark, etc.)2+ years of hands-on experience in writing complex, highly-optimized SQL queries across large data sets.2+ years of experience in scripting languages like Python etc.3+ years of hands-on experience in writing complex, highly-optimized SQL queries across large data sets.

Love data as much as we do? Want to influence at Amazon? We have the career for you.
Amazon's Employee Services Technology (ES Tech) team is seeking an outstanding Senior Data Engineer to join our BI team to build out the data platform with all of the data ingestion mechanisms required for the initiative. Our platform delivers business intelligence to a diverse, global community of internal customers from one of the world’s largest and most complex data sets. Amazon has culture of data-driven decision-making, and demands business intelligence that is timely, accurate, and actionable.

You will be responsible for designing and implementing data solutions using Amazon cloud technologies. A successful candidate knows and loves working with business intelligence ETL tools, is comfortable accessing and working with big data from multiple sources, and passionately partners with the business to identify strategic opportunities and deliver results. You should have an internal drive to answer “why?” questions, excellent analytical abilities, strong technical skills, as well as superior written and verbal communication skills. S/he would be a self-starter, comfortable with ambiguity, able to think big (while paying careful attention to detail), and enjoy working in a fast-paced dynamic environment.

Responsibilities include:
Build robust and scalable data integration (ETL) pipelines using SQL, EMR, Python and Spark.Build and deliver high quality data architecture to support business analyst, data scientists, and customer reporting needs.Interface with other technology teams to extract, transform, and load data from a wide variety of data sources.Continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers.Design and development ETL mappings within data integration tool.Design structured, multi-source data mappings to deliver the dashboards and reports that make data actionable.Drive the collection of new data and the refinement of existing data sources to continually improve data quality and implement business logic using efficient transformations.

Good instincts; you know what it means to be a subject matter expert and how to be a team playerAbility to work independently and problem solve with little to no direction. Impeccable customer service focus with a demonstrated desire to exceed expectations.Attention to detail; you prioritize multiple tasks simultaneously without sacrificing the ability to dive deep.
Amazon is an Equal Opportunity-Affirmative Action Employer - Female/Minority/Disability/Veteran/Gender Identity/Sexual Orientation."
38,Senior Data Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"About Blink
-----------

Blink Health is fixing how broken, opaque, and unfair healthcare is. We are a New York based, mission driven, well-funded healthcare technology company. We're changing healthcare through technology and transparency. With our proprietary technology, everyone now has access to one, low negotiated price on over 15,000 medications. But there is more work to do.

About The Team
--------------

Blink Engineering strives to build trusted, highly observable, data-driven products to bring affordable, accessible healthcare to all Americans. We understand healthcare is the most complex system most of us will ever fix. We believe in solving this complexity through the use of simple, well-known technologies. We are a highly collaborative team that believes in owning outcomes over owning code and putting patients at the center of everything we do.

The Blink Health Data Engineering and Analytics team is a small team responsible for building infrastructure, frameworks and tooling to enable data-driven decisions; building and maintaining our data warehouse for security and scale. This role is central to building and executing on a robust and forward-looking data strategy for the company, and the successful candidate blends top-tier software engineering expertise with the ability to look ahead at what we need to build for the future.

About the Role
--------------

As the senior software engineer for data, you will be a thought leader within the data engineering team that is designing and building our next generation of data tools and frameworks, in addition to developing and maintaining data products and infrastructure. You will proactively assess production DW support trends to determine and implement short- and long-term solutions, and be able to design for data integrity, reliability, and performance. You will set a high bar for clean and correct code, setting code standards, and performing peer code and architecture reviews.

Required Experience


You have 6+ years hands-on experience and demonstrated strength with:
Python, building data pipelines, and managing data at multiple companies.
Writing complex, highly-optimized SQL queries across large data sets.
Building and maintaining robust and scalable data integration (ETL) pipelines using SQL, EMR, Python and Spark.
Designing and maintaining columnar databases (e.g., Redshift, Snowflake)
Distributed data processing (Hadoop, Spark, Hive)
ETL with batch (Data Pipeline) and streaming (Kinesis, Airflow)
Integration and design for Business Intelligence tools (e.g., Looker, QuickSight)
Creating scalable data models for analytics.
You have experience designing and refactoring large enterprise data warehouses and associated ETLs, with continuous improvement examples for automation and simplification across all aspects of the DW environment, inclusive of both engineering and business reporting.
Experience owning features from design through delivery along with ongoing support.
Proven success with communicating effectively across diverse disciplines (including product engineering, infrastructure, analytics, data science, finance, marketing, customer support, etc.) to collect requirements and describe data engineering strategy and decisions.
Experience providing clear data engineering technical leadership, mentoring, and best practices for data management and quality within and across teams.
Undergraduate or graduate degree in Computer Science

Desired Experience


Healthcare-relevant company experience as part of the required experience above, with demonstrated industry knowledge of handling sensitive information.

"
39,Data Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,"
Expertise in at least one of the following domain areas: * Data warehouse modernization: building complete data warehouse solutions, including technical architectures, star/snowflake schema designs, infrastructure components, ETL/ELT pipelines, and reporting/analytic tools. Must have hands-on experience working with batch or streaming data processing software (such as Beam, Airflow, Hadoop, Spark, Hive).
Data migration: migrating data stores to reliable and scalable cloud-based stores, including strategies for near zero-downtime.
Backup, restore & disaster recovery: building production-grade data backup and restore, and disaster recovery solutions. Up to petabytes in scale.
Experience writing software in one or more languages such as Python, Java, Scala, or Go
Experience building production-grade data solutions (relational and NoSQL)
Experience with systems monitoring/alerting, capacity planning and performance tuning
Experience in technical consulting or other customer-facing role
",None Found,None Found,None Found,None Found,"Join SADA as a Data Engineer!

Your Mission

As a Data Engineer at SADA, you will work collaboratively with architects and other engineers to recommend, prototype, build and debug data infrastructures on Google Cloud Platform (GCP). You will have an opportunity to work on real-world data problems facing our customers today. Engagements vary from being purely consultative to requiring heavy hands-on work and cover a diverse array of domain areas, such as data migrations, data archival and disaster recovery, and big data analytics solutions requiring a combination of batch or streaming data pipelines, data lakes and data warehouses.

You will be recognized as an established contributor by your team. You will contribute design and implementation components for multiple projects. You will work mostly independently with limited oversight. You will also participate in client-facing discussions in areas of expertise.

Pathway to Success

#BeOneStepAhead: At SADA Systems we are in the business of change. We are focused on leading-edge technology that is ever-evolving. We embrace change enthusiastically and encourage agility. This means that not only do our engineers know that change is inevitable, but they embrace this change to continuously expand their skills, preparing for future customer needs.

Your success starts by positively impacting the direction of a fast-growing practice with vision and passion. You will be measured quarterly by the breadth, magnitude, and quality of your contributions, your ability to estimate accurately, customer feedback at the close of projects, how well you collaborate with your peers, and the consultative polish you bring to customer interactions.

As you continue to execute successfully, we will build a customized development plan together that leads you through the engineering or management growth tracks.

Expectations

Required Travel - 30% travel to customer sites, conferences, and other related events
Customer Facing - You will interact with customers on a regular basis, sometimes daily, other times weekly/bi-weekly. Common touchpoints occur when qualifying potential opportunities, at project kickoff, throughout the engagement as progress is communicated, and at project close. You can expect to interact with a range of customer stakeholders, including engineers, technical project managers, and executives.
Training - Ongoing with a first-week orientation at HQ followed by a 90-day onboarding schedule. Details of the timeline can be shared.

Job Requirements

Required Credentials:

Google Professional Data Engineer Certified

[https://cloud.google.com/certification/data-engineer] or able to complete within the first 45 days of employment

Required Qualifications:

Expertise in at least one of the following domain areas: * Data warehouse modernization: building complete data warehouse solutions, including technical architectures, star/snowflake schema designs, infrastructure components, ETL/ELT pipelines, and reporting/analytic tools. Must have hands-on experience working with batch or streaming data processing software (such as Beam, Airflow, Hadoop, Spark, Hive).
Data migration: migrating data stores to reliable and scalable cloud-based stores, including strategies for near zero-downtime.
Backup, restore & disaster recovery: building production-grade data backup and restore, and disaster recovery solutions. Up to petabytes in scale.
Experience writing software in one or more languages such as Python, Java, Scala, or Go
Experience building production-grade data solutions (relational and NoSQL)
Experience with systems monitoring/alerting, capacity planning and performance tuning
Experience in technical consulting or other customer-facing role

Useful Qualifications:

Experience working with Google Cloud data products (CloudSQL, Spanner, Cloud Storage, Pub/Sub, Dataflow, Dataproc, Bigtable, BigQuery, Dataprep, Composer, etc)
Experience with IoT architectures and building real-time data streaming pipelines
Applied experience operationalizing machine learning models on large datasets
Knowledge and understanding of industry trends and new technologies and ability to apply trends to architectural needs
Demonstrated leadership and self-direction -- a willingness to teach others and learn new techniques
Demonstrated skills in selecting the right statistical tools given a data analysis problem

About SADA

Values: We built our core values
[https://sadasystems.com/about/company-overview/] on themes that internally compel us to deliver our best to our partners, our customers and to each other. Ensuring a diverse and inclusive workplace where we learn from each other is core to SADA’s values. We welcome people of different backgrounds, experiences, abilities and perspectives. We are an equal opportunity employer.

1. Make them rave
2. Be data driven
3. Be one step ahead
4. Be a change agent
5. Do the right thing

Work with the best : SADA has been the largest partner in North America for GCP since 2016 and recently announced, at Google NEXT, as the
2018 Global Partner of the Year
[https://sadasystems.com/blog/google-cloud/gcp/sada-wins-2018-google-cloud-partner-award/]. SADA has also been awarded
Best Place to Work
[https://sadasystems.com/blog/news/sada-systems-best-places-work-2019/] by Inc. as well as LA Business Journal!

Benefits : Unlimited PTO
[https://sadasystems.com/blog/news/blogannouncementsblogannouncementsunlimited-pto-yes-unlimited-why-sada-is-the-best-place-to-work/], competitive and attractive compensation, performance-based bonuses, paid holidays, rich medical, dental, vision plans, life, short and long-term disability insurance, 401K with match,
professional development reimbursement program
[https://sadasystems.com/blog/news/blogannouncementsprofessional-development-how-we-do-it-why-it-matters/] as well as Google Certified training programs.

Business Performance: SADA has been named to the INC 5000 Fastest-Growing Private Companies list for 12 years in a row garnering Honoree status. CRN has also named SADA on the Top 500 Global Solutions Providers for the past 5 years. The overall culture continues to evolve with engineering at its core: 3200+ projects completed, 3000+ customers served, 10K+ workloads and 25M+ users migrated to the cloud."
40,Sr Data Engineer,"Bellevue, WA 98004",Bellevue,WA,98004,None Found," Deep experience with RDMS databases (SQL Server) and Data Warehouse (OLAP, Redshift) managing connection-pools, performance tuning and optimizations.
"," Deep experience with RDMS databases (SQL Server) and Data Warehouse (OLAP, Redshift) managing connection-pools, performance tuning and optimizations.
","
Deliver on large and complex solution data needs by leading requirements and technical specifications that drive resulting data designs. Participate in strategic and innovative data design, requirements, walkthroughs, and reviews. Design and document system integration/configuration as required.
Implement and advance data models and configurations in support of integrating data from source systems and environments to promote Continuous Integration/Continuous Deployment (CI/CD) and CQRS pattern caching.
Research, design, and implement next generation analytics and machine learning platforms.
Build tools, frameworks, APIs, and dashboards to support telemetry and advanced analytics focusing on ways to improve data security, accessibility, reliability, scalability, efficiency and quality.
Lead data governance and guide all data schema/configuration changes."," Deep experience with RDMS databases (SQL Server) and Data Warehouse (OLAP, Redshift) managing connection-pools, performance tuning and optimizations.
",None Found,"A Sr Data Engineer will build, manage, integrate, and optimize reservoirs for data in support of delivering relevant information for business consumption promoting advances in predictive analytics and machine learning. This individual develops, constructs, tests and maintains designs for databases and large-scale data processing systems in support of underlying business, solution, and enterprise architectures. They support and maintain pipelines delivering relevant data sets for business consumption and analysis. This individual works closely with architects to determine which data management systems are appropriate and with the business to determine what data is needed for analysis. This individual works with architects to guide/align data management systems and closely with the business to determine what data is needed for analysis. This individual will wrestle with problems associated with database integration and messy, unstructured data sets toward the ultimate goal of providing clean, usable data to whomever may require it.

Responsibilities

Deliver on large and complex solution data needs by leading requirements and technical specifications that drive resulting data designs. Participate in strategic and innovative data design, requirements, walkthroughs, and reviews. Design and document system integration/configuration as required.
Implement and advance data models and configurations in support of integrating data from source systems and environments to promote Continuous Integration/Continuous Deployment (CI/CD) and CQRS pattern caching.
Research, design, and implement next generation analytics and machine learning platforms.
Build tools, frameworks, APIs, and dashboards to support telemetry and advanced analytics focusing on ways to improve data security, accessibility, reliability, scalability, efficiency and quality.
Lead data governance and guide all data schema/configuration changes.
Required/Preferred Qualifications

Education Required:
B.S. in Computer Science, Mathematics, Software/Computer Engineering, Information Systems or science related field. A Data Professional Certification (e.g., ICCP Certified Data Professional, BI Professional, Big Data Professional, Data Governance Professional, or vendor equivalent) is encouraged.

Minimum Years of Related Work Experience Required:
Minimum of 7-10 years of data design & development experience in relevant technologies/systems required including technical experience implementing and delivering from system architecture, design, integration, implementation, security, and capability roadmap for a data environment.

Skills and Abilities Required:
 Deep experience with RDMS databases (SQL Server) and Data Warehouse (OLAP, Redshift) managing connection-pools, performance tuning and optimizations.
 Awareness/exposure to NoSQL technologies (Key/Value, Columnar, Document, Graph)
 Creative Problem-Solving: Approaches data organization challenges leveraging experience with multiple, diverse technical configurations, technologies and processing environments.
 Effective Collaboration: Carefully listens to business partners, data scientists and architects to ascertain their needs partnering to establishing optimal outcomes.
 Intellectual Curiosity: Awareness and exposure with Data Visualization (e.g., Power BI, Microstrategy, Tableau), big data systems including MapReduce technologies (e.g., Hadoop, Spark), NoSQL technologies (Key/Value, Columnar, Document, Graph), and Monitoring platforms (e.g., Splunk, the Elastic Stack, CloudTrail, CloudWatch).
 Awareness/exposure development and modeling programming languages (e.g., Java, C#, R, Python).

Symetra is a dynamic and growing financial services company with 60 years of experience and customers nationwide. In our daily work delivering retirement, employee benefits, and life insurance products, we're guided by the principles of VALUE, TRANSPARENCY AND SUSTAINABILITY. That means we provide products and services people need at a competitive price, we communicate clearly and honestly so people understand what they're getting, and we build products that stand the test of time. We work hard and do what's right for our customers, communities and employees. Join our team and share in our success as we work toward becoming the next national player in our industry."
41,Data Engineering Manager,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Degree in Computer Science, Engineering, Mathematics, or a related field and 7+ years industry experience2+ years of hands-on experience hiring and managing teams of Data Engineers and 5+ as a hands-on Data EngineerKnowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operationsProficiency with at least one Object Oriented language (e.g. Java, Python, Ruby)Highly proficient in SQL and knowledgeable about data warehousing concepts.Working knowledge of software development methodologies like AgileStrong customer focus, ownership, urgency and drive.Excellent communication skills and the ability to work well in a team.Effective analytical, troubleshooting and problem-solving skills.

What is the team?
The Workforce Staffing Research & Business Intelligence team is your opportunity to make an impact across multiple layers of the company and the hourly workforce as a whole. This team will lead and influence programs that will enable Amazon to scale more efficiently, while also providing a unique voice for the hourly labor population within the United States and Canada. Amazon’s mission is to be the most customer centric company in the world. The Workforce Staffing (WFS) Organization is on the front line of that mission by hiring hundreds of thousands of hourly associates across multiple types of roles and businesses. To drive the continued scale of Amazon’s labor needs within a constrained employment environment, and to improve the candidate/employee experience within Amazon’s operation, Amazon is investing in its Workforce Staffing Research & Business Intelligence programs.

What is the role?
As a Data Engineering Manager you will be leading a team of Data Engineers and SDEs and will play a thought leadership role in our team – the team will look to you for advice on data and business issues facing them. You work very efficiently and routinely deliver the right things. You will have a company-wide view of the Data Engineering solutions that you build, and you will consistently think in terms of automating or expanding the results company-wide. This high impact role will have an opportunity to lead a team to help design and build our data infrastructure and work with emerging technologies such as Redshift and associated AWS cloud services while driving business intelligence solutions end-to-end: business requirements, workflow instrumentation, data modeling and ETL. He/she should be an expert at designing, implementing, and operating stable, scalable, low cost solutions to flow data from production systems into the data lake and into end-user facing applications. The role requires someone who loves data, understands enterprise information systems, has a strong business sense, and can lead a team to put these skills into action.

Graduate degree in Computer Science, Engineering or related technical fieldExperience building data products incrementally and integrating and managing datasets from multiple sourcesExperience with AWS Tools and Technologies (Redshift, S3, EC2)Experience providing technical leadership and mentor other engineers for data engineering best practicesAdvanced knowledge and expertise with Data modelling skills, Advanced SQL with Oracle, MySQL, and Columnar DatabasesDemonstrated industry leadership in the fields of Database and/or Data Warehousing, Data Sciences and Big Data processing
Amazon.com is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age."
42,Backend Service Engineer,"Redmond, WA",Redmond,WA,None Found,None Found,"
2+ years of relevant software design and development in C# and Java
Experience with backend services and have developed backend APIs
Knowledge of Javascript and Typescript is preferred
Knowledge of the Azure services (Azure Table Storage and Azure Blob Storage) preferred
The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up
Self-directed and comfortable supporting the data needs of multiple teams, systems and products
The right candidate will be excited by the prospect of optimizing or even re-designing data architecture to support the next generation of products and data initiatives
Azure Data Factory and spark experience
Experience with Cosmos Database preferred as well as Azure table.
Experience with Micro-services and Kubernetes",None Found,"
Responsible for expanding and optimizing data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams
Support software developers, database architects, data analysts and data scientists on data initiatives and ensure optimal data delivery architecture is consistent throughout ongoing projects",None Found,None Found,"Beyondsoft Consulting, Inc., is a leading, technical solutions and consulting partner. We combine emerging technologies and proven methodologies to tailor elegant solutions that solve complex challenges and empower our customers to accelerate their business goals. Our services include end-to-end support for cloud, digital, data analytics, multi-language translation, and testing.

We are looking for a savvy Data Engineer to join our growing team of analytics experts. If you are passionate about programming and have experience with backend services this could be a perfect role for you. You will work with one of our major clients in the Greater Seattle area.
Responsibilities
Responsibilities:
Responsible for expanding and optimizing data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams
Support software developers, database architects, data analysts and data scientists on data initiatives and ensure optimal data delivery architecture is consistent throughout ongoing projects
Qualifications
Qualifications:
2+ years of relevant software design and development in C# and Java
Experience with backend services and have developed backend APIs
Knowledge of Javascript and Typescript is preferred
Knowledge of the Azure services (Azure Table Storage and Azure Blob Storage) preferred
The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up
Self-directed and comfortable supporting the data needs of multiple teams, systems and products
The right candidate will be excited by the prospect of optimizing or even re-designing data architecture to support the next generation of products and data initiatives
Azure Data Factory and spark experience
Experience with Cosmos Database preferred as well as Azure table.
Experience with Micro-services and Kubernetes"
43,"Manager, Data Engineering","Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelor’s degree or higher in an analytical area such as Computer Science, Physics, Mathematics, Statistics, Engineering or similar field.7+ years of experience as a BI Engineer or Data Engineer preferably in an internet-based company with large, complex data sources, or in an analysis or research role with progressively increasing responsibility.Deep understanding of advanced data warehousing concepts and a track record of applying these concepts on the job.Experience building self-service reporting solutions using business intelligence or data visualization software (e.g. Tableau Server, AWS Quicksight).Demonstrated experience in using SQL, ETL construction, Data Warehousing solutions and database modeling in a business environment with large-scale, complex datasets.Proven analytical and quantitative skills and an ability to use data and metrics to back up assumptions, develop business cases, and complete root cause analyses.Strong verbal/written communication and data presentation skills, including an ability to effectively communicate with both business and technical teams.Ability to work cross-functionally, building and maintaining trust with internal stakeholdersExperience with the Software Development Life Cycle (SDLC) and Agile/Scrum methods

Do you have passion to drive the performance of a business through creative analytical insight? Are you excited about data and bringing science to the art of managing and developing an extremely talented workforce?

We are looking for a passionate, insightful, results-oriented Data Engineering manager to join a team chartered with building People Analytics for all of Amazon. From statistical analysis, predictive analytics, data visualization, and data warehousing; we’ll do it all!

All with an aim to more effectively develop our most valuable of all resources – our people!
Our platforms are based on AWS technologies including EC2, Lambda, Step Functions, S3, Glue, Athena, and Redshift among others. Come innovate with us as we build with cutting-edge technologies and continue to deliver world-class business intelligence solutions to our internal customers.
Responsibilities:
Hire, develop and mentor a high-performance team of technical resources.Manage day to day activities of the Data Engineering team via Agile/Scrum methodologiesManage and execute against project plans and delivery commitments.Report on status of development, quality, operations and system performance to leadershipBuild and maintain inter-team relationships and be the chief point of contact for development partners and customersDevelop Long term vision and translate that into an achievable road map.Problem Solving and reducing ambiguity of road map to achieve task delivery dates.Deep dive into data quality issues and suggest corrective solutions.Use your knowledge to architect data warehousing and BI solutions that solve problems that cut across Amazon business functionsInterface with business customers, gathering requirements and delivering complete Data Engineering, Data Warehousing, and BI solutions.Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using PostgreSQL (Redshift), Spark (EMR), programming languages (e.g. Java/Python) and/or a scripting language (Perl, Unix shell) to process data for modelingCollaborate closely with the product owner: participating in customer utilization research projects to better understand how your customers are using your product.Recognize, adopt and spread best practices in development: data integrity, test design, analysis, validation, and documentation.
Tech Specific responsibilities:
Increase productivity of the tech team.Influence and challenge team during design discussions to come up with scalable and economical solutions using AWS technologies.Build platforms capable of storing and processing very large data volumes with high data quality standardsLead the team and optimize writing of scripts and SQL code to deep dive data quality problems on a regular basis.Design and develop web end-user interface for reporting and analytical tools with emphasis on customer experience.Constantly grow your knowledge of AWS technologies

Master’s or higher degree in an analytical area such as Computer Science, Physics, Mathematics, Statistics, Engineering.Experience using cloud storage and computing technologies such as AWS, Azure, or GoogleCloudFamiliarity and comfort with statistics and use of statistical applications such as R."
44,Senior Big Data Engineer (Data Platform),"Seattle, WA 98101",Seattle,WA,98101,None Found,"
BS or advanced degree in Computer Science/Engineering, information systems or related technical field.
Prior experience supporting platforms built using open source technologies like Jupyter, Hadoop, Hive, Presto, Spark etc.
Big Data tech - Hadoop, Hive, Presto, Yarn, HDFS, Spark, Tez etc. Significant experience with other ETL tech (Informatica, SSIS, etc) is very valuable, but expect to work in a ""Big Data"" environment. Experience in Hadoop cluster admin is preferred.
Python for scripting and automation and basic SQL experience is required.
Prior experience in either AWS or Azure or Cloudera technologies, and any MPP/Cloud data warehouse solutions.
Solid understanding of JRE (Java Runtime Environment) and JVM langauges (Java, Scala)
You have the desire and aptitude to learn how the pieces of big data platform work together
Curious, Determined, Talented and Inspired to solve user issues.
Sharp communicator who can explain complex data problems in clear and concise language.
Love freedom and hate being micromanaged. Given context, you're capable of self-direction. And be comfortable outside of your comfort zone.
",None Found,None Found,None Found,None Found,"Coupang is one of the largest and fastest growing e-commerce platforms on the planet. We are on a mission to revolutionize everyday lives for our customers, employees and partners. We solve problems no one has solved before to create a world where people ask, ""How did we ever live without Coupang?"" Coupang is a global company with offices in Beijing, Los Angeles, Seattle, Seoul, Shanghai, and Silicon Valley.

Job Overview:
As a Big Data Engineer of our data platform team, you will design, develop, test and implement the data infrastructure that supports company-wide Big Data Processing teams. This role will involve working closely with the bigdata user community across the company including Data Scientists, Engineers & Analysts who use our bigdata platform to do interesting and impactful analysis. You will have significant responsibility and influence in shaping the future of big data platform engineering at Coupang.

Qualifications:

BS or advanced degree in Computer Science/Engineering, information systems or related technical field.
Prior experience supporting platforms built using open source technologies like Jupyter, Hadoop, Hive, Presto, Spark etc.
Big Data tech - Hadoop, Hive, Presto, Yarn, HDFS, Spark, Tez etc. Significant experience with other ETL tech (Informatica, SSIS, etc) is very valuable, but expect to work in a ""Big Data"" environment. Experience in Hadoop cluster admin is preferred.
Python for scripting and automation and basic SQL experience is required.
Prior experience in either AWS or Azure or Cloudera technologies, and any MPP/Cloud data warehouse solutions.
Solid understanding of JRE (Java Runtime Environment) and JVM langauges (Java, Scala)
You have the desire and aptitude to learn how the pieces of big data platform work together
Curious, Determined, Talented and Inspired to solve user issues.
Sharp communicator who can explain complex data problems in clear and concise language.
Love freedom and hate being micromanaged. Given context, you're capable of self-direction. And be comfortable outside of your comfort zone.

"
45,Data Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"We are looking for a Data Engineer (BIE) with strong analytical, communication and project management skills to join our team. Working closely with business stakeholders and senior leadership, you will help identify and solve complex language and currency problems and develop metrics and reports to measure our impact on our business. In a typical day, you will work closely with the product management team, retail teams, machine-learning scientists, statisticians, software engineers, and various business groups.

About you:
You're looking for a career where you'll be able to build, to deliver, and to impress. You look at problems holistically and thrive on the intricate complexity of designing feedback loops and ecosystems. You want to work on projects where you are implementing solutions to real problems that require creative solutions and deep understanding of the problem space.

You challenge yourself and others to constantly come up with better solutions. This highly visible role requires frequent communication with senior leadership in order to help shape and deliver on the product roadmap and requires you to nimbly switch between strategic and tactical initiatives to achieve technical, business, and customer experience goals. You'll be given the unique opportunity to own and drive initiatives across the Our Retail as a whole - from algorithmic innovation, all the way down to the datasets that the back-end services consume.

About us together:
We're going to change the way that Our thinks about supporting our global customer. Along the way, we're going to face seemingly impossible problems. We're going to argue about how to solve them, and we'll work together to find a solution that is superior to each of the proposals we came in with. We'll make tough decisions, but we'll all understand why. We'll be the dream team.

The ideal candidate for this space will be highly quantitative, have great judgment, strong data mining and modeling skills and is comfortable facilitating ideation and working from concept through to execution. You will have demonstrated an ability to manage and develop medium to large-scale data tables, identify requirements and build financial reporting and planning models and tools that are statistically grounded but also explainable operationally, apply technical skills allowing the models to adapt to changing attributes, optimize forecast accuracy and to better understand and mitigate model variance drivers. In addition to building data tables, modeling and technical skills, you will possess strong written and verbal communication skills, strong focus on internal customers and professional demeanor and high intellectual curiosity with ability to learn new concepts and frameworks, algorithms and technology rapidly as changes arise.

Some problem spaces we'll be working on:

DATAMART - as we release new languages across marketplaces, our business teams will want to understand customer trends and interactions with these new marketplaces. Ideally, we want to enable our business teams to report on the various languages within a marketplace as if those languages were individual businesses. As such, we need to create a DataMart that enables all business metrics to be split by language and also enables business users to execute ad hoc queries to answer questions that we have not currently considered. As we create the DataMart, we will have to consider the scale of data that we will be handling (at the scale of our global retail business) and employ Bigdata techniques to aggregate and manipulate this data. We will need to design the platform to be robust and to seamlessly recover from disaster, should the need arise. Consistency and validation will be primary concerns as we understand that systems fail, specifically systems upon which we rely for signal and we need to protect our business teams from making decisions based upon incomplete information.

CUSTOMER EXPERIENCE - as arbiters of the customer experience, we need to understand our customers' experience in their languages of preference. Similarly, given the scope of this initiative, it is clear that we will not be able to translate all content in a single release. As a result, it is critical that we can truly measure the customer experience as a function of our translations (both coverage and quality) throughout their journey within the Our marketplace. This is further complicated by the fact that our customers receive a unique experience based upon their browse history, so our method of measurement must be considerate of and support such a dynamic experience. Furthermore, in real time and with zero latency, we want to understand when the experience is broken so that we can take appropriate actions. This is going to be a challenge that may make use of the latest Bigdata streaming technologies to provide a real-time data and measurement pipeline.

Questions?
You may already know if you're a fit, but perhaps you're worried about technology and experience requirements? Don't be - we're looking for smart, proven, engineers; if you're the right candidate, we're flexible.

BASIC QUALIFICATIONSBS or MS in a quantitative field such as Mathematics, Statistics, Physics, Engineering, Computer Science or EconomicsIndustry experience as a Data Engineer or related specialty (e.g. Software Engineer or Data Scientist) with extensive professional experience and a proven track record in a role focused on understanding, manipulating, processing and extracting value from large datasets.Experience processing, filtering, and presenting large quantities (Trillions of rows) of dataAble to write optimize SQL scripts and build scalable data pipelinesExcellent communication skills and the ability to work well in a team.Effective analytical, troubleshooting and problem-solving skills.
PREFERRED QUALIFICATIONSExperience in Statistical Software such as R, SAS, SPSS, MINITABAble to write SQL scripts for analysis and reporting (Redshift, SQL, MySQL)Experience using one or more or: Python, VBA, MATLAB, Java, C++"
46,Senior Data Engineer,"Seattle, WA 98168",Seattle,WA,98168,None Found,None Found,None Found,None Found,None Found,None Found,"As a Senior Data Engineer at Compass, you will be responsible for helping to build the data-driven decision-making culture throughout the organization. You'll work as part of a rapidly growing team in a fast-paced environment. You will be responsible for designing and managing large-scale, real-time analytical systems that impact multiple functions and teams across the organization. In this high impact role you will have an opportunity to work with emerging technologies, while driving analytical solutions end-to-end. You will empower the development of data-powered product features, real-time analytics and artificial intelligence. You are someone who loves data and analytics, strives to constantly learn new and fast-developing data technologies, and demonstrate passion about shipping high-quality software.

At Compass You Will:

Design, develop, and implement the infrastructure that elevates data-driven decision-making and machine learning for our proprietary real estate technology
Work with the enterprise business systems that facilitate end to end experience of real estate transactions

This position is responsible for:

Design and deliver flexible and scalable data solutions collecting process-level external and internal data and transforming it into enterprise wide data lake, denormalized data marts from which operational and process metrics and analytics can be reliably generated

What We're Looking For:

Bachelor's degree in Computer Science, Information Systems, a related field, or equivalent experience.
Extensive experience with a major cloud provider, for instance, AWS
4+ years of experience building data infrastructure using a state-of-the-art tool chain, including utilities such as Kafka, Airflow, Spark, Cassandra, etc.
4+ years of Data Warehousing experience, building ETL data pipes for populating dimensional marts
Familiarity with API design patterns (oAuth, tokens, JSON)
Familiarity with data encoding libraries, such as Avro, Protobuf, or Thrift
Experience with supporting Data Science and ML teams; experience supporting notebook environments for analytics/data science teams (Jupyter, Zeppelin, DataBricks)
5+ years of data intensive programming in your language of choice. Python, Scala, Clojure preferred.
Good understanding of relational databases and SQL
Familiarity with dimensional data modeling
Experience with version control, scalable code deployment (Git, Jenkins)
Highly productive developing and deploying in a Linux environment
Strong business communication skills
Strong drive to constantly learn and keep up to speed with the new data technologies

At Compass, our mission is to help everyone find their place in the world. This means we continually celebrate the diverse community different individuals cultivate. As an equal opportunity employer, we stay true to our mission by ensuring that our place can be anyone's place."
47,Big Data Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,"
Required minimum Bachelor’s degree in Computer Science","Job Description:

Ensure high throughput of development teams by identifying potential issues, removing impediments or guiding the team to remove impediments by collaborating with the appropriate resource
Manage sprint planning and execution which includes the management of project progress and provide status and visibility
Facilitate release planning and scheduling by providing empirical Scrum team statistics, identifying project dependencies, and creating velocity forecasts
Assist with internal and external communications to improve transparency and radiate information ensuring the team’s progress and successes are highly visible to all stakeholders including the team itself (e.g. backlogs, burn down/up charts, etc.)
Develop pipelines using copy activity from different sources like FTP, Windows Blob Storage, SQL SERVER, COSMOS big data etc. and scheduling the pipelines as per requirement using azure data factory.
Requirements:

Required minimum Bachelor’s degree in Computer Science"
48,Senior Data Engineer - Advertising Analytics Data Pipeline,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelor's degree in computer science, engineering, mathematics, or a related technical discipline5+ years of industry experience in software development, data engineering, business intelligence, data science, or related field with a track record of manipulating, processing, and extracting value from large datasetsDemonstrated strength in data modeling, ETL development, and data warehousingExperience using big data technologies (Hadoop, Hive, Hbase, Spark, EMR, Presto, etc.)Knowledge of data management fundamentals and data storage principlesKnowledge of distributed systems as it pertains to data storage and computingProficiency in, at least, one modern scripting or programming language such as Python, NodeJS, Java, or Scala.

Are you passionate about using Big Data to build customer trust and grow new business? Global advertisers rely on our team's performance insights to drive future investment in Amazon's Advertising Platform and improve the relevance of ads shown to customers. We are looking for passionate Data Engineers to own and optimize the big data pipeline that consumes the massive data sources we require to generate unique insights. Data is at the center of every product we will develop as we create brand new systems that serve the needs of our large and growing base of advertisers.

You will share in the ownership of the technical vision and direction for advanced analytics and insight products. You will be a part of a team of top notch technical professionals developing complex systems at scale and with a focus on sustained operational excellence. Members of this team will be challenged to innovate using big data technologies. We are looking for people who are motivated by thinking big, moving fast, and changing the way customers use data to drive profitability. If you love to implement solutions to hard problems while working hard, having fun, and making history, this may be the opportunity for you!
Amazon is well positioned to grow its share of a fast growing online advertising industry due to its unique assets - e-commerce data, service oriented architecture, and startup culture. Be part of a team of industry leading experts that builds and operates one of the largest big data analytics platform at Amazon. Amazon is applying the latest machine learning and big data technologies available to change the way marketers purchase, track, measure, and optimize their advertising spend. We apply these technologies on terabytes of data (over 10B new events per day) and operate clusters that push scalability limits of the existing technologies. We seek to measure every possible signal indicating impact of advertising to provide the most objective result of marketing spends.

Experience working with and tuning AWS big data technologies (EMR, Redshift, S3)Proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategyExperience providing technical leadership and mentoring other engineers for best practices on data engineeringKnowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations
Amazon.com is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age

#adsto #madsjob"
49,Cloud Solutions Architect,"Seattle, WA",Seattle,WA,None Found,None Found,"
Expertise in at least one of the following domain areas:
Infrastructure Modernization: migrating n-tiered workloads from on-prem and other clouds to GCP with near-zero-downtime (includes the full spectrum of lift and shift to complete re-platforming scenarios), or building hybrid-cloud solutions based on Anthos and containerization technologies, such as Docker, Kubernetes, and Istio.
Application Development: building custom web and mobile applications on top of the GCP stack.
Data Engineering: data warehouse modernization (including technical architectures, star/snowflake schema designs, infrastructure components, ETL/ELT pipelines and reporting/analytic tools), OLTP/OLAP data migrations, or backup, restore and disaster recovery solutions.
Excellent written and verbal communication skills with the ability to interface with and communicate complex technical concepts to a broad range of stakeholders.
Hands-on experience with cloud computing, traditional on-premises and enterprise data-center technologies.
Experience working with engineering and sales teams.
Experience producing technical assets or writing technical documentation, including, but not limited to, architecture designs and documentation, statements of work, project plans, and working code samples.
Time management with the ability to manage multiple streams.
",None Found,None Found,None Found,None Found,"Join SADA as a Cloud Solutions Architect!

Your Mission

As a Cloud Solutions Architect at SADA, you will work collaboratively with other architects and engineers to design, prototype and lead the deployment of scalable Google Cloud Platform (GCP) architectures. You will work with engineering teams, customers and sales teams to qualify potential engagements, craft robust architectural proposals, and deliver Statements of Work (SOWs) that engineering teams can successfully execute. You’re also hands-on, able to conduct experiments and build functioning prototypes that prove out ideas and build confidence in the solutions you advocate.

You will be an established contributor within SADA and will develop a reputation with customers as well as the Google Cloud sales and professional services organizations for the quality of your work. You will demonstrate repeated delivery of project architectures successfully. You will also lead early-stage opportunity technical qualification calls, as well as lead client-facing technical discussions.

Pathway to Success

#BeAChangeAgent: You are a rainmaker! You are way out in front of our delivery organization, meeting with the spectrum of corporate and enterprise customers that need our consultative services. You have your finger on the pulse of their technical needs and take pride in helping them solve their real-world problems on GCP.

You will be measured quarterly by a combination of (a) the volume of signed SOWs that you shepherd through the sales funnel, and (b) the level of customer satisfaction measured at the end of each engagement.

As you continue to execute successfully, we will build a customized development plan together that leads you through the solutions architecture or management growth tracks.

Expectations

Required Travel - 30% travel to customer sites, conferences, and other related events.
Customer Facing - This is very customer-facing role. You will usually interact with customers on a daily basis. You will participate on calls and onsite customer meetings to qualify consultative engagements with the engineering teams. You will present architecture proposals and code samples to build trust, confidence, and consensus both externally and internally.
Training - Ongoing with a first-week orientation at HQ followed by a 90-day onboarding schedule. Details of the timeline can be shared.

Job Requirements

Required Credentials:

Google Professional Cloud Architect Certified

[https://cloud.google.com/certification/cloud-architect] and/or Google
Professional Data Engineer Certified
[https://cloud.google.com/certification/data-engineer], or able to complete one of the above within the first 45 days of employment.

Required Qualifications:

Expertise in at least one of the following domain areas:
Infrastructure Modernization: migrating n-tiered workloads from on-prem and other clouds to GCP with near-zero-downtime (includes the full spectrum of lift and shift to complete re-platforming scenarios), or building hybrid-cloud solutions based on Anthos and containerization technologies, such as Docker, Kubernetes, and Istio.
Application Development: building custom web and mobile applications on top of the GCP stack.
Data Engineering: data warehouse modernization (including technical architectures, star/snowflake schema designs, infrastructure components, ETL/ELT pipelines and reporting/analytic tools), OLTP/OLAP data migrations, or backup, restore and disaster recovery solutions.
Excellent written and verbal communication skills with the ability to interface with and communicate complex technical concepts to a broad range of stakeholders.
Hands-on experience with cloud computing, traditional on-premises and enterprise data-center technologies.
Experience working with engineering and sales teams.
Experience producing technical assets or writing technical documentation, including, but not limited to, architecture designs and documentation, statements of work, project plans, and working code samples.
Time management with the ability to manage multiple streams.

Useful Qualifications:

Direct experience working with a variety of cloud technologies as well as designing and recommending elegant solutions that drive business outcomes.
Understanding of infrastructure automation, continuous integration/deployment, relational/NoSQL data stores, security, networking, and cloud-based delivery models.
Ability to lead an in-depth client meeting/workshop across a broad range of topics including discovery, cloud compliance and security.
Thought leadership with the ability to recommend cloud-native approaches to solve customer business and technical challenges.
Understanding of best practices, design patterns and reference architectures with an uncanny ability to recommend these as needed.

About SADA

Values: We built our core values
[https://sadasystems.com/about/company-overview/] on themes that internally compel us to deliver our best to our partners, our customers and to each other. Ensuring a diverse and inclusive workplace where we learn from each other is core to SADA’s values. We welcome people of different backgrounds, experiences, abilities and perspectives. We are an equal opportunity employer.

1. Make them rave
2. Be data driven
3. Be one step ahead
4. Be a change agent
5. Do the right thing

Work with the best : SADA has been the largest partner in North America for GCP since 2016 and recently announced, at Google NEXT, as the
2018 Global Partner of the Year
[https://sadasystems.com/blog/google-cloud/gcp/sada-wins-2018-google-cloud-partner-award/]. SADA has also been awarded
Best Place to Work
[https://sadasystems.com/blog/news/sada-systems-best-places-work-2019/] by Inc. as well as LA Business Journal!

Benefits : Unlimited PTO
[https://sadasystems.com/blog/news/blogannouncementsblogannouncementsunlimited-pto-yes-unlimited-why-sada-is-the-best-place-to-work/], competitive and attractive compensation, performance-based bonuses, paid holidays, rich medical, dental, vision plans, life, short and long-term disability insurance, 401K with match,
professional development reimbursement program
[https://sadasystems.com/blog/news/blogannouncementsprofessional-development-how-we-do-it-why-it-matters/] as well as Google Certified training programs.

Business Performance: SADA has been named to the INC 5000 Fastest-Growing Private Companies list for 12 years in a row garnering Honoree status. CRN has also named SADA on the Top 500 Global Solutions Providers for the past 5 years. The overall culture continues to evolve with engineering at its core: 3200+ projects completed, 3000+ customers served, 10K+ workloads and 25M+ users migrated to the cloud."
50,Senior Big Data Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"The world's largest and fastest-growing companies such as Accenture, Adobe, DocuSign and Salesforce rely on Demandbase to drive their Account-Based Marketing strategy and maximize their B2B marketing performance. We pioneered the ABM category nearly a decade ago, and today we lead the category as an indispensable part of the B2B MarTech stack. Our achievements and innovation would not be possible without the driven and collaborative teams here at Demandbase. As a company, we're as committed to growing careers as we are to building word-class technology. We invest heavily in people, our culture and the community around us, and have continuously been recognized as one of the best places to work in the Bay Area.

We are a group of talented individuals with deep expertise in the domain area of business applications and building large complex systems with simple user interfaces. We also have deep expertise in big data technology such as IR, NLP, and large graphs and utilize the best technology to provide innovative and novel products to frustrated end-users in the enterprise.

As a Senior Big Data Engineer, you will be responsible for building out all aspects relating to the Demandbase Data ecosystem and moving products from R&D into production scale. A successful Senior Data Engineer will possess a natural curiosity about data, strong work ethic, and clear technical leadership ability. Understanding of the ad ecosystem and the large scale data problems that come with it are going to be the root of your every day work.

You will be both hands-on and strategic—with both a broad ecosystem-level understanding of our market space and the ability to work closely with engineering, data science and product teams to deliver software in an iterative, continual-release environment. This is a high-visibility position involving close collaboration across many functional groups as well as interaction with executive stakeholders.

What you'll be doing...


Work with internal stakeholders to design and develop components in the next generation of Demandbase's core Data Products
Integration and conflation of multiple 1st and 3rd party data sources to build a key component in the core of our data platform
Write clear documentation to convey plans and technical architecture
Ensure all new and modified code and pipelines are tested and of the highest quality at delivery time
Build out new pipelines as part of an ever-evolving set of requirements for the core data asset as our business needs grow
Ensure high reliability of all maintained product offerings by building reporting and monitoring mechanisms into our infrastructure.

What we're looking for...


BS or Masters in Computer Science and 3+ years of working experience
Worked in a start-up (less than 150 employees) within the past 4 years is a strong plus
Proven experience with Hadoop or Spark or other large-scale data processing platforms
Proven experience processing and aggregating over billions to trillions of rows
Strong software design and development experience, preferably in Scala or Java or other compiled languages
Strong experience with Apache Parquet, Avro, or similar technologies
Deep desire for data is a must; this position lives in data
Understanding of cookies, mobile web traffic, and user behavior is a strong plus
Understanding of cloud infrastructure (preferably AWS) is a strong plus
Proven ability to solve problems using state of the art technology
Proven ability to innovate when necessary, but not reinvent the wheel
Ability to define standards and best practices for teams
Able to handle ambiguous delivery goals and turn them into concrete output
Ability to suggest technical direction when necessary to solve problems
Hands on and not afraid to wear multiple hats
Passion for career growth

About Demandbase

Demandbase is the leader in Account-Based Marketing (ABM) and an indispensable part of the B2B tech stack. The company offers the only end-to-end ABM platform that helps B2B marketers identify, engage, close and measure progress against best-fit accounts. The biggest and fastest growing companies in the world, such as Accenture, Adobe, DocuSign, GE, Salesforce and others rely on Demandbase to drive their ABM strategy and maximize their marketing performance. The company has been named to the JMP Securities list ""The Hot 100: The Best Privately Held Software Companies,"" the Deloitte Fast 500 and named a Gartner Cool Vendor for Tech Go-To Market. In 2019, Demandbase executives authored the definitive book on ABM, Account-Based Marketing: How to Target and Engage the Companies That Will Grow Your Revenue ( https://www.demandbase.com/account-based-marketing-best-practices-book/ ). For more information, please visit www.demandbase.com ( http://www.demandbase.com/ ) or follow the company on Twitter @Demandbase ( https://www.twitter.com/demandbase ).

Benefits:
Our benefits include 100% paid for Medical, Dental and Vision for you and your entire family, 100% paid for short-term and long-term disability, 100% paid for life insurance, 401k, flexible vacation policy, commuter benefits, free snacks, catered lunch every Friday, and much more!"
51,SAP Concur - Data Engineer,"Bellevue, WA 98004",Bellevue,WA,98004,None Found,None Found,None Found,None Found,None Found,"
4+ years of experience in design, develop, and maintain ETL solutions that support building SAP Concur’s AWS Enterprise Data Warehouse environment (EDW) in the cloud.
Experience with AWS code (glue, EMR, python, pyspark and redshift) to support dimensions and data warehouse tables
Knowledge of scripting languages (Python, Java, Shell, Unix, etc)
Experience with troubleshooting and maintaining ETL jobs for production and non-production support needs
Experience with performance tune ETL processing to meet business requirements and performance expectations
Demonstrated strength in data modeling, ETL development, and data warehousing
Proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategy
Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations
Excellent verbal/written communication & data presentation skills, including experience communicating to both business and technical teams
Ability to work effectively with both technical and non-technical staff
Knowledge of data management fundamentals and data storage principles
Knowledge of distributed systems as it pertains to data storage and computing
Must be comfortable with ambiguity and fast change with an ability to adapt quickly and easily. Ability to analyze complex problems and move them to resolution.
Be aware of, and comply with, all corporate policies.","Requisition ID: 230562
Work Area: Software-Design and Development
Expected Travel: 0 - 10%
Career Status: Professional
Employment Type: Regular Full Time

COMPANY DESCRIPTION
SAP started in 1972 as a team of five colleagues with a desire to do something new. Together, they changed enterprise software and reinvented how business was done. Today, as a market leader in enterprise application software, we remain true to our roots. That’s why we engineer solutions to fuel innovation, foster equality and spread opportunity for our employees and customers across borders and cultures.
SAP values the entrepreneurial spirit, fostering creativity and building lasting relationships with our employees. We know that a diverse and inclusive workforce keeps us competitive and provides opportunities for all. We believe that together we can transform industries, grow economics, lift up societies and sustain our environment. Because it’s the best-run businesses that make the world run better and improve people’s lives.
We are looking for a talented Data Engineer to help build/enhance the next generation enterprise data warehouse to support internal reporting and analytics. You will own many large datasets, implement new data pipelines that feed into or from critical data systems at SAP Concur, come help us utilize years of Travel and Expense data to build a data ecosystem that powers product analytics.

In the first 12 months you will:

Integrate internal product data and other general portfolios into the SAP Concur BI AWS data lake and build models using AWS tools.
Dig into SAP Concur’s data, to perform data discovery and source analysis to assess the quality and structure for various data sources.
Build BI solutions to support the SAP Concur AWS Enterprise Data Warehouse (EDW), and deliver through an agile BI Sprint process.
Contribute to the data management initiatives to ensure data integrity, quality, and common definitions.
Build cloud analytic solutions that are secure and compliant with best practices in data security and privacy
Support management reporting efforts from a data perspective to drive key business decisions.

Position Requirements:

4+ years of experience in design, develop, and maintain ETL solutions that support building SAP Concur’s AWS Enterprise Data Warehouse environment (EDW) in the cloud.
Experience with AWS code (glue, EMR, python, pyspark and redshift) to support dimensions and data warehouse tables
Knowledge of scripting languages (Python, Java, Shell, Unix, etc)
Experience with troubleshooting and maintaining ETL jobs for production and non-production support needs
Experience with performance tune ETL processing to meet business requirements and performance expectations
Demonstrated strength in data modeling, ETL development, and data warehousing
Proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategy
Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations
Excellent verbal/written communication & data presentation skills, including experience communicating to both business and technical teams
Ability to work effectively with both technical and non-technical staff
Knowledge of data management fundamentals and data storage principles
Knowledge of distributed systems as it pertains to data storage and computing
Must be comfortable with ambiguity and fast change with an ability to adapt quickly and easily. Ability to analyze complex problems and move them to resolution.
Be aware of, and comply with, all corporate policies.

Value Competencies:
Displays passion for & responsibility to the customerDisplays leadership through innovation in everything you doDisplays a passion for what you do and a drive to improveDisplays a relentless commitment to winDisplays personal & corporate integrity

WHAT YOU GET FROM US
Success is what you make it. At SAP, we help you make it your own.
A career at SAP can open many doors for you. If you’re searching for a company that’s dedicated to your ideas and individual growth, recognizes you for your unique contributions, fills you with a strong sense of purpose, and provides a fun, flexible and inclusive work environment – apply now.
SAP'S DIVERSITY COMMITMENT
To harness the power of innovation, SAP invests in the development of its diverse employees. We aspire to leverage the qualities and appreciate the unique competencies that each person brings to the company.
SAP is committed to the principles of Equal Employment Opportunity and to providing reasonable accommodations to applicants with physical and/or mental disabilities. If you are interested in applying for employment with SAP and are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to Recruiting Operations Team. (Americas:Careers.NorthAmerica@sap.com or Careers.LatinAmerica@sap.com, APJ: Careers.APJ@sap.com, EMEA: Careers@sap.com). Requests for reasonable accommodation will be considered on a case-by-case basis. Successful candidates might be required to undergo a background verification with an external vendor.
EOE AA M/F/Vet/Disability:
Qualified applicants will receive consideration for employment without regard to their age, race, religion, national origin, gender, sexual orientation, gender identity, protected veteran status or disability.
Successful candidates might be required to undergo a background verification with an external vendor.
Additional Locations:"
52,Data Engineer,"Seattle, WA 98104",Seattle,WA,98104,None Found,"3+ years of industry experience
Experience with high scale, distributed, 24x7 systems and applications
5+ years of experience with SQL in both transactional and analytical applications
Experience with Linux platforms
Experience with AWS data technologies
Experience with Ruby, Python, or a similar programming language
Strong analytical and design skills
Capacity for learning quickly in a fast paced environment and handling multiple tasks simultaneously
Strong written and oral communication skills
","3+ years of industry experience
Experience with high scale, distributed, 24x7 systems and applications
5+ years of experience with SQL in both transactional and analytical applications
Experience with Linux platforms
Experience with AWS data technologies
Experience with Ruby, Python, or a similar programming language
Strong analytical and design skills
Capacity for learning quickly in a fast paced environment and handling multiple tasks simultaneously
Strong written and oral communication skills
","Define the architecture, technologies, and processes used to create a high scale data processing pipeline
Work with engineers to create the tools and infrastructure used to collect, transform, and store data to be used for analytics
Identify and implement analytics tools used by internal stakeholders to engage with data
Ensure proper security and access control to analytics data
Work collaboratively with the team to deploy, support and operate your services and applications.
",BS/MS in Computer Science or Engineering,None Found,"doxo is disrupting bill pay. We are founded on the idea to create a simple, secure way to pay all your bills from a single account. We’re a rapidly growing startup looking for a high lead energy Data Engineer with experience building scalable data collection, storage, and analysis systems.

Major Responsibilities
Define the architecture, technologies, and processes used to create a high scale data processing pipeline
Work with engineers to create the tools and infrastructure used to collect, transform, and store data to be used for analytics
Identify and implement analytics tools used by internal stakeholders to engage with data
Ensure proper security and access control to analytics data
Work collaboratively with the team to deploy, support and operate your services and applications.
Skills and Qualifications
3+ years of industry experience
Experience with high scale, distributed, 24x7 systems and applications
5+ years of experience with SQL in both transactional and analytical applications
Experience with Linux platforms
Experience with AWS data technologies
Experience with Ruby, Python, or a similar programming language
Strong analytical and design skills
Capacity for learning quickly in a fast paced environment and handling multiple tasks simultaneously
Strong written and oral communication skills
Education
BS/MS in Computer Science or Engineering"
53,"Data Engineer, Amazon Devices","Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelor’s degree in an engineering or technical field such as Computer Science, Physics, Mathematics, Statistics, Engineering or similar.5+ years of experience with data warehouse technical architectures, ETL/ ELT, reporting/analytic tools and, scripting.5+ years of demonstrated quantitative and qualitative data experience with data modeling, ETL developmentKnowledge of data modeling and experience SQL with Redshift, Oracle, MySQL, and Columnar DatabasesExperience managing competing priorities simultaneously and driving projects to completion

The Amazon Devices team designs and engineers high-profile consumer electronics, including the best-selling Kindle family of products. We have also produced groundbreaking devices like Fire tablets, Fire TV, Amazon Dash, and Amazon Echo.

What will you help us create?

The Team: How often have you had an opportunity to be a founding member of a team that is solving a significant problem through innovative technology? Would you like to know more about how we are envisioning the use of data analytics, machine learning, AI and linear programming to solve these problems? If this sounds intriguing, then we’d like to talk to you about a role on a new Amazon team that's tackling a set of problems requiring significant innovation and scaling.

We are seeking a Data Engineer with strong analytical, communication and project management skills to join our team. This role will be a key member of a Science and Data technology team based in Seattle, WA. Working closely with business stakeholders, software development engineers and scientist colleagues, you will design, evangelize, and implement state-of-the-art solutions for never-before-solved problems, helping Amazon Device to provide customer great products and keep the data secure. You will work with the most complicated data environment, employ right architecture to handle big data and support various analytics use cases, including business reporting, production data pipeline, machine learning, optimization models, statistical models, simulation, etc. Your work will have a direct impact on the day-to-day decision making in the Amazon Devices Sales & Operations Technology, and end customers.

You are an individual with outstanding analytical abilities, excellent communication skills, good business understanding, and technically savvy. The successful candidate will be an analytical problem solver who enjoys diving into data, is excited about solving ambiguity problems, can multi-task, and can credibly interface between technical teams and business stakeholders.

Desire to create and maintain data warehouse systemsExperience with big data technologiesMaster's degree in an engineering or technical field such as Computer Science, Physics, Mathematics, Statistics, or EngineeringExperience with AWS services including S3, Lambda, EMR, RDS, Data-pipeline and other big data technologiesExperience with scripting (Python experience is a strong plus).Proficient in the composition of Advanced SQL (analytical functions) and query performance tuning skillsAbility to interact, communicate, present and influence with both business and technical teamsA self-starter who loves data and who enjoys spotting the trends in it!
Amazon is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age

#d2ctech tag"
54,"Staff Software Engineer - Data Storage, ETL and Analytics","Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,"
4 or more years of professional software engineering experience.
Knowledge and experience with the Hadoop ecosystem: Hadoop, HBase, Spark
Knowledge and experience with Java
Experience in developing high performance and scalable systems","Gigamon is an enterprise network security company focused on building capabilities that empower our customers to detect and track adversaries in real-time.
Our mission is to use the power of information to detect, track and dismantle hackers' means of attacking our customers.
Our team has seen all sides of the equation, as attackers and defenders, in addition to the complex engineering required to solve these problems at scale.
Our software helps security professionals get an unparalleled view into their networks, perform forensics on security incidents and build effective early warning systems.
We are looking for Data Engineer to help us solve complex search and pattern matching problems at petabyte scale. Our data collection needs to operate in near real-time, our data stores need to scale linearly with our datasets, our search needs to perform sub-second matches, our classifiers and behavior analytics need to operate over streaming data sets, and our pattern matching needs to support a variety of operators, window functions, and custom intersection semantics. We work with a number of data storage and processing systems, including MySQL, Postgres, Hadoop, HBase/Phoenix, Spark, Elasticsearch, a variety of AWS data services as well as some proprietary systems.

If you are passionate about building robust, high-scale system, working with large data sets and protecting public and private organizations from today's ever increasing cyber threats, then Gigamon might be the place for you.
Core Job Role
Design, build, test and deploy scalable systems to store, process and retrieve high-rate event streams.
Build systems and processes for ETL, enrichment, alerting, and indexing high-rate event streams.
Support the Operations team in capacity planning and performance tuning for large scale systems.
Implement processes for applying data-analysis algorithms to event-streams.
About us
Flexible work and vacation schedule
Competitive pay and benefits
We put great emphasis building well tested and stable solutions
Job Requirements
4 or more years of professional software engineering experience.
Knowledge and experience with the Hadoop ecosystem: Hadoop, HBase, Spark
Knowledge and experience with Java
Experience in developing high performance and scalable systems

Employment at Gigamon is contingent on meeting eligibility requirements which may include additional security screening on being able to obtain a government sponsored security clearance"
55,Sr. Business Intelligence Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelor’s degree in math, statistics, computer science, or finance or equivalent experience.5+ years of experience as a Data Engineer, BI Engineer, Business/Financial Analyst or Systems AnalystSQL writing experience and experience with ETLRedshift experience

Come help us shape the future of the best voice controlled computer in the cloud. Alexa and Echo are shaping the future of voice recognition and cloud-based content/services. Alexa is the name of the Amazon cloud-based voice service and the brain that powers Echo, the award-winning and groundbreaking Amazon device designed around your voice. Echo connects to Alexa, to provide information, answer questions, play music, read the news, check sports scores or the weather, and more—instantly. It's hands-free, and always ready. All you have to do is ask.

To achieve this, we blend of a variety of disciplines (such as NLP, data mining, machine learning, big data, semantic web, graph stores, cloud computing) in an effort to understand our customers and the things they're excited about. To complement our complex algorithms and extensive data analyses, we create elevated and inspirational mobile and web features across the entire communication experience. We use artificial intelligence, data mining and usability studies to develop new features, and we test them through hundreds of R & D experiments a year. We are also incredibly intent on solving some of the most complex computing problems to be found in industry and academia, and we get to test our solutions in the real world every day. And most importantly, we relentlessly ask: ""What haven't we thought of yet?""

The business intelligence engineer will work closely with data scientists, software engineers, and product managers to build out infrastructure, data pipelines and reporting. The outputs of your work will inform key stakeholders and decision-makers. In this role, you’ll design, execute and iterate on high visibility business intelligence for the teams of people that are actively building out Alexa's capabilities. If you love setting up and working with huge data sets and delivering the insights you discover through business intelligence reporting and automated systems, then this is the job for you.

Key Responsibilities
Create and optimize data infrastructureServe as an SME within a focused set of product/tech teamsCollect, analyze and share data to help product teams drive improvement in key business metrics and customer experiencePropose and prioritize changes to reporting and create additional metrics and processes based on program changes and customer requirementsWork closely with Alexa program teams to create ad-hoc reports to support timely business decisions and project workIdentify and implement new capabilities and best practices to develop and improve automated data analysis processesLearn and understand a growing range of Amazon data resources and discover how, and when to use which data sets
This role can work from Seattle or Bellevue.

Expert understanding of best practices to handle extremely large volume of dataAbility to create extensible and scalable data schema that lay the foundation for downstream analysisA clear passion for learning new BI skills and techniques independently and continuouslyAbility to prioritize multiple concurrent projects while still delivering timely and accurate resultsExperience working in a lean, successful start-up or on a new product team where continuous innovation is desired and ambiguity is the normExperience mentoring others in SQL, modeling, forecasting and the use of large datasetsProficiency with scripting languages and Unix systems (Python, perl, bash, etc.)Experience with the following is a plus: Looker, Tableau, MicrostrategyExperience in an internet-based company with large, complex data sources.
Amazon is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation"
56,Technical Sourcer - Amazon Advertising,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelor's degreeMinimum of 3+ years of corporate and/or executive recruiting experienceCTS/ATS experience with sourcing, tracking, and managing candidates.Strong communication skills, organizational and negotiation skills, with a keen focus on delivering business results

Amazon Advertising is seeking an exceptionally talented Sourcing Recruiter to join its ranks. In this role, you will be part of a small, elite recruiting team that supports Advertising tech recruiting efforts outside of SDE roles such as SDM, TPM, applied and data science, data engineer, QAE, technical writer, design tech, and various other technical roles critical to Amazon's business.

You will work with a team of top-flight recruiters, sourcers, and recruiting coordinators, focused on candidate talent search for non-technical, high level talent. Beyond filling positions, you will drive process improvement, strategy and development across our business. You will foster a collaborative team environment and a strong service oriented culture that ensures delivery of efficient, effective, quality driven service to internal customers and meets customer service level agreements.

As a Sourcing Recruiter supporting this team, you must be able to successfully manage, prioritize and close searches against a timeline and have experience setting benchmarks, metrics, and understand how to prioritize hitting all customer SLAs. You thrive in an innovative, fast-paced environment, can roll up your sleeves, work hard, have fun, and get the job done. The best candidates will draw on extensive knowledge of talent acquisition and functional areas of the business, forging dynamic relationships with business leaders, hiring managers and HR business partners. You have a reputation for being exceptional at candidate generation, client/account management, organization, and prioritization.

Please check out our site to learn more about Advertising at Amazon: https://advertising.amazon.com/

Bachelor's degreeMinimum of 5+ years of corporate and/or executive recruiting experienceExperiencing managing and prioritizing multiple strategic searches, projects and client relationshipsExperience building and driving talent sourcing initiativesExperience working with recruiting and people-related tools and systems, including applicant tracking systems, resume databases, internet sourcing tools and complex spreadsheetsStrong client focus and commitment to continuous improvement; ability to proactively network and establish effective working relationships, must pursue conscious cost-containment efforts in recruiting, continually seek new sourcing options, and develop creative approaches to delivering candidates to the customerSelf-sufficiency and an ability to work with little direct supervisionStrong consulting skills and demonstrated ability to work in a team environment, as a team leader and member
Amazon.com is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation / Age."
57,"Data Engineer, Prime Video","Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelor's Degree in Computer Science or a related technical discipline5+ years of experience in the field of data engineeringExpertise in the design, creation and management of very large datasetsExpertise in writing high quality, maintainable, and robust code, often in SQL and PythonExpertise in data modeling - understanding of 3NF, Star schema, etc.Expertise in designing systems and workflows (ETL) for handling Big data volumesExperience working with business owners to convert key business requirements into technical specifications

Prime Video is changing the way people watch movies and TV shows, with hundreds of thousands of titles available to stream and download on all your favorite devices - Amazon FireTV, iOS devices, Roku, game consoles and Fire Tablets. The mission of Prime Video- Product Analytics team is to drive product decisions that improve customer experience by building decision-making analytical products and deep customer insights. We are seeking a competent, curious, resourceful, and experienced Data Engineer to develop a scalable data warehouse architecture and performant data models that powers our analytical ecosystem and day-to-day decision making. The team presents an exciting opportunity to work on very large data sets in one of the world's largest data warehouse environments. Our data warehouse is built on AWS cloud technologies such as Spectrum and Redshift for performing ETL processing of TBs of relational data.

As a data engineer in this team, you will solve big data warehousing problems on a massive scale. You will apply cloud-based AWS services to solve challenging problems around: big data processing, data warehouse design, and enabling self-service. You will focus on automation and optimization for all areas of DW/ETL maintenance and deployment. You will work closely with the business intelligence engineers, product managers and the software development teams on many non-standard and unique business problems and use creative problem solving to deliver actionable output. The role of data engineer in Amazon requires excellent technical skills in order to develop systems and tools to process data as well as, but not limited to, the ability to analyze data. Your work will have a direct impact on the day-to-day decision making in the Prime Video team.

Experience with Amazon RedshiftExperience in scripting languagesExperience handling Big data volumes and performance tuningExposure/Experience in Big data Technologies (hadoop, spark, presto, etc.)Experience working in a UNIX/LINUX environmentStrong analytical and problem solving skillsExcellent verbal and written communication skills
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation."
58,Business Intelligent Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"BA/BS in Computer Science, Engineering, Information Systems, Statistics, Mathematics, Finance or related field3-5 years industry experienceStrong analytical skills including SQL, including the ability to pull data and use data to identify and solve ambiguous problemAdvanced skills in ExcelExperience with data visualization tools such as Tableau, QuickSight, MicroStrategyExperience working with large-scale, complex datasetsDemonstrated strength in data modeling, ETL development, and Data warehousing.

What do the latest AWS technologies, data analytics, delightful customers, and solving interesting business problems have in common? They are all key features of the Business Intelligence Engineer position on the Recruiting Analytics, Innovation, and Research (AIR) team within Amazon’s Advertising and Entertainment organization! As a BIE on the AIR team, you will have significant latitude to build analytics tools and extend your influence throughout the talent acquisition organization. In today’s competitive talent market, striking an optimal balance between precision and volume in the recruiting process is critical to achieving the hiring goals. We must do so while simultaneously increasing efficiency and improving customer satisfaction. The AIR teams owns providing the data analytics, insights, predictive solutions that help recruiting and business leaders make smart decisions about where and how to spend their time. We are a lean team and operate in very close partnership with our customers. To be successful in this role you should be passionate about working with disparate datasets to answer business questions. To be exceptional, you should have a knack for uncovering trends and answering questions that customers aren’t even asking yet. This position represents an exciting opportunity to be a part of a dynamic and high paced environment.

What you’ll do:
Manage Data – Write SQL queries to pull data from disparate databases so it can be analyzed. Research and source new data opportunities. Partner with other BIE’s across Amazon’s HR organization to understand present sources and connect to new sources of data.
Create Reports – Create and manage processes to assure the best way to reflect data in meaningful ways that gets end users to act on it. Present information into core and scalable reports that facilitate decision making for recruiting and business leaders.
Insight Mining – Explore data for insights about the opportunities and bottlenecks in the recruiting process.
Ad Hoc Analysis – Conduct data analysis to support needs of the recruiting leadership team as we seek to increase the volume and quality of hiring for our business teams.
Presentation – Display analysis and insights in front of influential audiences in a way that efficiently and effectively gets them to understand key themes.

Skills:
Analytical – Turns data into business insights. Skilled in identification of trends in data, their degree of statistical significance, and how reliably they can be inferred to broader populations. Educates and shares best practices in the field and brings sound yet innovative techniques
Influence – Using the data to make meaningful improvements in the recruiting process. Interpreting data in a way that make it impacting to the business versus data analysis for its own sake.
Reporting – Informing stakeholders on the best way to visualize data for optimum impact. Offering new ways to display data that had not been considered.
Business acumen – Demonstrates and cultivates an understanding of talent acquisition. Leverages this knowledge to explore for insights in data that prove or disprove long-held beliefs and helps to guide the ability to anticipate future talent needs that have not yet been identified

Master’s degree in Computer Science, Engineering, Information Systems, Statistics, Finance or related fieldAdvanced ability to draw insights from data and clearly communicate them to the stakeholders and senior management as required.Expert in writing and tuning SQL scriptsExperience working in very large data warehouse environmentsExperience in a data engineer or BIE role with a technology companyExperience conducting large scale data analysis to support business decision makingStrong verbal/written communication and data presentation skillsAbility and interest in working in a fast-paced and rapidly-changing environmentExperience with programming tools (Java, Python, Tableau and/or R)
Amazon is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age."
59,Sr. Data Engineer - AWS Demand Planning,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelor's Degree in Computer Science or a related technical field, and 6+ years of relevant experienceExperience in designing and operating large Data WarehousesStrong data modeling/architecture skillsExpert SQL skillsExperience using OLAP technologiesDesign and scripting experience in one of Python, Perl, Shell scriptExperience with Tableau or other visualization software

The AWS Long Range Planning team is hiring a Sr. Data Intelligence Engineer to improve the scalability and customer experience for our customers (AWS service owners) using our team’s products. Our team is responsible for growing the world's largest Cloud at the most optimized rate. The challenge is finding the optimum tradeoff between AWS service availability and fleet utilization, where a 1% improvement to utilization means millions in additional free cash flow. We own the development of methods and tools used by service owners and finance partners to forecast and plan service usage, infrastructure, and revenue. Our systems help business owners evaluate and make decisions about their service forecasts relative to their availability, utilization, revenue, and cost plans and goals. Our forecast and other demand signal outputs are used by downstream infrastructure supply chain and build organizations to drive server, network, and data center investments.
As an Amazon Data Engineer, you will be working in one of the world's largest data warehouse environments. This environment processes billions of time series events each week to build and test statistical models used to generate forecasts for all AWS services. These models and forecasts will be used in Business Intelligence reporting and dashboarding solutions that are consumed by thousands of users worldwide to optimize service availability and infrastructure costs. These data solutions support the growth of the world’s largest Cloud, solving challenging problems on a daily basis.
You should have deep expertise in the design, creation, management, and business use of large datasets. An ideal candidate will have excellent communication skills to be able to work with business owners to develop and define key business questions and to build data sets that answer those questions. You should be able to demonstrate an expertise in designing, implementing, and operating stable, scalable, low cost solutions to flow data from production systems into the data warehouse and into end-user facing applications. You should be able to work with business customers in a fast paced environment understanding the business requirements and implementing reporting solutions.
You will learn how to incorporate tested research results into modern software systems that improve the way AWS operates. You will also gain an understanding of Supply Chain Management for the Cloud and obtain an deep understanding of the internal workings of all AWS services. Your role will leverage AWS technologies such as Lambda, Glue, and Kinesis to craft ETL solutions.

Above all, you should bring your passion for working with huge data sets and bringing datasets together to answer business questions and drive change.
Key Responsibilities:
Work with managers, software developers, and scientists to design and develop data infrastructure to support the growth of AWS.Enable effective decision making by retrieving and aggregating data from multiple sources and compiling it into digestible and actionable forms.Perform deep-dives to find root causes of variances of key forecasting parameters over a given time period.Develop intelligent, insightful self-reporting tools.Optimizing the performance of business-critical queries and dealing with ETL job related issuesTuning application and query performance using Unix profiling tools and SQLIdentifying the data quality issues across the various platforms at Amazon

Master's Degree in Computer Science or a related technical field, and 6+ years of relevant experienceExperience in designing and operating large Data WarehousesExpert data modeling/architecture skillsDesign and scripting experience in one of Python, Perl, Shell scriptCapable of investigating, familiarizing and mastering new data sets quicklyStrong troubleshooting and problem solving skillsAbility to display complex quantitative data in a simple, intuitive format and to present findings in a clear and concise mannerSolid communication skills and team playerStrong organizational and multitasking skills with ability to balance competing prioritiesStrong troubleshooting and problem solving skillsAbility to display complex quantitative data in a simple, intuitive format and to present findings in a clear and concise mannerMeets/exceeds Amazon’s leadership principles requirements for this roleMeets/exceeds Amazon’s functional/technical depth and complexity for this role
Amazon is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age"
60,Sr Data Engineer - IMDb,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelor's degree or higher in a quantitative/technical field (e.g. Computer Science, Statistics, Engineering)5+ years of relevant experience in one of the following areas: Data engineering, database engineering, business intelligence or business analytics5+ years of hands-on experience in writing complex, highly-optimized SQL queries across large data setsDemonstrable experience in scripting languages (Python, Perl, Ruby) and ExcelDemonstrated strength in data modeling, ETL development, and Data warehousingExperience with AWS services such as Redshift, Athena, S3, AWS Glue, and EMRKnowledge of distributed systems as it pertains to data storage and computingPassionate about the entertainment industryWorks well individually or in a team, driving things forward even in the face of ambiguity and imperfect data

Do you love working with big data? Do you have a passion for movies and TV? IMDb is the place for you! With over 200 million monthly users, IMDb is the worlds’ most authoritative source for movies, TV, and celebrities. We sit at the unique intersection of entertainment, media, and technology, inside the world’s most innovative and customer-centric company – Amazon.com. The data and insights our team provides, powers all IMDb properties and feeds directly into the Amazon flywheel. IMDb employees enjoy the best of both worlds, the all benefits and resources of Amazon with the autonomy and impact of a small, nimble team.

We are looking for a highly skilled, Senior Data Engineer to build and expand IMDb’s analytic capabilities. As a data engineering leader, you will own the design, implementation, and successful delivery of large-scale, complex data solutions focused on improving customer understanding. Your work will include both building new data solutions and optimizing existing ones. You will heavily influence the team’s technical design decisions, write significant portions of “critical-path” code, and guide our long-term architectural vision. You will integrate our team’s data solutions with those owned by other teams, expanding the impact IMDb has on the wider Amazon. You will work with senior leaders across IMDb, influencing the company’s technical and business strategies, providing key insights and contributions on how best to leverage data to inform our decision making. You will take the lead in identifying and solving ambiguous problems, architectural challenges, and team operational bottlenecks. You will make our data solutions simpler. This is a rare opportunity to join the team that is empowered to provide the data and understanding which powers all IMDb product lines and guides IMDb’s long-term vision.

Master’s degree in a quantitative/technical field (e.g. Computer Science, Statistics, Engineering)Proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategyExperience working with other engineers in defining data engineering best practices and leveraging software development lifecycle best practices such as agile methodologies, coding standards, code reviews, source management, build processes, testing, and operationsExperience with Tableau, Matillion, and Spark
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation."
61,Data Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Organizational Overview

The SEIU 775 Benefits Group is a family of employee benefit plans negotiated and sponsored by SEIU 775, the labor union for long-term care workers in Washington State & Montana. We are leading the transformation of home care into a thriving career and helping to prevent the coming care crisis. With 10,000 people turning 65 every day in the U.S., there are not enough qualified, trained workers to care for the exponential rise in older adults needing care. Through groundbreaking initiatives, the SEIU 775 Benefits Group, together with its union and employer partners, are ensuring that Washington state home care workers have access to the skills and support they need to stay and grow in the field.

The Details:
Location: Downtown Seattle (remote is not available for this role)
Work Schedule: Our typical business hours are 8:30-5:00 Monday-Friday
Travel Requirements: None
Category: Full-Time, Exempt, Union

This position is approved through: June 30, 2021 and qualifies for our comprehensive benefits package
Physical Requirements: Must be able to sit for long periods of the day

What You'll Be Doing:

Reporting to the Enterprise Data Solutions Manager, the Data Engineer will help solve a variety of technical database challenges and work directly with the Business Analytics and Technology Solutions teams to support the development and maintenance of the organization’s data platform and reporting infrastructure. If you want to make a difference in the lives of home care workers and the seniors and people with disabilities they support, we want to hear from you!
Plan and coordinate data migrations between systems;
Support the construction of the Data Warehouse - including the design of Data Marts;
Work with business users and analysts to gather business requirements and convert those requirements into high level and low-level designs;
Define views and data marts, based upon business requirements;
Improve query performance and tuning of existing data marts;
Develop and maintain a front-end application to allow access to back end tables and data;
API Gateway articulation for data exchanges internally and externally.
Monitor production jobs, maintain, and enhance legacy ETL processes on a regular basis.
Develop and maintain automation of manual data extractions;
Support ETL development and maintenance;
Develop and update process and system documentation;
Work closely with the project team including Business Analysts, Architect and Data Developer’s, Project Managers & QA to deliver data capabilities.
Attend design meetings and recommend security and data improvements – and will be empowered to work on those prioritized changes.
Be open to learning new technologies and new problem domains;.
Participate in code reviews and documentation reviews;
Be a contributing member of a cross-functional team in charge of delivering new features and capabilities on an iterative basis;
Other duties as assigned by your manager.

You Will Need To Have:
5+ years of professional experience as an ETL developer in an Enterprise Data Warehousing environment.
3+ years’ Experience with connecting to and posting to API’s for data ingestion and publishing of data sets, including SOAP & REST and related transport technologies (XML/JSON);
Experience in all aspects of data warehousing solutions (Database issues, Data modeling, Data mapping, ETL Development, Metadata Management, Data Cleansing, Data Profiling and Data Migration)
Strong understanding of Business Intelligence and Data Warehousing principles, approaches, technologies, and architectures - including the concepts, designs, and usage of data warehouses and data marts;
Experience designing and customizing data models for data warehouses, supporting data from multiple sources in real time;
Experience with Operational Data Stores and Data Governance Routines (Plus).
Experience with De-Identification or Encrypting the Sensitive Data.
Experience in normalizing and de-normalizing tables and maintaining referential integrity by using triggers and primary and foreign keys;
Experience building data solutions on Amazon Web Services, (such as S3, RDS, Redshift and Aurora), or on Microsoft Azure or Google Cloud;
Experience with connecting to and posting to API’s for data ingestion and publishing of data sets, including SOAP & REST and related transport technologies (XML/JSON);
Experience with other object-oriented development tools such as C#/.Net ,Java, Python;
Critical Thinking – Thorough understanding of TSQL standards/techniques and knowing when to implement them to overcome an issue;
Experience with Salesforce integration is a plus;
Experience working in an Agile/Kanban environment;
The ability to demonstrate strong verbal and written communication skills and interact with all levels of business and IT organizations;
A team-oriented mindset, ability to manage multiple priorities, follow a project plan, and meet project delivery dates;
Strong organizational ability with excellent decision making, analytical, problem solving, and presentation skills;
Judgment and Decision Making — Ability to deal with ambiguity and change;
Time Management – Highly self-motivated and delivery focused.
It Will Be Great If You Have:
Bachelor’s degree in Computer Science or related field
The SEIU 775 Benefits Group provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.
Requisition # 1533"
62,Data Engineer - Security Partner Engineering (SPE),"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"4+ years experience with and detailed knowledge of data warehouse technical architectures, infrastructure components, ETL/ ELT and reporting/analytic tools and environments, data structures.3+ years experience in architecting data warehouse solutions and integrating technical components5+ years experience with relational and star schema data modeling concepts - Experience in relational database concepts with a solid knowledge of Oracle, SQL and PL/SQL.Demonstrated knowledge and experience in capacity planning for hardware and storage needsExcellent communication skills, both written and verbalStrong ability to interact, communicate, present and influence within multiple levels of the organizationExperience using Python, Ruby, or other scripting languages for automationBS in Computer Science or Information Systems

The Security Partner Engineering (SPE) group is responsible for the protection of customer and corporate data. We connect with all parts of the Amazon business supporting the security of external party data sharing, subsidiary acquisitions, and securing business operations in unique regions and contexts across Amazon’s massive, worldwide service-oriented architecture.
As a Data Engineer, you will build data pipelines, tools, and reports that enable analysts, knowledge engineers, software engineers, product managers, and executives to make key security decisions across multiple information verticals: vulnerability, incident, risk, application security, etc. In this highly visible role, you will work across teams to gather requirements for data logging, storing, transforming, and reporting, and will build scalable solutions under fast-paced environment.
The ideal candidate is an expert with all of the data warehousing technical components (e.g. ETL, Reporting, Data Model), infrastructure (e.g. hardware and software) and their integration. The ideal candidate will be responsible for developing overall architecture and high level design. The candidate must have extensive experience with Star Schemas, Dimensional Models, and Datamarts. Excellent written and verbal communication skills are required as the candidate will work very closely with a diverse teams

Familiarity with AWS solutions such as EC2, Dynamo DB, S3, and Redshift.Knowledge of the security domains within Amazon is a plus.Knowledge and direct experience using business intelligence reporting tools such as PowerBI, Business Objects, Cognos, Tableau, MicroStrategy, SSAS Cubes, etc."
63,Data Engineer AWS Product BI,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Basic Qualifications
Bachelor's Degree in Computer Science or a related technical field, and solid years of relevant experience.A strong grasp of SQL and at least one scripting or programming language.5+ years of experience with and detailed knowledge of data warehouse technical architectures, infrastructure components, ETL/ ELT and reporting/analytic tools and environments, data structures.2+ years of large IT project delivery for BI oriented projects.2+ years of working with very large data warehousing environment

Amazon is looking for an outstanding Data Engineer to join the AWS Product BI team. This is your opportunity to be a core part of the team that has direct impact on the day-to-day decision making in the many AWS Product teams like EC2, S3 and IoT.

Since early 2006, AWS has provided companies of all sizes with an infrastructure platform in the cloud. AWS is a high-growth, fast-moving division within Amazon with a start-up mentality where new and diverse challenges arise every day. On the AWS Product BI team you will be surrounded by people that are exceptionally talented, bright, and driven, and believe that world class BI is critical to our success. To help build this growing team, you must be highly analytical and possess a strong passion for analytics and accountability, set high standards with a focus on superior business success. We take working hard, having fun, and making history seriously. AWS sets the standard for functionality, cost, and performance for many cloud based services, but it’s still early days for cloud computing, and there are boundless opportunities to continue to redefine the world of cloud computing - come help us make history!
As a Data engineer on this team, you will get the exciting opportunity to work on very large data sets in one of the world's largest and most complex data warehouse environments. You will work closely with the business and technical teams in analysis on many non-standard and unique business problems and use creative-problem solving to deliver actionable output. Our team is serious about great design and redefining best practices with a cloud-based approach to scalability and automation. A successful candidate will be a self-starter, comfortable with ambiguity, with strong attention to detail, an ability to work in a fast-paced and ever-changing environment, and an ability to work effectively with cross-functional teams.

Key responsibilities include
Designing, developing, troubleshooting, evaluating, deploying, and documenting data management and business intelligence systems, enabling stakeholders to manage the business and make effective decisions.Building secure, available, scalable, stable, and cost-effective data solutions using data storage technologies, distributed file system, data processing, and business intelligence best practices.Working with business customers in understanding the business requirements and implementing solutions to support analytical and reporting needs.Designing and planning for solutions in the various engineering subject areas as it relates to data storage and movement solutions: data warehousing, enterprise system data architecture, data design (e.g., Logical and Physical Modeling), data persistence technologies, data processing, data management, and data analysis.Ensuring completeness and compatibility of the technical infrastructure to support system performance, availability and architecture requirementsReviewing and participating in testing of the data design, tool design, data extracts/transforms, networks and hardware selections

Preferred Qualifications
Experience in designing and delivering cross functional custom reporting solutions.
- Experience with Massively Parallel Processing (MPP) databases - Redshift, Teradata, etc
Experience with distributed systems and NoSQL databasesExperience with Big Data technologies e.g. Hadoop, Hive, Oozie, Presto, Hue, Spark, Scala and more!Excellent oral and written communication skills including the ability to communicate effectively with both technical and non-technical stakeholders.Proven ability to meet tight deadlines, multi-task, and prioritize workloadA work ethic based on a strong desire to exceed expectations.Strong analytical skills"
64,Data Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"About New Engen

New Engen helps companies and marketing teams perform at their peak. Our powerful
machine learning and AI technology solution fuels growth at companies across
industries, geographies and levels of maturity.

We are focused on helping our partners achieve massive scale of new customer value
across all digital marketing platforms. We are results driven, committed, iterative and
transparent. Our teams of expert Marketers, Application Developers and Data Scientists
help tackle some of the most complex digital marketing challenges.

At New Engen we don't just accept difference—we celebrate it, we support it, and we
embrace it for the benefit of our employees, our partners, and our community. We are
committed to equal employment opportunity and diversity.

About the Role

We are seeking a Data Engineer to execute on our vision for building scalable and
reliable data infrastructure for a high-growth, data reliant business. You will create
something new, using new technology which sets us up for future growth and success.

-----------------------------
We'd love to hear from you if
-----------------------------


You want a chance to create and optimize data pipelines for large amounts of data
You're committed to choosing the best technology and strategy for data gathering, storage and retrieval
You love building reusable data stores for a rapidly growing company
You are comfortable collaborating with people inside and outside our organization
You have dedication to your customers and want to make a difference
You do not have an ego and enjoy working with others

--------------
Qualifications
--------------


2+ years of experience implementing data solutions including data modeling, data warehousing, ETL, and analytics
3+ year of experience in SQL
2+ years programming experience coding with Python
Some experience with Java or other Object-Oriented Languages
Some experience with AWS technologies
Desire to build complex data structures that serve varying needs
A real passion for keeping up with new technology and scalability

---------------------------------
Extras that Will Give you an Edge
---------------------------------


You've worked in a fast-paced agile environment
You have experience with distributed data processing (Apache Hadoop, Spark, Hive, Presto)
Experience with RESTful web services
Knowledge of streaming technologies (Kinesis, Kafka, Spark Stream)
You have worked with NoSQL solutions (Cassandra, HBase, DynamoDB, Bigtable)
You enjoy challenges and jump at the chance to create something new

"
65,Systems Data Engineer - New Glenn,"Kent, WA",Kent,WA,None Found,None Found,"Minimum of a B.S. degree in Electrical Engineering, Systems Engineering, Computer Science, Computer Engineering, Physics, Mathematics, or other major requiring engineering core courses
Minimum of 5+ years of experience with aerospace/ control systems and software
Excellent written communication and presentation skills
Ability to collaborate across teams and balance priorities
The ability to quickly absorb information in an unfamiliar domain
A self-driven nature with the ability to seek out requirements and propose solutions with minimal direction
Technical expertise in data visualization tools (e.g. Tableau, PowerBI)
Strong analytic skill set and a high degree of proficiency in data mining
Must be a U.S. citizen or national, U.S. permanent resident (current Green Card holder), or lawfully admitted into the U.S. as a refugee or granted asylum.
",None Found,"Work with various subject matter experts to build reports and run analysis for various program and tactical related questions
Give voice to the data, talk with people, ensure they understand what it means and it meets their needs
Act as a change agent, help engineering teams adopt new more efficient methods of operating within large related data sets
Determine and articulate balance of priorities to enable incremental delivery of needed functionality
Perform data mining for valued projects
Capture user feedback
Work as a flexible contributor in an agile team including building consensus on designs and participating in code reviews
Participate in Strategic Development of technical performance / launch system health monitoring solutions
",None Found,None Found,"Job Description
As part of a small, passionate, and accomplished team of experts, you will fill a flexible role within a fast pace development team. Your initial focus will be to interface with engineering teams and aid them in managing their data sets. You will be part of the software / process development team and will influence the features within the software tools. You will advocate for the customer in setting software development priorities and will primarily be focused on ensuring the underlying data sets are valid, current, and correct. You will work across the New Glenn program with teams of engineers in fluids, mechanical, electrical, and software subsystem teams to integrate and align data sets. Your work will ensure we have robust configuration control of data used to manufacture and operate New Glenn. We are expecting you to bring engineering analytical skills and experience working the interface between hardware and software. Once this foundation is established, your role will transition into support for building reliable health monitoring and prediction capabilities that will truly enable our vehicles to be reusable. This hands-on position requires a commitment to quality and attention to detail commensurate with safe human spaceflight. This is a rare opportunity to directly impact the future of human space exploration.
Responsibilities:
Work with various subject matter experts to build reports and run analysis for various program and tactical related questions
Give voice to the data, talk with people, ensure they understand what it means and it meets their needs
Act as a change agent, help engineering teams adopt new more efficient methods of operating within large related data sets
Determine and articulate balance of priorities to enable incremental delivery of needed functionality
Perform data mining for valued projects
Capture user feedback
Work as a flexible contributor in an agile team including building consensus on designs and participating in code reviews
Participate in Strategic Development of technical performance / launch system health monitoring solutions
Qualifications:
Minimum of a B.S. degree in Electrical Engineering, Systems Engineering, Computer Science, Computer Engineering, Physics, Mathematics, or other major requiring engineering core courses
Minimum of 5+ years of experience with aerospace/ control systems and software
Excellent written communication and presentation skills
Ability to collaborate across teams and balance priorities
The ability to quickly absorb information in an unfamiliar domain
A self-driven nature with the ability to seek out requirements and propose solutions with minimal direction
Technical expertise in data visualization tools (e.g. Tableau, PowerBI)
Strong analytic skill set and a high degree of proficiency in data mining
Must be a U.S. citizen or national, U.S. permanent resident (current Green Card holder), or lawfully admitted into the U.S. as a refugee or granted asylum.
Desired:
Exposure to product lifecycle / configuration management systems, specifically Windchill
Experience in multiple coding languages
Proficiency in scripting languages (e.g. Python)
Experience with collaboration tools such as Confluence and JIRA
Experience with web based APIs (e.g. REST, SOAP)
Experience with micro-service architecture
Proficiency in database interrogation of SQL and NOSQL databases (e.g. Oracle, MySQL, Neo4J, MongoDB)
Blue Origin offers a phenomenal work environment and awesome culture with competitive compensation, benefits, 401K, and relocation.


Blue Origin is an equal opportunity employer . In addition to EEO being the law, it is a policy that is fully consistent with Blue's principles. All qualified applicants will receive consideration for employment without regard to status as a protected veteran or a qualified individual with a disability, or other protected status such as race, religion, color, national origin, sex, sexual orientation, gender identity, genetic information, pregnancy or age. Blue Origin prohibits any form of workplace harassment."
66,Data Engineer III,"Mountlake Terrace, WA",Mountlake Terrace,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Join Our Team: Do Meaningful Work and Improve People’s Lives

Our purpose, to improve customers’ lives by making healthcare work better, is far from ordinary. And so are our employees. Working at Premera means you have the opportunity to drive real change by transforming healthcare.

To better serve our customers, we’re creating a culture that promotes employee growth, collaborative innovation, and inspired leadership. We are committed to creating an environment where employees can do their best work and where best-in-class talent comes, stays, and thrives!
As a Data Engineer III for our Corporate Data and Analytics team, you will work on fast and streaming data to enable analytics and data science which allows for the creation of nearly instantaneous personalization opportunities and highly informed decisions. You will be working with Tier 1 data to create, modify, and test the code, forms, and scripts that construct the data sets that drive our analytic capabilities.
What you’ll do
Solve business and data engineering problems using data centric programming and scripting skills to create data models and pipelines
Consult with the business to create understanding of the needs, pace and direction for our business partners, translate these needs into requirements and specifications, and maintain contact with the customers through project completion
Lead all phases of architecture, conceptualization, design, development, testing, and production support data solutions
Architect, design, and build best-of-class production processes that ensure security, efficiency, and availability of analytic tools and data
Collaborate with data scientists and analyst to further understand business problems
Program and manage APIs for data exchange
Lead and conduct unit and system testing to ensure design is still relevant and implementation is producing a useful, maintainable, reliable product
Mentor and train other team members by introducing them to new technologies, methods and learning resources
Act as a resource to technical community as well as business partners
What you'll bring
Bachelor’s degree in computer science, computer engineering, or similar area
5 years’ relevant experience in data integration, design and management
Experience with the following as they apply to our source/targets (Teradata, Netezza, Azure, Amazon Redshift) experience with the following:
o SQL
o ETL tools
o Scripting language
3 years' experience in data integration, design, and/or management using NoSQL/Hadoop would be nice to have
Experience providing data integration services within healthcare organizations
Strong understanding of change data capture (CDC) methodology and working experience with one of the data replication tools (Attunity Replicate, Oracle Goldengate etc.)
Significant industry knowledge of healthcare specific regulatory requirements for data management and knowledge of health insurance concepts and terms
Ability to lead and participate in analytic projects
Advanced analytical and problem solving skills and data processing programming skills across SQL-based and Hadoop-based technologies
Strong understanding of web services
Excellent problem definition, problem-solving, and technical writing skills
Strong written and verbal communication skills and ability to deal with management of various levels
#LI-MS1
What we offer
Medical, vision and dental coverage
Life and disability insurance
Retirement programs (401K employer match and pension plan)
Wellness incentives, onsite services, a discount program and more
Tuition assistance for undergraduate and graduate degrees
Generous Paid Time Off to reenergize
Free parking
Equal employment opportunity/affirmative action:
Premera is an equal opportunity/affirmative action employer. Premera seeks to attract and retain the most qualified individuals without regard to race, color, religion, sex, national origin, age, disability, marital status, veteran status, gender or gender identity, sexual orientation, genetic information or any other protected characteristic under applicable law.
If you need an accommodation to apply online for positions at Premera, please contact Premera Human Resources via email at careers@premera.com or via phone at 425-918-4785."
67,Sr. Big Data Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelor’s degree in computer science, engineering, mathematics, or a related technical discipline7+ years of industry experience in software development, data engineering, business intelligence, data science, or related field with a track record of manipulating, processing, and extracting value from large datasets5+ years of experience in designing and developing data processing pipelines using big data technologies (Hadoop, Hive, Hbase, Spark, EMR, etc.)5+ years of experience in designing and developing analytical systemsExperience building large-scale applications and services with big data technologiesExperience providing technical leadership and mentoring other engineers for best practices on data engineeringExpertise in SQL, DB and storage Internals, SQL tuning, and ETL developmentAbility to work and communicate effectively with developers and Business usersStrong organizational and multitasking skills with ability to balance competing prioritiesWorking knowledge of scripting languages such as Python, Perl, etc.

Amazon’s Profit Intelligence is seeking a talented Senior Big Data Engineer to join the Profit Intelligence team. We develop software solutions that are revolutionizing Amazon business intelligence through advanced algorithms running on big data technologies. The ideal candidate thrives in a fast-paced environment and relishes working with petabytes of extremely complex and dynamic data. In this role you will be part of a team of high caliber data and software engineers to build data pipelines using big data technologies such as Apache Spark, Hive/Hadoop, and distributed query engines. You should be passionate about working with big data and have the aptitude to incorporate new technologies and evaluate them critically. You must possess excellent business and communication skills and be able to work with business owners to analyze requirements and build solutions. You are a self-starter, has a proven track record of dealing with ambiguity and working in a fast-paced, highly dynamic environment. Working experience of any one of the programming languages such as Java, C#, C++, Scala, etc. is a big plus.

Major Responsibilities:
Interface with PMs, business customers, and software developers to understand requirements and implement solutionsCollaborate with both Retail Finance and central FP&A teams to understand the interdependencies and deliverablesDesign, develop, and operate highly-scalable, high-performance, low-cost, and accurate data pipelines in distributed data processing platforms with AWS technologiesRecognize and adopt best practices in data processing, reporting, and analysis: data integrity, test design, analysis, validation, and documentationKeep up to date with big data technologies, evaluate and make decisions around the use of new or existing software products to design the data architecture

7+ years of experience as a Data Engineer, BI Engineer, Business/Financial Analyst or Systems Analyst in a company with large, complex data sources.Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data setsExperience with full software development life cycle, including coding standards, code reviews, source control management, build processes, and testingExperience with AWS technologies (EMR, Dynamo, RDS, Redshift, Athena, S3)Demonstrated strength in data modeling, ETL development, and data warehousingProven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategy"
68,BI Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"BA/BS in Computer Science, Engineering, Statistics, Mathematics, Finance or related field.3+ years’ experience as a BIE, data scientist, data engineer or similar job function with a technology company.Demonstrated strength in SQL, data modeling, ETL development, and data warehousing.Advanced skills in Excel as well as any data visualization tools like Quicksight, Tableau or Cognos Solutions.Understanding of Finance concepts is a plus.Working knowledge of Python/Java or similar coding languages.Familiarity with AWS solutions such as Redshift, S3.Advanced ability to draw insights from data and clearly communicate them to the stakeholders and senior management.Have ability to independently influence and drive outputs, meet deadlines, and set clear expectations and roadmaps.

If you enjoy creating solutions from scratch that revolve around BI and Analytics then this role is for you.

Amazon Web Services seeks an experienced Business Intelligence Engineer (BIE) to join the AWS Finance BI(FinBI) team. The team is made of up Data Engineers, BIEs and tool developers. This team is building several platform solutions for all of AWS Finance to help invent and simplify on behalf of the customers. In this organization every day is Day 1 and no projects are the same. In this role you'll own solution designing, customer engagement and full end to end development on products. Some technologies used in the roll will be S3,Redshift, ETL, ETL automation, ad-hoc reporting with tools like QuickSight and IBM Cognos Analytics, and long term analytical projects that will affect the effectiveness of the FinBI team and the customer. You'll work with multiple AWS Finance Stakeholders and Functions, and will work with multiple sources on a wide range of data technologies developing the next generation of reporting solutions.

The successful candidate will be a self-starter comfortable with ambiguity, with strong attention to detail, and the ability to work in a fast-paced environment. You will consult, design, build and manage analytical projects with your customer in mind. You should have a strong expertise and proven success in the design, creation, management, and business use of extremely large datasets. You should be experienced at designing, implementing, and operating stable, scalable, low cost solutions to flow data from production systems into the data warehouse and into end-user facing applications or reports. Above all you should be passionate about inventing on behalf of your customers while learning new solutions to answer business questions to drive tangible change.
Duties & responsibilities for this role will include:
The successful candidate will demonstrate good business acumen, experience in developing reports and conducting analysis, strong communication skills, an ability to work effectively with cross functional teams, and an ability to work in an ever-changing environment.Interfacing with business customers to gather data and metrics requirements, then driving analytic projects which will help solve complex challenges.Design, implement, and support key datasets that provide structured and timely access to actionable business information.Perform deep-dives to find the root causes behind variances of key parameters.Experience working in a very large data warehouse environment and multi data sources.Analyzing data and driving insights related to operation and compliance.Build data pipelines for the customers to self-serve very seamlessly.Investigate and implement new big data technologies to provide automatic resolutions to address stakeholder needs.

MBA or Master’s in Computer Science, Engineering, Statistics, Mathematics, Finance or related field.Experience in projects involving complex data sets and high variability.A history of teamwork and willingness to roll up one’s sleeves to get the job done.Excellent communication (verbal and written) and interpersonal skills and an ability to effectively communicate with both business and technical teams.Experience handling confidential and sensitive data.Design and develop data infrastructure to support business growth.
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation"
69,Senior Software Engineer - Data Streaming,"Bellevue, WA",Bellevue,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Epic is seeking a Senior Data Engineer to help build and manage our big data streaming technologies. You'll be deeply involved with optimizing our existing streaming services, evaluating new technologies, managing cloud infrastructure and more. Our ingestion pipelines peak at over 90GB per minute. If you’re interested in working with data at massive scale, let’s chat.
Responsibilities:
Building and supporting highly available streaming services, written in Java / Scala using Apache Flink
Developing and operating applications on distributed NoSQL key-value stores such as HBase, DynamoDB or FoundationDB
Managing cloud infrastructure launched in AWS via Terraform
Participating in an on-call rotation for Epic Games streaming tech stack
Evaluating new technologies and components of the big data ecosystem for inclusion in our environment
Qualifications:
Experience building high throughput Java / Scala streaming services using technologies such as Flink or Spark
Strong understanding of distributed message brokers such as Kafka and Kinesis
Experience with performance tuning of distributed computing technologies at massive scale
Experience working with AWS services such as Kinesis, EC2, EMR, RDS via infrastructure as code technologies
Experience working with high throughput, distributed NoSQL databases
Capable of independently performing root cause analysis on high throughput systems
This is going to be Epic!
#LI2"
70,Data Engineer,"Bellevue, WA",Bellevue,WA,None Found,None Found,"
At least 5-years of experience as a software development or data engineer
At least 3-years of experience with SQL, Python and/or other data collection tools & reporting
Experience with Pyspark or Scala is necessity (Databricks or Spark).
Advanced knowledge and skills with Azure, or similar cloud platforms.
Excellent collaboration skills to work on a team as well as independently (be self-reliant and resourceful)
Excellent organization skills and able to multi-task and detailed oriented
Excellent verbal and written communication skills (must be able to write clear and concise emails for any audience, etc.
",None Found,None Found,None Found,None Found,"Who is Blueprint?

Blueprint Technologies is a group of solution minded thinkers changing the face of Technology in Bellevue, WA. We follow a Mission, Vision, and Core Values that allow us to function as a collaborative unit.

What are our Solutions?

Blueprint is a technology solutions firm that connects strategy, product and delivery. We help companies digitally transform. We have a special focus in cloud and infrastructure, data platform and engineering, data science and analytics, organizational modernization and customer experience optimization.

Why you want to be a part of Blueprint?

We are innovators. Motivators. Thought provokers. And coffee drinkers. Our collective backgrounds bring diverse perspectives that enable us to consistently think differently. Our people are our solutions. We want you to bring your biggest and best ideas to help positively impact our culture, clients and the community around us. We believe in the importance of a healthy and happy team, which is why our benefits include full medical, dental and vision coverage, as well as paid time off, 401k, paid volunteer hours and tuition reimbursement.

Blueprint is looking for Data Engineer to join us as we build cutting-edge technology solutions!

Qualifications:

At least 5-years of experience as a software development or data engineer
At least 3-years of experience with SQL, Python and/or other data collection tools & reporting
Experience with Pyspark or Scala is necessity (Databricks or Spark).
Advanced knowledge and skills with Azure, or similar cloud platforms.
Excellent collaboration skills to work on a team as well as independently (be self-reliant and resourceful)
Excellent organization skills and able to multi-task and detailed oriented
Excellent verbal and written communication skills (must be able to write clear and concise emails for any audience, etc.

Nice to have


Experience working with Business Intelligence BI tools such as PowerBI
Bachelor's Degree

**We are not able to sponsor Visa's at this time or do Corp-to-Corp arrangements. Must be able work on a W2 basis please!"
71,"Strategic Customer Engagements, Sr Business Analyst","Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelor's degree in Business, Engineering, Statistics, Computer Science, Mathematics, Supply Chain or related field5+ years of work experienceAbility to drive project success in an ambiguous environment2+ years of experience in a business analyst/data analyst/statistical analyst roleData proficiency and a mastery of SQLAbility to communicate with both technical and non-technical partnersExperience building financial models

Are you an entrepreneur that thrives in a fast-paced ambiguous environment? Do you want to be involved in making strategic deals come to life?

If so, we are looking for a Sr. Business Analyst to join the Strategic Customer Engagements team to develop reporting and scalable analytical tools to support complex deals. The Strategic Customer Engagements Deal Team works with our customers on commercial private pricing opportunities to meet their desired business outcomes while ensuring alignment with AWS business objectives.

In this role, you will be responsible for understanding and modeling customer usage patterns, the competitive environment, and the pricing strategy for our largest AWS service. You will work with a data engineer to identify the data sources and metrics needed to support our largest customer facing deals. You will work cross-functionally with our competitive insights team and with technical partners to understand business tradeoffs and develop tools for our team to quickly analyze deals. You will also provide strategic support to model large deals and be a voice in the room during the deal process.

The ideal candidate will be able to work independently in an ambiguous environment. They will understand financial modelling and be able to communicate complex relationships to senior leaders.

MBA5+ years of product management experienceExperience working with data engineersExperience working with AWS services"
72,Data Engineer - Alexa,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelor’s degree in Computer Science, Mathematics, Statistics, Finance, related technical field, or equivalent work experience.Relevant experience in analytics, data engineering, business intelligence, market research or related fieldExperience gathering business requirements, using industry standard business intelligence tool(s) to extract data, formulate metrics and build reportsExperience using SQL, ETL and databases with large-scale, complex datasets

Interested in Amazon Alexa? Come work on it. We’re building the speech and language solutions behind Amazon Echo and other Amazon products and services. We’re working hard, having fun, and making history!

We are looking for candidates who want to help shape the future of human-computer interactions. Specifically, we are looking for an outstanding Data Engineer who is looking to work in a new space to help define how we use data to understand customer behavior and satisfaction. In this role, you will develop and support the analytic technologies that give our teams flexible and structured access to their data, including implementation of a BI platform, defining metrics and KPIs, and automating reporting and data visualization.

The successful candidate will be an expert with SQL, ETL (and general data wrangling) and have exemplary communication skills. The candidate will need to be a self-starter, comfortable with ambiguity in a fast-paced and ever-changing environment, and able to think big while paying careful attention to detail.

Responsibilities

You know and love working with business intelligence tools, can model multidimensional datasets, and can partner with customers to answer key business questions. You will also have the opportunity to display your skills in the following areas:

· · Design, implement, and support a platform providing ad hoc access to large datasets
· · Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using SQL
· · Manage AWS Resources
· · Model data and metadata for ad hoc and pre-built reporting
· · Interface with business customers, gathering requirements and delivering complete reporting solutions
· · Own the design, development, and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisions
· · Recognize and adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation
· · Continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers

Graduate degree in computer science, business, mathematics, statistics, economics, or other quantitative fieldBoth technically deep and business savvy enough to interface with all levels and disciplines within the organizationDemonstrated ability to coordinate projects across functional teams, including engineering, IT, product management, marketing, finance, and operationsKnowledge of Advanced SQL and a programming languageExperience with data visualization using Tableau or similar toolsExperience with large-scale data warehousing and analytics projects, including using AWS technologies – Redshift, S3, EC2, Data-pipeline and other big data technologiesProven track record of successful communication of analytical outcomes through written communication, including an ability to effectively communicate with both business and technical teams
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation."
73,"Data Engineer, Amazon Global Sellers","Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelor's degree or higher in a quantitative/technical field (e.g. Computer Science, Statistics, Engineering).3+ years of relevant experience in one of the following areas: Data engineering, database engineering, business intelligence or business analytics.3+ years of hands-on experience in writing complex, highly-optimized SQL queries across large data sets.3+ years of experience in scripting languages like Python etc.Demonstrated strength in data modeling, ETL development, and Data warehousing. Data WarehousingExperience with RedshiftExperience using big data technologies (Hadoop, Hive, Hbase, Spark, EMR, etc.)Knowledge of data management fundamentals and data storage principlesKnowledge of distributed systems as it pertains to data storage and computingExperience with AWS services including Redshift, EMR, Kinesis and RDS.

Amazon Global Sellers supports Amazon’s strategic vision by bringing worldwide cross-border product selection at the lowest price to our customers and helping sellers and vendors (manufacturers, distributors and brand owners) navigate international trade and logistics. We design and build products and programs with a focus on customer, seller, and vendor experience, and global scalability. We’re looking for exceptional leaders to join our team.
AGL works directly with logistics cross-border carriers and partner with several stakeholder teams to constantly improve the international delivery experience. AGL Exports Business Intelligence team is seeking a highly skilled and motivated Data Engineer to join our team in Seattle. The AGL Exports business is growing rapidly and the data required to support critical business decisions in this space is provided by the AGL Business Intelligence team. Our ideal candidate is someone who is always learning and improving as the business grows and the relevant technologies continue to evolve. If you enjoy innovating, thinking big and want to contribute directly to the success of an industry changing business, you may be a prime candidate for this position.

CORE RESPONSIBILITIES:
Contribute to the architecture, design and implementation of next generation BI solutions – including streaming data applications.Manage AWS resources including EC2, RDS, Redshift, Kinesis, EMR, Lambda etc.Collaborate with data scientists, BIEs and Business Analysts to deliver high quality data architecture and pipelines.Interface with other technology teams to extract, transform, and load data from a wide variety of data sourcesContinually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers

5+ years of experience as a Data Engineer, BI Engineer, Business/Financial Analyst or Systems Analyst in a company with large, complex data sources.Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data setsExperience working with AWS big data technologies (EMR, Redshift, S3)Demonstrated strength in data modeling, ETL development, and data warehousingProven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategyExperience providing technical leadership and mentoring other engineers for best practices on data engineering
Amazon is an Equal Opportunity Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation / Age"
74,"Business Intelligence Engineer, SCAR","Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelors degree in quantitative or technical discipline and/or 2+ years of Amazon experience.Prior experience in database and data table designPrior experience working with large data sets and writing complex SQL statements including query and server optimizationPrior experience in developing requirements and formulating business metrics for reporting

The SCAR (Strategy Capacity Analytics and Research) Team that supports Global Specialty Fulfillment (GSF) org is seeking an exemplary Business Intelligence Engineer with broad technical skills to help build the infrastructure and tools required to support a new, fast growing business. The ideal candidate will draw upon advanced analytical, critical thinking, problem solving skills, software development experience, and a passion for creating maintainable, highly reliable, distributed systems which operate 24/7/365. You will work with analytic tools, write excellent SQL scripts, partner with customers to answer key business questions, and act as an advocate for your customers. Successful members of this team collaborate effectively with internal end-users, cross-functional software development teams, and technical support/sustaining engineering teams to solve problems, implement new solutions, and deliver successfully against high operational standards of system availability and reliability. We look for candidates who are excellent communicators, self-motivated, flexible, hardworking, and who like to have fun.

The complexity of research and skills for a Data Engineer is well beyond basic data entry and extraction. It involves design and development of automated data pipelines, sophisticated analytical model and intuitive data visualization. In addition, this role is on a large analytical team that supports a wide range of businesses. This role has great exposure to a broad scope that can really help shape the future of operational fulfillment and promotes career progression.

Main responsibilities of this role include but are not limited to:

Perform data extraction, manipulation and production from database tablesCreate automated tools via VBA and SQL connection to streamline process executionCreate data flows and develop/manage new metricsDesign, implement and validate complex logic using queriesSupport analytical researches and provide recommendations to business challenges

3+ years of experience in a business intelligence, business analyst, data analyst or statistical analysis rolePrior experience conducting advanced statistical analysisPrior experience with product design/managementPrior experience working with Tableau reporting softwareProficiency in a programming languageAdvanced Microsoft Office skills, particularly Excel and experience creating tools and reports with VBAPrior experience working with a coding language (Ruby/Python/Java)
Amazon is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age"
75,Business Intelligence Engineer (AWS),"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Background in computer engineering or information systems3+ years of relevant work experience as a business intelligence engineer or data engineer role3+ years of experience in SQL programming3+ years of experience in building data warehouses and dimensional modeling3+ years of experience with business intelligence and data visualization tools (e.g. Tableau)3+ years of experience with a modern programming language (e.g., Java, Ruby, Python, etc.)Experience with ETL tools and processes

Have questions about this role? Start a chat with the recruiter today!

copy and paste this link into a new window: http://bit.ly/chatnowaws

Are you interested in building the data foundation for helping scale the growth of the Solutions Architecture function with Amazon Web Services? In a fast-paced, high-growth environment, making data driven decisions is critical. The Amazon Web Services Solutions Architecture (SA) organization is looking for a Business Intelligence Engineer to join our Solution Architecture Tools Engineering team and better enable our decision making through the use of data analytics.

As an engineer on the team you'll leverage tools and services including Amazon Redshift, Amazon QuickSight, and AWS Glue to build solutions that deliver data-driven reports, dashboards, and tools to internal stakeholders. You'll work directly with customers and stakeholders to understand the different business problems and use cases. You'll work with the rest of the engineering team to identify and consume data sources, transform the data, and build the reports and visualizations needed to meet the requirements.

Developing this capability will provide insights that are used to lead decision making around resource allocation, program effectiveness, productivity analysis and business impact. Consumers of these insights will include individual SAs, SA and Sales management, and AWS senior and executive leadership.

Roles and Responsibilities:

Build solutions using AWS services that deliver data-driven reports, dashboards, and tools.Distill problem definitions, models, and constraints from informal business requirements.Dive deep into source data from various internal systems.Think strategically and analytically about the business, our products, and technical challenges.Follow established engineering best practices and define new best practices where required.

Experience using AWS services for data analytics (i.e., Athena, Glue, Redshift, EMR, etc.)Experience developing custom ETL solutions using Python and SQLExperience with Tableau Desktop and Tableau ServerStrong written and verbal communications skills
For more information on Amazon Web Services please visit: http://aws.amazon.com/

Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation / Age"
76,"Sr. Splunk Consultant Seattle, WA","Seattle, WA",Seattle,WA,None Found,None Found,None Found,"
Splunk Certified Consultant (SCC-2, SCC-II, Core Certification)
Experience designing and implementing distributed Splunk installations including all Splunk server roles (Search Head, Indexers, Heavy Forwarders, and Universal Forwarders, etc.)
Experience with advanced configuration of Splunk including Indexer Clustering and Search Head Clustering
Experience maintaining and administering enterprise-scale implementations
Experience developing custom Splunk content including scheduled searches, reports, dashboards and alerts
Proficient at data on-boarding activities including custom parsing rules, custom TAs, props, transforms, and adhering to the Common Information Model (CIM)
Experience configuring indexes, index routing, retention policies, etc.
Excellent written and oral skills, ability to work closely with multiple customers, manage expectations, and track engagement scope",None Found,None Found,None Found,"Arcus Data is seeking experienced Splunk consultants to join their team. Arcus Data is a high growth solutions provider that celebrates and rewards innovation. Join a world-class team of extremely technical engineers that work together in a collaborative culture.
Required Skills
Splunk Certified Consultant (SCC-2, SCC-II, Core Certification)
Experience designing and implementing distributed Splunk installations including all Splunk server roles (Search Head, Indexers, Heavy Forwarders, and Universal Forwarders, etc.)
Experience with advanced configuration of Splunk including Indexer Clustering and Search Head Clustering
Experience maintaining and administering enterprise-scale implementations
Experience developing custom Splunk content including scheduled searches, reports, dashboards and alerts
Proficient at data on-boarding activities including custom parsing rules, custom TAs, props, transforms, and adhering to the Common Information Model (CIM)
Experience configuring indexes, index routing, retention policies, etc.
Excellent written and oral skills, ability to work closely with multiple customers, manage expectations, and track engagement scope
Required Experience
Splunk engineer with experience managing and configuring Splunk environments, performing data on-boarding, developing custom content on Splunk platform, troubleshooting methodologies, and ability to walk customers through requirements gathering phase and develop appropriate system designs.
Recommended Skills
Splunk premium apps (ITSI, Exchange, Enterprise Security, VMWare, Business Flow)
Understanding of Syslog daemon configuration principles, ideally Syslog-NG
Understanding of modern data pipelines (Kafka, Cribl, Kinesis, Firehose)
Cloud experience (AWS, Azure, GCP)
Development and API experience (Python, REST, XML)
Automation Experience (Ansible, TerraForm, Puppet, Chef)
High-level Job Description
We’re looking for candidates who have a strong technical background and ability to think creatively. You’ll be responsible for building, deploying, and enhancing Splunk for our diverse customer base. This involves working with the customers directly, understanding their business needs, and building innovative solutions to solve interesting & challenging problems.

Detailed Job Description
Our customer deployments range from on-prem, to hybrid, to 100% cloud. You will be supporting a wide variety of clients — some who are just getting started on their Splunk journey — all the way up to advanced 20+ TB customers with thousands of daily active users. This will include the installation and configuration of Splunk Enterprise according to Splunk best practices. Our customers need assistance developing solutions to support their use cases, which requires data onboarding, dashboard development, custom alerting, and third-party tool integrations.
You will also be involved in planning and requirements gathering discussions with the client and will need to possess excellent written and verbal communication skills. The candidate will be required to document system design, capacity planning guides, status reports, and standard operating procedures.
As an Arcus Data engineer you’ll have full access to our internal knowledge base and use case libraries, which is driven by our internal development teams. You’ll also have the technical backing of our entire engineering team to encourage collaboration and growth through information sharing and knowledge workshops. We celebrate and reward innovative thinking!
About Arcus Data
Arcus Data is a proven leader in business analytics, cloud adoption, and automation. We empower organizations to solve some of their most challenging business needs through innovative solutions and advanced use case development. We deliver solutions across all industries including Technology, Healthcare, Energy & Utilities, Retail, and Financial Services."
77,Machine Learning Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,"
Demonstrated ability to connect business purpose to data-driven analysis.
Experience working with Python (dataframes, scikit-learn), SQL, Spark.
Experience working with Machine Learning Algorithms (Linear, Logistic, Decision Trees, Random Forests, Support Vector Machines, Neural Networks, KNN, etc)
Proficient in handling unstructured/structured data, including analyzing and troubleshooting complex data for quality and integrity.
Experience with building and maintaining large scale data processing pipelines using technologies like Kafka, Hadoop, or Spark.
Bachelor’s degree in Computer Science, Maths or related field, or equivalent practical experience.","
Demonstrated ability to connect business purpose to data-driven analysis.
Experience working with Python (dataframes, scikit-learn), SQL, Spark.
Experience working with Machine Learning Algorithms (Linear, Logistic, Decision Trees, Random Forests, Support Vector Machines, Neural Networks, KNN, etc)
Proficient in handling unstructured/structured data, including analyzing and troubleshooting complex data for quality and integrity.
Experience with building and maintaining large scale data processing pipelines using technologies like Kafka, Hadoop, or Spark.
Bachelor’s degree in Computer Science, Maths or related field, or equivalent practical experience.",None Found,None Found,None Found,"Company Introduction

Wicket Labs is focused on delivering actionable insights to media companies that are facing a shifting audience, in an arena where the consumer has to be the focus and data is the differentiator. We’re talking about the evolution of the television market towards new devices, services and consumption models. Our goal is to help traditional and new media business leaders succeed in this environment with better data, and more predictive insights.

We are a venture-backed software company located in the heart of Pioneer Square in Seattle. We are part of a great, vibrant technology and art community in an area with a rich cultural heritage.

We strongly believe in the value of diversity, equity, and inclusion and aim to reflect that belief in the team that we build. We hope you will consider joining us.

Job Description

Join a small team building a big impact product. We’re looking for a Data Engineer to help us design and implement software that turns large volumes of raw data into attractive and actionable business insights. You’ll have the opportunity to build the first versions of our data processing architecture.

Technologies We’re Using

We are building analytical platforms using open source big data tools and technologies. Our data pipeline leverages technologies like Presto, Spark, Python, SQL and S3 using AWS cloud services.

What You’ll Do

Interface with business customers, gathering requirements and developing new datasets.
Extracting and combining data from various heterogeneous data sources
Modelling data and metadata to support ad-hoc and pre-built reporting
Designing, implementing and supporting a platform that can provide ad-hoc access to large datasets as well as a 'hands-off' automated pipeline
Work on a highly collaborative agile team with skilled teammates
Champion test standards and best practices for data pipelines
Collaborate across business teams
Listen and communicate ideas effectively with respectful and responsive interactions
Adopt a team player approach by doing what needs done and cheering each other on
Skills and Qualifications

Demonstrated ability to connect business purpose to data-driven analysis.
Experience working with Python (dataframes, scikit-learn), SQL, Spark.
Experience working with Machine Learning Algorithms (Linear, Logistic, Decision Trees, Random Forests, Support Vector Machines, Neural Networks, KNN, etc)
Proficient in handling unstructured/structured data, including analyzing and troubleshooting complex data for quality and integrity.
Experience with building and maintaining large scale data processing pipelines using technologies like Kafka, Hadoop, or Spark.
Bachelor’s degree in Computer Science, Maths or related field, or equivalent practical experience."
78,Distributed Systems Cloud Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,"3+ years of data management and engineering
3+ years of database management and engineering using Oracle database technologies
3+ years of data modeling experience for Analytical and OLTP systems
3+ years of Object Oriented software development experience
3+ years of hands-on hardware management and operating systems experience (Unix, Linux)
3+ years of hands-on experience working with cloud technologies (OCI, AWS, Azure, GCP)
Bachelor’s degree in Computer Science, Engineering, Mathematics or Physical Sciences",None Found,None Found,None Found,None Found,"Distributed Systems Cloud Engineer-190018MJ


Preferred Qualifications

OCI Data Engineer
Business Description
The Oracle Cloud Infrastructure (OCI) team can provide you the opportunity to build and operate a suite of massive scale, integrated cloud services in a broadly distributed, multi-tenant cloud environment. OCI is committed to providing the best in cloud products that meet the needs of our customers who are tackling some of the world’s biggest challenges.

We offer unique opportunities for smart, hands-on engineers with the expertise and passion to solve difficult problems in distributed highly available services and virtualized infrastructure. At every level, our engineers have a significant technical and business impact designing and building innovative new systems to power our customer’s business critical applications.

Primary Responsibilities
The Data Engineer at Oracle Cloud Infrastructure will participate in building global scale data ingestion, analytics and prediction frameworks for Oracle Cloud Infrastructure (OCI) and its customers. In this role, the Data Engineer will build flexible and scalable solutions for sourcing and ingesting Petabytes worth of structured and non-structured data. The engineer will design, build and maintain vast data lakes and data stores, understanding various data consumption and data visualization models using core Oracle technologies. The Data Engineer will work closely with business teams to develop these platforms that will drive the next generation of data science and predictive insights/intelligence

Basic Qualifications
3+ years of data management and engineering
3+ years of database management and engineering using Oracle database technologies
3+ years of data modeling experience for Analytical and OLTP systems
3+ years of Object Oriented software development experience
3+ years of hands-on hardware management and operating systems experience (Unix, Linux)
3+ years of hands-on experience working with cloud technologies (OCI, AWS, Azure, GCP)
Bachelor’s degree in Computer Science, Engineering, Mathematics or Physical Sciences
Preferred Qualifications
Master’s Degree in Computer Science, MBA
5+ years’ experience as an Oracle Database Engineer (versions 11g+)
5+ years as a Data Engineer working with Petabyte scale Data Warehouses and Data Lakes
Experience with Oracle suite of products including Oracle Database, Oracle Autonomous Data Warehouse, Oracle Application Cloud, Oracle Data Integration, OBIEE
3+ Years hands on experience with PL/SQL, Java/Python
Oracle supports workforce diversity and is an equal employment opportunity employer.

Detailed Description and Job Requirements

Design, develop, troubleshoot and debug software programs for databases, applications, tools, networks etc.

As a member of the software engineering division, you will assist in defining and developing software for tasks associated with the developing, debugging or designing of software applications or operating systems. Provide technical leadership to other software developers. Specify, design and implement modest changes to existing software architecture to meet changing needs.

Duties and tasks are varied and complex needing independent judgment. Fully competent in own area of expertise. May have project lead role and or supervise lower level personnel. BS or MS degree or equivalent experience relevant to functional area. 4 years of software engineering or related experience.

Oracle is an Affirmative Action-Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability, protected veterans status, age, or any other characteristic protected by law."
79,Data Engineer,"Seattle, WA 98101",Seattle,WA,98101,None Found,None Found,None Found,None Found,None Found,None Found,"Are you passionate about customers and end-users, and does that passion translate to your ability to lead, run and drive seamless and timely product implementation? Do you have a technical background that allows you solve hard problems on the fly, while using your business skills to communicate easily to customers about what is happening, and why?
If the opportunity to combine your technical acumen and your product, customer and business thinking prowess to deliver delightful customer implementation experiences in an emerging and critical market sounds like something you'd like to take on with a collaborative, motivated team at a growing start-up, send us your resume today!
What you can expect to do:
Perform customer deployment and implementation processes that ensure timely, accurate delivery of the Integris product suite
Create, manage and deploy complex software components in and at various customer ecosystems
Create clear documentation of processes and workflows, iterating as the product evolves, and communicate new ideas, changes and strategies both internally and externally
Assist the software engineering team in building the next generation, best-in-class privacy and data risk intelligence platform at scale
Perform hands-on coding to deliver product features that reveal key insights for all our enterprise and cloud partners
Architect and build Lego-like micro-services infrastructures that establish a highly scalable, performant data pipeline to handle both data at rest and data in motion, both on cloud and on-premise.
Lead by example, exhibiting the Integris values (H.E.A.R.T.)
What you bring to the table:
Strong coding skills and computer science fundamentals
Experience programming in Java in an industry role
Know-how of Bigdata ETL/Data Engineering (a huge plus)
Functional data-engineering skills, working with tools like Hadoop, Kafka, and/or Apache Storm
Ability to meet the needs of a continuous deployment environment, and to use tools like Python, Ansible, and JavaScript
Understanding of data source technologies like Oracle, MongoDB, Cassandra, MySQL, etc.
Ability to contribute to DevOps operations with working knowledge of container-based technologies like Docker, Kubernetes, Linux/Ubuntu
Experience working with cloud stacks like AWS (EC2, S3, EMR, Redshift), Azure, and Google Cloud
Expertise with code processes and process tools like Git, Jenkins (for CI), and Restful APIs
At least 5+ years of experience in a technical role, including some responsibility for big-data technologies
Stellar communication skills: whether speaking or writing, you've got communication nailed
A great attitude: we collaborate like crazy, and you can build relationships at all levels of the organization
A degree: A Bachelor's degree in Computer Science in a related field is preferred; a graduate degree is a bonus
What we put on the table:
The opportunity to tackle timely, interesting and challenging problems that matter
A solid funding story that includes backing from Madrona Venture Group, Aspect Ventures, Workday Ventures, and Amplify Partners
An incredible leadership team committed to leading by example with integrity, and to success
A fun, collaborative culture that enables our people to do their best work, and have a bunch of fun while doing it
The opportunity to learn, grow and develop your professional skill set
Our H.E.A.R.T. (Company Values):
Humility: We check our egos at the door and celebrate our diversity, individuality, right to privacy and the contributions of all
Excellence: We strive to do our best in intent and action, and commit this excellence to each other
Accountability: We dream, crave feedback, take ownership, and are accountable in an effort to continuously improve as a collective
Resourcefulness: We are resourceful, we persevere through any challenge, are tenacious, and results driven
Transparency: We are transparent in our interactions and communication with each other
Competitive compensation packages that include equity ownership and a variety of benefits
Who we are:
Integris Software, headquartered in downtown Seattle and founded in 2016, is a Data Privacy Automation vendor. Data has become the single most important asset for many organizations, and enterprises need a defendable and scalable data privacy solution that can adapt to a constantly evolving data landscape. The Integris industry-leading solution suite continuously monitors sensitive data that enables a defensible compliance strategy for enterprises and allows businesses to have confidence that their customers are protected.
We celebrate our inclusive culture, and welcome diversity in age, race, gender, gender identity, religion, and ethnicity to help keep our innovation and learning spirit alive.
R5QAEe0FI2"
80,"Senior Data Engineer, BI and Analytics (5905)","Seattle, WA 98104",Seattle,WA,98104,None Found,None Found,None Found,None Found,None Found,None Found,"Avalara, Inc., (www.Avalara.com), is a leading provider of cloud-based software that delivers a broad array of compliance solutions related to sales tax and other transactional taxes.

Job Summary: The Data Engineer within the BI and Analytics team will be a major contributor and architect of Avalara's cloud based centralized reporting platform. Hence strong experience in large scale reporting platforms, MPP cloud data technologies, advanced ETL/ELT and data streaming tools and deep understanding of long term benefits and pitfalls of various data structures (NOSQL vs SQL) is an absolute must.

Responsibilities :

Build a long term 'data analytics stack' for Avalara. Work with the product managers, DBA teams and broader engineering teams build scalable data orchestration, transformation and reporting streams that can capture and prepare billions of transactions per day for customer reporting.
Build strong and captivating data visualizations in PowerBI/Tableau Experience building powerful dashboards which are embedded in web and mobile applications is a major plus.
Practice/Implement data security, encryption and masking policies across various data sets and data sources.
Develop and manage end-to-end project plans and ensure on-time delivery.
Communicate status and big picture to the project team and management.
Work with business and engineering teams to identify scope, constraints, dependencies, and risks.
Identify risks and opportunities across the business and drive solutions.
Minimum Qualifications

8+ years combined in data engineer, business intelligence and in-app embedded analytics.
Advanced SQL, scripting (Python or R) and advanced data visualization experience a must.
Bachelor's degree in Computer Science or Engineering, or equivalent work experience
Experience managing efforts in distributed systems and/or developing large scale web applications
Proven ability to combine business acumen, technical acumen and process expertise to define client (internal/external) engagement and program execution
Ability to communicate effectively with technical and non-technical stakeholders across multiple business units
Excellent problem-solving skills
(5602)"
81,"Data Engineer, Alexa Smart Home","Bellevue, WA",Bellevue,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelor’s degree in Computer Science, Mathematics, Statistics, Finance, related technical field, or equivalent work experience.7+ years of professional experience3+ years of relevant work experience in analytics, data engineering, business intelligence, market research or related fieldExperience gathering business requirements, using industry standard business intelligence tool(s) to extract data, formulate metrics and build reportsExperience w/ Python/Shell scripting and Java/Scala codingExperience using SQL, ETL and databases in a business environment

Alexa is the Amazon cloud service that powers Echo, the groundbreaking new Amazon device designed around your voice. We believe voice is the most natural user interface for interacting with the home and is fundamental to enabling the dream of the smart, connected home.

We are looking for candidates who want to help shape the future of human-computer interactions. Specifically, we are looking for an outstanding Data Engineer who is looking to work in a new space to help define how we use multi-modal data (voice, mobile, desktop) to understand customer behavior and satisfaction. In this role, you will develop and support the analytic technologies that give our teams flexible and structured access to their data, including implementation of a BI platform, defining metrics and KPIs, and automating reporting and data visualization.

Responsibilities

You know and love working with business intelligence tools, can model multidimensional datasets, and can partner with customers to answer key business questions. You will also have the opportunity to display your skills in the following areas:

Design, implement, and support a platform providing ad hoc access to large datasetsInterface with other technology teams to extract, transform, and load data from a wide variety of data sources using SQLModel data and metadata for ad hoc and pre-built reportingInterface with business customers, gathering requirements and delivering complete reporting solutionsOwn the design, development, and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisionsRecognize and adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentationContinually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customersParticipate in strategic & tactical planning discussions, including annual budget processes

Graduate degree in computer science, business, mathematics, statistics, economics, or other quantitative fieldExperience in consumer-facing industryBoth technically deep and business savvy enough to interface with all levels and disciplines within the organizationDemonstrated ability to coordinate projects across functional teams, including engineering, IT, product management, marketing, finance, and operationsProven track record of successful communication of analytical outcomes through written communication, including an ability to effectively communicate with both business and technical teamsExpert with SQL, ETL (and general data wrangling)Experience with data visualization using Tableau or similar toolsExperience with AWS technologies including Redshift, RDS, S3, EMR, EMLSelf-starter that is comfortable with ambiguity in a fast-paced and ever-changing environmentAble to think big while paying careful attention to detail.Exemplary communication skills
Amazon is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age"
82,Big Data Engineer,"Renton, WA",Renton,WA,None Found,None Found,None Found,"5-years in SQL, SQL Server, Oracle, JDBC
5-years in Hadoop, HDFS, MapReduce, YARN
5-years in Sqoop, Oozie, Parquet, Hive, Impala, Spark, HBase, HUE
",None Found,None Found,None Found,"Job Details
Job Code
JPSC-6693
Posted Date
01/12/18
Experience
8 Years
Primary Skills
Oracle,FIORI,sql server,Hive,MapReduce,HDFS,Oozie,• 5-years in SQL,JDBC • 5-years in Hadoop,YARN • 5-years in Sqoop,Parquet
Required Documents
Resume
Overview
Role: Big Data Engineer
Location: Renton, Washington
Duration: 6 Months
Top Three Skills:
5-years in SQL, SQL Server, Oracle, JDBC
5-years in Hadoop, HDFS, MapReduce, YARN
5-years in Sqoop, Oozie, Parquet, Hive, Impala, Spark, HBase, HUE

Job Description:
Client is looking for a Big Data, Data Engineer.
This is deployed on the Microsoft Azure platform using core Cloudera technologies such as Cloudera Director 2.1, CDH 5.7, and Cloudera Manager along with Apache Hive, Yarn, HBase, and Spark.
Cloudera based data lake
CDH 5.7.3 on Azure cloud platform
Moving data from large SQL Server based tables into lake is biggest challenge
Concerns around Incremental data load strategy
Performance and Scalability issues in order to meet SLA with business teams
Limited internal bandwidth and skill set on No SQL database (Hbase)
Data Source - Epic (Clarity DB)
Mostly all structure data sets to ingest to lake
Large volume of data in some tables
 Please Fill up following details and send me back ASAP if you’re interested in this Position.

Full Name:
Email id:
Contact Information:
Current Location:
Visa status (Need Visa copy):
Visa Validity:
Availability:
Preferred interview timings:
Are you ready for F2F Interview:
Willingness to relocate across US:
Reason for looking new project :
Year of Graduation & Degree & university Name:
Date of Birth:
Skype ID:
Last 4 Digits of SSN:
References:
Details
Reference-1
Reference-2

Full Name

Company

Designation

Contact/Email

Syed Raza
585 532 7200 Ext 9002
Syed.j@avanitechsolutions.com"
83,"Snr, Data Engineer, WWCS","Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"7+ years industry experience as a Data Engineer or in a related field (i.e. Business Intelligence Engineer, Quantitative Analyst, Data Scientist, Software Engineer, etc.) with a strong track record of working with large and unstructured datasetsData Warehousing Experience with Oracle, Redshift, Teradata, etc.Proficiency in Python or another general-purpose programming language.Understanding of data management fundamentals, data storage principles and distributed systemsHands-on experience with cloud computing and UNIX/Linux based systems.Advanced Query performance tuning skills

We are rebuilding the tool used to drive CS quality from scratch. In this role, you will be working with SDEs, PMs, and BIEs to develop and implement a DE strategy in one of the world's largest data environments. You should be passionate about working with disparate datasets, ingesting new data and connecting it all to drive better customer experiences.

KEY RESPONSIBILITIES:
Lead the DE function for Amazon’s global Customer Service Operational Excellence TeamDesign and develop efficient and reliable data pipelines. You will need to capture and store comments from thousands of customer service managers (CSMs) and vend quality metrics to hundreds of thousands of end users.Provide Redshift server administration and infrastructure support for a large-scale analytical platform providing adhoc access to large datasetsWork with a Machine Learning (ML) team to capture model outputs and vend them to end users.Enhance the automation framework used to source, compile and distribute key business intelligence to stakeholdersBuild near real-time data solutions

Master's degree in an engineering or technical field such as Computer Science, Physics, Mathematics, Statistics, or EngineeringExperience leading large-scale data warehousing and analytics projects, including using AWS technologies – Redshift, S3, EC2, EMR, Kinesis, etc.Knowledge of Reporting tools such Tableau, Power BI or QuickSightExperience with distributed systems and NoSQL databasesExperience with Big Data technologies (e.g. Hadoop, Hive, Oozie, Presto, Hue, Spark, Scala, etc)
Amazon.com is an Equal Opportunity Employer – Minority /
Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age."
84,Data Scientist / Data Engineer,"Bellevue, WA",Bellevue,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Data Scientist / Data Engineer (Bellevue, WA)
Location: Bellevue, Washington, United States
Full-timeAllows Remote
The New York Times describes Thunder as ""an ad engine to put Mad Men out of business."" We're changing how digital ads are created and distributed by automating much of what people thought couldn't be done by computer. Our technology retrieves all relevant content about an advertiser across the web to intelligently design a beautiful set of ads for desktop, tablet, and mobile devices all in under a minute.


THE JOB

Thunder is looking for a talented Data Scientist with a track record working with Big Data and Distributed Systems to manage a cutting-edge infrastructure used by the world’s largest digital advertisers. We’re using Big Data in groundbreaking ways to uncover customer insights, personalize customer experiences and fix digital advertising. You will contribute as a key member of the Product Engineering team where you will be driving product and engineering innovation to better leverage Thunder's growing personal graph. We are looking for a self-starter who thrives with ambiguity and loves solving challenging problems.


RESPONSIBILITIES

Design and develop Big Data and real-time analytics solutions using industry standard technologies
Collaborate with internal business and product teams to identify product features that can be powered by advanced data analytics
Use various machine learning and statistical techniques to analyze data, build models and identify requirements for operationalizing those models into production services
Work with external customers on challenging data analysis problems


QUALIFICATIONS

Ideal candidates will have hands-on, operational experience building and operating large-scale data analytics services and thrive working in a fast-paced startup environment.

5 -7 years of hands-on experience with using advanced statistics techniques and machine learning to build operational production services
Strong understanding of machine learning, recommendation systems, predictive analytics, and multivariate analysis
Strong computer science fundamentals including data structures, algorithms, distributed systems and common design patterns
Strong database and data engineering experience with hands-on experience building services that leverage a variety of database systems including SQL, Redshift Spectrum, Druid, Hadoop, Hive, HBase, Spark, Kafka, AWS Kinesis, MongoDB
B.S. or M.S. in Computer Science, Computer Engineering, Mathematics, Statistics, Applied Mathematics or related experience"
85,Sr Software Engineer,"Bellevue, WA",Bellevue,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"eBay is looking for a skilled and dynamic big data engineer to help drive the evolution of data acquisition and delivery in a high-performance, massive-scale analytics environment that powers a rapidly growing business where over 100 million active worldwide users.

You will assist in developing our suite of capabilities that enable rapid development on our platforms for data acquisition, transformation, integration, delivery, and presentation. All applications in this environment are characterized by extremely large data and processing volumes, as such, there is a premium placed on hyper-efficient design leveraging low-cost, highly- scalable infrastructure. You will focus on enhancing our existing, world-class analytics application to improve data availability, data quality, and speed of data. Experience supporting Machine Learning algorithms will also be beneficial.

People in the team are friendly, highly motivated, and extremely bright. Our team tries to maintain a work climate of professionalism, innovation, career growth, and fun. We provide you with the best opportunity to work in a challenging, highly visible and fast paced environment.
Job Requirements
Proficiency in big data technologies including Hadoop
Excellent programming skills - Java/Python/Scala
Advanced SQL expertise with excellent understanding of SET operations
Working knowledge of Hadoop Systems (Hive, MapR, Spark, HDFS)
Expertise with Linux File and directory permissions.
Strong knowledge of cloud technologies, distributed systems programming
Outstanding problem solving skills
Excellent communication skills
Experience with agile and waterfall project development methodologies
Experience with Spark, Storm, Kafka is a big plus
Working knowledge of traditional RDMS systems like Teradata is a plus but not necessary
This website uses cookies to enhance your experience. By continuing to browse the site, you agree to our use of cookies
View our privacy policy
View our accessibility info
eBay Inc. is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, sex, sexual orientation, gender identity, veteran status, and disability, or other legally protected status. If you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at talent@ebay.com. We will make every effort to respond to your request for disability assistance as soon as possible.
For more information see:
EEO is the Law Poster
EEO is the Law Poster Supplement"
86,Data Engineer II,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"A desire to work in a collaborative, intellectually curious environment.Degree in Computer Science, Engineering, Mathematics, or a related field and 4-5+ years industry experienceOne year of experience in the following skill(s):Developing and operating large-scale data structures for business intelligence analytics using: ETL/ELT processes; OLAP technologies; data modeling; SQL;Experience with at least one relational database technology such as Redshift, Oracle, MySQL or MS SQLExperience with at least one massively parallel processing data technology such as Redshift, Teradata, Netezza, Spark, or Hadoop based big data solutionsCoding proficiency in at least one modern programming language (Python, Ruby, Java, etc)Experience in gathering requirements and formulating business metrics for reporting

HS3C-Compliance is responsible for keeping our Customers and partners safe, and ensuring we maintain WW compliance. We build scalable solutions that grow with the Amazon business. HS3C-Compliance team collects petabytes of data from thousands of data sources inside and outside Amazon including the Amazon catalog system, inventory system, customer order system, and page views on the website. We provide interfaces for our internal customers to access and query the data hundreds of thousands of times per day, using Amazon Web Service’s (AWS) Redshift, Hive, and Spark.
HS3C-Compliance is growing, and the data processing landscape is shifting. Our data is consumed by teams across HS3C including Research Scientists, Machine Learning Specialists, Business Analysts, and Data Engineers. We are seeking an outstanding Data Engineer to join the HS3C-Compliance data technologies team. The HS3C-Compliance data technologies team manages the core HS3C business data from hundreds of source systems. Amazon has culture of data-driven decision-making, and demands business intelligence that is timely, accurate, and actionable. If you join the HS3C-Compliance data technologies team, your work will have an immediate influence on day-to-day decision making at Amazon.

As an Amazon Data Engineer II, you will be working in one of the world's largest cloud-based data lakes. You should be skilled in the architecture of data warehouse solutions for the Enterprise using multiple platforms (EMR, RDBMS, Columnar, Cloud). You should have extensive experience in the design, creation, management, and business use of extremely large datasets. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions, and to build data sets that answer those questions. Above all you should be passionate about working with huge data sets and someone who loves to bring datasets together to answer business questions and drive change.

As a Data Engineer II on the HS3C-Compliance data technologies team, you will design, develop, implement, test, document, and operate large-scale, high-volume, high-performance data structures for analytics and deep learning. Implement data ingestion routines both real time and batch using best practices in data modeling, ETL/ELT processes leveraging AWS technologies and Big data tools. Gather business and functional requirements and translate these requirements into robust, scalable, operable solutions that work well within the overall data architecture. Analyze source data systems and drive best practices in source teams. Participate in the full development life cycle, end-to-end, from design, implementation and testing, to documentation, delivery, support, and maintenance. Produce comprehensive, usable dataset documentation and metadata. Evaluate and make decisions around dataset implementations designed and proposed by peer data engineers. Evaluate and make decisions around the use of new or existing software products and tools. Mentor junior data engineers.

Industry experience as a Data Engineer or related specialty (e.g., Software Engineer, Business Intelligence Engineer, Data Scientist) with a track record of manipulating, processing, and extracting value from large datasets.Coding proficiency in at least one modern programming language (Python, Ruby, Java, etc)Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data setsExperience building data products incrementally and integrating and managing datasets from multiple sourcesQuery performance tuning skills using Unix profiling tools and SQLExperience leading large-scale data warehousing and analytics projects, including using AWS technologies – Redshift, S3, EC2, Data-pipeline and other big data technologiesExperience providing technical leadership and mentor other engineers for the best practices on the data engineering spaceLinux/UNIX including to process large data sets.Experience with AWS"
87,Data Engineer II - Payment Acceptance & Experience,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelor’s Degree in Computer Science or related field, or 4+ year relevant work experience2+ years professional experience in software developmentComputer Science fundamentals in object-oriented designComputer Science fundamentals in data structuresComputer Science fundamentals in algorithm design, problem solving, and complexity analysis Proficiency in, at least, one modern programming language such as C, C++, Java, or PerlExperience with AWS technologies2+ years professional experience in data engineeringData engineering fundamentals in data set designData engineering fundamentals in data architecture

The Payments Acceptance & Experience (PAE) organization makes paying on Amazon possible for millions of around the world. The PAE Data team is a cross functional team of data engineers, scientists, and business intelligence professionals that are constantly looking to improve data availability and accessibility for a variety of use cases. Our team provides a full-stack data solution - everything from building data capture mechanisms into software services to building business forecasts and deploying machine learning (ML) models. We are looking for motivated individuals to contribute immediately to our team in Seattle, Washington. The selected candidates will act as data engineers to design and develop sustainable, large-scale data solutions that integrate with various software and ML services using AWS building blocks whenever possible. We are also looking to develop a flexible ML data suite, with a feature repository, run time feature engineering capabilities, and versioning control to accelerate model building and deployment, so functional SDE skills are required for these positions.

Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation

Experience building complex software systems that have been successfully delivered to customersKnowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operationsAbility to take a project from scoping requirements through actual launch of the projectExperience in communicating with users, other technical teams, and management to collect requirements, describe software product features, and technical designs.
Amazon is an equal opportunity employer"
88,Data Engineer,"Seattle, WA 98101",Seattle,WA,98101,None Found,"
Bachelor’s Degree in computer science or relevant information technology field
3-4 years of DBA experience
3-4 years of SQL replication experience and managing complex ETL processes","
Ability to communicate effectively with stakeholders to define requirements
Proficiency in writing SQL procedures and functions for administration and application support
Strong knowledge of operating systems, shell scripting, and python scripting
Good interpersonal skills along with effective communication (both written and verbal)
Demonstrated ability to solve complex systems and database environment issues
Experience with cloud platforms (AWS and AZURE)
Experience building data pipelines & ETL
Experience with command line
Experience with version control software (git) and best practices
Demonstrated experience leading database architecture development
Experience with big data technologies at scale
Strong understanding of PostgreSQL database fundamentals
Strong understanding of database security management
Experience with ETL tools
Experience with BI tools
Willingness to take ownership over wide range of databases and processes","
Collaborate with senior management, product management, data analytics, and web/app developers in the development of data products, pipelines, and infrastructure
Develop reliable and near real time data pipelines that make data easily consumable by end users and other systems that we use at All Star
Develop tools to monitor, debug, and analyze data pipeline health
Design and implement data schemas and models that can scale
Mentor technology team members to build the company's overall expertise
Administer all database automation and take corrective action when required",None Found,None Found,"Job Description:
Who We Are
Since 2001, All Star Directories has been empowering people to advance their careers and improve their lives through education. As an independent marketing and technology company, we build long-term relationships with higher education institutions across the nation while providing millions of students with the resources they need to help them reach their goals.

At All Star, we pride ourselves on our authenticity, accountability, and flexibility. Our team is made up of hardworking, collaborative, and highly motivated people who strive to stay ahead of industry trends. Here, we work in an Agile environment on challenging projects both big and small, with each day offering new opportunities for growth.

All of our hard work is rewarded with competitive salaries, incredible benefits, and serious fun. After all, as an employee-owned company, we care about the people who work here just as much as the customers we serve. Joining the All Star team means generous PTO, ping pong tournaments, in-office massages, and a fully stocked fridge. (Oh, and your dog can join us too.) We also care deeply about our community, offering paid volunteer days off as well as toy and clothing drives throughout the year.
https://www.allstardirectories.com
Who You Are
We are looking for a passionate and experienced Data Engineer. The successful candidate will drive automation, personalization and data pipeline initiatives. You will own critical systems throughout our various platforms and be responsible for their development, new/valuable features, and administering that these systems perform correctly in production.

Required Experience:

Responsibilities
Collaborate with senior management, product management, data analytics, and web/app developers in the development of data products, pipelines, and infrastructure
Develop reliable and near real time data pipelines that make data easily consumable by end users and other systems that we use at All Star
Develop tools to monitor, debug, and analyze data pipeline health
Design and implement data schemas and models that can scale
Mentor technology team members to build the company's overall expertise
Administer all database automation and take corrective action when required
Essential Skills and Experience
Ability to communicate effectively with stakeholders to define requirements
Proficiency in writing SQL procedures and functions for administration and application support
Strong knowledge of operating systems, shell scripting, and python scripting
Good interpersonal skills along with effective communication (both written and verbal)
Demonstrated ability to solve complex systems and database environment issues
Experience with cloud platforms (AWS and AZURE)
Experience building data pipelines & ETL
Experience with command line
Experience with version control software (git) and best practices
Demonstrated experience leading database architecture development
Experience with big data technologies at scale
Strong understanding of PostgreSQL database fundamentals
Strong understanding of database security management
Experience with ETL tools
Experience with BI tools
Willingness to take ownership over wide range of databases and processes
Qualifications
Bachelor’s Degree in computer science or relevant information technology field
3-4 years of DBA experience
3-4 years of SQL replication experience and managing complex ETL processes
From: All Star Directories

Benefits:
We provide a full benefits package including:
Medical, Dental, and Vision
401(k) with company match
Commuter benefits (ORCA card or parking stipend)
Generous PTO and Volunteer Time Off
Eight paid holidays
Full kitchen with coffee and snacks
An amazing office one block from Pike Place Market with views of Elliot Bay."
89,Senior Software Engineer,"Redmond, WA",Redmond,WA,None Found,None Found,"Dedication for design and enjoy crafting highly performance servicesExperience with an OO programming language like Java/C#/C++; Experience with at least one scripting language (Python, Perl, Ruby, Shell etc.).Experience in data transformation and data visualization.Familiar with various machine learning toolkits and productionalizing machine learning models.Have experience building production data pipelines using one or more frameworks such as Spark, Flink or Hive/Hadoop.Experience with Data Warehouse design, ETL (Extraction, Transformation & Load), architecting efficient software designs for DW platform.Experience with highly scalable, distributed service architectures, productionalizing ML models, high velocity streaming pipelines or high scale data pipelines, etc.Experience with technologies such as Azure Data Lake, Hadoop, Spark, Hive, Kusto, Elasticsearch, etc.Familiarity with Gaming and Social Network domains.A strong performance history.",None Found,"Chip in to and learn from a wider community of developers at Xbox to innovate and craft excellent services for our customers.Integrate and solve cloud services used in numerous customer experiences across multiple platforms.You are experienced in a wide array of ML techniques, with a penchant for problem solving.You are extraordinary with the theoretical, practical, and business aspects of machine learning.As a product innovator, you will ideate, scope, and drive implementation and validation.",None Found,None Found,"Xbox Live, the leading gamer network spanning console, PC and mobile games, is central to Microsoft’s gaming strategy. Xbox Live provides the breadth of social gaming experiences with Xbox Live clubs, friends, chat, messaging, community hubs, game hubs, game activity feed, and much more. Xbox Live has an exemplary future as it expands to serve many more scenarios where consumers, and creators inspire each other.

We are looking for a creative, analytical and experienced software and data engineer to join our group of similarly inspired and hardworking engineers. You will help us build the next generation of experiences that will make Xbox Live the best community for everyone. You will closely collaborate with Xbox developers, designers, and data scientists, helping us deepen our understanding of gamers and their relationship with other gamers and game content, to provide more meaningful and richer experiences.

Xbox Live is an extraordinary place to work – for every gamer, and every non-gamer with a real passion for deeply understanding our current and future gaming fans. It is a place where we recognize that we are better when we work together, and even better still when we lift and grow one another. We are made stronger by our array of dynamic perspectives and ideas. And we have fun, a lot of fun. You should join us.
ResponsibilitiesChip in to and learn from a wider community of developers at Xbox to innovate and craft excellent services for our customers.Integrate and solve cloud services used in numerous customer experiences across multiple platforms.You are experienced in a wide array of ML techniques, with a penchant for problem solving.You are extraordinary with the theoretical, practical, and business aspects of machine learning.As a product innovator, you will ideate, scope, and drive implementation and validation.
We do not have a fixed list of requirements. You are excited for the end to end experience. You will deliver actionable insights, recommendations and product improvements. Deeply understanding what excites our existing users and what motivates new users to join Xbox Live is core to our success, and your skills are central to this success.
Qualifications

BA/BS or advanced degree in computer science, statistics, math, economics, business or engineering is ideal
Dedication for design and enjoy crafting highly performance servicesExperience with an OO programming language like Java/C#/C++; Experience with at least one scripting language (Python, Perl, Ruby, Shell etc.).Experience in data transformation and data visualization.Familiar with various machine learning toolkits and productionalizing machine learning models.Have experience building production data pipelines using one or more frameworks such as Spark, Flink or Hive/Hadoop.Experience with Data Warehouse design, ETL (Extraction, Transformation & Load), architecting efficient software designs for DW platform.Experience with highly scalable, distributed service architectures, productionalizing ML models, high velocity streaming pipelines or high scale data pipelines, etc.Experience with technologies such as Azure Data Lake, Hadoop, Spark, Hive, Kusto, Elasticsearch, etc.Familiarity with Gaming and Social Network domains.A strong performance history.

#xboxlivejobs
#getjobs
#gamingjobs

Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.

Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.

XGAXGETXBL"
90,Data Engineer II (L5) - Business Data Technologies,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"A desire to work in a collaborative, intellectually curious environment.Degree in Computer Science, Engineering, Mathematics, or a related field and 4-5+ years industry experienceMust have one year of experience in the following skill(s):Developing and operating large-scale data structures for business intelligence analytics using: ETL/ELT processes; OLAP technologies; data modeling; SQL;Experience with at least one relational database technology such as Redshift, Oracle, MySQL or MS SQLExperience with at least one massively parallel processing data technology such as Redshift, Teradata, Netezza, Spark or Hadoop based big data solution

Amazon’s eCommerce Foundation (eCF) organization is responsible for the core components that drive the Amazon website and customer experience. Serving millions of customer page views and orders per day, eCF builds for scale.
As an organization within eCF, the Business Data Technologies (BDT) group is no exception. We collect petabytes of data from thousands of data sources inside and outside Amazon including the Amazon catalog system, inventory system, customer order system, page views on the website and Alexa systems. We also support Amazon subsidiaries such as IMDB and Audible. We provide interfaces for our internal customers to access and query the data hundreds of thousands of times per day, using Amazon Web Service’s (AWS) Redshift, Hive, and Spark. We build scalable solutions that grow with the Amazon business.

BDT is growing, and the data processing landscape is shifting. Our data is consumed by thousands of teams across Amazon including Research Scientists, Machine Learning Specialists, Business Analysts and Data Engineers. Amazon.com is seeking an outstanding Data Engineer to join the BDT Content team. The BDT Content team manages the core Amazon business data from hundreds of source systems. Amazon.com has culture of data-driven decision-making, and demands business intelligence that is timely, accurate, and actionable. If you join the Amazon.com BDT Content team, your work will have an immediate influence on day-to-day decision making at Amazon.com.

As an Amazon.com Data Engineer II you will be working in one of the world's largest cloud-based data lakes. You should be skilled in the architecture of data warehouse solutions for the Enterprise using multiple platforms (EMR, RDBMS, Columnar, Cloud). You should have extensive experience in the design, creation, management, and business use of extremely large datasets. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions, and to build data sets that answer those questions. Above all you should be passionate about working with huge data sets and someone who loves to bring datasets together to answer business questions and drive change.

As a Data Engineer II on Amazon.com’s Business Data Technologies team, design, develop, implement, test, and operate large-scale, high-volume, high-performance data structures for analytics and deep learning. Implement data ingestion routines both real time and batch using best practices in data modeling, ETL/ELT processes leveraging AWS technologies and Big data tools. Gather business and functional requirements and translate these requirements into robust, scalable, operable solutions that work well within the overall data architecture. Analyze source data systems and drive best practices in source teams. Participate in the full development life cycle, end-to-end, from design, implementation and testing, to documentation, delivery, support, and maintenance. Produce comprehensive, usable dataset documentation and metadata. Evaluate and make decisions around dataset implementations designed and proposed by peer data engineers. Evaluate and make decisions around the use of new or existing software products and tools. Mentor junior data engineers.

Industry experience as a Data Engineer or related specialty (e.g., Software Engineer, Business Intelligence Engineer, Data Scientist) with a track record of manipulating, processing, and extracting value from large datasets.Coding proficiency in at least one modern programming language (Python, Ruby, Java, etc)Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data setsExperience building data products incrementally and integrating and managing datasets from multiple sourcesQuery performance tuning skills using Unix profiling tools and SQLExperience leading large-scale data warehousing and analytics projects, including using AWS technologies – Redshift, S3, EC2, Data-pipeline and other big data technologiesExperience providing technical leadership and mentor other engineers for the best practices on the data engineering spaceLinux/UNIX including to process large data sets.Experience with AWS
Amazon is an equal opportunities employer. We believe passionately that employing a diverse workforce is central to our success and we make recruiting decisions based on your experience and skills. We welcome applications from all members of society irrespective of age, gender, disability, sexual orientation, race, religion or belief."
91,Renewable Data Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelor's degree in computer science, engineering, mathematics, or a related technical discipline3+ years of relevant experience data engineering or business intelligence roles2+ years of experience in scripting languages such as Python, Ruby, Perl, Bash2+ years of database experience in database schema design, writing advanced SQL queries, data warehousing in Redshift, Oracle, MySQL, or other relational database systems2+ years of experience with ETL and report automation1+ years of experience creating visual data representations, such as Tableau, QuickSight, or other BI platforms

Do you love transforming raw data to business critical decisions? Are you excited to be a part of a more renewable, sustainable future?

The AWS Renewable Energy Team is looking for a passionate, results-oriented Renewable Energy Data Engineer to build our renewable energy data platform. The candidate will help AWS march toward its goal of powering our global data center infrastructure with 100% renewable energy. This role will work with data on a scale unique to our business. Collaborating with our data scientists, the Data Engineer will turn this data into valuable business information. This information will drive solutions to problems regarding the optimization of data center power procurement and renewable energy projections.

A successful candidate will streamline data collection process, build automation tools, enhance the quality of the data, and develop the visual dash boarding to monitor our renewable energy portfolio performance and identify new financial opportunities. We obtain this information from multiple sources via APIs, SCADA systems, utility online portals, real estate and construction databases and documents, internal Redshift databases, accounting systems, invoices, and energy trading platforms. The ideal candidate will know how to design logical schemas that organize data in a meaningful, efficient way and understand how to build scalable and maintainable data pipelines. This candidate is an expert at data modeling, ETL design and business intelligence tools, and has hands-on knowledge of databases such as Redshift. The Data Engineer will partner closely with internal customers and research scientists to invent new technical solutions to highly complex energy data analytics problems.

Masters or MBA in related field1+ years of experience with AWS services such as Redshift, DynamoDB, S3, EC2, Lambda, EMR, RDS, Aurora1+ years with statistical software or programming languages such as R, SAS, Stata, JMP, Minitab1+ years of experience with big data technologies such as Hadoop, Hive, Hbase, Pig, SparkPrevious experience building risk-based financial models and advanced proficiency in ExcelProven track record partnering with business owners to understand requirements and developing analysis to solve their business problemsExcellent speaking-listening-writing skills and attention to detailsBe a passionate self-starterMeets/exceeds Amazon’s functional/technical depth and complexity for this roleMeets/exceeds Amazon’s leadership principles requirements for this role
Amazon.com is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation / Age."
92,Staff Data Engineer / Staff Software Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,"
Degree in Computer Science, Computer Engineering, or Statistics or commensurate experience
6-8 years of software engineering, Big Data Engineering and/or team lead experience
Proven track record of building and shipping large-scale engineering products
Experience working with large, complex data sets from a variety of sources
Ability to collaborate with a diverse set of engineers, data scientists and product managers
Experience with functional and object-oriented programming, Scala a plus
Experience with Databricks, Spark, AWS and EMR
Effective communication skills (both written and verbal), comfortable presenting to a group
Comfort in a fast-paced startup environment
",None Found,None Found,None Found,None Found,"About Foursquare:
Foursquare is the leading independent location technology platform, powering business solutions and consumer products through a deep understanding of location. Foursquare's business solutions include Pilgrim SDK, Places API, Analytics, Placed powered by Foursquare, and Pinpoint. Together, these products empower brands to analyze trends; measure foot traffic lift; optimize advertising campaigns; and drive deeper engagement via Foursquare's industry-leading developer tools, which have been selected by 150,000 developers including AccuWeather, Apple, Samsung, Microsoft, Snapchat, Tinder, TripAdvisor, Twitter and Uber. Our toolkit also includes our consumer apps Foursquare City Guide and Swarm. Over the past 10 years, we've counted more 13 billion verified signals from people around the world, helping us to keep our dynamic map and models fresh and up-to-date.

About our Engineering Team:
As a member of Foursquare's engineering team, we want you to bring experience building real products from the ground up. We're passionate about tackling tough challenges in the location space and look for others who like to dive deep into code and help solve hard problems. You should be comfortable running with your own ideas and eager to learn new skills on a bleeding edge platform. We use a variety of tools, technologies, and languages to build software (Scala, Python, Thrift, MongoDB, Memcached, JS/jQuery, Kafka, Pants, Hadoop, MR, Spark, Databricks) but experience with equivalent ones will do just fine.

As a senior/staff engineer on the team, you will own critical pieces of our machine learning and analytics platforms. You will build data processing pipelines that process terabytes of data every day, and collaborate with core tech's major teams, product owners across the company and actively build our next-gen products that set us apart in the location intelligence space.

About Core Tech Offline Visitation Team:
Pilgrim SDK, which is our always-on, passive location detection engine. It provides contextual awareness to mobile applications and connected devices to understand where and how users are moving through the real world. Pilgrim Core Visits are generated as a part of The Pilgrim SDK, the team is responsible for generating valuable visitation data that powers downstream products and consumers and internal tools. The team generates all the visits that are used across the entire company, which is the core infrastructure piece of Foursquare's location intelligence and is a high impact team with a big impact on the broader company success.

About the role:
Join us and help bring our feature ideas (and your own!) off the whiteboard and into reality.

As our Core Visits Staff Software Engineer, you will be responsible for the following:


Launch features that enable developers to build rich contextual location experiences in their apps.
Create and execute on technical designs, develop and deliver new Visitation Offline pipelines processing big data at scale.
Establish process and tooling improvements to increase code quality, bring in best practices team can learn from.
Build pipelines in Scala/Spark and/or Py/Spark to run on Databricks.
Mentor and coach junior engineers on the team and demonstrate leadership skills.
Collaborate with product owners and product managers on roadmaps and OKRs.
Work on cross-functional project teams with product managers, designers, Android engineers, and server engineers.

*** The position is available in our Seattle engineering office.

Qualifications:
---------------


Degree in Computer Science, Computer Engineering, or Statistics or commensurate experience
6-8 years of software engineering, Big Data Engineering and/or team lead experience
Proven track record of building and shipping large-scale engineering products
Experience working with large, complex data sets from a variety of sources
Ability to collaborate with a diverse set of engineers, data scientists and product managers
Experience with functional and object-oriented programming, Scala a plus
Experience with Databricks, Spark, AWS and EMR
Effective communication skills (both written and verbal), comfortable presenting to a group
Comfort in a fast-paced startup environment

Foursquare is proud to foster an inclusive environment that is free from discrimination. We strongly believe in order to build the best products, we need a diversity of perspectives and backgrounds. This leads to a more delightful experience for our users and team members. We value listening to every voice and we encourage everyone to come be a part of building a company and the products we love.

Foursquare is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected Veteran status, or any other characteristic protected by law."
93,"DATA ENGINEER I, AWS DATA PLATFORM","Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"This position requires a Bachelor's Degree in Computer Science or a related technical field, and 2+ years of meaningful employment experience.

2+ years of work experience with ETL, Data Modeling, and Data Architecture.Expert-level skills in writing and optimizing SQL.Experience with Big Data technologies such as Hive/Spark.Proficiency in one of the scripting languages - python, ruby, java or similar.Experience operating very large data warehouses or data lakes.Proven interpersonal skills and standout colleague.A real passion for technology. We are looking for someone who is keen to demonstrate their existing skills while trying new approaches.

Amazon Web Services is seeking an extraordinary Data Engineer to join the AWS Data Lake team.

Our teams take on some of the hardest scalability, performance, and distributed computing challenges the world. We process trillions of events per month using stream processing techniques (Kinesis), process billions of line items via map reduce (EMR) and handle artifacts through the latest in database technologies (DynamoDB and Aurora). We process big data and provide tools for customers to interactively understand their bills. We also provide the analytics that let customers handle billions of dollars of IT usage and spending. Because we sit at the nexus of all AWS services and interact directly with end-customers, we also work closely across all AWS teams to ensure that we offer a great customer experience.

The AWS Data Lake team's vision is to help customers handle the full life cycle of data at all levels of granularity, simplify data collection, integration, and aggregation of AWS data assets, and provide services (compute, storage, security) to access datasets at scale. We collect and process billions of usage and billing transactions every single day into actionable information in the Data Lake and make it available to our internal service owners to analyze their business and service our external customers.

We are truly leading the way to disrupt the data warehouse industry. We are accomplishing this vision by bringing to bear Big Data technologies like Elastic Map Reduce (EMR) in addition to data warehouse technologies like Redshift to build a data platform capable of scaling with the ever-increasing volume of data produced by AWS services. You will have the ability to craft and build AWS' data lake platform and supporting systems for years to come.

You should have deep expertise in the design, creation, management, and business use of large datasets, across a variety of data platforms. You should have excellent business and interpersonal skills to be able to work with business owners to understand data requirements, and to build ETL to ingest the data into the data lake. You should be an authority at crafting, implementing, and operating stable, scalable, low cost solutions to flow data from production systems into the data lake. Above all you should be passionate about working with huge data sets and someone who loves to bring datasets together to answer business questions and drive growth.

Authoritative in ETL optimization, designing, coding, and tuning big data processes using Apache Spark or similar technologies.Experience with building data pipelines and applications to stream and process datasets at low latencies.Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.Sound knowledge of distributed systems and data architecture (lambda)- design and implement batch and stream data processing pipelines, knows how to optimize the distribution, partitioning, and MPP of high-level data structures.Knowledge of Engineering and Operational Excellence using standard methodologies."
94,Senior Data Engineer,"Bellevue, WA",Bellevue,WA,None Found,None Found,None Found,None Found,"
Build and operate large scale data infrastructure in production.
Design, implement and debug distributed data processing systems.
Thinking through long-term impacts of key design decisions and handling failure scenarios.
Building self-service platforms to power all other OfferUp teams.
Mentor other engineers and help them with their growth.
Drive engineering best practices, set standards and propose larger projects which may require cross-team collaboration.
Contribute at a senior level to the data warehouse design and data preparation by implementing a robust and extensible design
Design and develop applications to process large amounts of critical information in batch and near real-time to power user-facing features.
Influence technical direction for the company, leveraging your prior experiences and helping evaluate emerging technologies and approaches.
",None Found,"
5+ years of professional software development experience.
Strong ability in distributed systems for processing large scale data processing.
Ability to communicate technical information effectively to technical and non-technical audiences.
Proficiency in Java, Scala and Python.
Experience leveraging open source data infrastructure projects, such as Apache Spark, Airflow, Kafka, Flink, Samza, Avro, Parquet, Hadoop, Hive, HBase.
Experience building data pipelines and real-time data streams.
Experience building software in AWS or a similar cloud environment is highly desirable.
Experience with AWS services like EMR, Kinesis, Firehose, Lambda, Sagemaker, Athena, Elasticsearch is a big plus.
Computer Science or Engineering degree required, Masters degree preferred.
Must be eligible to work in the United States.
","From the very beginning, OfferUp has believed that the right people united by the right mission can redefine the possible.

OfferUp is dedicated to building the simplest and most trustworthy way for people to buy and sell in their communities. Every year, millions of people use OfferUp to buy and sell locally, resulting in billions of dollars of local commerce. As the largest mobile marketplace for local buyers and sellers in the U.S., our iOS and Android app has been in the top five most popular shopping apps lists for more than three years. Join us as we build the marketplace of the future and help more people discover value right where they are.

At a Glance
-----------


85+ Million Downloads
Geekwire App of Year
15%+ of adults in several markets use OfferUp every month (LA, Miami, Phoenix, Seattle, Las Vegas, Riverside, Orlando)

Senior Data Engineer

Here at OfferUp, data is at the core of our business, providing insights into the effectiveness of our products, and enabling technology that powers them. As the Data Engineering team, we build and operate OfferUp's data platform for streaming and batch computation, for data analysis and BI, and to train ML models. If you're passionate about building large scale distributed data processing systems, and you are motivated to make an impact in creating a robust and scalable data platform used by every team, come join us. You will be part of a team that builds the data ingestion, transport, storage, and orchestration layers. You will help shape the vision and architecture of OfferUp's next generation data infrastructure, making it easy for developers to build data-driven products and features.

Building the largest and most responsive mobile marketplace poses unique data challenges that require leveraging the latest developments in data infrastructure. We leverage open source infrastructure where we can, but are ready to build and share solutions if they don't exist yet. You will be building an analytics platform working with cutting-edge technologies like Kafka, Spark, Snowflake, and Airflow.

We regard culture and trust highly, and are looking forward to welcoming your contribution to the team!

Responsibilities:

Build and operate large scale data infrastructure in production.
Design, implement and debug distributed data processing systems.
Thinking through long-term impacts of key design decisions and handling failure scenarios.
Building self-service platforms to power all other OfferUp teams.
Mentor other engineers and help them with their growth.
Drive engineering best practices, set standards and propose larger projects which may require cross-team collaboration.
Contribute at a senior level to the data warehouse design and data preparation by implementing a robust and extensible design
Design and develop applications to process large amounts of critical information in batch and near real-time to power user-facing features.
Influence technical direction for the company, leveraging your prior experiences and helping evaluate emerging technologies and approaches.

Requirements:

5+ years of professional software development experience.
Strong ability in distributed systems for processing large scale data processing.
Ability to communicate technical information effectively to technical and non-technical audiences.
Proficiency in Java, Scala and Python.
Experience leveraging open source data infrastructure projects, such as Apache Spark, Airflow, Kafka, Flink, Samza, Avro, Parquet, Hadoop, Hive, HBase.
Experience building data pipelines and real-time data streams.
Experience building software in AWS or a similar cloud environment is highly desirable.
Experience with AWS services like EMR, Kinesis, Firehose, Lambda, Sagemaker, Athena, Elasticsearch is a big plus.
Computer Science or Engineering degree required, Masters degree preferred.
Must be eligible to work in the United States.

OfferUp is changing the way people buy and sell locally...Come do work that matters. join the team and take the ride of your life!

OfferUp provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, OfferUp complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, transfer, leaves of absence, compensation, and training.

OfferUp expressly prohibits any form of workplace harassment based on race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, genetic information, disability, or veteran status. Improper interference with the ability of OfferUp's employees to perform their job duties may result in discipline up to and including discharge."
95,Senior Data Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"We are looking for Data Engineers who has a passion for data and a passion for supplying their clients with that data. You know and love working with analytic tools, can write excellent SQL and Unix scripts and can use your technical skills and creative approaches to solve some unique problems in the BI space, can partner with customers to answer key business questions, and you are an advocate for your customers and you have a sense of ownership. You don’t quit. You should also have the following skills or experiences:
Bachelors degree in CS or related technical field and 7+ years experience in Data WarehousingExcellent knowledge of SQL and UnixExcellent Knowledge of data warehousing concepts

From Jeff Bezos’s, 2014 Amazon shareholder letter (http://tinyurl.com/q8zpobu): “Internally, Marketplace was known as SDP for Single Detail Page. The idea was to take our most valuable retail real estate – our product detail pages – and let third-party sellers compete against our own retail category managers.” Today, millions of third party sellers offer products alongside Amazon Retail though the Amazon Marketplace. The Featured Merchant Algorithm (FMA) team owns the system and algorithms that select the offers that are featured on the ‘Add to Cart’ button (aka the ‘Buy Box’) on Amazon’s most valuable retail real estate – the Product Detail Page referenced above. The FMA team’s mission is to ensure that featured offers provide the best possible customer value based on factors including price, availability, delivery options and customer service. Our team leverages sophisticated econometric, machine learning, and big data technologies to help customers to discover the right products at the right prices from millions of trusted sellers billions of times a day. If you are looking for a career-defining opportunity on one of the most customer centric and business impacting teams within Amazon, we’d love to hear from you.

As an Amazon.com Data Engineer you will be working in one of the world's largest and most complex data warehouse environments. You should have deep expertise in the design, creation, management, and business use of extremely large datasets. We are looking for an Data Engineer to help build the next generation of Buy Box algorithms. These new set of algorithms will incorporate the continually changing preferences of our customers and continue to scale with numerous new programs that Amazon is introducing for our customers. You should be expert at designing, implementing, and operating stable, scalable, low cost solutions to flow data from production systems into the data warehouse and into end-user facing applications. You should be able to work with business customers in understanding the business requirements and implementing reporting solutions. Above all you should be passionate about working with huge data sets and someone who loves to bring datasets together to answer business questions and drive change.You will provide guidance and support for other engineers with industry best practices and direction.

Design, implement and support a platform that can provide ad-hoc access to large datasetsModel data and metadata to support adhoc and pre-built reportingInterface with business customers, gathering requirements and delivering complete BI solutionsTune application and query performance using Unix profiling tools and SQL

This position requires a Bachelor's Degree in Computer Science or a related technical field, and 4+ years of relevant employment experience.Good work experience in using SQL and databases in a business environment.Oracle and Unix skills requiredTune application and query performance using Unix profiling tools and SQLSolid communication skills and team playerScripting languages like perl and Unix shell scriptsExperience must involve design and development of large-scale data structures for business intelligence analytics, using ETL/ELT processes, data modeling, SQL, and Oracle
Amazon.com is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation."
96,"BI Engineer, AWS Commercial Sales Finance","Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelor’s degree in math, statistics, computer science, or finance or equivalent experience3+ years of experience as a Data Engineer, BI Engineer, Business/Financial Analyst or Systems AnalystSQL writing experience and experience with ETLStrong team player and the ability to work in a diverse environment with people in various locationsExcellent attention to detail, passion for processes, systems and data miningAbility to work independently in a fast-paced and rapidly changing environment

Amazon Web Services (AWS) seeks a Business Intelligence Engineer (BIE) to be a key member in our AWS SMS (Sales, Marketing, and Support) Finance team. This is an exciting opportunity to join one of Amazon’s fastest growing businesses, serving millions of customers in more than 190 countries. We are reshaping the way global enterprises use information technology, and we are powering the next generation of global business leaders. We are looking for entrepreneurial, analytical, and creative leaders to help us redefine the information technology industry. If you want to join a fast-paced, innovative team that is making history, this is the place for you!

The AWS SMS Analytics team builds Business Intelligence technology platforms for the AWS Global Sales business. We build, deliver, and operate data resources that provide the AWS sales organization with insights into all areas of business performance. This role requires an individual with excellent analytical abilities as well as outstanding project management skills. The candidate will need to be comfortable with ambiguity in a fast-paced and ever-changing environment, and able to think big while paying careful attention to detail.

KEY RESPONSIBILITIES
Own the design, development, and maintenance of ongoing metrics, reports, and analyses used to drive key business decisionsRecognize and adopt best practices in reporting and analysis, including data integrity, accuracy, and reliability, as well as documentationIdentify and implement new capabilities to develop and improve automated data analysis processesDrive data democratization throughout the organization, enabling others to self-serve their data needsPresent business insights to senior managementImprove our understanding of input/output metrics to better analyze sales productivity and revenue trendsWork closely with business/finance teams to create ad-hoc reports to support timely business decisions and project workLearn and understand a growing range of Amazon data resources and discover how, and when to use which datasets

Expert understanding of best practices to handle extremely large volume of dataAbility to create extensible and scalable data schema that lay the foundation for downstream analysisAbility to prioritize multiple concurrent projects while still delivering timely and accurate resultsExperience working in a lean team where continuous innovation is desired and ambiguity is the norm
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation"
97,Python Data Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Required skills:
Working knowledge of delivering on AWS services such as S3, Lambda Functions, Dynamo DB, Cloud watch
Kinesis, Athena, SNS, API Gateway, Cloud Formation, Cloud 9 is a plus.
OR Experience with Azure Data Services:
Azure SQL, BLOB, ADF (Azure Data Factory), CosmosDBOR Experience with
Handling large datasets using GCP (Google Cloud Platform) bigData, BigQuery, designing data pipelines ETL, cleaning, and data validation.
Desirable skills:
Apache Kafka or Apache Spark
Data manipulation of large amounts of unstructured data
Location: Seattle, WA"
98,Data Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Data Engineers at HigherEducation.com drive business value by transferring and structuring data for production and consumption by engineers, businesses, analysts, data scientists and partners.You will join a team of highly skilled engineers who design, develop and automate high-quality, scalable solutions across the entire data lifecycle, from raw data to powerful insights and analytics. Basically, we are using Spark as our universal program on how we are transferring data across multiple platforms. If you want to join a team of highly skilled engineers who design, develop and automate high-quality, scalable solutions across the entire data lifecycle, from raw data to powerful insights and analytics; this is the role for you.

What You'll Be Doing:

Building large scale, real time data pipelines with spark.
Working with a cross functional team of data scientists and analysts to understand business requirements leverage our data.
Design scalable solutions across distributed systems utilizing cutting edge cloud and big data technologies.

What We're Looking For:

Spark, working in RDDs and DataFrames/Datasets API (with emphasis on DataFrames) to query and perform data manipulation
Spark Structured Streaming
Experience building large scale Spark applications, ideally with either Batch processing and/or Streaming processing
Scala would be ideal but a solid knowledge of Java or Python is also acceptable
Experience in SparkSQL (Broadcast Joins)
Experience with cloud computing platforms, we use AWS (Kinesis, S3, Lambda, DynamoDB, Redshift, CloudFormation)
Has experience with ANSI SQL relational database (Postgres, MySQL)

Even better:

Linux common working knowledge, including navigating through the file system and simple bash scripting
Experience with Infrastructure as Code (Terraform, Serverless, CloudFormation)
General knowledge of distributed systems and distributed data processing frameworks
Experience with Storm or Cassandra is a plus
Knowledge about agile software processes

Who We Are:
HigherEducation.com is an industry-leading online education company, powering the largest marketplace of high-intent prospective students in the US. H-E leverages proprietary data, algorithms, and technology to provide over 150 university partners with unparalleled, cost-effective access to successful students at every step of the student journey. For more information visithttps://www.highereducation.com ( https://www.highereducation.com ).

Founded in 2000, Red Ventures is a portfolio of growing digital businesses that bring consumers and brands together through integrated e-commerce, strategic partnerships and many proprietary brands including Bankrate, AllConnect.com and Reviews.com. Headquartered south of Charlotte, NC, Red Ventures has over 3000 employees in offices across the US, as well as London and Sao Paulo. For more information, visit www.redventures.com ( http://www.redventures.com ).

At Red Ventures we believe that diversity makes us stronger - at work and in the world. Red Ventures is an equal opportunity employer that does not discriminate against any employee or applicant because of race, creed, color, religion, gender, sexual orientation, gender identity/expression, national origin, disability, age, genetic information, veteran status, marital status, pregnancy or any other basis protected by law. Employment at Red Ventures is based solely on a person's merit and qualifications."
99,"Data Engineer, Transportation Execution","Bellevue, WA",Bellevue,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelors in Computer Science, Computer Engineering or relevant fieldExpert in SQL with proficient knowledge of advanced SQL functions and database design3+ years of relevant experience working and creating sophisticated data pipelines and BI reporting.2+ years of experience in data modeling experience and using data models to improve the performance of software services.2+ years of experience in programming or scripting language (R, Python, Ruby).2+ years of experience in data warehouse and business intelligence application development.

Are you interested in applying your technical and engineering skills to shape the world’s most complex supply chain fulfillment and transportation network? Are you interested in driving the development of methods, models and systems for state-of-the-art robotics, transportation and fulfillment systems? If so, then this is the job for you.

Amazon Global Transportation Technology team is responsible for building next-gen software to optimize and automate different aspects of our transportation network. As a Data Engineer you'll shape the data handling strategy; build robust data pipelines that feed several real time decision making/modeling systems; leverage strong data extraction and transformation skills to engineer reporting mechanisms; and support transportation network planning.

Masters in Computer Engineering, Information Systems or relevant field.Understand business processes, logical data models, and relational and non-relational database implementationsCapable of investigating, familiarizing and mastering new data sets quicklyAbility to transform and publish data such that it can be consumed by BI tools such as Quick Sight/TableauStrong ability to interact, communicate, present and influence within multiple levels of the organization.Knowledge of AWS data systems and toolsStrong organizational skills with ability to balance competing priorities
Amazon offers competitive packages including comprehensive health care, 401(k), restricted stock units, growth potential and a challenging and exciting work environment.

Amazon is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age."
100,Data Engineer,"Issaquah, WA",Issaquah,WA,None Found,None Found,None Found,None Found,None Found,"Serve as a subject matter expert in Data Science, developing strong relationships with partners across Talking Rain as you conduct and support white-boarding sessions, workshops, design sessions, and project meetings.
Deliver solutions leveraging the emerging machine learning (ML) methods and technologies:
Big Data and streaming analytics
Exploratory data analysis (EDA) & cleansing
Feature engineering
Model selection, model evaluation, and cross-validation
Hyperparameter tuning, containerization, and deployment at all scales
Own productionalization and ongoing performance tuning for all models.
Ensure we’re ahead of the curve, staying abreast of the ever-shifting retail landscape and how we can best leverage syndicated data.
Develop custom data models and algorithms to generate predictive insights.
Ensure food safety, quality, and SQF practices are followed at all times, notifying immediate manager of any food safety and/or quality issues.
Complete other responsibilities as assigned.
",None Found,"Job Details
Level
Experienced
Job Location
Issaquah - Issaquah, WA
Position Type
Full Time
Education Level
Graduate Degree
Who We Are
We’re Talking Rain, and we’re so much more than water. We build flavorful brands, like Sparkling Ice and Talking Rain Sparkling Waters, creating connections with every sip!
Want to get to know us better? Click to learn about us and our careers. You can also follow us on LinkedIn, Instagram, Twitter and Facebook.
When it comes to success, we know we’re only as strong as our team, so we empower our Rain Makers to forge the way—finding opportunity at the intersection of what they love, what we need, and where they thrive.
What to Expect
Data is more than stats to our Business Transformation team—it’s a story waiting to be told. They translate the details into actionable information and strategy, helping us drive forward.

You’ll form partnerships across our business to help define and drive our strategy, reducing complexity within our operations and enhancing the effectiveness of our marketing activities.
Serve as a subject matter expert in Data Science, developing strong relationships with partners across Talking Rain as you conduct and support white-boarding sessions, workshops, design sessions, and project meetings.
Deliver solutions leveraging the emerging machine learning (ML) methods and technologies:
Big Data and streaming analytics
Exploratory data analysis (EDA) & cleansing
Feature engineering
Model selection, model evaluation, and cross-validation
Hyperparameter tuning, containerization, and deployment at all scales
Own productionalization and ongoing performance tuning for all models.
Ensure we’re ahead of the curve, staying abreast of the ever-shifting retail landscape and how we can best leverage syndicated data.
Develop custom data models and algorithms to generate predictive insights.
Ensure food safety, quality, and SQF practices are followed at all times, notifying immediate manager of any food safety and/or quality issues.
Complete other responsibilities as assigned.
Reports to: Senior Manager, Business Transformation
Direct Reports: N/A
What You Bring
Advanced degree in a highly quantitative field (e.g., MS or PhD in Data Science, Computer Science, Mathematics, or Physics).
Minimum of five (5) years of experience building and leading the development and productionalization of applied machine learning solutions and data products, ideally in consumer packaged goods (CPG).
Experience with traditional predictive ML models, such as decision trees, ensemble learning & random forests, KNN, support vector machines, and recommender systems.
Advanced knowledge of Python and/or R and their Data Science frameworks and libraries strongly preferred, such as PySpark, MLlib, SciKit Learn, MLFlow, Delta Lake, Koalas, and the Databricks Unified Analytics Platform.
Working knowledge of SQL, Apache Spark, Kafka, Pandas, and NumPy for the use of data extraction, cleansing, and analysis.
Experience using data visualization tools such as D3.js, Tableau, Qlik, or Power BI is a strong plus.
Experience leveraging Azure or AWS cognitive service APIs is a plus.
Highly refined communication skills, with the ability to speak both to technical engineers and executive stakeholders.
Integrity is at the core of who you are. You earn people’s trust with your ability to maintain confidentiality, particularly when handling sensitive information and situations.
You drive, not ride. You’re stellar at prioritization, time-management, and troubleshooting.
Your curious mindset enables you to interpret complex data, developing and communicating value-add solutions.
You’re approachable, actively listening and adapting your style to the audience.
You’re flexible. You pivot on a dime and embrace the change.
To help ensure a safe, positive work environment, this role may be subject to random drug testing (including alcohol, cannabinoids, cocaine, methamphetamine, opiates, phencyclidine)."
101,"Data Engineer, PerfectMile","Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Experience performing quantitative analysis, preferably for an Internet with large, complex data sources.Hands-on experience on Big data technologies and frameworks. Hive, Spark, Hadoop, SQL on Big Data, RedshiftExperience in near real time analyticsExperience with scripting languages i.e. Python, Perl, etc.Experience with ETL, Data Modeling, and working with large-scale datasets. Extremely proficient in writing performant SQL working with large data volumesAbility to manage competing priorities simultaneously and drive projects to completion.Bachelor's degree or higher in a quantitative/technical field (e.g. Computer Science, Statistics, Engineering).

Amazon Logistics is looking for a smart and ambitious individual to develop and support Amazon Logistics business intelligence and operations reporting and management systems. Amazon Logistics is a large, rapidly growing package delivery operation, that handles packages for Amazon and our customers with worldwide operations.

Do you want to be in the forefront of engineering big data solutions that takes Transportation models to the next generation? Do you have a solid analytical thinking, metrics driven decision making and want to solve problems with solutions that will meet the growing worldwide need? We are looking for top notch Data Engineers to be part of our world class Transportation Business Intelligence team.

The ideal candidate relishes working with large volumes of data, enjoys the challenge of highly complex technical contexts, and, above all else, is passionate about data and analytics. He/she is an expert with data modeling, ETL design and business intelligence tools and passionately partners with the business to identify strategic opportunities where improvements in data infrastructure creates out-sized business impact. He/she is a self-starter, comfortable with ambiguity, able to think big (while paying careful attention to detail), and enjoys working in a fast-paced and global team. It's a big ask, and we're excited to talk to those up to the challenge!

Experience performing quantitative analysis using complex data sources.Hands-on experience on Big data technologies and frameworks. Hive, Spark, Hadoop, SQL on Big Data, RedshiftExperience in near real time analyticsExperience with scripting languages i.e. Python, Perl, etc.Experience with ETL, Data Modeling, and working with large-scale datasets. Extremely proficient in writing performant SQL working with large data volumesAbility to manage competing priorities simultaneously and drive projects to completion.Bachelor's degree or higher in a quantitative/technical field (e.g. Computer Science, Statistics, Engineering).Experience with large scale data processing, data structure optimization and scalability of algorithms a plus

· Experience with large scale data processing, data structure optimization and scalability of algorithms a plus"
102,Data Engineer,"Seattle, WA 98108",Seattle,WA,98108,None Found,None Found,None Found,None Found,None Found,None Found,"Basic qualifications
Bachelors or Master’s degree in computer science, engineering, statistics, information science or a related fieldAt least 5 years of working experience with data pipelines, ETL processes and SQL in a business environment with large-scale, complex datasets3+ years of experience as a software developer or related technical field with fluency in at least one of the programming languages such as Python, Ruby, Java or ScalaExperience with AWS Big Data technologies (e.g. RedShift, S3, Data Pipeline, etc.) and AWS cloud infrastructureExperience working with disparate data sources to develop complex database architecture and data modelsKnowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes and testingKnowledge of data management fundamentals and data storage principlesKnowledge of distributed systems as it pertains to data storage and computingExcellent verbal and written communication skills and technical writing skills

At Amazon, we are working to be the most customer-centric company on earth. To get there, we need exceptionally talented, bright and driven people. Are you excited to help us learn more about how our customers shop and how satisfied they are when using our services? We are looking for a talented Data Engineer to join our Global Cross Channel and Cross Category (XCM) Insights team to focus on building advanced data pipelines and innovative data solutions.

This role requires an individual with excellent data modeling, database architecture, and software development skills. A successful candidate will have the ability to work with technology, research, marketing, finance and business teams. They will have passion for data and analytics, be a self-starter comfortable with ambiguity, with strong attention to detail, ability to work in a fast-paced and entrepreneurial environment and driven by a desire to innovate on behalf of our customers.

Key Responsibilities:
Architect and develop end to end scalable data applications and data pipelinesHelp build a data lake of disparate data sourcesEstablish scalable, efficient, automated processes for data analyses, model development, model validation and model implementationDevelop strong collaborative relationships with key partners in data engineering, software development, research, modeling and marketing teamsDevelop complex SQL queries and scripts for business logic implementationParticipate in data strategy and road map exercises, data warehouse design and implementation
Basic qualifications
Bachelors or Master’s degree in computer science, engineering, statistics, information science or a related fieldAt least 5 years of working experience with data pipelines, ETL processes and SQL in a business environment with large-scale, complex datasets3+ years of experience as a software developer or related technical field with fluency in at least one of the programming languages such as Python, Ruby, Java or ScalaExperience with AWS Big Data technologies (e.g. RedShift, S3, Data Pipeline, etc.) and AWS cloud infrastructureExperience working with disparate data sources to develop complex database architecture and data modelsKnowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes and testingKnowledge of data management fundamentals and data storage principlesKnowledge of distributed systems as it pertains to data storage and computingExcellent verbal and written communication skills and technical writing skills
Preferred qualifications
Masters in computer science, statistics, engineering or other quantitative fieldsKnowledge of data security and data privacy regulation processes, operations, principles, architectural requirements, engineering and vulnerabilitiesExperience with AWS solutions such as Amazon Simple Notification Service (SNS), Amazon SQS queues, AWS Lambda functions is a plusExperience developing cloud software services and an understanding of design for scalability, performance, privacy, security and reliabilityExperience with implementing supervised and unsupervised machine learning models for marketing use cases is a plusAbility to provide data-driven decision support and business intelligence that is timely, accurate, and actionableExperience gathering requirements and formulating business metrics for reportingExperience working with teams across different geographies

Preferred qualifications
Masters in computer science, statistics, engineering or other quantitative fieldsKnowledge of data security and data privacy regulation processes, operations, principles, architectural requirements, engineering and vulnerabilitiesExperience with AWS solutions such as Amazon Simple Notification Service (SNS), Amazon SQS queues, AWS Lambda functions is a plusExperience developing cloud software services and an understanding of design for scalability, performance, privacy, security and reliabilityExperience with implementing supervised and unsupervised machine learning models for marketing use cases is a plusAbility to provide data-driven decision support and business intelligence that is timely, accurate, and actionableExperience gathering requirements and formulating business metrics for reportingExperience working with teams across different geographies"
103,Business Intelligence Engineer - Security Partner Engineering (SPE),"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Master’s degree in information systems, engineering, statistics, or related discipline.Proven analytical and quantitative skills and ability to use hard data and metrics to support assumptions.Advanced knowledge and application of SQL.Advanced knowledge of setting up databases on AWS technologies.5+ years in the analysis space as a Business Intelligence Engineer, Business Analyst, Data Engineer, or similar roles.Experience using Python, Ruby, or other scripting languages to automate data retrieval, manipulate, and analyze

The Security Partner Engineering (SPE) group is responsible for the protection of customer and corporate data. We connect with all parts of the Amazon business supporting the security of external party data sharing, subsidiary acquisitions, and securing business operations in unique regions and contexts across Amazon’s massive, worldwide service-oriented architecture. We are looking for a Business Intelligence Engineer to scale, re-imagine, and build a world class metrics and scoring system that will allow us to make data driven decisions that support leadership and team goals and show us where process improvements are necessary.
This role requires an individual with excellent analytical abilities, deep knowledge of business intelligence solutions, and the ability to work with technology, security engineering, and business operations teams. A successful candidate will have a passion for data and analytics, strong attention to detail, and the ability to work in a fast-paced and entrepreneurial environment. This candidate must also be a self-starter that is comfortable with ambiguity and driven by a desire to innovate Amazon’s approach to this space.
Since our team is fundamental to Amazon’s growth through acquisitions and innovation through the use of third party technologies, you will also have the opportunity to learn about various Amazon business, technologies and their impact on our greater security landscape.

Master’s degree in Computer Science, Engineering, Math, Finance, Statistics or a related discipline.Familiarity with AWS solutions such as EC2, Dynamo DB, S3, and Redshift.Knowledge of the security domains within Amazon is a plus.Knowledge and direct experience using business intelligence reporting tools such as OBIEE, Business Objects, Cognos, Tableau, MicroStrategy, SSAS Cubes, etc.Experience partnering with business owners to understand requirements and develop supporting analysis to solve business problems."
104,Big Data Engineer,"Seattle, WA 98127",Seattle,WA,98127,None Found,"Cloud experience is must (AWS-S3, Snowflake, Redshift, Big Query etc.)
Experience with open source such as Hadoop, Spark, Kafka, Druid, Pilosa and Yarn/Kubernetes.
Experience in SQL, ETL Tools is required
Are passionate about data, technology, & creative innovation.
Experience in working with Data Scientists to operationalize machine learning models.",None Found,None Found,None Found,None Found,"We are looking for strong Big Data Engineers and Data Analysts. This person will be handling petabytes of consumer data for analytics. Excellent salary and benefits.


Locations – Connecticut, Los Angeles, Seattle and New York.


Basic Qualifications:

Have 5+ years of experience developing with a mix of languages (Scala, Python, SQL, etc.) and frameworks to implement data ingest, processing, and serving technologies. Experience with real-time and very large scalable online systems are preferred.

Cloud experience is must (AWS-S3, Snowflake, Redshift, Big Query etc.)
Experience with open source such as Hadoop, Spark, Kafka, Druid, Pilosa and Yarn/Kubernetes.
Experience in SQL, ETL Tools is required
Are passionate about data, technology, & creative innovation.
Experience in working with Data Scientists to operationalize machine learning models."
105,Risk Data Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelor's or Master's degree or in a quantitative/technical field (e.g. Computer Science, Statistics, Engineering).5+ years of advanced hands-on and proficient experience in writing complex, highly-optimized SQL queries across large data sets.Demonstrated strength in data modeling, ETL development, data warehousing, and data mining.Experience with developing advanced data visualization dashboards using tools such as Tableau.3+ years of developing end-to-end Business Intelligence solutions: data modeling, ETL and reporting.

Are you interested in guiding key business decisions and solving dynamic fast-paced challenges on a worldwide basis, while improving our selling partner experience? We are looking for a Data Engineer to join our team who is innovative, results-oriented, and enthusiastic about solving dynamic challenges, working with ambiguous data, looking around corners, spotting trends, and naturally curious to learn more.
In this role, you will solve complex data challenges, support operational improvements, and recommend data outputs for key business decisions. Additionally, you will dive deep to extract, analyze, and verify ambiguous data for key reporting to internal and external parties.

Responsibilities:
Design, architect, implement, and support key data sets that provide structured and timely access to actionable business information.Identify, verify, retrieve, and analyze data using data RedShift, ETL, SQL and other data management systems from multiple sources.Perform data analysis on ambiguous data to identify trends and act to mitigate potential risks.Develop comprehensive self-service reporting solutions.Build efficient, flexible, and extensive data solutions that can be used repetitively to support ad hoc requests and projects, as well as ongoing reporting and metrics.Interact with business partners to identify and suggest data for data requests.Provide written documentation of process and change management for audit purposes.Contribute to technical specifications for automation projects.

Experience in Linux shell scripting and/or execution.Experience with Tableau, Cognos, Microstrategy, or Quicksight.Experience with Hadoop, Spark, DynamoDB, Taradata, RedShift, or OBIEE.Working knowledge of an Object oriented language.Proven experience in working and delivering end-to-end projects independently.Proven knowledge of distributed systems as it pertains to data storage and computing.Proven analytical and quantitative ability and a passion for enabling customers to use data and metrics to back up assumptions, develop business cases, and complete root cause analyses
Strong verbal and written communication skills, including an ability to effectively lead and influence interactions with both business and technical teams
Amazon is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age"
106,Sr. Data Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,"
5-8 years of Python or Java/J2EE development experience
3+ years of demonstrated technical proficiency with Hadoop and big data projects
5-8 years of demonstrated experience and success in data modeling
Fluent in writing shell scripts [bash, korn]
Writing high-performance, reliable and maintainable code
Ability to write MapReduce jobs
Knowledge of database structures, theories, principles, and practices
Understand how to develop code in an environment secured using a local KDC and OpenLDAP
Familiarity with and implementation knowledge of loading data using Sqoop
Knowledge and ability to implement workflow/schedulers within Oozie
Experience working with AWS components [EC2, S3, SNS, SQS]
Analytical and problem-solving skills, applied to Big Data domain
Proven understanding and hands on experience with Hadoop, Hive, Pig, Impala, and Spark
Aptitude in multi-threading and concurrency concepts
M.S. in Computer Science or Engineering",None Found,"
Translate complex functional and technical requirements into detailed design
Hadoop technical development and implementation
Loading from disparate data sets by leveraging various big data technology e.g. Kafka
Pre-processing using Hive, Impala, Spark, and Pig
Design and implement data modeling
Maintain security and data privacy in an environment secured using Kerberos and LDAP
High-speed querying using in-memory technologies such as Spark
Following and contributing best engineering practice for source control, release management, deployment etc
Production support, job scheduling/monitoring, ETL data quality, data freshness reporting",None Found,None Found,"Beyondsoft Consulting, Inc., is a leading, technical solutions and consulting partner. We combine emerging technologies and proven methodologies to tailor elegant solutions that solve complex challenges and empower our customers to accelerate their business goals. Our services include end-to-end support for cloud, digital, data analytics, multi-language translation, and testing.

Our client is growing their Data Engineering team within a demanding and well recognized enterprise and information technology company. This role will be the core solution of the Strategic Analytics organization, ensuring both the reliability and applicability of the team’s data products to the organization. This individual will have extensive experience with ETL design, coding, and testing patterns as well as engineering software platforms and large-scale data infrastructures. The Data Engineers will have the capability to architect highly scalable end-to-end pipeline using different open source tools, including building and operationalizing high-performance algorithms. Proven experience with technologies to solve big data problems with expert knowledge in programming languages like Java, Python, Linux, PHP, Hive, Impala, and Spark.
Responsibilities
Responsibilities:

Translate complex functional and technical requirements into detailed design
Hadoop technical development and implementation
Loading from disparate data sets by leveraging various big data technology e.g. Kafka
Pre-processing using Hive, Impala, Spark, and Pig
Design and implement data modeling
Maintain security and data privacy in an environment secured using Kerberos and LDAP
High-speed querying using in-memory technologies such as Spark
Following and contributing best engineering practice for source control, release management, deployment etc
Production support, job scheduling/monitoring, ETL data quality, data freshness reporting
Qualifications
Qualifications:

5-8 years of Python or Java/J2EE development experience
3+ years of demonstrated technical proficiency with Hadoop and big data projects
5-8 years of demonstrated experience and success in data modeling
Fluent in writing shell scripts [bash, korn]
Writing high-performance, reliable and maintainable code
Ability to write MapReduce jobs
Knowledge of database structures, theories, principles, and practices
Understand how to develop code in an environment secured using a local KDC and OpenLDAP
Familiarity with and implementation knowledge of loading data using Sqoop
Knowledge and ability to implement workflow/schedulers within Oozie
Experience working with AWS components [EC2, S3, SNS, SQS]
Analytical and problem-solving skills, applied to Big Data domain
Proven understanding and hands on experience with Hadoop, Hive, Pig, Impala, and Spark
Aptitude in multi-threading and concurrency concepts
M.S. in Computer Science or Engineering"
107,Healthcare Data Engineer,"Seattle, WA 98104",Seattle,WA,98104,None Found,None Found,None Found,None Found,None Found,None Found,"Company Overview

Navigating Cancer is the pioneer in patient relationship management software and services for cancer care. The company has developed the first patient-centered oncology platform that improves the care delivery model for patients, providers, pharmaceutical manufacturers and payers. By putting patients at the center of their care, providers become economically viable in value-based payment models, payers and at-risk providers reduce the total cost of cancer care, and pharmaceutical manufacturers improve medication adherence for their life-saving treatments. Most importantly, patients receive a holistic service offering to support their individual goals and preferences.

The company is backed by industry-leading patient satisfaction ratings and currently supports over a million patients, thousands of care providers, dozens of pharmaceutical manufacturers, and several payer models nationwide to lower costs, improve patient satisfaction, and drive better outcomes.

Job Summary

As our Healthcare Data Engineer, you will be responsible for architecting & implementing complex big data projects with a focus on collecting, parsing, managing, analyzing and visualizing large sets of data to turn information into insights using multiple platforms. You will be a key contributor in influencing infrastructure and big data platform decisions. Collaborating closely with peers in the Product, Engineering & Data Sciences team, you will also be at the forefront of developing prototypes and proof of concepts for various lines of businesses. Your work will impact the way cancer patients experience Navigating Care.

The Successful Candidate


Extremely strong skills in at-least one programming and scripting language (Java, Python, Scala, Julia, Stata, Ruby, R).
Has built large-scale batch and real-time data pipelines using technology such as Airflow, Spark, AWS Big Data stack, Cloudera, HortonWorks,H20.
Developing with high volume heterogeneous data, Hadoop based technologies like MapReduce, Hive, Cassandra, Hbase and Impala.
Experience with AWS Services (Redshift, Redshift Spectrum, S3, Glacier, DynamoDB), Parquet/Avro/ORC.
Strong documentation skills.
Shows a preference for standard, well supported tools over in house, custom solutions.
Experience with one or more data analytics and visualization packages.
Expert knowledge of scaling and tuning SQL and NoSQL systems.
Familiarity with DevOps tools (e.g. Docker, Ansible, Hashicorp, Jenkins, etc.)
Deep understanding of how algorithms work and have experience building high-performance algorithms
Ability to multi-task, prioritize assignments and work well under deadlines in a changing environment.
Strong quantitative, analytical, process development, facilitation and organizational skills required.
Bachelor's degree in Information Systems, MIS, Statistics, related field or equivalent work experience required.
Work in cross functional agile teams to continuously experiment, iterate and deliver on new product objectives.
5+ years of experience in building and sustaining similar solutions, preferably in the healthcare industry.

Nice to have:

Experience building and querying from a variety of electronic health records systems.
Prior experience in regulated industries with high Data Quality and Governance standards.
Basic knowledge of the medical terminologies, messaging standards, healthcare coding systems.

Why work here?

We support thousands of healthcare professionals and tens of thousands of cancer patients every day. We help cancer patients get better care—and consider this a valuable and meaningful reason to come to work everyday. You get to work with leading technology, wear many hats, and contribute every day to our business success! You get to help us grow and establish ourselves as a world-class business. We are lean, agile, and lightweight. We believe in each other, believe in our work, and have fun along the way.

This position is a full time, on-site, with the Navigating Cancer team, in our downtown Seattle office. We offer competitive compensation, benefits and a fantastic work environment. Come join our team and make a difference!

Our Values

Work with Purpose . Work together to improve the lives of cancer patients. Collaborate with team members, have passion, enthusiasm and mission for the work that we do.

Act with Integrity . Communicate openly, be honest, follow through.

Be Agile . Discover creative solutions, welcome change. Adapt and pursue continuous improvement.

Seek Simplicity . Reduce complexity for our customers and patients. Simplify our products, our processes and our messages.

Strive for Growth . Constantly strive to achieve personal, professional, and company goals. Continuous reflection, learning and achievement."
108,Big Data Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,"
BS degree in CS or related engineering field
Excellent communication and collaboration skills
Passion for quality with strong customer empathy and focus
Strong intellectual curiosity and passion about learning new technologies",None Found,None Found,None Found,None Found,"Senior Software Engineer with total 5+ years’ and 1-2 yrs+ experience in Apache Spark with Scala. Candidate should be able to create data pipelines; handling big data across multiple data sources.
Design, Development, Test, Deploy and maintain as big data systems for enterprise products
Coding, participating in Code Reviews, Enhancement discussion, maintenance of existing pipelines & systems, testing and bug-fix activities carried out on an on-going basis
Nice to have experience in Cloud environment, work experience on Azure is a plus. Knowledge in Azure Data Factory will be a plus
Candidate will deliver sprint work as defined by product backlog and prioritized by engineering leadership
Experience with Azure Data Services: Azure SQL, BLOB, ADF (Azure Data Factory) and Cosmos DB is desired but not necessary
Qualifications and other skills:
BS degree in CS or related engineering field
Excellent communication and collaboration skills
Passion for quality with strong customer empathy and focus
Strong intellectual curiosity and passion about learning new technologies
Preferred skills
Apache Kafka or Apache Spark
Data manipulation of large amounts of unstructured data
Location: Seattle, WA"
109,Business Intelligence Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"We are looking for a Business Intelligence Engineer (BIE) with strong analytical, communication and project management skills to join our team. Working closely with business stakeholders and senior leadership, you will help identify and solve complex language and currency problems and develop metrics and reports to measure our impact on our client’s business. In a typical day, you will work closely with the product management team, retail teams, machine-learning scientists, statisticians, software engineers, and various business groups.

About you:
You're looking for a career where you'll be able to build, to deliver, and to impress. You look at problems holistically and thrive on the intricate complexity of designing feedback loops and ecosystems. You want to work on projects where you are implementing solutions to real problems that require creative solutions and deep understanding of the problem space.

You challenge yourself and others to constantly come up with better solutions. This highly visible role requires frequent communication with senior leadership in order to help shape and deliver on the product roadmap and requires you to nimbly switch between strategic and tactical initiatives to achieve technical, business, and customer experience goals. You'll be given the unique opportunity to own and drive initiatives across the our Retail as a whole - from algorithmic innovation, all the way down to the datasets that the back-end services consume.

About us together:
We're going to change the way that we think about supporting our global customer. Along the way, we're going to face seemingly impossible problems. We're going to argue about how to solve them, and we'll work together to find a solution that is superior to each of the proposals we came in with. We'll make tough decisions, but we'll all understand why. We'll be the dream team.

The ideal candidate for this space will be highly quantitative, have great judgment, strong data mining and modeling skills and is comfortable facilitating ideation and working from concept through to execution. You will have demonstrated an ability to manage and develop medium to large-scale data tables, identify requirements and build financial reporting and planning models and tools that are statistically grounded but also explainable operationally, apply technical skills allowing the models to adapt to changing attributes, optimize forecast accuracy and to better understand and mitigate model variance drivers. In addition to building data tables, modeling and technical skills, you will possess strong written and verbal communication skills, strong focus on internal customers and professional demeanor and high intellectual curiosity with ability to learn new concepts and frameworks, algorithms and technology rapidly as changes arise.

Some problem spaces we'll be working on:

DATAMART - as we release new languages across marketplaces, our business teams will want to understand customer trends and interactions with these new marketplaces. Ideally, we want to enable our business teams to report on the various languages within a marketplace as if those languages were individual businesses. As such, we need to create a DataMart that enables all business metrics to be split by language and also enables business users to execute ad hoc queries to answer questions that we have not currently considered. As we create the DataMart, we will have to consider the scale of data that we will be handling (at the scale of our global retail business) and employ Bigdata techniques to aggregate and manipulate this data. We will need to design the platform to be robust and to seamlessly recover from disaster, should the need arise. Consistency and validation will be primary concerns as we understand that systems fail, specifically systems upon which we rely for signal and we need to protect our business teams from making decisions based upon incomplete information.

CUSTOMER EXPERIENCE - as arbiters of the customer experience, we need to understand our customers' experience in their languages of preference. Similarly, given the scope of this initiative, it is clear that we will not be able to translate all content in a single release. As a result, it is critical that we can truly measure the customer experience as a function of our translations (both coverage and quality) throughout their journey within our marketplace. This is further complicated by the fact that our customers receive a unique experience based upon their browse history, so our method of measurement must be considerate of and support such a dynamic experience. Furthermore, in real time and with zero latency, we want to understand when the experience is broken so that we can take appropriate actions. This is going to be a challenge that may make use of the latest Bigdata streaming technologies to provide a real-time data and measurement pipeline.

Questions?
You may already know if you're a fit, but perhaps you're worried about technology and experience requirements? Don't be - we're looking for smart, proven, engineers; if you're the right candidate, we're flexible.

BASIC QUALIFICATIONSBS or MS in a quantitative field such as Mathematics, Statistics, Physics, Engineering, Computer Science or EconomicsIndustry experience as a Business Intelligence Engineer or related specialty (e.g. Software Engineer, Data Engineer, and Data Scientist) with extensive professional experience and a proven track record in a role focused on understanding, manipulating, processing and extracting value from large datasets.Experience with statistical analysis, regression modeling and forecasting, time series analysis, data mining, financial analysis, and demand modelingStrong analytical skills with passions on working with structural data setsProficiency with TABLEAU, Microsoft Excel to include making charts, data manipulation, pivot tables, creating macros, and visual basic knowledgeExperience processing, filtering, and presenting large quantities (100K to Millions of rows) of dataAble to write SQL scripts for analysis and reporting (Redshift, SQL, MySQL)Excellent communication skills and the ability to work well in a team.Effective analytical, troubleshooting and problem-solving skills.

PREFERRED QUALIFICATIONSExperience in Statistical Software such as R, SAS, SPSS, MINITABAble to write SQL scripts for analysis and reporting (Redshift, SQL, MySQL)Experience using one or more Python, VBA, MATLAB, Java, C++ programming languages"
110,"Data Engineer, Affiliate Marketing","Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelor's degree in computer science, engineering, mathematics, or a related technical discipline3+ years of industry experience in software development, data engineering, business intelligence, data science, or related field with a track record of manipulating, processing, and extracting value from large datasetsExperience using big data technologies (Hadoop, Hive, Hbase, Spark, EMR, etc.)Knowledge of data management fundamentals and data storage principlesKnowledge of distributed systems as it pertains to data storage and computing

Do you want a unique, exciting opportunity to help build something from the ground up?

We are looking for builders who are passionate about front end development to join the Amazon Associates team. Amazon Associates is the world’s largest affiliate marketing program and its success has been built on a rich selection of websites and blogs, all creating original content relevant to products sold on Amazon. We are passionate about building scalable, well-designed software services, and strive to constantly improve our technical foundation and user experience.

We are looking for a talented data engineer to help build/enhance the customer-facing systems. You will own many large datasets, implement new data pipelines that feed into or from critical data systems for Amazon Associates, and your insights will impact millions of Customers, Brands and Associates. You will develop new data engineering patterns that leverage new cloud architectures, and will extend or migrate existing data pipelines to the architectures as needed.

You are an ideal candidate if you are passionate about quality, consistency, maintainability, performance, security and all the other things that make great software great. Join us today to transform the world of advertising and affiliate marketing!

Major Responsibilities
Build data pipelines to feed recommendation models for real-time and large-scale offline use cases.Modelling data and metadata to support ad-hoc and pre-built reporting. Interface with business stakeholders, gathering requirements and developing new datasets for reporting and analytics.Design and implement scalable ETL pipelines in AWS platform to support the rapidly growing and dynamic business demand for data, and use it to deliver the data as service which will have an immediate influence on day-to-day decision making for new programs.

4+ years of industry experience as a Data Engineer or related specialty (e.g., Software Engineer, Business Intelligence Engineer, Data Scientist) with a track record of manipulating, processing, and extracting value from large datasets.Knowledge and direct experience using business intelligence reporting tools. (e.g. Tableau, QuickSight etc.)Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data setsExperience working with AWS big data technologies (Athena, EMR, Redshift, S3)Demonstrated strength in data modeling, ETL development, and data warehousingProven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategyExperience providing technical leadership and mentoring other engineers for best practices on data engineeringKnowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation"
111,Data Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,"
Develop data processes for data modeling, mining, reporting and QA
Ensure architecture will support the business requirements
Employ a variety of languages and tools (e.g. scripting languages) to integrate data from different systems.
Recommend ways to improve data reliability, efficiency and quality.
Employ sophisticated analytics programs, machine learning and statistical methods to prepare data for use in predictive and prescriptive modeling.
Explore and examine data to find hidden patterns.
Analyze potential data quality issues to determine the root cause and create effective solutions.
Optimize processes involving large data sets to improve performance.
Work with stakeholder to understand their business and make recommendations to help solve problems or improve processes.
Deliver high quality projects on time and budget in a fast-paced environment.
Preparing and presenting technical information to non-technical and highly technical audiences.
Working on multiple projects simultaneously.
Training and supporting others as needed.
","Description:
Campfire data engineers balance between strategy and execution to deliver best-in-class client service. We don't hire 'report monkeys' - we're looking for bright and curious minds who love to explore data, dig for insights, and mine opportunities for the clients we serve. Our Data Engineers are comfortable operating without oversight to solve problems and deliver value. Client-facing consulting experience is strongly preferred.

Requirements:
Responsibilities


Develop data processes for data modeling, mining, reporting and QA
Ensure architecture will support the business requirements
Employ a variety of languages and tools (e.g. scripting languages) to integrate data from different systems.
Recommend ways to improve data reliability, efficiency and quality.
Employ sophisticated analytics programs, machine learning and statistical methods to prepare data for use in predictive and prescriptive modeling.
Explore and examine data to find hidden patterns.
Analyze potential data quality issues to determine the root cause and create effective solutions.
Optimize processes involving large data sets to improve performance.
Work with stakeholder to understand their business and make recommendations to help solve problems or improve processes.
Deliver high quality projects on time and budget in a fast-paced environment.
Preparing and presenting technical information to non-technical and highly technical audiences.
Working on multiple projects simultaneously.
Training and supporting others as needed.

Minimum Qualifications


Very strong Problem solving / critical thinking skills
Demonstrated experience working directly with and creating data architectures.
Advanced SQL Server programming (e.g. functions, views, stored procedures, parameters) and knowledge of data warehousing best practices.
Creating stored procedures, SSIS packages and using other methods to import/translate/manipulate data.
Working experience with job automation (e.g. SQL server agent, Azure Data flow.. etc.).
Advanced knowledge designing, developing, testing, and supporting SSAS technologies, and dimensional modeling.
Ability to manage projects, lead teams, document findings, and track action items to closure.
Report development experience (Tableau, PowerBI, Excel or other reporting solutions)
Performance Tuning (e.g. indexing, partitioning, optimizing queries)

Preferred Qualifications


Experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets.
Experience creating and using advanced machine learning algorithms and statistics and their real-world advantages/drawbacks: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, text mining, social network analysis etc.
Experience with distributed data/ cloud computing tools: Azure, AWS, Map/Reduce, MS Cosmos, Hadoop, Hive, Spark
Experience with DAX and MDX (eg: Ranking, date changing, data transformations, relating data)
MCSE certification preferred
Knowledge of best practices for database hardware & software environments and configurations.
Degree in Computer, Science, Math, Engineering, MIS or related Fields (Or equivalent experience)

"
112,Senior Software Engineer,"Seattle, WA 98109",Seattle,WA,98109,None Found,None Found,None Found,None Found,None Found,None Found,"Req #: 1903123
Location: Seattle, Washington, United States
Job Category: Clinical Operations
Work Location: 400 Dexter Ave N. 98109
Organization: Data Management
Employee Status: Full-time
Job Type: Regular
At Celgene Corporation, we’re committed to changing the course of human health through bold pursuits in science, life-enhancing therapies and a promise to always put patients first. Our Automation and Data Management team, part of Cell Therapy Development & Operations, is a highly collaborative, skilled group of individuals who deliver value daily to the production of Celgene’s products.

To continue to do this important work, we are hiring a Data Engineer/Data Engineering Manager for our Cell Therapy Organization.

Our ideal Data Engineer/Data Engineering Manager will join a small talented and experienced data engineering team to develop and maintain systems to enable the rapid advancement of cellular therapy candidates from pre-clinical development through commercialization. Depending on the experience level and interest of the individual, they will lead a small team or be an individual contributor as part of a small team.

The Automation and Data Management team develops automated software and hardware systems which streamline the execution of assays in our development and manufacturing processes. A successful candidate will contribute a full stack software and also contribute to the design and specification our systems. The ideal candidate will have experience both as a software developer and a system designer/architect. The ability to work independently as a developer while partnering with coworkers in regulatory and scientific roles is critical to the position.

Basic Qualifications:

Demonstrated proficiency in C# and the .NET framework
Demonstrated proficiency with developing SQL based solutions
Experience working in and/or implementing SDLC processes
Experience developing unit and integration tests
Experience working with Microsoft Team Foundation System or analogous systems

Preferred Qualifications:

Experience with deploying systems into GxP environments
Experience with working with scientists and/or scientific data
Experience with statistics and statistical methods
Experience with manufacturing systems analysis
Experience managing and mentoring other developers


About Us

COMMITTED TO IMPROVING THE LIVES OF PATIENTS WORLDWIDE

At Celgene, we seek to deliver truly innovative and life-changing drugs for our patients. Our vision as a company is to build a major global biopharmaceutical corporation while focusing on the discovery, the development, and the commercialization of products for the treatment of cancer and other severe, immune, inflammatory conditions.

""At Celgene, we seek to deliver truly innovative and life-changing drugs for our patients.""

There are more than 300 clinical trials at major medical centers using compounds from Celgene. Investigational compounds are being studied for patients with incurable hematological and solid tumor cancers, including multiple myeloma, myelodysplastic syndromes, chronic lymphocytic leukemia (CLL), non-Hodgkin’s lymphoma (NHL), triple-negative breast cancer and pancreatic cancer. As committed as we are to clinical accomplishment, we are equally committed to patient support, which is a guiding principle at Celgene. We believe all who can benefit from our discoveries should have the opportunity to do so. Celgene puts patients first with industry-leading programs that provide information, support and access to our innovative therapies."
113,Data Engineer,"Seattle, WA 98101",Seattle,WA,98101,None Found,None Found,None Found,None Found,None Found,None Found,"Facebook's mission is to give people the power to build community and bring the world closer together. Through our family of apps and services, we're building a different kind of company that connects billions of people around the world, gives them ways to share what matters most to them, and helps bring people closer together. Whether we're creating new products or helping a small business expand its reach, people at Facebook are builders at heart. Our global teams are constantly iterating, solving problems, and working together to empower people around the world to build community and connect in meaningful ways. Together, we can help people build stronger communities — we're just getting started.
At Facebook, we have many opportunities to work with data each and every day. In this role as a Data Engineer on the Analytics team, your primary responsibility will be to partner with key stakeholders, data scientists and software engineers to support and enable the continued growth critical to Facebook's Data Center organization. You will be responsible for creating the technology that moves and translates data used to inform our most critical strategic and real-time decisions. You will also help translate business needs into requirements and identify efficiency opportunities. In addition to extracting and transforming data, you will be expected to use your expertise and provide meaningful recommendations and actionable strategies to partnering data scientist for performance enhancements and development of best practices, including streamlining of data sources and related programmatic initiatives. The ideal candidate will have a passion for working in white space and creating impact from the ground up in a fast-paced environment. This position is part of the Infrastructure Data Center team and located in Fremont, CA.
RESPONSIBILITIES
Apply proven expertise and build high-performance scalable data warehouses
Design, build and launch efficient & reliable data pipelines to move and transform data (both large and small amounts)
Securely source external data from numerous partners
Intelligently design data models for optimal storage and retrieval
Deploy inclusive data quality checks to ensure high quality of data
Optimize existing pipelines and maintain of all domain-related data pipelines
Ownership of the end-to-end data engineering component of the solution
Collaboration with the Data Center SMEs, Data Scientists, and Program Managers
Support on-call shift as needed to support the team
Design and develop new systems in partnership with software engineers to enable quick and easy consumption of data
MINIMUM QUALIFICATIONS
BS/MS in Computer Science or a related technical field
7+ years of SQL (Oracle, Vertica, Hive, etc.) experience and relational databases experience (Oracle, MySQL)
7+ years of experience in custom or structured (i.e. Informatica/Talend/Pentaho) ETL design, implementation and maintenance
7+ years’ experience in data engineering, experience in applying DWH/ETL best practices
7+ years of Java and/or Python development experience
2+ years experience in LAMP and the Big Data stack environments (Hadoop, MapReduce, Hive)
2+ years experience working with enterprise DE tools and experience learning in-house DE tools
Facebook is committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, you may contact us at accommodations-ext@fb.com."
114,Sr. Business Intelligence Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelor’s degree in computer science, mathematics, statistics, economics, or other quantitative field5+ years of relevant work experience in a role requiring application of data modeling and analytic skillsStrong experience with ETL development, data modeling, data warehousing, MySQL, Tableau, and databases in a business environment with large-scale, complex datasetsAdvanced ability to draw insights from data and clearly communicate them to the stakeholders and senior management as requiredSelf-driven, with demonstrated ability to deliver on ambiguous projects as well as projects/requests where the underlying data is incompleteStrong verbal/written communication and presentation skillsExperience in gathering requirements and formulating business metrics for reportingExperienced working in a fast-paced, high-tech environment and comfortable navigating conflicting priorities and ambiguous problems

Amazon is seeking an exceptional Sr. Business Intelligence Engineer (BIE) to join the Global Outsourcing (GO) Customer Service (CS) team. This is a unique, high visibility opportunity for someone with a passion to dive deep into disparate, large-scale data sets, surface data that provide unique insights to leaders of the GO organization and ultimately have an impact on the direction of our business. The GO CS network consists of numerous business process outsourcing (BPO) vendors operating a large variety of small to large CS sites across traditional and non-traditional BPO centers around the world. The network is supported by an internal group of Vendor Managers who among other responsibilities monitor numerous quality and performance metrics associated with these vendors.

The ideal candidate will have excellent analytical abilities, outstanding business acumen and judgment, intense curiosity, strong technical skills, and superior written and verbal communication skills. S/he will be a self-starter, comfortable with ambiguity, able to think big and be creative (while paying careful attention to detail), and enjoys working in a fast-paced dynamic environment. To be successful in this role, you should have broad skills in database design, be comfortable dealing with large and complex data sets, have experience building self-service dashboards and using visualization tools, while always applying analytical rigor to solve business problems. In addition to leading the design, development, and management of our analytical tools and reporting, we will also look to this person to provide thought leadership and business analysis support as needed.

The candidate will need to understand the complexities of a high growth, fast-paced, high performing organization and possess the ability to handle multiple, abstract projects while dealing with constant change. S/he should have a strong desire to achieve results, continuously raise the bar, and demonstrate an ability to effectively manage time, priorities and deliverables.

The primary responsibilities of this role include:
Design, develop and maintain scalable, automated, user-friendly systems, reports, dashboards, etc. that will support our analytical and business needsAnalyze key metrics to uncover trends and root causes of issuesInvent and innovate - Tell the story of business trends, patterns, and outliers through rich visualizationsWork closely with various stakeholders, including GO leadership, to define the information needed and how best to present itSuggest and build new metrics and analysis that enable better perspective on businessWork with GO vendors to identify and resolve issues related to existing reportsDesign and develop weekly, monthly, and quarterly dashboards, scorecards and reporting for the team and present insights to stakeholdersRecognize and adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation
Amazon is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age

MBA or Master’s degree in Computer Science, Engineering, Statistics, Mathematics or related fieldExpert in writing and tuning SQL scriptsExperience working in very large data warehouse environments3+ years of experience in a data engineer or BIE role with a technology companyAdvanced capabilities with productivity software such as Excel and Access
Amazon.com is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age."
115,"Sr. Data Engineer, Ads Partner Network","Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelor's degree or higher in a quantitative/technical field (e.g. Computer Science, Statistics, Engineering).5+ years of relevant experience in one of the following areas: Data engineering, database engineering, business intelligence or business analytics.5+ years of hands-on experience in writing complex, highly-optimized SQL queries across large data sets.5+ years of experience in scripting languages like Python etc.

Amazon Advertising is dedicated to driving measurable outcomes for brand advertisers, agencies, authors, and entrepreneurs. Our ad solutions—including sponsored, display, video, and custom ads—leverage Amazon’s innovations and insights to find, attract, and engage intended audiences throughout their daily journeys. With a range of flexible pricing and buying models, including self-service, managed service, and programmatic ad buying, these solutions help businesses build brand awareness, increase product sales, and more.

As the Senior Data Engineer on our team, you will lead the development of our data platform and put together the Ads, content, partner, seller and customer engagement data into one scalable design to enable the best possible customer experiences. You will also communicate effectively with engineers, partners, leaders and a broad set of stakeholders.

A successful engineer in this role is:
Highly analytical: You solve problems in ways that can be backed up with verifiable data. You focus on driving processes, tools, and statistical methods which support rational decision-making.Technically fearless: You aren't satisfied by performing 'as expected' and push the limits past conventional boundaries. Your dial goes to '11'.Team obsessed: You help grow your team members to achieve outstanding results. You foster the creative atmosphere to let engineers innovate, while holding them accountable for making smart decisions and delivering results.Humbitious: You’re ambitious, yet humble. You recognize that there’s always opportunity for improvement and use introspection and feedback from teammates and peers to raise the bar for your team.Engaged by ambiguity: You're able to explore new problem spaces with unique constraints and thus non-obvious solutions; you’re quick to identify any gaps in the team and the right person to fill them to best deliver value to customers.
Your responsibilities in this role will include:
Leading architecture design and implementation of next generation BI solutionsManaging AWS resources including EC2, RDS, Redshift, Kinesis, EMR, Lambda etc.Mentoring and developing other DE's and BIE's.Building and deliver high quality data architecture and pipelines to support business analyst, data scientists, and reporting needs.Interfacing with other technology teams to extract, transform, and load data from a wide variety of data sources.Continually improving ongoing reporting and analysis processes, automating or simplifying self-service support for customers.Designing and building systems from scratch.

Demonstrated strength in data modeling, ETL development, and Data warehousing. Data WarehousingExperience with Redshift,Experience with AWS services including S3, Redshift, EMR, Kinesis and RDS.Experience with Big Data Technologies (Hadoop, Hive, Hbase, Pig, Spark, etc.).Experience in working and delivering end-to-end projects independently.Knowledge of distributed systems as it pertains to data storage and computing.Proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategy.Experience providing technical leadership and mentoring other engineers for best practices on data engineering.Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations.Masters in computer science, mathematics, statistics, economics, or other quantitative field
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation."
116,Data engineer - Search Marketing,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelor’s Degree in Computer Science or related field2+ years of Industry experience as a Data Engineer or related specialty (e.g. Software Engineer, Business Intelligence Engineer, and Data Scientist) and a proven track record in a role focused on understanding, manipulating, processing and extracting value from large datasets.Significant experience in relational database concepts with an expert knowledge of Logical data modeling, SQL, Metadata management.Excellent communication skills and the ability to work well in a team.Effective analytical, troubleshooting and problem-solving skills for building systems to process both structured and unstructured data .

Amazon’s Automated Marketing and Advertising team is building the Internet's largest-scale fully-automated Search advertising system. The team is responsible for a scaled, high availability system, and the algorithms that automatically generate, target, measure, and optimize tens of millions of search engine ad placements. Big data processing systems and algorithms including statistical modeling, machine learning, and data mining are the core of our business. With essentially full ownership of our own product road map, there is a large R&D component to our work. To meet the challenge, we are seeking strong Data Engineers who want to stretch both their technical abilities and their business awareness while solving such problems. Amazon.com Data engineering is a fast paced environment where every day brings new challenges and new opportunities. As a Data Engineer working on the Search Marketing team, you will be implementing and supporting the analytics technologies that give our customers timely, flexible and structured access to their data. You will collaborate with Software Engineers and Data scientists to build the necessary data infrastructure required for Machine learning algorithms to operate at scale. You will interact with business customers, gathering requirements and gaining a deep-dive understanding of key datasets. You will also drive adoption of storing single source of truth for paid search data, with emphasis on data quality and accurate metrics used in aiding advertising experiment results.

Bachelor’s Degree in Computer Science or related field2+ years of Industry experience as a Data Engineer or related specialty (e.g. Software Engineer, Business Intelligence Engineer, and Data Scientist) and a proven track record in a role focused on understanding, manipulating, processing and extracting value from large datasets.Experience with Agile / SCRUM development methodologiesExperience with designing, developing and testing software solutions for production use to drive real world business problems.Hands-on experience with recent advances in Data processing technologies such as MapReduce, MPP architectures, and NoSQL databases.Proficiency with software development using AWS technologies
Amazon.com is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation."
117,Business Intelligence Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelor’s degree in math, statistics, computer science, or finance or equivalent experience.5+ years of experience as a Data Engineer, BI Engineer, Business/Financial AnalystExperience in data mining (SQL, ETL, data warehouse, etc.) and using databases in a business environment with big data technologies and large-scale, complex datasets.Experience in complex data analysis (model creation, A/B testing, etc.)Verbal/written communication & data presentation skills, including experience to effectively communicate with both business and technical teams.

Do you want to change the world? Alexa and Echo are shaping the future of voice recognition and cloud-based content/services. Alexa is the name of the Amazon cloud-based voice service and the brain that powers Echo, the award-winning and groundbreaking Amazon device designed around your voice. Echo connects to Alexa, to provide information, answer questions, play music, read the news, check sports scores or the weather, and more—instantly. It's hands-free, and always ready. All you have to do is ask.

To achieve this, we blend of a variety of disciplines (such as NLP, data mining, machine learning, big data, semantic web, graph stores, cloud computing) in an effort to understand our customers and the things they're excited about. To complement our complex algorithms and extensive data analyses, we create elevated and inspirational mobile and web features across the entire communication experience. We use artificial intelligence, data mining and usability studies to develop new features, and we test them through hundreds of R & D experiments a year. We are also incredibly intent on solving some of the most complex computing problems to be found in industry and academia, and we get to test our solutions in the real world every day. And most importantly, we relentlessly ask: ""What haven't we thought of yet?""

Our BIE duties & Responsibilities will include:
Define and deliver analyses and reports that supports the analytical needs of internal business leaders.Use analytical insights to help increase teams effectiveness against key strategic goals.Define process/methodology to help measure KPIs for the organization and provide an environment where key trends are recognized and acted-upon proactively.Identify and implement new capabilities and best practices to develop and improve automated data analysis processesEnsure clear communication and coordination across the product, engineering and central BI teams. Effectively collaborate with product managers to make critical product decisions and engineering to instrument key features.Quickly build a thorough understanding of Alexa customer base- feature preference, device preference, seasonality, global trends etc.

Data visualization and dashboarding experience (Tableau preferred)Expert understanding of best practices to handle extremely large volume of dataAbility to create extensible and scalable data schema that lay the foundation for downstream analysisA clear passion for learning new BI skills and techniques independently and continuouslyAbility to prioritize multiple concurrent projects while still delivering timely and accurate resultsExperience working in a lean, successful start-up or on a new product team where continuous innovation is desired and ambiguity is the normProficiency with scripting languages and Unix systems (Python, perl, bash, etc.)Experience in an internet-based company with large, complex data sources."
118,Senior Data Engineer,"Bellevue, WA",Bellevue,WA,None Found,None Found,"
8+ years of professional experience as a Data Engineer/BI Developer
4+ years of professional experience implementing and using Power BI
Expertise in Microsoft Business Intelligence Stack (SSRS, SSAS, SSIS) and T-SQL using SQL Server , SSIS
Well versed experience with SQL, Python and/or other data collection tools & reporting
Extensive experience with PySpark or Scala is necessity (Databricks or Spark).
Advanced knowledge and skills with Azure, or similar cloud platforms.
Experience required with DAX/MDX
Excellent collaboration skills to work on a team as well as independently (be self-reliant and resourceful)
Excellent organization skills and able to multi-task and detailed oriented
Excellent verbal and written communication skills (must be able to write clear and concise emails for any audience, etc.
",None Found,None Found,None Found,None Found,"Who is Blueprint?

Blueprint Technologies is a group of solution minded thinkers changing the face of Technology in Bellevue, WA. We follow a Mission, Vision, and Core Values that allow us to function as a collaborative unit.

What are our Solutions?

Blueprint is a technology solutions firm that connects strategy, product and delivery. We help companies digitally transform. We have a special focus in cloud and infrastructure, data platform and engineering, data science and analytics, organizational modernization and customer experience optimization.

Why you want to be a part of Blueprint?

We are innovators. Motivators. Thought provokers. And coffee drinkers. Our collective backgrounds bring diverse perspectives that enable us to consistently think differently. Our people are our solutions. We want you to bring your biggest and best ideas to help positively impact our culture, clients and the community around us. We believe in the importance of a healthy and happy team, which is why our benefits include full medical, dental and vision coverage, as well as paid time off, 401k, paid volunteer hours and tuition reimbursement.

Blueprint is looking for Senior Data Engineer to join us to join our team in Bellevue, WA!!

Basic Qualifications:

8+ years of professional experience as a Data Engineer/BI Developer
4+ years of professional experience implementing and using Power BI
Expertise in Microsoft Business Intelligence Stack (SSRS, SSAS, SSIS) and T-SQL using SQL Server , SSIS
Well versed experience with SQL, Python and/or other data collection tools & reporting
Extensive experience with PySpark or Scala is necessity (Databricks or Spark).
Advanced knowledge and skills with Azure, or similar cloud platforms.
Experience required with DAX/MDX
Excellent collaboration skills to work on a team as well as independently (be self-reliant and resourceful)
Excellent organization skills and able to multi-task and detailed oriented
Excellent verbal and written communication skills (must be able to write clear and concise emails for any audience, etc.

FLSA - Job Classification: Exempt, Full Time Position.

**We are not able to sponsor Visa's at this time or do Corp-to-Corp arrangements. Must be able work on a W2 basis please!"
119,"Data Engineer, Woot!","Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"§ Bachelor’s degree in computer science, mathematics, statistics, economics, or other quantitative field
§ 3+ years of relevant work experience in a role requiring application of analytic skills to integrate data into operational/business planning or advanced degree
§ Strong experience with ETL development, data modeling, data warehousing, MySQL, and databases in a business environment with large-scale, complex datasets
§ Advanced ability to draw insights from data and clearly communicate them to the stakeholders and senior management as required.
§ Experience in gathering requirements and formulating business metrics for reporting.
§ Experienced working in a fast-paced, high-tech environment and comfortable navigating conflicting priorities and ambiguous problems
§ Strong track record in converting data analysis into tangible and significant real-world changes.
§ Strong grasp of quantitative data analysis and statistics.
§ Python scripting experience
§ AWS or Azure production development and managment
§ The ability to exclaim Woot!

Do you feel passionate about data? Are you excited about figuring out ways slice, dice, and send data to multiple sources? Woot.com, the innovative company who invented the deal-of-the-day business model, is looking for a talented, self-motivated Data Engineer.

Woot specializes in daily deals across multiple categories and offers our customers unique content giving them many reasons to visit our website and mobile apps frequently.

As a result of strong business growth, we are looking for a DE to join our Data Team to further build and automate our reporting, high value action (HVA) recommending, and business prioritizing system to enhance team efficiency and effectiveness. The ideal candidate will be passionate about contributing to the team growth through his/her expertise in utilizing big data technology to answer business questions and identify growth opportunities. This person will build new business intelligence solutions as an owner end-to-end, at the same time, collaborate with data engineers and data scientists to automate recommendation and prioritization system.

To be successful in this role, you should have broad skills in database design, be comfortable dealing with large and complex data sets, have experience building self-service dashboards and using visualization tools, always applying analytical rigor to solve business problems. You should have strong business and communication skills and be able to work closely with product managers and business units to define key business questions and build data sets and models that answer them. Our DEs are expected to have a detailed understanding of our business and never lose sight of the broader problems that we are trying to solve.

The primary responsibilities of this role include:
Design, develop and maintain scalable, automated, user-friendly systems, reports, dashboards, etc. that will support our analytical and business needsWrite SQL code to retrieve and analyze data from database tables (ex. Redshift, MySQL, DBs), and learn and understand a broad range of Amazon’s data resources and know how, when, and which to use and which not to useDevelop queries and visualizations for ad-hoc requests and projects, as well as ongoing reportingCreate pipelines for automated Use analytical and statistical rigor to solve complex problems and drive business decisions.Develop Machine Learning modelsWrite scripts in Python for data processing
Congrats on making it this far! Woot has Screaming Monkeys, lots of Screaming Monkeys, oh, and bags of crap! If that's your thing, hit the ""apply"" button ASAP.

§ MBA or Master’s degree in Computer Science, Engineering, Statistics, Mathematics or related field
§ Expert in writing and tuning SQL scripts
§ Experience working in very large data warehouse environments
§ 3+ years of experience in a data engineer or BIE role with a technology company
§ Experience conducting large scale data analysis to support business decision making
§ Strong verbal/written communication and data presentation skills, including an ability to effectively communicate with both business and technical teams
§ Be self-driven, and show ability to deliver on ambiguous projects with incomplete or dirty data.
§ Strong verbal/written communication & data presentation skills, including an ability to effectively communicate with both business and technical teams.
§ Strong dashboarding skills with Tableau/Microstrategy/Looker, etc.
§ Understand the meaning of Moofi"
120,"Data Engineer II (Woot LLC, Seattle, WA)","Seattle, WA",Seattle,WA,None Found,None Found,"Bachelor’s degree in computer science, mathematics, statistics, economics, or other quantitative field
3+ years of relevant work experience in a role requiring application of analytic skills to integrate data into operational/business planning or advanced degree
Strong experience with ETL development, data modeling, data warehousing, MySQL, and databases in a business environment with large-scale, complex datasets
Advanced ability to draw insights from data and clearly communicate them to the stakeholders and senior management as required.
Experience in gathering requirements and formulating business metrics for reporting.
Experienced working in a fast-paced, high-tech environment and comfortable navigating conflicting priorities and ambiguous problems
Strong track record in converting data analysis into tangible and significant real-world changes.
Strong grasp of quantitative data analysis and statistics.
Python scripting experience
AWS or Azure production development and managment
The ability to exclaim Woot!
",None Found,"Design, develop and maintain scalable, automated, user-friendly systems, reports, dashboards, etc. that will support our analytical and business needs
Write SQL code to retrieve and analyze data from database tables (ex. Redshift, MySQL, DBs), and learn and understand a broad range of Amazon’s data resources and know how, when, and which to use and which not to use
Develop queries and visualizations for ad-hoc requests and projects, as well as ongoing reporting
Create pipelines for automated Use analytical and statistical rigor to solve complex problems and drive business decisions.
Develop Machine Learning models
Write scripts in Python for data processing
",None Found,None Found,"We are looking for a lethally talented DE to join our Data Team to further build and automate our reporting, high value action (HVA) recommending, and business prioritizing system to enhance team efficiency and effectiveness. The ideal candidate will be passionate about contributing to the team growth through his/her expertise in utilizing big data technology to answer business questions and identify growth opportunities. This person will build new business intelligence solutions as an owner end-to-end, at the same time, collaborate with data engineers and data scientists to automate recommendation and prioritization system.

To be successful in this role, you should have broad skills in database design, be comfortable dealing with large and complex data sets, have experience building self-service dashboards and using visualization tools, always applying analytical rigor to solve business problems. You should have strong business and communication skills and be able to work closely with product managers and business units to define key business questions and build data sets and models that answer them. Our DEs are expected to have a detailed understanding of our business and never lose sight of the broader problems that we are trying to solve.

Responsibilities:
Design, develop and maintain scalable, automated, user-friendly systems, reports, dashboards, etc. that will support our analytical and business needs
Write SQL code to retrieve and analyze data from database tables (ex. Redshift, MySQL, DBs), and learn and understand a broad range of Amazon’s data resources and know how, when, and which to use and which not to use
Develop queries and visualizations for ad-hoc requests and projects, as well as ongoing reporting
Create pipelines for automated Use analytical and statistical rigor to solve complex problems and drive business decisions.
Develop Machine Learning models
Write scripts in Python for data processing
Basic Qualifications:
Bachelor’s degree in computer science, mathematics, statistics, economics, or other quantitative field
3+ years of relevant work experience in a role requiring application of analytic skills to integrate data into operational/business planning or advanced degree
Strong experience with ETL development, data modeling, data warehousing, MySQL, and databases in a business environment with large-scale, complex datasets
Advanced ability to draw insights from data and clearly communicate them to the stakeholders and senior management as required.
Experience in gathering requirements and formulating business metrics for reporting.
Experienced working in a fast-paced, high-tech environment and comfortable navigating conflicting priorities and ambiguous problems
Strong track record in converting data analysis into tangible and significant real-world changes.
Strong grasp of quantitative data analysis and statistics.
Python scripting experience
AWS or Azure production development and managment
The ability to exclaim Woot!
Preferred Qualifications:
MBA or Master’s degree in Computer Science, Engineering, Statistics, Mathematics or related field
Expert in writing and tuning SQL scripts
Experience working in very large data warehouse environments
3+ years of experience in a data engineer or BIE role with a technology company § Experience conducting large scale data analysis to support business decision making
Strong verbal/written communication and data presentation skills, including an ability to effectively communicate with both business and technical teams
Be self-driven, and show ability to deliver on ambiguous projects with incomplete or dirty data.
Strong verbal/written communication & data presentation skills, including an ability to effectively communicate with both business and technical teams.
Strong dashboarding skills with Tableau/Microstrategy/Looker, etc.
Understand the meaning of Moofi
Woot, An Amazon Company, is an Equal Opportunity/Affirmative Action Employer - Female/Minority/Disability/Veteran."
121,"Data Engineer, Global Workforce Solutions","Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Degree in Computer Science, Engineering, Mathematics, or a related field and 5+ years industry experienceExperience in data modeling, ETL development, and data warehousingData Warehousing Experience with Oracle, Redshift, Teradata, etc.Experience in Python and/or other data ingestion languages and tools.Strong customer focus, ownership, urgency and drive.Excellent communication skills and the ability to work well in a team.Effective analytical, troubleshooting and problem-solving skills.

What is the team? The Workforce Staffing Research & Business Intelligence team is your opportunity to make an impact across multiple layers of the company and the hourly workforce as a whole. This team leads and influences workforce strategies that enable Amazon to scale more efficiently, while also providing a unique voice for the hourly labor population throughout the globe. Amazon’s mission is to be the most customer centric company in the world and Workforce Staffing (WFS) is on the front line of that mission by hiring hundreds of thousands of hourly associates across multiple types of roles and businesses. Here’s how you can help…
The DE role will own ingesting and modeling data from new sources in order for new businesses and countries to be absorbed into our research and reporting products. You will work with a diverse team of Research and Data Scientists, SDEs, Data Engineers and BIEs to design personalized, best in class analytical products that can be expanded worldwide, and will be the Research & Business Intelligence team's intake mechanism for new customers.
The role requires a uniquely gifted athlete who is naturally curious and runs towards big challenges. This will be a highly visible and global role impacting all of Amazon Fulfillment. If you are passionate and curious about data, obsess over customers, love questioning the status quo, and want to see and feel a tangible impact to your team’s work, this is the role for you.
Key Responsibilities Include:
Partner with our Amazon Global Workforce Solutions team and AMZL Delivery Station tech teams to support new and innovative internal and 3P staffing models from an analytics perspectiveUnderstand and document business processes and systems and design a path to incorporate new businesses/countries into existing solutions (or build new ones where required)Partner with our Research and Business Intelligence team to design, build and measure new and existing data driven tools and how new, complex businesses and countries could similarly adoptBuild scalable solutions to business problems via robust data pipelines and modelingRepresent your customers constantly

Graduate degree in Computer Science, Engineering or related technical field.Industry experience as a Data Engineer or related specialty (e.g., Software Engineer, Business Intelligence Engineer, Data Scientist) with a track record of manipulating, processing, and extracting value from large datasets.Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets.Experience building data products incrementally and integrating and managing datasets from multiple sources.Experience with AWS Tools and Technologies (S3, EC2, Data Pipeline etc.).Experience providing technical leadership and mentor other engineers for the best practices on the data engineering space.
Amazon.com is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age."
122,Associate Professional Services Consultant - 2020 United States,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Enrolled in a Bachelor's degree in Computer Science, Computer Engineering, or related fieldsGraduating between August 2019 and July 2020Experience with one of the following programming languages: Java, Python, Ruby, Node.js, C#, or C++Experience with Networking fundamentals, Security, Databases (Relational and/or NoSQL), Operating Systems (Unix, Linux, and/or Windows)

Note: By applying to this position, your application will be considered for all locations we hire for in the United States including, but not limited to: Seattle, WA; Washington DC Metro area; New York City; Chicago, IL; and San Francisco, CA

Do you have a deep passion for utilizing technology to empower businesses? Are you passionate about collaborating with technology and business leaders to deliver cloud-based solutions?

Amazon Web Services (AWS), a subsidiary of Amazon.com and a leader in Cloud Computing, is seeking early career talent to join our AWS Tech U Program. This is a unique opportunity for driven, self-starters to play a key role in a fast-growing business, and to deliver significant value to AWS customers of all sizes from nimble startups to global brands. You will learn from top AWS subject matter experts and get paid while you train for an exciting career in the tech industry.

These are some of the most challenging and exciting roles in the IT industry today. We work with cutting edge technologies supporting the largest and most innovative businesses, non-profits, and government agencies around the world. This is a an unparalleled opportunity to leapfrog your peers and take a leadership role helping AWS to transform the way the world uses technology to solve their business challenges. The skills and experiences you gain will be highly sought after throughout the industry and give you the opportunity for the career of a lifetime.

Associate Professional Services Consultant

In this role, you must possess the following:

An affinity for the new and unknown. We are always experimenting with innovative technologies including Cloud Computing, Machine Learning, and Internet of Things.
Enjoy working with customers of all shapes and sizes. You will have a passion for educating, training, designing, and building solutions for a diverse and challenging set of customers ranging from small businesses to large enterprises.
About Tech U

As an Associate Professional Services Consultant, you will be part of AWS Tech U, which is an accelerated career development program for those who want to advance both their technical and business skills. The Program will provide you with training and work experience that aligns in the fields of Solutions Architecture, Technical Training and Professional Service Consulting.

This unique program consists of a 6-month instructor lead, project-based learning curriculum (where you must be open to both Herndon, VA, and Seattle, WA for this portion of the program), followed by a 6-month On-the-Job Training (OJT) learning assignment within Solutions Architecture, Technical Training, or Professional Services Consulting, located in a U.S. city (location TBD as based on the needs of the business). AWS will provide relocation assistance for both the academic and OJT training assignments. At the end of your six months of OJT, you will choose a track suited to your strengths and preference.

These tracks include:
DevOps Specialist – A leader in building advanced computing systems that harness continuous integration/continuous deployment pipelines and utilize the strengths of cloud computing to build scalable and economical systems for clients.

Cloud Infrastructure Architect – An expert in cloud-based networking and system rollouts. CIAs specialize in network performance, infrastructure provisioning, and building Application Programming Interfaces (APIs)

Application Developer – AppDev resources are specialists in designing applications that run natively in the cloud. They are experts in building programs that run on any number of platforms including virtualized instances, containers, or server less architecture.

Data Lake & Analytics Specialist – This role will specifically focus on Data processing capabilities and helping our customers and partners to remove the constraints that prevent our customers from leveraging their data to develop business insights. Engagements will include migration of existing applications and development of new applications using AWS cloud services.

Data Warehouse & MPP Specialist – This role will specifically focus on large scale data warehousing and database migration capabilities. Engagements will include Redshift implementations and helping customers to migrate from their existing on-premises data warehouses using other databases to Amazon Redshift.

Data Engineer – In this role, you will work with our partners, customers and focus on our AWS Analytics service offering such Amazon Kinesis, AWS Glue, Amazon Redshift, Amazon EMR, Athena, AWS ML, and more.

Are you ready to embrace the challenge? Come build the future with us.

Note: Applications are reviewed on a rolling basis. For an update on your status, or to confirm your application was submitted successfully, please login to your candidate portal. Please note that we are reviewing a high volume of applications and appreciate your patience.

Experience with QA, testing, helpdesk, IT support, or any technician or quality assurance type workExperience implementing a cloud-based technology solution in a school project or while working for a companyExperience with one or more of the following domains: systems administration (Linux/Window), network administration (DNS, IPsec, BGP, VPN, Load Balancing), or programming (Node.JS, Java, Ruby, C#, C++, Python, or PHP)
Amazon does not sponsor for immigration, including for H-1B, TN, and other non-immigrant visas, for this role.

Amazon is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age. Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records. Pursuant to the Los Angeles Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records."
123,"Senior Software Engineer, Data","Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"About Foursquare:
Foursquare is the leading independent location technology platform, powering business solutions and consumer products through a deep understanding of location. Foursquare's business solutions include Pilgrim SDK, Places API, Analytics, Placed powered by Foursquare, and Pinpoint. Together, these products empower brands to analyze trends; measure foot traffic lift; optimize advertising campaigns; and drive deeper engagement via Foursquare's industry-leading developer tools, which have been selected by 150,000 developers including AccuWeather, Apple, Samsung, Microsoft, Snapchat, Tinder, TripAdvisor, Twitter and Uber. Our toolkit also includes our consumer apps Foursquare City Guide and Swarm. Over the past 10 years, we've counted more 13 billion verified signals from people around the world, helping us to keep our dynamic map and models fresh and up-to-date.

About our Engineering Team:
As a member of Foursquare's engineering team, we want you to bring experience building real products from the ground up. We're passionate about tackling tough challenges in the location space and look for others who like to dive deep into code and help solve hard problems. You should be comfortable running with your own ideas and eager to learn new skills on a bleeding edge platform. We use a variety of tools, technologies, and languages to build software (Scala, Thrift, MongoDB, Memcached, JS/jQuery, Kafka, Pants, Hadoop, MR, Spark) but experience with equivalent ones will do just fine.

As a data engineer, you will own critical pieces of the machine learning and analytics platforms. You will build data processing infrastructure to derive insights from billions of location data points every day. You will collaborate with Product, Engineering, and Data Science teams to create tools and processes to bring research and machine learning models to production.

What you'll do:

Influence key decisions on architecture and implementation of scalable data processing and analytics structure
Work with the Data Science team to bring machine learning models into production
Build Hadoop MapReduce and Spark processing pipelines using Java, Python, and Ruby
Build REST APIs for data access by systems across our infrastructure
Focus on performance, throughput, and latency, and drive these throughout our architecture
Write test automation, conduct code reviews, and take end-to-end ownership of deployments to production
Mentor junior engineering staff

What we're looking for:

BS/BA in a technical field such as computer science or equivalent experience
7+ years of software development experience
Proficiency in Python, Java, C#, and/or Ruby
3+ years of experience with Hadoop MapReduce and/or Spark data processing pipelines, analytics systems (e.g. OLAP, BI tools), and machine learning technologies
Experience operating systems in AWS
Excellent communication skills, including the ability to identify and communicate data-driven insights

Foursquare is proud to foster an inclusive environment that is free from discrimination. We strongly believe in order to build the best products, we need a diversity of perspectives and backgrounds. This leads to a more delightful experience for our users and team members. We value listening to every voice and we encourage everyone to come be a part of building a company and products we love.

Foursquare is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected Veteran status, or any other characteristic protected by law."
124,Principal Data Engineer - Temporary,"Everett, WA 98203",Everett,WA,98203,None Found,"Bachelor’s Degree in computer science, engineering, mathematics, MIS or similar field.
10 years in technology roles.
Must have experience with the following technologies:
C#
ASP.net
T-SQL
HTML/CSS
JavaScript
Nodejs
Demonstrated analytical skills
Demonstrated problem solving skills
Promotes information sharing
Ability to work within tight timeframes and meet strict deadlines.
Possesses strong technical Aptitude.
",None Found,None Found,None Found,None Found,"Description:
Providence St. Joseph Health is calling a Principal Data Engineer to one of our following locations: Renton, WA (preferred), Spokane, WA, Richland, WA, Everett, WA, Olympia, WA, Anchorage, AK, Missoula, MT, Portland, OR, Beaverton, OR, Anaheim, CA, Burbank, CA or Lubbock, TX. This position is 1 year-long in duration with full medical, dental, vision and vacation benefits. We are open to the possibility of working remotely within our 7 state region of operation: AK, WA, OR, MT, CA, NM and TX.
We are seeking a Principal Data Engineer to design and build modern data-centric software applications to support clinical and operational processes across all parts of the health system. These applications leverage cloud computing, big data, mobile, data science, and modern software development methodologies and frameworks. Data Engineers build data pipelines, enrichment processes, provisioning layers, APIs and user interfaces to meet the requirements of key initiatives. The Principal Data Engineer will take point on development of best practices and standards across the engineering team and participate in research and development of new technologies. A Principal Data Engineer should be able to and emphasize mentoring less experienced Data Engineers and training the team, as needed, to develop a robust skillset among the entire team. Strongly encourages and places a priority on collaboration with meticulous source control and documentation. An emphasis on simple solutions to complex problems through the use of modern and emerging methods and tools is critical. This position will works closely with the Product, Platform, and Architecture teams to deliver on joint efforts.
In this position you will have the following responsibilities:
Design, build and deliver quantitative applications that improve operations and generate value
Participate in DevOps, Agile, and continuous integration frameworks
Stay abreast of emerging technologies, open source projects, and best practices in the field
Data warehousing, big data, enterprise search, business intelligence, analytics, modern and mobile applications
Build processes that are fault-tolerant, self-healing, reliable, resilient and secure
Work effectively and in real-time with other developers, product managers, and customers to deliver on collective goals
Actively participate in code reviews, support the overall code base, and support the establishment of standard processes and frameworks. Take a lead role in the development of standard practices and enforce following standard processes.
Qualifications:
Required qualifications for this position include:
Bachelor’s Degree in computer science, engineering, mathematics, MIS or similar field.
10 years in technology roles.
Must have experience with the following technologies:
C#
ASP.net
T-SQL
HTML/CSS
JavaScript
Nodejs
Demonstrated analytical skills
Demonstrated problem solving skills
Promotes information sharing
Ability to work within tight timeframes and meet strict deadlines.
Possesses strong technical Aptitude.
Preferred qualifications for this position include:
Master’s Degree.
Cloud computing, Linux, Hadoop, MapReduce, Spark, Hbase, Kudu and NoSQL platforms in general; Apache Solr and Lucene
Java, Scala, C#, Python, shell scripting and/or similar languages
Relational database platforms, database design, and SQL
APIs, JSON, REST and other relevant W3C open standards
Modern application development frameworks
Familiarity with commercial or open source ETL tools
About the department you will serve.
Providence Strategic and Management Services provides a variety of functional and system support services for all eight regions of Providence Health & Services from Alaska to California. We are focused on supporting our Mission by delivering a robust foundation of services and sharing of specialized expertise.
We offer a full comprehensive range of benefits - see our website for details
http://www.providenceiscalling.jobs/rewards-benefits/
Our Mission
As expressions of God’s healing love, witnessed through the ministry of Jesus, we are steadfast in serving all, especially those who are poor and vulnerable.
About Us
Providence Health & Services is a not-for-profit Catholic network of hospitals, care centers, health plans, physicians, clinics, home health care and services guided by a Mission of caring the Sisters of Providence began over 160 years ago. Providence is proud to be an Equal Opportunity Employer. Providence does not discriminate on the basis of race, color, gender, disability, veteran, military status, religion, age, creed, national origin, sexual identity or expression, sexual orientation, marital status, genetic information, or any other basis prohibited by local, state, or federal law.
Schedule: Full-time
Shift: Day
Job Category: Information Technology
Location: Alaska-Anchorage
Other Location(s): Oregon-Portland, Oregon-Beaverton, Montana-Missoula, Washington-Everett, Washington-Renton, Washington-Richland, Washington-Spokane, California-Anaheim
Req ID: 234029"
125,"Data Engineer, AmazonSmile","Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Candidates are expected to have the following qualifications:
Bachelor's degree in computer science, engineering, mathematics, or a related technical discipline2+ years of industry experience in software development, data engineering, business intelligence, data science, or related field with a track record of manipulating, processing, and extracting value from large datasetsData Warehousing Experience with Oracle, Redshift, PostgreSQL, etc.Query performance tuning skillsCoding proficiency in at least one modern programming language (Python, Ruby, Java, etc)Experience using business intelligence reporting tools (Tableau, Business Objects, Cognos, etc.)Knowledge of data management fundamentals and data storage principles

AmazonSmile is redefining how technology, business and philanthropy intersect and is putting the scale of Amazon to good use by creating innovative products that both engage customers and provide much needed assistance to charitable organizations. Having donated over $150 million in the last five years to thousands of charities, we are poised to grow even larger.

The team is looking for a talented Data Engineer who will design and build the future data infrastructure for the team. AmazonSmile’s systems interact with millions of customers and orders per day, and we need someone who can transform how we think about the massive data sets we own and create efficiencies in the processing of tens of terabytes of data each day.

Your role will include:
The design, implementation, and support of a platform providing access to large datasets.Interfacing with other technology teams to extract, transform, and load data from a wide variety of data sources using SQL and other AWS technologiesImplementing data structures using best practices in data modeling, ETL processes, SQL, Redshift, and EMROptimizing the performance of business-critical queriesAdvise SDEs by serving as the data subject matter expert on the teamInterfacing with business customers, gathering requirements and delivering complete reporting solutionsContinually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers

3+ years of experience as a Data Engineer, BI Engineer, Business/Financial Analyst or Systems Analyst in a company with large, complex data sources.Experience with MicroStrategyExperience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data setsExperience working with AWS big data technologies (EMR, Redshift, S3)Demonstrated strength in data modeling, ETL development, and data warehousingProven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategy
Amazon.com is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation."
126,Data Engineer - AWS,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"B.S. degree in mathematics, statistics, computer science or a similar quantitative field5+ years’ work experience and detailed knowledge of data warehouse technical architectures, infrastructure components, ETL/ ELT and reporting/analytic tools.3+ years of work experience with very large data warehousing environmentExperience in designing and building data warehouse solutions and integrating technical componentsExperience in gathering requirements and formulating business metrics for reporting.Experience in using SQL to analyze data in a database or data warehouse and a major programming (e.g. Python/Java) and/or a scripting language (Perl, Unix shell) to process data for modelingExperience working with a wide range of predictive and decision models and data mining techniques, as well as tools for developing such modelsExcellent communication skills, both written and verbal

Amazon Web Services (AWS) is one of Amazon’s fastest growing businesses. We are passionate about thinking big, innovating on behalf of our customers, and tackling problems at scale. Cloud computing is disrupting, and we are eagerly seeking talented, entrepreneurial-minded individuals to join us as we continue build on the AWS platform.

We are looking for an experienced data engineer to support our service team: AWS Certificate Manager (ACM). This is a new role on a team with very lofty goals. We need a strong data engineering leader to help us identify trends, make better decisions, and measure our performance. It’s a bold challenge with huge upside and great visibility.
The right candidate will be a self-starter, bringing together strong experience in data engineering and business intelligence, along with a roll-up-your-sleeves, entrepreneurial approach to solving problems at scale. This position requires a solution-oriented candidate with a combination of business acumen, knowledge of statistical best practices, and an analytical mindset. You should have strong working knowledge of the latest big-data systems and tools with a proven track record of delivering results. You must have the ability to work with diverse stakeholder groups to solve business problems and provide data solutions that are organized and simple to understand. You will be part of a world-class team in a fast-paced environment that has the feel of a start-up.

Amazon is an exciting environment where we “Work Hard, Have Fun, Make History.” We do not desire to simply produce good solutions here at AWS... we want to produce disruptive, history-changing innovations. This is an opportunity to join a growing AWS service team, gain top-notch experience in cloud computing, and help bring new disruptive solutions to market at massive scale.

An advanced degree in mathematics, statistics, computer science or a similar quantitative field is strongly preferredExperience with AWS Redshift is preferred.Expert understanding of ETL techniques and best practices to handle extremely large volumes of data.
#AWSCrypto Amazon is an Equal Opportunity-Affirmative Action Employer – Women / Minority / Disability/Veteran / Gender Identity / Sexual Orientation / Age."
127,Data Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,"Master’s degree in Computer Science, Engineering, or equivalent work experience
Two to four years’ experience working with datasets with hundreds of millions of rows using a variety of technologies
Intermediate to expert level programming experience in Python and SQL in Windows and Mac/Linux environment
Intermediate level experience working with distributed computing frameworks, especially Spark",None Found,"Build and Maintain serverless data ingestion and refresh pipelines in terabyte scale using AWS cloud services – Amazon Glue, Amazon Redshift, Amazon S3, Amazon Athena, DynamoDB, and others
Incorporate new data sources from external vendors using flat files, APIs, web-scraping, and databases.
Maintain and provide support for the existing data pipelines using Python, Glue, Spark, and SQL
Work to develop and enhance the database architecture of the new analytic data environment that includes recommending optimal choices between relational, columnar, and document databases based on requirement
Identify and deploy appropriate file formats for data ingestion into various storage and/or compute services via Glue for multiple use cases
Develop real-time/near real-time data ingestion from web and web service logs from Splunk
Maintain existing processes and develop new methods to match external data sources to Homesite data using exact and fuzzy methods
Implement and use machine learning based data wrangling tools like Trifacta to cleanse and reshape 3rd party data to make suitable for use.
Develop and implement tests to ensure data quality across all integrated data sources.
Serve as internal subject matter expert and coach to train team members in the use of distributed computing frameworks for data analysis and modeling including AWS services and Apache projects
",None Found,None Found,"Homesite Insurance was founded in 1997 and was one of the first companies to enable customers to purchase home insurance directly online, during a single visit. Since then, we've continued to innovate rapidly to meet the needs of our customers and their changing expectations.
One thing that's stayed the same since our founding: our commitment to our customers, partners and employees.
Join us on our journey as we continue to grow into a powerful contender in the field of insurance.
Data Engineer

We’re looking for a Data Engineer to help us transform our data systems and architecture to support greater variety, volume, and velocity of data and data sources. You might be a good fit if:

You enjoy extracting data from a variety of sources and find ways to connect them and make them suitable for use in software systems and for the development of models and algorithms.
You enjoy interacting with new database systems and learning new data technologies and are interesting in developing your knowledge of new tools and techniques.
You are interested in automating data engineering efforts to minimize human interaction and optimizing data quality.
You have an interest in developing your knowledge of practical data science techniques and technologies in addition to your data engineering knowledge and experience.
This role requires comprehensive data engineering skills and is not a SQL developer role though SQL is a required skill.
Responsibilities:
We’re looking for an experienced data engineer to help us:
Build and Maintain serverless data ingestion and refresh pipelines in terabyte scale using AWS cloud services – Amazon Glue, Amazon Redshift, Amazon S3, Amazon Athena, DynamoDB, and others
Incorporate new data sources from external vendors using flat files, APIs, web-scraping, and databases.
Maintain and provide support for the existing data pipelines using Python, Glue, Spark, and SQL
Work to develop and enhance the database architecture of the new analytic data environment that includes recommending optimal choices between relational, columnar, and document databases based on requirement
Identify and deploy appropriate file formats for data ingestion into various storage and/or compute services via Glue for multiple use cases
Develop real-time/near real-time data ingestion from web and web service logs from Splunk
Maintain existing processes and develop new methods to match external data sources to Homesite data using exact and fuzzy methods
Implement and use machine learning based data wrangling tools like Trifacta to cleanse and reshape 3rd party data to make suitable for use.
Develop and implement tests to ensure data quality across all integrated data sources.
Serve as internal subject matter expert and coach to train team members in the use of distributed computing frameworks for data analysis and modeling including AWS services and Apache projects
Qualifications:
Master’s degree in Computer Science, Engineering, or equivalent work experience
Two to four years’ experience working with datasets with hundreds of millions of rows using a variety of technologies
Intermediate to expert level programming experience in Python and SQL in Windows and Mac/Linux environment
Intermediate level experience working with distributed computing frameworks, especially Spark"
128,Siri - Data Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Summary
Posted: Aug 27, 2019
Weekly Hours: 40
Role Number: 200092335
Would you like to play a part in the next revolution in human-computer interaction? Contribute to a product that is redefining way people and devices interact and work with the people who built the intelligent assistant that helps millions of people get things done — just by asking?
Using data as the voice of our customers, you will improve Siri by using data to inform the evolution of Siri. We're looking for a passionate individual able to improve the processing, analysis and preparation of huge data sets used to train Siri's machine learned models. You will love big-data technologies, including data exploration, visualisation, distributed processing, and applications at scale.
Key Qualifications
Spark
Scala
Python
Description
Working as part of an extraordinary team, including world renowned academics, top software engineers and expert machine learning practitioners, we are passionate about applying groundbreaking techniques to conversational dialogue.
Siri processes more than a billion requests every week and good data is the at heart of this engine. Each commit you make has the potential to impact Siri users worldwide through the creation of better data. Our work powers state of the art machine learning models and data visualisations. You will engineer distributed data pipelines and use your understanding of data annotation and how it is used in building real world ML models to improve our systems. To bring new ideas and innovation any research experience involving the use or creation of datasets, corpora, and annotation is a plus.
If this is you, we'd love to hear from you.
Education & Experience
Degree in Computer Science or equivalent"
129,"Data Engineer (Term-Limited through June 30, 2021)","Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Job Description

Position Summary

Reporting to the Enterprise Data Solutions Manager, the Data Engineer will help solve a variety of technical database challenges and work directly with the Business Analytics and Technology Solutions teams to support the development and maintenance of the organization’s data platform and reporting infrastructure. If you want to make a difference in the lives of home care workers and the seniors and people with disabilities they support, we want to hear from you!
The Details:
Location: Downtown Seattle (remote is not available for this role)
Work Schedule: Our typical business hours are 8:30-5:00 Monday-Friday
Travel Requirements: None
Category: Full-Time, Exempt, Union
This position is approved through: June 30, 2021 and qualifies for our comprehensive benefits package
Physical Requirements: Must be able to sit for long periods of the day
You Will:
Plan and coordinate data migrations between systems;
Support the construction of the Data Warehouse - including the design of Data Marts;
Work with business users and analysts to gather business requirements and convert those requirements into high level and low-level designs;
Define views and data marts, based upon business requirements;
Improve query performance and tuning of existing data marts;
Develop and maintain a front-end application to allow access to back end tables and data;
API Gateway articulation for data exchanges internally and externally.
Monitor production jobs, maintain, and enhance legacy ETL processes on a regular basis.
Develop and maintain automation of manual data extractions;
Support ETL development and maintenance;
Develop and update process and system documentation;
Work closely with the project team including Business Analysts, Architect and Data Developer’s, Project Managers & QA to deliver data capabilities.
Attend design meetings and recommend security and data improvements – and will be empowered to work on those prioritized changes.
Be open to learning new technologies and new problem domains;.
Participate in code reviews and documentation reviews;
Be a contributing member of a cross-functional team in charge of delivering new features and capabilities on an iterative basis.

Qualifications

You Have:
Bachelor’s degree in Computer Science or related field, or equivalent experience;
5+ years of professional experience as an ETL developer in an Enterprise Data Warehousing environment.
3+ years’ Experience with connecting to and posting to API’s for data ingestion and publishing of data sets, including SOAP & REST and related transport technologies (XML/JSON);
Experience in all aspects of data warehousing solutions (Database issues, Data modeling, Data mapping, ETL Development, Metadata Management, Data Cleansing, Data Profiling and Data Migration)
Strong understanding of Business Intelligence and Data Warehousing principles, approaches, technologies, and architectures - including the concepts, designs, and usage of data warehouses and data marts;
Experience designing and customizing data models for data warehouses, supporting data from multiple sources in real time;
Experience with Operational Data Stores and Data Governance Routines (Plus).
Experience with De-Identification or Encrypting the Sensitive Data.
Experience in normalizing and de-normalizing tables and maintaining referential integrity by using triggers and primary and foreign keys;
Experience building data solutions on Amazon Web Services, (such as S3, RDS, Redshift and Aurora), or on Microsoft Azure or Google Cloud;
Experience with connecting to and posting to API’s for data ingestion and publishing of data sets, including SOAP & REST and related transport technologies (XML/JSON);
Experience with other object-oriented development tools such as C#/.Net ,Java, Python;
Critical Thinking – Thorough understanding of TSQL standards/techniques and knowing when to implement them to overcome an issue;
Experience with Salesforce integration is a plus;
Experience working in an Agile/Kanban environment;
The ability to demonstrate strong verbal and written communication skills and interact with all levels of business and IT organizations;
A team-oriented mindset, ability to manage multiple priorities, follow a project plan, and meet project delivery dates;
Strong organizational ability with excellent decision making, analytical, problem solving, and presentation skills;
Judgment and Decision Making — Ability to deal with ambiguity and change;
Time Management – Highly self-motivated and delivery focused;
Additional Information

The SEIU 775 Benefits Group provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.
Requisition #1533"
130,Data Engineer,"Renton, WA 98057",Renton,WA,98057,None Found,None Found,None Found,None Found,None Found,None Found,"Company Information
PACCAR is a Fortune 500 company established in 1905. PACCAR Inc is recognized as a global leader in the commercial vehicle, financial, and customer service fields with internationally recognized brands such as Kenworth, Peterbilt, and DAF trucks. PACCAR is a global technology leader in the design, manufacture and customer support of premium light-, medium- and heavy-duty trucks under the Kenworth, Peterbilt and DAF nameplates and also provides customized financial services, information technology and truck parts related to its principal business.
Whether you want to design the transportation technology of tomorrow, support the staff functions of a dynamic, international leader, or build our excellent products and services, you can develop the career you desire with PACCAR. Get started!
Division Information
PACCAR's Information Division (ITD), located in Renton, WA utilizes cutting-edge technology to provide systems development, consulting, voice and data communications services to the entire Corporation, which has high visibility in the technology sector.
Requisition Summary
Does empowering teams to make data driven decisions excite you? Do you wake up in the morning wondering what possibilities could be unlocked with more data? PACCAR is looking for a seasoned data engineer with AWS experience to join the team. Data Engineering focuses on making possible fast, accurate, and reliable access to data. We build data pipelines, manage a data warehouse, and support the production use of our data. We advocate for good data practices and make sure that our business users are able to make good data driven decisions.
Job Functions / Responsibilities
Work with business users and application architects to understand data requirements, definitions and business rules
Create conceptual and logical data models that accurately reflect these requirements in a way easily understood by business users and development teams
Work with dev teams to create sound physical data designs that reflect the project architecture and choice of data/database technology
Implement data structures on a variety of database platforms, including SQL Server, Oracle, Teradata and Snowflake
Work with dev teams to create database objects (views, functions, stored procedures) that improve application performance, functionality and scalability
Build data pipelines (including data migration from legacy data sources, cleansing and transformation), data validation frameworks, job schedules with emphasis on automation and scale
Contribute to overall architecture, framework, and design patterns to store and process high data volumes
Ensure product and technical features are delivered to spec and on-time
Design and implement features in collaboration with product owners, reporting analysts / data analysts, and business partners within an Agile / Scrum methodology
Proactively support product health by building solutions that are automated, scalable, and sustainable – be relentlessly focused on minimizing defects and technical debt
Qualifications
Masters’ or Bachelors' degree in Software Engineering or a related field
5+ years of experience in large-scale software development (preferably Agile) with emphasis on data modeling and database development
5+ years of experience with data modeling tools (Erwin, ER/Studio, PowerDesigner)
5+ years of experience with relational DBMSs and SQL coding (SQL Server, Oracle, Teradata, Snowflake)
Ability to communicate effectively (both orally and in writing) with business users, project team leaders and application developers
Proficiency with ETL tools and techniques (SSIS, Attunity, Informatica)
2+ years experience with AWS and related services (EC2, S3, DynamoDB, ElasticSearch, SQS, SNS, Lambda, Airflow, Snowflake, etc.)
Education
Bachelors' degree in Computer Science or a related field
Additional Job Board Information
PACCAR is an Equal Opportunity Employer/Protected Veteran/Disability."
131,Data Engineer in Applied Machine Learning â€“ Intermediate,"Seattle, WA",Seattle,WA,None Found,None Found,"Bachelor's degree in computer science or closely related field with strong software development and machine learning skills with 2 years' experience or a Master's degree with 0-2 years' experience, or a Ph.D with 0 years’ experience is required.
",None Found,None Found,None Found,None Found,"Organization and Job ID
Job ID: 309746
Directorate: National Security Directorate
Division: Computing and Analytics Division
Group: Data Sciences and Analytics
Job Description
Do you want to create a legacy of meaningful research for the greater good? Do you want to lead and contribute to work in support of an organization that addresses some of today’s most challenging problems that face our Nation? Then join us in the Data Sciences and Analytics Group at the Pacific Northwest National Laboratory (PNNL)!
For more than 50 years, PNNL has advanced the frontiers of science and engineering in the service of our nation and the world in the areas of energy, the environment and national security. PNNL is committed to advancing the state-of-the-art in artificial intelligence through applied machine learning and deep learning to support scientific discovery and our sponsors’ missions. Help us advance this frontier and protect our nation!
Data Engineering at the Pacific Northwest National Laboratory (PNNL) addresses critical national and global issues by developing data processing/storage systems utilizing cloud, parallel and distributed architectures. We provide capabilities in data modeling and the design, development and deployment of relational, data warehousing, non-relational, and streaming systems. Also focuses on high-performance extract-transform-load processes and big data services that form the foundation of our data science research.
Job Description:
The Data Engineer should have working knowledge in several of the following related-skillsets:

Acquiring/integrating data within a distributed environment (e.g., AWS, Azure, OpenStack, Hadoop)

Data pipeline development (e.g. Spark, NiFi, Kafka, AWS Glue, Kinesis)

Data cleansing and ETL (e.g. Python, SQL)

Scalable/massively parallel databases (e.g. Hive, Redshift, Impala, Athena)

NoSQL databases and cache/indexing services (e.g. Elasticsearch, HBase, MongoDB, Redis).

Interest, curiosity and technical depth to support the development and advancement of a variety of applied problems specific to the national security community.

Discipline, principal job duties/expectations, and qualitative and quantitative measures of performance that exceed the Functional Descriptor:
Technical knowledge in developing and deploying applications in multiple environments – cloud, container services, clusters.

Contribute to the technical content of proposals and technical products such as journal and conference publications technical presentations, and software releases will be expected. Must possess excellent verbal and written communication skills.

The hiring level will be determined based on the education, experience and skill set of the successful candidate based on the following:
Level 2

Design and implement technical approaches to well-defined tasks supporting larger projects.

Mentoring junior staff and students

Work effectively in a dynamic team environment with high expectations for quality.

Level 3

Lead medium sized projects or large tasks.

Key role in defining technical approach and setting technical direction.

Provides solutions to an extensive range of complex and/or ambiguous problems.

Minimum Qualifications
Bachelor's degree in computer science or closely related field with strong software development and machine learning skills with 2 years' experience or a Master's degree with 0-2 years' experience, or a Ph.D with 0 years’ experience is required.
Preferred Qualifications
Bachelor's degree in computer science or closely related field with strong software development and machine learning skills with 5 years of experience, MS/MA with 3 years of experience, or PhD with 1 year of experience.
Equal Employment Opportunity
Battelle Memorial Institute (BMI) at Pacific Northwest National Laboratory (PNNL) is an Affirmative Action/Equal Opportunity Employer and supports diversity in the workplace. All employment decisions are made without regard to race, color, religion, sex, national origin, age, disability, veteran status, marital or family status, sexual orientation, gender identity, or genetic information. All BMI staff must be able to demonstrate the legal right to work in the United States. BMI is an E-Verify employer. Learn more at jobs.pnnl.gov.
Other Information
This position requires the ability to obtain and maintain a federal security clearance.
Requirements:
U.S. Citizenship

Background Investigation: Applicants selected will be subject to a Federal background investigation and must meet eligibility requirements for access to classified matter in accordance 10 CFR 710, Appendix B.

Drug Testing: All Security Clearance (L or Q) positions will be considered by the Department of Energy to be Testing Designated Positions which means that they are subject to applicant, random, and for cause drug testing. In addition, applicants must be able to demonstrate non-use of illegal drugs, including marijuana, for the 12 consecutive months preceding completion of the requisite Questionnaire for National Security Positions (QNSP).

Note: Applicants will be considered ineligible for security clearance processing by the U.S. Department of Energy until non-use of illegal drugs, including marijuana, for 12 consecutive months can be demonstrated.
Directorate: National Security Dir
Job Category: Computation and Information Sciences
Group: Data Sciences & Analytics
Opening Date: 2019-09-03
Closing Date: 2019-10-18"
132,.Net Developer,"Redmond, WA",Redmond,WA,None Found,None Found,None Found,"5+ years of software design and development experience using C#, SQL Server, database technologies and proficient in developing large scale data applications using Microsoft technologies.Experience in developing BI applications using MS Azure TechnologiesAble to analyze data, understand patterns and derive inferencesDesign and problem-solving skills, with a bias for architecting for performance, scalability, usability, security, and reliabilityStrong communication skills: should be able communicate complex information to technical and non-technical stakeholders",None Found,None Found,None Found,"Job Description

Job Details
.Net Developer
6-12 Months Contract / Full time role
Redmond, WA
As a Software Development Engineer, you will be
Build reliable, highly scalable and highly performing applications or distributed systemsCode pipelines, scrips to extract dataEngineer infrastructure, services, automation and tools to improve overall efficiency and productivitySeek opportunities in our day-to-day workflow to improve quality and efficiency from ideation to deploymentDocument your processes and workflow in sharable documents for future reuse and adoption

Skills
5+ years of software design and development experience using C#, SQL Server, database technologies and proficient in developing large scale data applications using Microsoft technologies.Experience in developing BI applications using MS Azure TechnologiesAble to analyze data, understand patterns and derive inferencesDesign and problem-solving skills, with a bias for architecting for performance, scalability, usability, security, and reliabilityStrong communication skills: should be able communicate complex information to technical and non-technical stakeholders

Qualifications

5+ years of software design and development experience using C#, SQL Server
Additional Information

Please send your updated resume, available time for phone discussion and expected salary per annum to vinoth.xyant@gmail. com"
133,"Senior Software Engineer, Big Data","Seattle, WA 98101",Seattle,WA,98101,None Found,None Found,None Found,None Found,None Found,None Found,"About the team
We build the pipelines and processes responsible for daily ingestion of terabytes of data. We productionalize intelligent, data-driven systems to help Zillow capture strategic opportunities in the market. Our work enriches Zillow's unparalleled living database of all homes and hundreds of millions of customers and empowers teams downstream to build analytics tools and products to delight our users.

Small team = big impact. Engineering teams are highly decentralized in order to create the small team speed and autonomy of a start-up environment but backed by big company resources.Fast-moving, developer driven organization full of brilliant and ambitious people.Learn more about what we are doing at www.zillow.com/engineering and www.zillow.com/data-science
About the role
We are looking for a strong technical contributor with a background in software development to create intelligent data driven systems and pipelines. As a Data Engineer, you will be responsible for all phases of the development cycle: design, implementation, testing, and release. You will leverage your deep knowledge and experience to provide technical leadership for the team, take ideas from zero to completion, and provide the bridge between raw data and actionable business insights. You will:
Build and maintain highly-scalable ETL pipelines and data-driven systems
Work closely with business stake holders, data analysts and machine learning engineers to productionalize analytic solutions
Design and implement new data pipelines to support business analysts and data scientists
Design and build infrastructure to support our petabyte scale data lake
Who you are
Data engineer with experience with building and shipping highly scalable distributed systems on cloud platforms (AWS/Azure/GCP) and database technologies (SQL/NoSQL/column-oriented datastores/distributed databases)
Experience with the Big Data ecosystem (Hadoop/Hive/Spark/Presto/Airflow)
Proven track record of leading and delivering large projects independently
Proven ability to learn new technologies quickly
A degree (BS/MS+) in Computer Science or a related technical discipline
Experience with Hive, Spark, Presto, Airflow and or Python a plus
Get to know us
At Zillow Group, we're powered by our inclusive work culture, where everyone has the support and resources to do the best work of their careers. Our efforts to streamline the real estate transaction is supported by our passion to empower people and enrich lives around everything home, a deep-rooted culture of innovation, a fundamental commitment to Equity and Belonging, and world-class benefits. But, don't just take our word for it. Read our reviews on Glassdoor and recent recognition from multiple organizations, including: Fortune 100 Best Companies to Work For (#69), Fortune Best Workplaces for Diversity (#38), Fortune Best Workplaces for Parents (#31), Fortune Best Workplaces for Women (#20), Fatherly's Best Workplaces for New Dads (#37), JUST Capital 100 Company (#69), Bloomberg Gender Equality Index constituent.
Zillow Group is an equal opportunity employer committed to fostering an inclusive, innovative environment with the best employees. Therefore, we provide employment opportunities without regard to age, race, color, ancestry, national origin, religion, disability, sex, gender identity or expression, sexual orientation, or any other protected status in accordance with applicable law. If there are preparations we can make to help ensure you have a comfortable and positive interview experience, please let us know."
134,Data Engineer Manager,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelor’s degree or higher in a quantitative/technical field (e.g. Computer Science, Statistics, Engineering)3+ years of hands-on experience hiring and managing teams and5+ years as a hands-on Data Engineer or developer7+ years of relevant experience in one of the following areas: Data engineering, database engineering, business intelligence or business analytics4+ years experience working with Open Source Big Data tools (Parquet, Spark, Hadoop, Presto)

Are you inspired by innovation? Do you like to build products that are global? Do you like extending machine learning and NLP in the areas of data engineering and analytics? Answer yes to any of these and you’ll fit right in here at AWS-BTS Engineering. We are a team of doers who work passionately to apply cutting edge advances in technology and software to solve challenges that are unique to AWS and transform our customers’ experiences.

As an Amazon Data Engineering and Analytics leader, you will be working on and building large scale data environments that power our next generation products. We are passionate about building highly scalable real time data engines and seek a leader who can drive the vision, lead data engineers, BI engineers, ML and data scientists to deliver the solutions.

The Data Engineering & Analytics team will build next generation data stores and real time insights by working with multiple data sources, warehouses and platforms. These solutions will power real time web applications and recommendation platforms. We collaborate with product managers, business stakeholders and data platform teams to make feature trade-offs, design, and power new applications. The solutions will include statistical modeling, machine learning, predictive analytics, and data visualization.

A successful candidate should have a background in business analytics, data science, data visualization, and data engineering.

Master's degree or higher in a quantitative/technical field (e.g. Computer Science, Statistics, Engineering)Experience working with AWS Big Data Technologies (EMR, Redshift, S3)Proven track record of delivering a big data solution with ML and predictive use cases.Experience working with both Batch and Real Time data processing systemsProven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategyExperience providing technical leadership and mentoring other engineers for best practices on data engineeringKnowledge of software coding practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operationsAbility to plan roadmap, prioritize tasks, manage dependencies and deliver on time.Excellent understanding of software development life cycle and/or agile development environment with emphasis on BI practices.Ability to create collaborative relationships with partners, stakeholders and customers while managing expectations, managing concerns and risks, and communicating progress.Proficiency in at least one modern programming language such as Java, Scala, or PythonKnowledge of data management fundamentals and data storage principlesKnowledge of distributed systems as it pertains to data storage and cloud computingStrong problem-solving skills and ability to prioritize conflicting requirements.Excellent written and verbal communication skills and ability to succinctly summarize key findings.Meets/exceeds Amazon’s leadership principles requirements for this roleMeets/exceeds Amazon’s functional/technical depth and complexity for this role
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Age/ Female / Disability / Veteran / Gender Identity / Sexual Orientation"
135,Business Intelligence Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"BA/BS in Computer Science, Engineering, Information Systems Finance or related field3+ years of demonstrated experience in data modeling, ETL, data warehousing, and transformation of large scale data sources using SQL, Redshift, Oracle, or other Big Data technologiesStrong analytical skills with SQL/R, including the ability to pull data and use data to identify and solve ambiguous problem.Advanced skills in Excel as well as any data visualization tools like Tableau or similar BI toolsExperience of complex operational, process, and performance improvement projectsBe self-driven, and show ability to deliver on ambiguous projects with incomplete or dirty dataAbility and interest in working in a fast-paced and rapidly-changing environment

Amazon is seeking an exceptional Business Intelligence Engineer (BIE) to join the Amazon Fashion (Softlines) Marketing team. This is a unique, high visibility opportunity for someone with a passion to dive deep into large-scale data sets, surface data that provide unique insights to leaders of the Softlines organization and ultimately have an impact on the direction of our business.

This position requires excellent statistical and analytical abilities, deep knowledge of business intelligence solutions and data engineering practices, and the ability to collaborate with various teams across Amazon. The successful candidate will be a self-starter comfortable with ambiguity, capable of working in a fast-paced environment, possess a strong attention to detail, and able to collaborate with customers to understand and transform business problems into requirements and deliverables.

Responsibilities:

Design, implement, and support a platform providing ad hoc access to large datasets.
Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using SQL.Apply mathematical modelling to data and metadata for ad hoc and pre-built reporting.Interface with business customers to gather requirements and deliver complete reporting solutions.Design, develop, and maintain ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisions.Recognize and adopt best practices in reporting and analysis, including data integrity, test design, analysis, validation, and documentation.Improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers.Participate in strategic and tactical planning discussions, including annual budget processes.

Master’s degree in Computer Science, Engineering, Information Systems, Statistics, Finance or related fieldAdvanced ability to draw insights from data and clearly communicate them to the stakeholders and senior management as required.Expert in writing and tuning SQL scriptsExperience working in very large data warehouse environmentsExperience in a data engineer or BIE role with a technology companyExperience conducting large scale data analysis to support business decision makingStrong verbal/written communication and data presentation skills, including an ability to effectively communicate with both business and technical teams
Amazon.com is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age."
136,Data Engineer - Alexa,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelor’s degree in Computer Science, Mathematics, Statistics, Finance, related technical field, or equivalent work experience.Relevant experience in analytics, data engineering, business intelligence, market research or related fieldExperience gathering business requirements, using industry standard business intelligence tool(s) to extract data, formulate metrics and build reportsExperience using SQL, ETL and databases with large-scale, complex datasets

Interested in Amazon Alexa? Come work on it. We’re building the speech and language solutions behind Amazon Echo and other Amazon products and services. We’re working hard, having fun, and making history!

We are looking for candidates who want to help shape the future of human-computer interactions. Specifically, we are looking for an outstanding Data Engineer who is looking to work in a new space to help define how we use data to understand customer behavior and satisfaction. In this role, you will develop and support the analytic technologies that give our teams flexible and structured access to their data, including implementation of a BI platform, defining metrics and KPIs, and automating reporting and data visualization.

The successful candidate will be an expert with SQL, ETL (and general data wrangling) and have exemplary communication skills. The candidate will need to be a self-starter, comfortable with ambiguity in a fast-paced and ever-changing environment, and able to think big while paying careful attention to detail.

Responsibilities

You know and love working with business intelligence tools, can model multidimensional datasets, and can partner with customers to answer key business questions. You will also have the opportunity to display your skills in the following areas:

· · Design, implement, and support a platform providing ad hoc access to large datasets
· · Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using SQL
· · Manage AWS Resources
· · Model data and metadata for ad hoc and pre-built reporting
· · Interface with business customers, gathering requirements and delivering complete reporting solutions
· · Own the design, development, and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisions
· · Recognize and adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation
· · Continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers

Graduate degree in computer science, business, mathematics, statistics, economics, or other quantitative fieldBoth technically deep and business savvy enough to interface with all levels and disciplines within the organizationDemonstrated ability to coordinate projects across functional teams, including engineering, IT, product management, marketing, finance, and operationsKnowledge of Advanced SQL and a programming languageExperience with data visualization using Tableau or similar toolsExperience with large-scale data warehousing and analytics projects, including using AWS technologies – Redshift, S3, EC2, Data-pipeline and other big data technologiesProven track record of successful communication of analytical outcomes through written communication, including an ability to effectively communicate with both business and technical teams
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation."
137,"Data Engineer, Internal Benchmarking","Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelor's degree in Computer Science, Mathematics, Statistics, Finance, related technical field, or equivalent work experience3+ years of relevant work experience in software development, analytics, data engineering, business intelligence or related IT fields, with 1+ years in data engineeringExperience in writing and optimizing SQL queries in a business environment with large-scale, complex datasetsDetailed knowledge of data warehouse technical architecture, infrastructure components, ETL and reporting/analytic tools and environmentsExperience in data visualization software (Tableau/Quicksight) or open-source projects

Would you like to be a Data Engineering and Analytics SME who constantly learns new domains, tools and data sources to identify best practices from across Amazon and propagate them globally?

Amazon’s Internal Benchmarking team is looking for a Data Engineer (DE) to join our Seattle-based team to design, manage, and continuously enhance our BEnchmarking Analytics Foundation (BEAF). BEAF is a shared foundation upon which multiple Benchmarking teams develop and deliver a wide variety of analytics applications including metrics generation, metrics correlation, econometric models, knowledge modeling, and many other use cases to help improve process effectiveness, customer experience, supplier experience, and employee and candidate experience. As the member of the BEAF team, you will manage the Redshift/Spectrum/EMR infrastructure and analytics tools, as well as build data pipelines, tools, and reports that enable product managers, analysts, BIEs, solution architects, and executives to design, deliver, and consume benchmarking services. You will work on three fronts: (1) collaborate with the 15+ specialized Benchmarking teams (4-5 of them are most active) to gather requirements for data collection, logging, storage, transforming, analysis, and reporting; (2) when appropriate, work directly with a benchmarking service team to design and develop data pipelines to process structured and unstructured data to support ML and other analytics applications; and (3) design and execute experiments to test new tools and new benchmarking ideas.

Key Responsibilities:
Manage Redshift/Spectrum/EMR infrastructure, and drive architectural plans and implementation for future data storage, reporting, and analytic solutionsDesign data schema and operate internal data warehouses and SQL/NoSQL database systemsDesign, implement, automate, and monitor data pipelinesDevelop Extract-Transform-Load (ETL) jobs and Redshift/Spectrum/EMR jobs to design and generate business metricsOwn the design, development, and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisions

Graduate degree in Computer Science, Mathematics, Statistics, Finance, or related technical field1+ years of experience in implementing big data processing technology (Hadoop, etc.)Strong ability to effectively communicate with both business and technical teamsDemonstrated experience delivering actionable insights for a consumer businessCoding proficiency in at least one modern programming language (Python, Ruby, Java, etc.)Experience with AWS technologies including Redshift, RDS, S3, EMR (or equivalent with other cloud-based technologies)Experience and interest in statistical analysis would be highly useful
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation"
138,Data Streaming Platform Engineer,"Seattle, WA 98101",Seattle,WA,98101,None Found,None Found,None Found,None Found,None Found,None Found,"About the team
We build the real time streaming platform responsible for ingesting of billions of real-time events and terabytes of data. We aim to provide teams across all of Zillow Group a robust, scalable and lightning fast way of passing their data to diverse set of use cases which enrich Zillow’s unparalleled living database of all homes and hundreds of millions of customers and empowers teams downstream to build analytics tools and products to delight our users.

Small team = huge impact. Engineering teams are highly decentralized in order to create the small team speed and autonomy of a start-up environment but backed by big company resources.Fast-moving, developer driven organization full of forward-thinking and ambitious people.Learn more about what we are doing at https://www.zillow.com/engineering and https://www.zillow.com/data-science
About the role
We are looking for a strong software engineer with a background in real time streaming to create an end to end streaming platform. As a Data Engineer, you will be responsible for all phases of the development cycle: design, implementation, release and operations. You will leverage your knowledge and experience to provide technical leadership for the team, take ideas from zero to completion, and get down to the details for building a system from scratch. You will:
Build and maintain highly scalable, low-latency, fault-tolerant streaming data platform that empowers Data Scientists, Engineers to build real time data applications.
Work closely with business and technology stakeholders to build the next generation Distributed Streaming Data Platform using Apache Kafka
Work closely with the real time data processing platform team to build shared infrastructure abstractions and self service tooling
Who you are
Data Engineer with experience using streaming technologies (Kafka/Kinesis/EventHubs)
Experience running applications on top of cloud platforms (AWS/Azure/GCP)
Experience with Java
Excellent communication skills and demonstrative empathy
Understanding of distributed systems and concepts
Proven track record of leading and delivering large projects independently
Proven ability to learn new technologies quickly
Knowledge of Computer Science fundamentals (CS Degree or related)
Experience running Apache Kafka cluster is a plus
Get to know us
Zillow Group houses the largest portfolio of real estate brands on mobile and the web. We are on a mission to rewire the real estate transaction and are building transformational tools and services that make it easier for everyone to find and get into a home they love. We are working to create an on-demand real estate transaction experience for every stage of the home lifecycle - for buyers, sellers, renters and borrowers - and we're well on our way. No matter what job you're in, you will play a critical role in making this vision a reality for millions of people.
At Zillow Group, we're powered by our inclusive work culture, where everyone has the support and resources to do the best work of their careers. Our efforts to streamline the real estate transaction is supported by our passion to empower people and enrich lives around everything home, a deep-rooted culture of innovation, a fundamental commitment to Equity and Belonging, and world-class benefits. But, don't just take our word for it. Read our reviews on Glassdoor and recent recognition from multiple organizations, including: Fortune 100 Best Companies to Work For (#69), Fortune Best Workplaces for Diversity (#38), Fortune Best Workplaces for Parents (#31), Fortune Best Workplaces for Women (#20), Fatherly's Best Workplaces for New Dads (#37), JUST Capital 100 Company (#69), Bloomberg Gender Equality Index constituent.
Zillow Group is an equal opportunity employer committed to fostering an inclusive, innovative environment with the best employees. Therefore, we provide employment opportunities without regard to age, race, color, ancestry, national origin, religion, disability, sex, gender identity or expression, sexual orientation, or any other protected status in accordance with applicable law. If there are preparations we can make to help ensure you have a comfortable and positive interview experience, please let us know."
139,Lead Data Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"----------------
Role Description
----------------

The Data Engineer is responsible for designing and developing robust, scalable solutions for collecting, analyzing large data sets, creating and maintaining data pipelines, data structures and reports to be used by the revenue organization at Dropbox.

----------------
Responsibilities
----------------


Understand business processes, applications and how data is gathered; and tie application telemetry to transactional data model.
Design, build and manage data marts to satisfy our growing data needs.
Develop and manage data pipelines at enterprise scale
Build data expertise and own data quality for various data flows
Launch and support new data models that provide intuitive analytics to internal customers
Design and develop new framework and automation tools to enable teams to consume and understand data faster
Use your expert coding skills across a number of languages like SQL, Python and Java to support analysts and data scientists
Interface with internal data consumers to understand data needs
Collaborate with multiple teams in high visibility roles and own the solution end-to-end

------------
Requirements
------------


5+ years of SQL (Oracle, AWS Redshift, Hive, etc) experience required, No-SQL experience is a plus.
5+ years of Python or Java development experience.
5+ years of experience with schema design and dimensional data modeling.
Hands-on experience working in data warehousing, data architecture and/or data engineering environments at enterprise scale.
Ability to analyze data to identify deliverables, gaps and inconsistencies.
Experience designing, building and maintaining data processing systems
Experience working with visualization tools like Tableau or MicroStrategy
Communication skills including the ability to identify and communicate data driven insights
BS or MS degree in Computer Science or a related technical field

------------------
Benefits and Perks
------------------


100% company paid individual medical, dental, & vision insurance coverage
401k + company match
Market competitive total compensation package
Free Dropbox space for your friends and family
Wellness Reimbursement
Generous vacation policy
10 company paid holidays
Volunteer time off
Company sponsored tech talks (technology and other relevant professional topics)

"
140,Sr. Machine Learning Data Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelor’s degree in Data Science, Applied Science, Computer Science, Computer Engineering or related technical disciplin5+ years of experience as a data/software developer/scientist or related technical job5+ years of experience with SQLExperience managing platforms or infrastructure software systemsExperience building/managing big data or traditional DW platform componentsExperience as tech lead for data/software engineering/science team

Passionate about books and data science? Kindle/Books Demand Science and Analytics team is seeking an experienced Sr. Data Engineer to work with ML Scientists, Economists, SDEs and BA/IEs on the next generation of science and ML-based products that will help customers discover and buy more of their favorite books on Amazon (in Kindle, Print, or Audio format).
The Kindle/Books Demand Science and Analytics team owns the development of science-based/ML applications aimed at growing customer engagement through
shopping and discovery CX (pricing, deals, personalized rewards, and ranking of recommendations and relevant content across multiple surfaces)targeted marketing (email, push, on-site, paid media)subscription products (including selection and marketing of books for programs like Kindle Unlimited and Prime Reading)
As a Sr. Data Engineer, you will transform billions of daily customer interactions (e.g. browsing, buying, and reading/listening behavior) into highly reliable, quality, and low-latency data structures for analytics, data science, and ML use cases. Ultimately, your work will deepen and accelerate the extent to which we can understand and delight book customers. You will work with a large variety of data sources and will experiment and apply the latest set of big data technologies (ETL and Data Lakes, Redshift, S3, EMR, EC2) to transform data into a better CX with books.

Core Responsibilities
Use SparkSQL, Redshift, EDX and other big data technologies to build and maintain data infrastructure using software engineering best practicesManage AWS resources including EC2, RDS, Redshift, Kinesis, EMR, Lambda etcBuild and deliver high-quality data architecture and automated pipelines to support data science and ML use casesInterface with other technology teams to extract, transform, and load data from a wide variety of data sourcesContinually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customersDevelop understanding and documentation of data sources and appropriate logic for consumption from various data providers (e.g. search, clickstream, reading, marketing, transactions)Enable science and analytics teams to discover and access new data sources
Core Leadership capabilities
Ownership (think long term, don’t sacrifice long-term value for short-term results)Invent and simplify (look for new ideas from everywhere, find ways to simplify to implement innovation)Insist on high standards (continuously raise the bar on data quality, access, speed, and documentation)Deliver results (focus on the key inputs to deliver the high quality-solutions in a timely fashion)

Masters in computer science, mathematics, statistics, economics, engineering or other quantitative field5+ years of experience as a data/software developer/scientist or related technical portfolio
· 2+ years of experience with object-oriented languages such as Python and Scala · Experience with Machine Learning applications (feature generation/selection, supervised/unsupervised learning)
Excellent verbal and written communication skills and technical writing skillsExperience providing technical leadership and mentoring other engineers for best practices on data engineering.Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operationsExperience developing cloud software services and an understanding of design for scalability, performance, privacy, security and reliability
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation"
141,"Senior Business Intelligence Engineer, AWS Training & Certification","Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelor’s degree in Business, Technology, or a similar discipline7+ years of relevant work experience as a business intelligence engineer or data engineer role5+ years of experience in SQL programming4+ years of experience in building data warehouses and dimensional modeling4+ years of experience with business intelligence and data visualization tools (e.g. Tableau)Experience with ETL tools and processesExperience with on boarding and developing data structures

The AWS Training and Certification organization educates customers, partners, and AWS Employees globally on AWS products, solutions, and best practices. We are seeking a talented and experienced Business Intelligence Engineer to help us develop reporting solutions and processes to support the analysis and reporting of metrics for the AWS Training and Certification organization.

As part of the AWS Training and Certification (T&C) Business Intelligence and Data Analytics team you will develop data and reporting solutions to provide insights into the KPIs and metrics that drive the organization. We are looking for someone who will help create automated reporting processes, develop data structures for reports, build insightful dashboards, and deliver data insights to our teams across the globe. The right candidate will be passionate about working with large datasets and should be someone who loves to bring data together to answer complex business questions that deepen our understanding of our business drivers. As a Business Intelligence Engineer within AWS, you will have the exciting opportunity to help shape and deliver our strategy to build a scalable reporting infrastructure that will broaden AWS’s penetration in the cloud computing market.

The ideal candidate will have a background in data warehousing (SQL, ETL techniques, data modeling, Redshift, etc.) and business intelligence tools (e.g. Tableau). A successful candidate should have the technical proficiency to query data in a Redshift data warehouse environment, structure data to be leveraged within business intelligence tools, and be able to develop insightful reports that are delivered to business stakeholders.

Responsibilities:
Serve as a key member of the AWS Training & Certification Business Intelligence and Data Analytics team by supporting all reporting requests from global operations, helping procure new data streams (from both internal and external sources), and ultimately turn data into actionable insights by building meaningful reports.Conduct analysis, perform analysis, and prototype new metrics that will be shared with the Operations Team and executive stakeholdersLeverage internal tools including Tableau and AWS Redshift to deliver data-driven recommendations, tools, dashboards, reports, and findings to internal stakeholders.Manage numerous requests concurrently and strategically, prioritizing when necessary.Support cross-functional teams on the day-to-day execution of projects and initiatives.Drive small to medium projects that help build AWS into the most customer-centric platform.

Master’s degree in Business, Technology, or a similar disciplineAbility to distill problem definitions, models, and constraints from informal business requirementExperience with supporting enterprise business analyticsExperience with Tableau Desktop and Tableau ServerExperience administrating Tableau ServerExperience with RedshiftStrong verbal, written, and presentation skills
Amazon.com is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age."
142,Data Engineer with testing,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Job Details
Job Code
JPSC-7555
Posted Date
06/13/18
Experience
7 Years
Primary Skills
• 3 + years’ experience with 1 or more Databases like Oracle,SQL Server ( basic SQL Concepts,writing simple to medium PL/SQL queries a must) • 2 + yrs Experience with Java server-side web application technology Spring,Hibernate and/or SpringBoot • 2+ yrs Experience with web services and REST architecture (using or building XML/JSON web/serverside APIs) • 1 + yrs of hands-on coding experience in an Agile based multi-tier application framework and environment.
Required Documents
Resume
Overview
Role: Data Engineer with testing
Location: Seattle, WA
Duration: 6+ Months

Job Description:
3 + years’ experience with 1 or more Databases like Oracle, SQL Server ( basic SQL Concepts , writing simple to medium PL/SQL queries a must)
2 + yrs Experience with Java server-side web application technology Spring, Hibernate and/or SpringBoot
2+ yrs Experience with web services and REST architecture (using or building XML/JSON web/serverside APIs)
1 + yrs of hands-on coding experience in an Agile based multi-tier application framework and environment.
Good understanding of software development frameworks, terminology
Competent using version control systems such as GIT, SVN, VSS
Knowledge of continuous integration and development (CI/CD) methodologies
Knowledge/Understanding of RESTful APIs
Knowledge/Understanding of Cloud native Platforms like PCF (Pivotal Cloud Foundry)
Knowledge/Understanding of Cloud Datastores – In-Memory/Persistent, NOSQL / Relational
Knowledge/Understanding of Logging - using tools like SPLUNK.

In the COMMENTS include:
Legal name:
Phone #:
Email address:
Daily Rate:
DOB (Date and Month) :
Skype ID :
Location (City and State):
Relocate:
Availability to start:
Visa type and expiration:
Hiring Status: C2C/W2/1099
Open for CTH:
Timeslots for phone conversation:
Timeslots for WebEx/video interview :

Summary:

Thanks Regards,
Syed Raza
Desk Number: 585 - 532 - 7200 Extension 9002
687 Lee Road, Suite 250, Rochester, NY 14606
Email : Syed.j@avanitechsolutions.com
Email: syed_j@iic.com
Gmail hangouts: syedraza199025@gmail.com
www.iic.com
www.avanitechsolutions.com"
143,Data Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"About Assurance
At Assurance we are disrupting the antiquated and inefficient world of insurance and financial services. Our team of world class software engineers, data scientists, and business professionals are modernizing how people obtain and manage their financial life all through our powerful platform ecosystem. We are rapidly growing as we expand our product offerings and global footprint, and this growth continues to present new and exciting challenges as we push our industry into its future. We eliminate waste throughout the industry and calculate the complex into simple, valuable solutions to improve people's lives. We are humble, driven, and committed to improving the lives of millions.

About the Position
As we build the future of consumer insurance in a modern age, data is at the core of everything that we do. The role requires team members who are adept at building software tools to move and organize data with an approach that is rooted in improving the insights and efficiency of the business. Our team uses a variety of data mining and analysis methods, a variety of data tools, builds and implements models, develops algorithms, and creates simulations. Our Data Engineers design and build the backbone that makes this development possible with no support from engineering (we own our stack end to end). At Assurance, we hire experts in their field, and we give them the independence and trust to build based on their expertise.
To be successful in this role, you must possess the following:
Expertise in modeling data
Experience with Spark, Hadoop/EMR, SQL
Ability to optimize data access for speed/reliability/velocity as needed by the business
Comfort with QA’ing your own data, to include ‘menial tasks’ like listening to calls or scrubbing excel files to ensure everything is correct
Comfort with learning new technologies to help the team explore new solutions to existing problems
A drive to move fast and deliver business value
Excellent communication ability – you can explain your work in a way that anyone on the team can understand, and you can frame problems in a way that ensures the right question is being asked.
Business Acumen – you are always eager to understand how the business works, and more specifically, how your work impacts the business.
Enthusiastic yet humble – you are excited about the work you do, but you are also humble enough to embrace feedback – you don’t need to be the smartest person in the room.
The following additional experience is desired:
Capable of modifying an existing job to add a new field and get it into production within a day.
Capable of creating a new data pipeline/job within 2-3 days.
You have a proven ability to drive business results by building the right infrastructure that enables data-based insights. You are comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for enabling the discovery of solutions hidden in large data sets and working with stakeholders to improve business outcomes. We’re growing at a rapid pace, so it’s important that you embrace the opportunity to blaze your own trail. You thrive in a fast-paced environment where priorities can shift rapidly as we corner opportunity. You can work independently, with little oversight or guidance.

At Assurance, we hire experts in their field, and we give them the independence and trust to build based on their expertise. If this sounds like a good fit for you, give us a shout, we’d love to chat!"
144,Azure Data Architect,"Seattle, WA 98104",Seattle,WA,98104,None Found,"At least 5 years of consulting or client service delivery experience on Azure
",DevOps on an Azure platform,None Found,None Found," Proven ability to build, manage and foster a team-oriented environment
","Are you ready to step up to the New and take your technology expertise to the next level?
Join Accenture and help transform leading organizations and communities around the world. The sheer scale of our capabilities and client engagements, in conjunction with the way we collaborate, operate and deliver value, provides an unparalleled opportunity to grow and advance. Choose Accenture and make delivering innovative work part of your extraordinary career.
People in our Client Delivery & Operations career track drive delivery and capability excellence through the design, development and/ or delivery of a solution, service, capability or offering. They grow into delivery-focused roles, and can progress within their current role, laterally or upward. We partner with our clients to help transform their data into an ‘Appreciating Business Asset.’

As part of our Data Business Group, you will lead technology innovation for our clients through robust delivery of world-class solutions. You will build better software better! There will never be a typical day and that’s why people love it here. The opportunities to make a difference within exciting client initiatives are unlimited in the ever-changing technology landscape. You will be part of a highly collaborative and growing network of technology and data experts, who are taking on today’s biggest, most complex business challenges using the latest data and analytics technologies. We will nurture your talent in an inclusive culture that values diversity. You will have an opportunity to work in roles such as Data Scientist, Data Engineer, or Chief Data Officer covering all aspects of Data including Data Management, Data Governance, Data Intelligence, Knowledge Graphs, and IoT. Come grow your career in Technology at Accenture!

The Azure Technical Architect Delivery is responsible for delivering Data On Cloud projects for Azure based deals. The ideal candidate would also be responsible for developing and delivering Azure cloud solutions to meet todays high demand in areas such as AIML, IoT, advanced analytics, open source, enterprise collaboration, microservices, serverless, etc. The Regional Azure Technical Architect is a highly performant Azure Architect responsible for delivering Cloud based Big Data and Analytical Solutions to our clients. Responsibilities include evangelizing data on cloud solutions with customers, leading Business and IT stakeholders through designing a robust, secure and optimized Azure architectures and ability to be hands-on delivering the target solution. This role will work with customers and leading internal data engineers in delivering big data solutions on cloud. Using Azure public cloud technologies, our Technical Architect professionals implement state of the art, scalable, high performance Data On Cloud solutions that meet the need of today's corporate and emerging digital applications.

Role & Responsibilities:Work with Sales and Bus Dev teams in providing Azure Technical Architecture expertise while pursuing client opportunities.Ability to build cloud architectures and provide prescriptive guidance across network, storage, Big Data Platform Services, serverless architectures, hadoop ecosystem, vendor products, RDBMS & NoSQL databases and security.Participate in deep architectural discussions to build confidence and ensure customer success when building new solutions and migrating existing data applications on the Azure platform.Conduct full technical discovery, identifying pain points, business and technical requirements, “as is” and “to be” scenarios.
- Assess the full technology stack of services required including PaaS (Platform as-a-service), IaaS (Infrastructure as-a-service), SaaS (software as-a-service), operations, management and automation.Lead the discussions and early analysis of the cloud concepts as it relates to Clients’s Journey to Cloud methodology so that clear use cases are developed and prioritized as well as transitioning these concepts from ideas to proof-of-concepts all the way to production delivery with the full support of the appropriate teams.Compare solution alternatives across both technical and business parameters which support the define cost and service requirements.Apply Accenture methodology, Accenture reusable assets, and previous work experience to delivery consistently high-quality work.Stay educated on new and emerging technologies/patterns/methodologies and market offerings that may be of interest to our clients.Adapt to existing methods and procedures to create possible alternative solutions to moderately complex problems.Understand the strategic direction set by senior management as it relates to team goals.Use considerable judgment to define solution and seeks guidance on complex problems.Prepare and deliver product messaging in an effort to highlight value proposition and unique differentiators.Primary upward interaction is with direct supervisor. May interact with peers and/or management levels at a client and/or within Accenture. Establish methods and procedures
on new assignments with guidance.
Manage small teams of deliver engineers successfully delivering work efforts (if in an independent contributor role) at a client or within Accenture.
Extensive travel may be required

Qualifications
Basic Qualifications
At least 5 years of consulting or client service delivery experience on Azure
At least 10 years of experience in big data, database and data warehouse architecture and delivery
Minimum of 5 years of professional experience in 2 of the following areas:
§ Solution/technical architecture in the cloud
§ Big Data/analytics/information analysis/database management in the cloud
§ IoT/event-driven/microservices in the cloud
Experience with private and public cloud architectures, pros/cons, and migration considerations.
Extensive hands-on experience implementing data migration and data processing using Azure services: Networking, Windows/Linux virtual machines, Container, Storage, ELB, AutoScaling, Azure Functions, Serverless Architecture, ARM Templates, Azure SQL DB/DW, Data Factory, Azure Stream Analytics, Azure Analysis Service, HDInsight, Databricks Azure Data Catalog, Cosmo Db, ML Studio, AI/ML, etc.
 Cloud migration methodologies and processes including tools like Azure Data Factory, Event Hub, etc.
 - Familiarity with the Technology stack available in the industry for data management, data ingestion, capture, processing and curation: Kafka, StreamSets, Attunity, GoldenGate, Map Reduce, Hadoop, Hive, Hbase, Cassandra, Spark, Flume, Hive, Impala, etc.
Bachelors or higher degree in Computer Science or a related discipline.

Candidate Must Have Completed The Following Certifications
MCSA Cloud Platform (Azure) Training & Certification
MCSE Cloud Platform & Infratsructiure Training & Certification
MCSD Azure Solutions Architect Training & Certification

Nice-to-Have Skills/Qualifications:
DevOps on an Azure platform
Experience developing and deploying ETL solutions on Azure
Strong in Power BI, Java, C##, Spark, PySpark, Unix shell/Perl scripting
Familiarity with the technology stack available in the industry for metadata management: Data Governance, Data Quality, MDM, Lineage, Data Catalog etc.
- Multi-cloud experience a plus - Azure, AWS, Google

Professional Skill Requirements
 Proven ability to build, manage and foster a team-oriented environment
 Proven ability to work creatively and analytically in a problem-solving environment
 Desire to work in an information systems environment
 Excellent communication (written and oral) and interpersonal skills
 Excellent leadership and management skills
 Excellent organizational, multi-tasking, and time-management skills
 Proven ability to work independently

All of our professionals receive comprehensive training covering business acumen, technical and professional skills development. You'll also have opportunities to hone your functional skills and expertise in an area of specialization. We offer a variety of formal and informal training programs at every level to help you acquire and build specialized skills faster. Learning takes place both on the job and through formal training conducted online, in the classroom, or in collaboration with teammates. The sheer variety of work we do, and the experience it offers, provide an unbeatable platform from which to build a career.

Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status).

Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.

Accenture is a Federal Contractor and an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities.

Equal Employment Opportunity

All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.

Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.

Accenture is committed to providing veteran employment opportunities to our service men and women."
145,"Software Solutions Architect Seattle, WA","Seattle, WA",Seattle,WA,None Found,None Found,None Found,"
Splunk Certified Consultant (SCC-2, SCC-II, Core Certification)
Experience designing and implementing distributed Splunk installations including all Splunk server roles (Search Head, Indexers, Heavy Forwarders, and Universal Forwarders, etc.)
Experience with advanced configuration of Splunk including Indexer Clustering and Search Head Clustering
Experience maintaining and administering enterprise-scale implementations
Experience developing custom Splunk content including scheduled searches, reports, dashboards and alerts
Proficient at data on-boarding activities including custom parsing rules, custom TAs, props, transforms, and adhering to the Common Information Model (CIM)
Experience configuring indexes, index routing, retention policies, etc.
Excellent written and oral skills, ability to work closely with multiple customers, manage expectations, and track engagement scope
Minimum Education: Bachelors Degree",None Found,None Found,None Found,"Arcus Data is seeking experienced Splunk consultants to join their team. Arcus Data is a high growth solutions provider that celebrates and rewards innovation. Join a world-class team of extremely technical engineers that work together in a collaborative culture.
Required Skills
Splunk Certified Consultant (SCC-2, SCC-II, Core Certification)
Experience designing and implementing distributed Splunk installations including all Splunk server roles (Search Head, Indexers, Heavy Forwarders, and Universal Forwarders, etc.)
Experience with advanced configuration of Splunk including Indexer Clustering and Search Head Clustering
Experience maintaining and administering enterprise-scale implementations
Experience developing custom Splunk content including scheduled searches, reports, dashboards and alerts
Proficient at data on-boarding activities including custom parsing rules, custom TAs, props, transforms, and adhering to the Common Information Model (CIM)
Experience configuring indexes, index routing, retention policies, etc.
Excellent written and oral skills, ability to work closely with multiple customers, manage expectations, and track engagement scope
Minimum Education: Bachelors Degree
Required Experience
Splunk engineer with experience managing and configuring Splunk environments, performing data on-boarding, developing custom content on Splunk platform, troubleshooting methodologies, and ability to walk customers through requirements gathering phase and develop appropriate system designs.
Recommended Skills
Splunk premium apps (ITSI, Exchange, Enterprise Security, VMWare, Business Flow)
Understanding of Syslog daemon configuration principles, ideally Syslog-NG
Understanding of modern data pipelines (Kafka, Cribl, Kinesis, Firehose)
Cloud experience (AWS, Azure, GCP)
Development and API experience (Python, REST, XML)
Automation Experience (Ansible, TerraForm, Puppet, Chef)
High-level Job Description
We’re looking for candidates who have a strong technical background and ability to think creatively. You’ll be responsible for building, deploying, and enhancing Splunk for our diverse customer base. This involves working with the customers directly, understanding their business needs, and building innovative solutions to solve interesting & challenging problems.
Detailed Job Description
Our customer deployments range from on-prem, to hybrid, to 100% cloud. You will be supporting a wide variety of clients — some who are just getting started on their Splunk journey — all the way up to advanced 20+ TB customers with thousands of daily active users. This will include the installation and configuration of Splunk Enterprise according to Splunk best practices. Our customers need assistance developing solutions to support their use cases, which requires data onboarding, dashboard development, custom alerting, and third-party tool integrations.
You will also be involved in planning and requirements gathering discussions with the client and will need to possess excellent written and verbal communication skills. The candidate will be required to document system design, capacity planning guides, status reports, and standard operating procedures.
As an Arcus Data engineer you’ll have full access to our internal knowledge base and use case libraries, which is driven by our internal development teams. You’ll also have the technical backing of our entire engineering team to encourage collaboration and growth through information sharing and knowledge workshops. We celebrate and reward innovative thinking!
About Arcus Data
Arcus Data is a proven leader in business analytics, cloud adoption, and automation. We empower organizations to solve some of their most challenging business needs through innovative solutions and advanced use case development. We deliver solutions across all industries including Technology, Healthcare, Energy & Utilities, Retail, and Financial Services."
146,Senior Data Engineer,"Redmond, WA",Redmond,WA,None Found,None Found,"5+ years of relevant experience regarding designing and implementing software systemsSoftware engineering skill in one or more high level languages (C#, C++, Java, Python)",None Found,"5+ years of relevant experience regarding designing and implementing software systemsSoftware engineering skill in one or more high level languages (C#, C++, Java, Python)",None Found,None Found,"We live in the Age of Data. And we LOVE Data! Data and insights from data power an increasing range of applications, transforming not just the technology industry but society at large. Individuals and businesses need a powerful, elastic, and highly available Data Platform that can help them derive insights from large volumes of data. The Database Systems organization is delivering such a platform for a range of Relational Database workloads, from online transaction processing workloads, to data warehousing solutions, from on premise enterprise systems, to on-demand cloud services. Uniquely in the industry, we deal with the full breadth of environments, from server-based to cloud-based systems, delivering features that work across these environments, providing differentiated value to our customers.
We are a full stack team, tackling the breadth of technology from distributed systems, availability, scalability, security, query processing, storage, operating systems, networking, management tools, web development, and most other fields in Computer Science. As an organization, we are also proud of our world class team, our deep investments in growing and retaining talent, and the diversity of skills, experiences, interests and personalities that makes our team strong. Along with the positive impact to society from our technology, our team also prides itself on direct involvement in various social causes, particularly related to broadening access to technology to all sections of society. To help our business to succeed in its ambitions, the Database Systems team is building up Business Analytics capabilities that allow us to track and improve customer experience, provide metrics around growth of existing and new offerings we are constantly developing, and want to apply Machine Learning techniques to answer various business questions. We are creating and maintaining data pipelines and Data Warehouses that allow us to analyze very large data sets that are emitted from our cluster telemetry, and relevant data from across the company. We won’t work in isolation but will leverage analytical work that has been done across the company.
Responsibilities
We are looking for engineers who are passionate about data and want to work in a multi-disciplinary team of Software Engineers, Data Engineers and Data Scientists to solve real-world business problems. You will work on either data from diverse structured and unstructured data sources, and various formats including tabular, text and time series or can contribute to our core data pipeline. In addition, we have deep investments in on-prem telemetry that we need to update/modernize. This business-critical telemetry stack enables business insights for our existing and new features on Windows and Linux. We expect all team members to contribute broadly, with an agile and growth mindset, so your ability to step into multiple areas will be a key attribute that we are looking for.
Qualifications
Basic Qualifications:
5+ years of relevant experience regarding designing and implementing software systemsSoftware engineering skill in one or more high level languages (C#, C++, Java, Python)BS, MS, or PhD in computer science (or equivalent)

Preferred, but not required:
Common ML and analysis tools (R, SAS, SPSS, MatLab)Experience with large scale applied machine learning techniques is a plus but not requiredExperience with SQL or equivalent query language.

AZDAT #ENGGJOBS
#AZDATABASE

Ability to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings: Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter.
Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.

Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work."
147,Senior Data Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,"
Build large-scale batch and real-time data pipelines with data processing frameworks by leveraging Google Cloud Platform, AWS, and Python data science tools.
Help drive optimization, testing and tooling to improve data quality.
Collaborate with other software engineers, ML experts and business stakeholders. And the opportunity to learn and lead every single day.
Work in multi-functional and agile teams to continuously experiment, iterate and deliver on new product objectives to meet customers needs.",None Found,None Found,"This is an onsite position, i.e. not working remotely. The office is located in downtown Seattle.
Are you energized by the idea of disrupting an established industry with cutting-edge technologies? Are you motivated by the opportunity to shape the next milestone of a growing company?
AI and Machine learning (ML) is ripe for broad market adoption. At Kavout, we are the pioneer in AI for investing. As a FinTech company, Kavout’s mission is to empower institutions and investors with augmented intelligence to generate alpha, manage wealth and do more with less.
The company was founded in 2016 and is headquartered in Seattle.
We are looking for a Data Engineer with a solid background in Python, Google Cloud Platform, AWS. In this role you will be exposed to different challenging tasks from data engineering to analytics, and be part of a team to build the next generation investing platform for capital markets with AI and machine learning.
Responsibilities
Build large-scale batch and real-time data pipelines with data processing frameworks by leveraging Google Cloud Platform, AWS, and Python data science tools.
Help drive optimization, testing and tooling to improve data quality.
Collaborate with other software engineers, ML experts and business stakeholders. And the opportunity to learn and lead every single day.
Work in multi-functional and agile teams to continuously experiment, iterate and deliver on new product objectives to meet customers needs.
Who you are
You know how to work with high volume heterogeneous data, preferably with distributed systems such as GCP, AWS, Hadoop, BigTable, Redis, MongoDB etc.
You are knowledgeable about data modeling, data access, data analysis, and data storage techniques.
You appreciate agile software processes, data-driven development, reliability, and responsible experimentation.
The ability to rapidly learn and understand complex data systems.
Comfortable dealing with ambiguity and working independently.
You understand the value of partnership within teams.
This is an onsite role, i.e. not a remote position. The office is at downtown Seattle.
Benefits
We offer a collaborative working environment. And we encourage accountability and integrity.
Competitive salary
Health insurance coverage
Paid time-off
Holiday pay
Please submit your resume to contact@kavout.co"
148,"Data Engineer, Amazon Air","Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelor degree in Engineering, Computer Science, or Statistics; or Masters in Math/Statistics/Finance or related disciplineMinimum three (3) years of experience data modeling, ETL, data warehousing, and transformation of large scale data sources using SQL, Redshift, Oracle, or other Big Data technologiesAbility to source and combine disparate data sets to answer business questionsMinimum of (2) years Advanced SQL with Oracle, SQL or MySQL, and Columnar Databases

Amazon seeks a passionate, results-oriented, Data Engineer to identify strategic initiatives that will form the next generation of air delivery to delight Amazon customers. As an Amazon.com Data Engineer you will be working in one of the world's largest and most complex data warehouse environments. This individual should have deep expertise in the design, creation, management, and business use of extremely large datasets. This high impact role will have an opportunity to help design and build our data infrastructure from the ground up, work with emerging technologies such as Redshift, while driving business intelligence solutions end-to-end: business requirements, workflow instrumentation, data modeling, ETL, metadata, reporting, and dashboard development. He/she should be an expert at designing, implementing, and operating stable, scalable, low cost solutions to flow data from production systems into the data warehouse and into end-user facing applications. This individual should also be able to work with business customers in understanding the business requirements and implementing reporting solutions. The role requires someone who loves data, understands enterprise information systems, has a strong business sense, and is an excellent communicator.

Responsibilities include:
Conduct deep-dive investigations into business problems and identify potential opportunitiesIdentify and adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentationContinually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customersWork with in-house data scientists, global supply chain, transportation and logistics teams, and software teams to identify new features and projectsIdentify ways to automate analysis through smarter software systemsTrack realized savings and impacts, and communicate results with senior leadersThis is an individual contributor role that will partner with internal stakeholders across multiple teams, gathering requirements and deliver complete solutions

Master degree in Engineering or Math/Statistics/Finance or related disciplineAbility to work in a deadline-driven work environment; ability to re-prioritize on a regular basis in order to remain current with business needsExperience guiding and mentoring other data engineers and influencing large scale projects or organizationsQuantitative and qualitative data science experience with impact to a business, a track record of problem solving using software systems, and the desire to create and maintain data warehouse systems
Amazon.com is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age.

#AmazonAir"
149,Data Engineer,"Seattle, WA",Seattle,WA,None Found,None Found, Hadoop/MapR Certification,None Found,None Found, B.S. in Computer Science (or similar),None Found,"The Splunk Data Engineer is responsible for supporting the efforts of the data science team and it’s overall mission of providing a platform for the ingestion, management, storage, and analysis of unstructured and semi-structured machine generated data. This includes supporting the deployment and management of the underlying big data infrastructure including Splunk, HUNK, Hadoop/MapR.

Primary Duties and Responsibilities:Assist in the deployment and management of the Splunk, HUNK, Hadoop/MapR infrastructureDeploy various configurations in the lab for testing and evaluation by the data science teamDeploy and Manage the staging and production Splunk and MapR environmentsWork with the operations team as needed for support and maintenance issues related to Splunk and MapRProvide level 2 on call support as needed for Splunk, HUNK and MapR environmentsTroubleshoot production issues related to data ingestion and other big data related issues as needed
Qualifications
 2+ years experience with data engineering concepts
 2+ years experience deploying and maintaining Splunk environments
 Working knowledge of event logging and key performance indicators
 Analytical and problem solving skills
 Very strong troubleshooting skills
 Solid written and verbal communication skills
 Ability to work directly with customers and vendors in a congenial manner
 Willingness to be a team player
 Self-motivated with the ability to work independently with minimal supervision
 Proficient with common business software (Microsoft Office, Adobe Acrobat, etc.)
 Command line proficiency in server management with a wide variety of UNIX environments
Optional Desired Qualifications:
 Hadoop/MapR Certification
 Hadoop/MapR ecosystem experience
 Working knowledge of telephony and related concepts
 Splunk administration certification or training
 Experience with Splunk ITSI
Education and Certifications:
 B.S. in Computer Science (or similar)
We have been delivering industry-leading solutions for the payments, financial and telecommunications industries since 1990. We are the preferred supplier of networking, integrated data and voice services to many leading organizations in the global payments and financial communities, as well as a provider of extensive telecommunications network solutions to service providers.
We are a privately held company with a healthy balance sheet, secure assets and a loyal customer base that includes some of the largest global blue-chip companies in the world. Many of the world’s leading companies continue to count on us as their primary provider of a range of networking and communication services, enabling them to expand regionally, nationally and globally. We provide services to customers in over 60 countries throughout the world.
We manage some of the largest real-time community networks in the world, enabling industry participants to simply and securely interact and transact with other businesses, to access the data and applications they need, over managed and secure communications platforms. Our existing footprint supports millions of connections and provide access to critical databases. Our network securely blends private and public networking to enable customers to utilize a single connection for ""one-to-many"" and ""many-to-many""connections over a global platform.
Since our launch we have helped our customers and communities of interest, requiring secure and reliable communications solutions, to evolve from legacy to leading-edge technologies. Today the company provides a full range of services from dedicated connections to managed IP network solutions, providing local support and global reach to medium and large enterprises and service providers.
Application Instructions
Applicants are encouraged to submit an electronic resume when applying for our positions. Job postings are open until filled, unless otherwise specified."
150,Data Engineer- ACES,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Ø Bachelor’s degree in Computer Science (or similar), or 4+ years of software development/data engineering experience
Ø Experience in at least one modern object-oriented programming language (Ruby, Python, Java)
Ø Demonstrated strength in data modeling, ETL development, and Data warehousing.
Ø Experience with Redshift, Oracle, NoSQL etc.
Ø Experience in working and delivering end-to-end projects independently.
Ø Knowledge of distributed systems as it pertains to data storage and computing

Business/Team Introduction
ACES (Amazon Customer Excellency System) is seeking a highly talented and motivated Data Engineer to join the Quantitative Business Intelligence Tools (QuBIT) team. In this role, you will be for responsible for building a data lake and implementing data pipelines from various Fulfillment and Transportation applications used to provide seamless data access/visibility across North American Customer Fulfillment (NACF) Network with visibility spanning from Fulfillment Center teams to corporate leadership. This NACF network includes hundreds of fulfillment centers charged with completing and shipping hundreds of millions of packages to customers each year! Every package we ship out is an opportunity for improvement, translating to better prices and service to our customers.

Data Engineer Responsibilities
You should be enthusiastic about learning new technologies and be able to design and implement solutions using these technologies to empower internal customers and scale the existing platforms. This team has a broad scope including all of NACF, allowing creative freedom to explore broad business problems and areas of opportunity needing scalable and fast moving solutions. Application breadth can range from creating a new solution to an old problem, or diving into a space to create new value for our operators in Fulfillment Centers. You should also be enthusiastic about building deep domain knowledge about Amazon’s business and the fulfillment quality space. You must possess strong verbal and written communication skills, be self-driven and deliver high quality results in a fast paced environment. You need to really enjoy working closely with your peers in a group of very smart and talented engineers.

1. Experience with Agile development methodologies
Ø Experience with AWS services including S3, Redshift, EMR, Kinesis and RDS.
Ø Experience with Big Data Technologies (Hadoop, Hive, Hbase, Pig, Spark, etc.)
Ø Experience with building pipelines from application database.

Amazon.com is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation."
151,"Data Engineer, Runner Performance Lab","Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,"
Create and maintain optimal data pipeline architecture for the Run Research Lab
 Lead and drive the re-structuring of the current data architecture, development and implementation of new data management projects & capabilities, data applications and data cleansing.
 Collaborate with appropriate data owners and key stakeholders including Research, Assessment, Run Sights and Product Creation to identify and map data from the source environment to the target data environment
Clean, prepare and optimize data at scale for ingestion and consumption including interfaces between Brooks and third-party systems to enable real time data consumption and preparation for analysis
 Identify data quality gaps and work with data owners to develop solutions and close gaps. Participate in on-going service delivery, including documentation and ownership of relevant change control requests (including evaluation, test, implementation, and verification).
Write code or use specialized development tools to create product features, enhance and/or customize software components
 Anticipate, identify and solve issues concerning data management in the Lab to improve data quality.
Troubleshoot data issues and perform root cause analysis to proactively resolve product and operational issues
 Build continuous integration, test-driven development and production deployment frameworks. Drive collaborative reviews of design, code, test plans and data set implementation in support of maintaining data engineering standards. Test developed programs and integration of data from various sources.
Liaise with enterprise data teams to ensure that development adheres to organizational architecture guidelines.
Participate in key architectural and technical decisions as they apply to the Run Research Lab
Coordinate and conduct application testing (new support packages, releases, functionality and customizing) in close cooperation with the technology team.
Engage system owners to filter, size and prioritize business requests and drive towards appropriate decision points.
Establish consistent technical architecture & contribute to development policies, standards and conventions
Maintain expert knowledge of development tools, technologies and related delivery methods.",None Found,"
Bachelor’s degree in computer science, statistics or applicable engineering fields with a focus in biomechanics and a research environment a plus.
3+ years’ experience with data management tools and industry standard relational database systems preferably in the lab based setting.
 An expert in database technologies (SQL, Big Data frameworks (Hadoop, Spark), advanced data modelling, cloud platforms (AWS, Azure) as well as real-time (Kafka) and batch data integration frameworks
Significant experience in writing programs to analyze biomechanical data is strongly preferred (matlab, visual 3D, Labview, ATL, Python, Jave, C/C++)
Advanced knowledge and experience in use of biomechanics systems for analyzing running/walking gait (3D mocap systems (Motion Analysis, Vicon, Qualysis), Visual 3D, plantar pressure systems (Novel)
Experience in algorithms, especially in the field of AI and machine learning
Experienced in Agile/ Scrum methodologies and collaboration with cross functional teams
Strong project management and analytical skills
Ability to work cross functionally in a fast paced, dynamic environment
Curious and open minded; always open for a challenge, inventive, creative. Ability to challenge the status quo – always looking at improving our products and processes while also displaying a willingness to dive into the details.
Unwavering demonstration of Brooks’ corporate values: Serve People, Lead Thought, Compete as a Team, Have Integrity, Be Active, Have Fun!
A passion for the running enthusiast and active lifestyle
Travel 5% of the time","Who We Are:
Brooks is a team of passionate people united by a desire to do meaningful work, lead healthy lives and make a difference. We share a focused mission: to inspire everyone to run and be active. That’s it. No distractions—it’s all about the run. Through science, creativity, service, authenticity and connection, we obsess over delivering the best running gear on the planet. We do it our way, with our unique spirit, with a goal of being more relevant to runners than any other brand, day after day and mile after mile. We are determined to innovate, challenging ourselves to lead thought at every turn. Inside these walls and on the roads, tracks and trails, we live and breathe Run Happy, celebrating the positive impact running has on our lives and others. We inject it into all we do because it makes everything better, smarter, more fun and more memorable. Our company culture defines us, bonds us together and creates the conditions for success. It is lived daily as a behavioral expression of our collective set of brand values: Connect with People, Innovate for our Customer, Compete as a Team, Build Trust, Have Fun & Bring Passion, and Be Active. If you’re on our team, it means you’re part of creating something extraordinary. You’re part of Brooks.

We are looking for a passionate Data Engineer on the Run Research team to help us build and create the future of the run. From optimizing performance to assessing injury risk to improving the experience on the run, you’ll help design & build the components, frameworks and libraries to support and scale our analytics programs that will enable our teams to create amazing products and elevate experiences for our runners. In this role, you will work cross functionally, collaborating with the research teams, our product assessment teams and our product creation teams to develop data & analytics capabilities that will allow us to leverage data to inform how we help runners achieve their path to a better self. You will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection. The right candidate is excited and passionate about optimizing the Run Research Lab’s data architecture to support our next generation of products and data initiatives.

Job Responsibilities
Create and maintain optimal data pipeline architecture for the Run Research Lab
 Lead and drive the re-structuring of the current data architecture, development and implementation of new data management projects & capabilities, data applications and data cleansing.
 Collaborate with appropriate data owners and key stakeholders including Research, Assessment, Run Sights and Product Creation to identify and map data from the source environment to the target data environment
Clean, prepare and optimize data at scale for ingestion and consumption including interfaces between Brooks and third-party systems to enable real time data consumption and preparation for analysis
 Identify data quality gaps and work with data owners to develop solutions and close gaps. Participate in on-going service delivery, including documentation and ownership of relevant change control requests (including evaluation, test, implementation, and verification).
Write code or use specialized development tools to create product features, enhance and/or customize software components
 Anticipate, identify and solve issues concerning data management in the Lab to improve data quality.
Troubleshoot data issues and perform root cause analysis to proactively resolve product and operational issues
 Build continuous integration, test-driven development and production deployment frameworks. Drive collaborative reviews of design, code, test plans and data set implementation in support of maintaining data engineering standards. Test developed programs and integration of data from various sources.
Liaise with enterprise data teams to ensure that development adheres to organizational architecture guidelines.
Participate in key architectural and technical decisions as they apply to the Run Research Lab
Coordinate and conduct application testing (new support packages, releases, functionality and customizing) in close cooperation with the technology team.
Engage system owners to filter, size and prioritize business requests and drive towards appropriate decision points.
Establish consistent technical architecture & contribute to development policies, standards and conventions
Maintain expert knowledge of development tools, technologies and related delivery methods.
Requirements
Bachelor’s degree in computer science, statistics or applicable engineering fields with a focus in biomechanics and a research environment a plus.
3+ years’ experience with data management tools and industry standard relational database systems preferably in the lab based setting.
 An expert in database technologies (SQL, Big Data frameworks (Hadoop, Spark), advanced data modelling, cloud platforms (AWS, Azure) as well as real-time (Kafka) and batch data integration frameworks
Significant experience in writing programs to analyze biomechanical data is strongly preferred (matlab, visual 3D, Labview, ATL, Python, Jave, C/C++)
Advanced knowledge and experience in use of biomechanics systems for analyzing running/walking gait (3D mocap systems (Motion Analysis, Vicon, Qualysis), Visual 3D, plantar pressure systems (Novel)
Experience in algorithms, especially in the field of AI and machine learning
Experienced in Agile/ Scrum methodologies and collaboration with cross functional teams
Strong project management and analytical skills
Ability to work cross functionally in a fast paced, dynamic environment
Curious and open minded; always open for a challenge, inventive, creative. Ability to challenge the status quo – always looking at improving our products and processes while also displaying a willingness to dive into the details.
Unwavering demonstration of Brooks’ corporate values: Serve People, Lead Thought, Compete as a Team, Have Integrity, Be Active, Have Fun!
A passion for the running enthusiast and active lifestyle
Travel 5% of the time


At Brooks, we celebrate diversity & equity. We are committed to creating an inclusive environment, and encourage people of all backgrounds, perspectives, experiences, and skills to apply. Brooks is proud to be an equal employment opportunity employer. All employment decisions are made without regard to race, religion, color, national origin, gender, gender identity, the presence of a sensory, physical or mental disability, medical condition, military status, marital status, pregnancy or child birth, sexual orientation, age, genetic information, status as a victim of domestic violence, sexual assault or stalking, political ideology, or any other non-merit based factors."
152,Business Analyst,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelor’s degree in computer science, mathematics, statistics, economics, or other quantitative field5+ years of relevant work experience in a role requiring application of data modeling and analytic skillsStrong experience with ETL development, data modeling, data warehousing, MySQL, Tableau, and databases in a business environment with large-scale, complex datasetsAdvanced ability to draw insights from data and clearly communicate them to the stakeholders and senior management as requiredSelf-driven, with demonstrated ability to deliver on ambiguous projects as well as projects/requests where the underlying data is incompleteStrong verbal/written communication and presentation skillsExperience in gathering requirements and formulating business metrics for reportingExperienced working in a fast-paced, high-tech environment and comfortable navigating conflicting priorities and ambiguous problems

Are you interested in defining the future operating model for Amazon’s NA Capacity Planning? Are you excited by high-visibility, strategic supply chain solutions and like to help drive Amazon's operations planning and forecasting? As a team player, you have an opportunity to work with some of the best Technical Engineers, Program Managers, 160+ FCs located across the network and Business Leaders to design the best fulfillment network on the planet. North America Supply Chain Operations team is looking for a Sr. Business Intelligence Engineer who will work on highly visible strategic projects that will influence business critical decisions.

The ideal candidate will have excellent statistical and analytical abilities, outstanding business acumen and judgment, intense curiosity, strong technical skills, and superior written and verbal communication skills. S/he will be a self-starter, comfortable with ambiguity, able to think big and be creative (while paying careful attention to detail), and enjoys working in a fast-paced dynamic environment. To be successful in this role, you should have broad skills in database design, be comfortable dealing with large and complex data sets, have experience building self-service dashboards and using visualization tools, while always applying analytical rigor to solve business problems. In addition to leading the design, development, and management of our analytical tools and reporting, we will also look to this person to provide thought leadership and business analysis support as needed. Your analytics will be used by the Capacity Planning, Capacity Execution, and Demand Planning teams. You will gain knowledge about Amazon’s operations in the capacity planning and forecasting space. You will work as a liaison with different stakeholders (Product Managers, Program Managers, Technical Engineers, Ops Engineering, Finance, and SCOT) in order to diagnose and solve complex business problems by analyzing data and providing recommendations. You will experience a wide range of problem solving situations, strategic to real-time, requiring extensive use of data collection and analysis.

Job duties include:
Design, develop and maintain scalable, automated, user-friendly systems, reports, dashboards, etc. that will support our analytical and business needsAnalyze key metrics to uncover trends and root causes of issuesSuggest and build new metrics and analysis that enable better perspective on businessCapture the right metrics to influence stakeholders and measure successDevelop domain expertise and apply to operational problems to find solutionIn-depth research of capacity-related issues, i.e., fullness, space utilization etcWork across teams with different stakeholders to prioritize and deliver data and reportingRecognize and adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation

MBA or Master’s degree in Computer Science, Engineering, Statistics, Mathematics or related fieldFamiliarity with supply chain management concepts including planning, forecasting and optimization gained through work experienceExpert in writing and tuning SQL scriptsExperience working in very large data warehouse environments3+ years of experience in a data engineer or BIE role with a technology companyAdvanced capabilities with productivity software such as Excel and Access"
153,Data Engineer - Business Intelligence,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelor's degree in Math/Statistics/Engineering or other equivalent quantitative discipline.3+ years in relevant experience as data engineer, data scientist, business intelligence engineer, or equivalent.Advanced working knowledge of large data manipulation and data mining using SQLAdvanced knowledge in developing insightful visualizations and dashboards for large user base using BI tools such as Tableau, Quicksight, OBIEE, or QlikViewAdvanced ability to draw insights from data and clearly communicate them (verbal/written) to the stakeholders and senior management as requiredExperienced in building self-service reporting solutions using business intelligence softwareKnowledge of ETL Tools and Data Warehousing.Knowledge of any programming language (Java, Python, etc) and/or scripting language (Perl, Unix Shell, etc) to process data for modelingBe self-driven, and show ability to deliver on ambiguous projects with incomplete or dirty dataStrong as an individual contributor creating, managing standard operating procedures and internal processStrong sense of ownership, urgency, and drive

BACKGROUND
EC2 Capacity Lifecycle is part of Amazon Web Services. We are responsible for writing software for perfecting capacity elasticity science, delivering the best possible instance lifecycle experience considering optimum hardware and software configurations, managing our ever-growing multi-billion-dollar in-fleet hardware for most optimum utilization, and expanding the AWS footprint in many new regions every quarter.
This role is in EC2 Capacity Engagement team which is a team that is within the EC2 Capacity Lifecycle organization. EC2 Capacity Engagement team manages, escalates, and drives resolution for all active and anticipated capacity shortages that impact Amazon EC2's compute utility service. This teams also documents and reports on all of these issues, and serves as the voice that brings visibility to these events and their impact on customers. They are responsible for all the management of capacity and customers that is not yet automated (e.g., reviewing current and future pool health, driving actions across internal teams, and coordinating with customers) as well as building or evolving the UI tools that enable humans to better meet these needs and feeding back into automation roadmaps to solve recurring failure modes
The EC2 Capacity Engagement team is searching for a passionate and talented Data Engineer or Business Intelligence Engineer (BIE) to help us manage our supply and demand management systems on a global scale.

Data Engineer -BIE Role Core Responsibilities within the EC2 CE team
Create, maintain, and expand a central repository for high-quality cleaned and audited data from the various sourcesDesign, develop and maintain scalable, automated, user-friendly systems, reports, dashboards, scorecards, etc. that will support our analytical and business needs, as well as, and present insights to stakeholdersAnalyze key metrics to uncover trends and root causes of issuesWork closely with various stakeholders to define the information needed and how best to present itLeverage Amazon EC2 AWS capacity knowledge to explore for insights in data that prove or disprove long-held beliefs and helps to guide the ability to anticipate future capacity needs that have not yet been identified.Recognize and adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation

Advanced knowledge of ETL Tools and Data Warehousing.Advanced understanding of AWS services (e.g. DynamoDB, S3, Redshift, and Athena), including complex database ingestion operationsFamiliarity with analytics methods. At least three (Data Prep / Wrangling, Custom Reports / Dashboards, Statistical Inference, Clustering, regression & classification).Demonstrated ability to manage and prioritize workload and roadmapsPrior success working with large, complex data setsDemonstrated ability to achieve stretch goals in a highly innovative and fast-paced environment.Experience in machine learningExperience in Root Cause Analysis"
154,Software Engineer II,"Redmond, WA",Redmond,WA,None Found,None Found,5+ years of professional software development experience.Experience in cloud computing and distributed systems.Customer obsession and a dedication for delivering delightful consumer experiences.Good problem solving and debugging skills associated with production cloud services.Sincere love for the product and seeks out opportunity to innovate and follow through with execution.,None Found,"Contribute to and learn from a diverse community of developers at Team Xbox.You will collaborate with teams across Microsoft, building cloud services used in numerous customer experiences that reach across multiple client platforms.Create and maintain optimal data pipeline architecture. Assemble large, complex data sets that meet functional / non-functional business requirements.Work with data scientist team members that assist them in building and optimizing our product into an innovative industry leader.You are experienced in a wide array of ML techniques, with a penchant for problem solving.As a product innovator, you will ideate, scope work, and drive implementation, validation, and release of new product features.",None Found,None Found,"Software & Data II Engineer in Xbox Live Community

Xbox Live, the leading gamer network spanning console, PC and mobile games, is central to Microsoft’s gaming strategy. Xbox Live provides the breadth of social gaming experiences with Xbox Live clubs, friends, chat, messaging, community hubs, game hubs, game activity feed, and much more. Xbox Live has an exemplary future as it expands to serve many more scenarios where consumers, and creators inspire each other.

We are looking for a creative, analytical and knowledgeable software and data engineer to join our group of similarly inspired and hardworking engineers. You will help us build the next generation of experiences that will make Xbox Live the best community for everyone. You will closely collaborate with Xbox developers, designers, and data scientists, helping us deepen our understanding of gamers and their relationship with other gamers and game content, to provide more meaningful and richer experiences.

Xbox Live is an exceptional place to work – for every gamer, and every non-gamer with a real passion for deeply understanding our current and future gaming fans. It is a place where we recognize that we are better when we work together, and even better still when we lift and grow one another. We are made stronger by our array of dynamic perspectives and ideas. And we have fun, a lot of fun. You should join us.
ResponsibilitiesContribute to and learn from a diverse community of developers at Team Xbox.You will collaborate with teams across Microsoft, building cloud services used in numerous customer experiences that reach across multiple client platforms.Create and maintain optimal data pipeline architecture. Assemble large, complex data sets that meet functional / non-functional business requirements.Work with data scientist team members that assist them in building and optimizing our product into an innovative industry leader.You are experienced in a wide array of ML techniques, with a penchant for problem solving.As a product innovator, you will ideate, scope work, and drive implementation, validation, and release of new product features.

We do not have a fixed list of requirements. Instead, your passion to deeply understand what will excite our existing users and motivate new users to join Xbox Live will set you apart. You will work directly with product owners, designers, client developers, deliver actionable insights, recommendations, and more.
Qualifications5+ years of professional software development experience.Experience in cloud computing and distributed systems.Customer obsession and a dedication for delivering delightful consumer experiences.Good problem solving and debugging skills associated with production cloud services.Sincere love for the product and seeks out opportunity to innovate and follow through with execution.
Preferred Qualifications:
BA/BS or degree in computer science, statistics, math, economics, business or engineering preferred but not required.Dedication for design and enjoy crafting highly performance servicesExperience with integrating services with different client side architectures, caching, experimentation etc.Experience with an OO programming language like Java/C#/C++; Experience with at least one scripting language (Python, Perl, Ruby, Shell etc.).Experience in data transformation and data visualization.Familiar with machine learning toolkits and productionalizing machine learning models.Have experience building production data pipelines using one or more frameworks such as Spark, Flink or Hive/Hadoop.Experience with Data Warehouse design, ETL (Extraction, Transformation & Load), architecting efficient software designs for DW platform.Experience with highly scalable, distributed service architectures, productionalizing ML models, high velocity streaming pipelines or high scale data pipelines, etc.Experience with technologies such as Azure Data Lake, Hadoop, Spark, Hive, Kusto, Elasticsearch, etc.Familiarity with Gaming and Social Network domains.
#xboxlivejobs

#getjobs
#gamingjobs

Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.

Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.

XGAXGETXBL"
155,"Data Strategy Specialist - Business & Data Analysis, Cloud, AWS, Azure, Big Data","Seattle, WA 98104",Seattle,WA,98104,None Found,None Found, 3+ years with business responsibilities (Business Analyst or Project Lead) of data and analytics solutions spanning:,None Found,None Found,None Found,"Are you ready to step up to the New and take your technology expertise to the next level?

Join Accenture and help transform leading organizations and communities around the world. The sheer scale of our capabilities and client engagements, in conjunction with the way we collaborate, operate and deliver value, provides an unparalleled opportunity to grow and advance. Choose Accenture and make delivering innovative work part of your extraordinary career.

People in our Client Delivery & Operations career track drive delivery and capability excellence through the design, development and/ or delivery of a solution, service, capability or offering. They grow into delivery-focused roles, and can progress within their current role, laterally or upward. We partner with our clients to help transform their data into an ‘Appreciating Business Asset.’

As part of our Data Business Group, you will lead technology innovation for our clients through robust delivery of world-class solutions. You will build better software better! There will never be a typical day and that’s why people love it here. The opportunities to make a difference within exciting client initiatives are unlimited in the ever-changing technology landscape. You will be part of a highly collaborative and growing network of technology and data experts, who are taking on today’s biggest, most complex business challenges using the latest data and analytics technologies. We will nurture your talent in an inclusive culture that values diversity. You will have an opportunity to work in roles such as Data Scientist, Data Engineer, or Chief Data Officer covering all aspects of Data including Data Management, Data Governance, Data Intelligence, Knowledge Graphs, and IoT. Come grow your career in Technology at Accenture!

The North America Data Strategy & Architecture capability is part of the Data Business Group (DBG) within Accenture Technology. This team provides advisory services to clients that create an architecture blueprint and an execution roadmap to rotate to “Data in the New” and become intelligent data driven enterprises.

 Connect business vision and current state problems with data, analytics and technology solutions and architectural patterns Interview business stakeholders to understand their vision and challenges Understand and document current state pain points including limitations caused by existing data, analytics and technology gaps Identify and detail business ‘use cases’, or ways that stakeholders would like to drive business value (e.g. increase revenue, decrease expenses, increase efficiency) through data and analytics Aggregate use cases into business consumption patterns detailing the data and technology designs that would support the execution of multiple use cases Ensure alignment between the client’s business needs of the future state with data and technology architecture, operating model and governance recommendations Synthesize business needs with enabling target state recommendations into a vision that client executives, department heads, business and technical resources can understand and align around Develop an execution roadmap detailing a strategic journey from current state to realization of the future state vision with incremental release of technical and operational features and business value Analyze business case for execution against the strategy, including the collection of business case inputs (costs, value drivers) as well as the calculation of return on investment Present data strategy to clients and gain buy in Participate in defining data governance strategy and operating model

Required Skills 3+ years with business responsibilities (Business Analyst or Project Lead) of data and analytics solutions spanning:
o Data Management solutions with capabilities, such as Data Ingestion, Data Curation, Metadata and Catalog, Data Security, Data Modeling, Data Wrangling
o Data Warehousing / BI / Reporting solutions that generate business value using platforms and technologies such as Hadoop, Teradata, Netezza, Greenplum, MapReduce, Spark, etc.
o Data Science, AI / ML, Advanced Analytic solutions that meet business problems 3+ years of consulting experience, interviewing business stakeholders and developing relationships within client organizations Strong communication, presentation, written and facilitation skills Superior critical thinking, analytical and problem-solving skills Ability to interface with client at any level, executive to engineer Competent in leveraging Microsoft Office tools, specifically PowerPoint, Word, and Excel
 Able to travel up to 100% (Mon-Thu)

Optional Skills (Plus): Industry knowledge in Life Sciences, Financial Services or Healthcare Experience in data governance and operating model
 Experience in compiling business cases and roadmaps for data, analytics and technology investments

All of our professionals receive comprehensive training covering business acumen, technical and professional skills development. You'll also have opportunities to hone your functional skills and expertise in an area of specialization. We offer a variety of formal and informal training programs at every level to help you acquire and build specialized skills faster. Learning takes place both on the job and through formal training conducted online, in the classroom, or in collaboration with teammates. The sheer variety of work we do, and the experience it offers, provide an unbeatable platform from which to build a career.

Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status).

Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.

Accenture is a Federal Contractor and an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities.

Equal Employment Opportunity

All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.

Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.

Accenture is committed to providing veteran employment opportunities to our service men and women."
156,New York Hiring Conference - Data Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelor's degree or higher in a quantitative/technical field (e.g. Computer Science, Economics, Finance, Mathematics, Statistics, Engineering).4+ years of relevant experience in one of the following areas: data science, data engineering, business intelligence or business analytics.Strong analytical and problem-solving skills.Expertise in the design, creation and management of large datasets/data models.Expert-level proficiency in writing complex, highly-optimized SQL queries across large datasets.Ability to work with business owners to define key business requirements and convert to technical specifications.Ability to manage priorities simultaneously and drive projects to completion.

Amazon Global Finance & Finance Tech teams are coming to New York!
We are hosting an exclusive hiring event for lead engineers in the data space on October 10th & 11th, 2019 – if you are passionate about Big Data, BI systems, Cloud/AWS & ML, and always enjoy a good challenge of highly complex technical contexts, we have the opportunity for you!

Even the best analysts’ and scientists’ impact is dependent on having access to high quality, reliable data at scale. We are looking for top data engineers to join various teams within the Finance & Finance Tech space in our Seattle HQ, and the person will be responsible of partnering with our research team to understand data needs, establish/manage a data store, work with teams across multiple functions to identify normative data sources, and build data pipelines for production level systems. As a Data Engineer, you will be owning the technical architecture of BI and Data platforms, working with very large data sets in one of the world's largest and most complex data warehouse environments, and you will work closely with the business and technical teams in analyzing many unique business problems and use creative problem-solving to deliver results. You will work in a fast paced environment with some of the brightest engineers to innovate on behalf of the customer. You should be somebody that is passionate about solving customers’ problems and gets excited about owning infrastructure services that serve critical finance systems. You will also guide the team on software development best practices and set examples by using them in the solutions you build.

In summary, a typical Data Engineer in Amazon works on:
Architecture design and implementation of next generation BI solutions, enabling stakeholders to manage the business and make effective decisions.Designing, planning, and building for secure, available, scalable, stable, and cost-effective data solutions in the various engineering subject areas as it relates to data storage and movement solutions: data warehousing, enterprise system data architecture, data design (e.g., Logical and Physical Modeling), data persistence technologies, data processing, data management, and data analysis.

Masters in computer science, mathematics, statistics, economics, or other quantitative field.Proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategy.Experience providing technical leadership and mentoring other engineers for best practices on data engineering.Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations.Experience with AWS services including S3, Redshift, EMR and RDS.Knowledge with statistical and/or econometric modeling.Experience in BI/DW as a change leader providing strategic research, recommendations, and implementations.
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation"
157,"Data Engineer, Analytics - Seattle","Seattle, WA 98101",Seattle,WA,98101,None Found,None Found,None Found,None Found,None Found,None Found,"Facebook's mission is to give people the power to build community and bring the world closer together. Through our family of apps and services, we're building a different kind of company that connects billions of people around the world, gives them ways to share what matters most to them, and helps bring people closer together. Whether we're creating new products or helping a small business expand its reach, people at Facebook are builders at heart. Our global teams are constantly iterating, solving problems, and working together to empower people around the world to build community and connect in meaningful ways. Together, we can help people build stronger communities — we're just getting started.
Do you like working with big data? Do you want to use data to influence product decisions for products being used by over half a billion people every day? If yes, we want to talk to you. Our data warehouse team works very closely with Product Managers, Product Analysts and Internet Marketers to figure out ways to acquire new users, retain existing users and optimize user experience - all of this using massive amounts of data. In this role, you will see a direct link between your work, company growth, and user satisfaction. In this role, you will work with some of the brightest minds in the industry, and you'll get an opportunity to solve some of the most challenging business problems on the web and mobile Internet, at a scale that few companies can match.


This is a full-time position based in our office in Seattle.
RESPONSIBILITIES
Manage data warehouse plans for a product or a group of products.
Interface with engineers, product managers and product analysts to understand data needs.
Build data expertise and own data quality for allocated areas of ownership.
Design, build and launch new data models in production.
Design, build and launch new data extraction, transformation and loading processes in production.
Support existing processes running in production.
Define and manage SLA for all data sets in allocated areas of ownership.
Work with data infrastructure to triage infra issues and drive to resolution.
MINIMUM QUALIFICATIONS
2+ years experience in the data warehouse space.
2+ years experience in custom ETL design, implementation and maintenance.
2+ years experience working with either a MapReduce or an MPP system.
2+ years experience with object-oriented programming languages.
2+ years experience with schema design and dimensional data modeling.
2+ years experience in writing SQL statements.
Experience analyzing data to identify deliverables, gaps and inconsistencies.
Experience managing and communicating data warehouse plans to internal clients.
PREFERRED QUALIFICATIONS
BS/BA in Technical Field, Computer Science or Mathematics.
Knowledge in Python or Java.
Facebook is committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, you may contact us at accommodations-ext@fb.com."
158,Data Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Job Description

Our Data Engineering team builds and maintains a secure, scalable, flexible and user-friendly analytics hub that allows us to make informed and data-driven decisions. They also construct and curate business-critical data sets that allow us to realize the value of all the data we collect.
A Data Engineer utilizes a multidisciplinary approach to providing ETL solutions for the business, combining technical, analytical, and domain knowledge. The perfect applicant for this role has strong development skills, experience transforming and profiling data to determine risks associated with proposed analytics solutions, a willingness to continually interface with analysts in order to determine an optimal approach, and an eagerness to explore data sources to understand the availability, utility, and integrity of our data.
What you'll own:
Data pipeline / ETL development:
Building and enhancing data curation pipelines using tools like SQL, Python, Glue, Spark and other AWS technologies
Focus on data curation on top of datalake data to produce trusted datasets for analytics teams
Data Curation:
Processing and cleansing data from a variety of sources to transform collected data into an accessible and curated state for Analysts and Data Scientists
Migrating self-serve data pipeline to centrally managed ETL pipelines
Advanced SQL development and performance tuning
Some exposure to Spark, Glue or other distributed processing frameworks helpful
Work with business data stewards & analytics team to research and identify data quality issues to be resolved in the curation process
Data Modeling:
Design and build master dimensions to support analytic data requirements
Replacing legacy data structures with new datasets sourced from streaming data feeds from the core product and other operational systems
Design, build and support pipelines to deliver business critical datasets
Resolve complex data design issues & provide optimal solutions that meet business requirements and benefit system performance
Query Engine Expertise & Performance Tuning:
Assist Analytics teams with tuning efforts
Curated dataset design for performance
Orchestration:
Management of job scheduling
Dependency management mapping and support
Documentation of issue resolution procedures
Data Access
Design and management of data access controls mapped to curated datasets
Leveraging devops best practices, such as IAC and CI/CD to build upon a scalable and extensible data environment

Experience you'll need:
Strong experience designing and building end-to-end data pipelines
Extensive SQL development experience
Knowledge of data management fundamentals and data storage principles
Data modeling:
Normalization
Dimensional/OLAP design and data warehousing
Master data management patterns
Modeling trade-offs impacting data management & processing/query performance
Knowledge of distributed systems as it pertains to data storage, data processing and querying
Extensive experience in ETL and DB performance tuning
Hands on experience with a scripting language (Python, bash, etc.)
Some experience with Hadoop, Spark, Kafka, Impala, or other big data technologies helpful

Familiarity with the technology stacks available for:
Metadata management: Data Governance, Data Quality, MDM, Lineage, Data Catalog etc.
Data management, data processing and curation:
Postgres, Hadoop, Hive, Impala, Presto, Spark, Glue, etc.
Experience in data modeling for batch processing and streaming data feeds; structured and unstructured data
Experience in data security / access management, data cataloging and overall data environment management

Experience with cloud services such as AWS and APIs helpful
You’d be a great fit if your current track record looks like this:
5+ years of progressive experience data engineering and data warehousing
Experience with a variety of data management platforms (e.g. RDBMS (Postgres), Hadoop (CDH, EMR))
Experience with high performance query engines (Hive, Impala, Presto, Athena, MPP engines like RedShift)
Strong capability to manipulate and analyze complex, high-volume data from a variety of sources
Effective communication skills with technical team members as well as business partners. Able to distill complex ideas into straightforward language
Ability to problem solve independently and prioritize work based on the anticipated business value

Qualifications

null

Additional Information

All your information will be kept confidential according to EEO guidelines."
159,Sr Data Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Bachelor’s degree in Computer Science, Mathematics, Statistics, Finance, related technical field, or equivalent work experience5+ years of relevant work experience in analytics, data engineering, business intelligence, market research or related fieldExperience in data modeling, ETL development, and data warehousing, or similar skillsExperience using SQL with large data sets (e.g. Oracle, SQL Server, Redshift)Experience with AWS technologies including Redshift, RDS, S3, EMR, Kinesis

Alexa is the cloud service that powers Amazon Echo, the groundbreaking device designed around your voice. This is an opportunity to join a growing team that is working to build an exciting new Amazon business in voice.

We are looking for an exceptional Data Engineer who will own building and maintaining Alexa Skill’s data model and architecture. This includes implementation of a BI platform, promotion of scalability through automation and reporting tools, and adherence to the highest data quality and governance standards. The candidate will also drive the design and implementation of world class big data infrastructure to support machine learning and econometric analysis using Skills data.

The successful candidate will be an expert with SQL, Python, AWS technologies and have exemplary communication skills. The candidate will need to be a self-starter, comfortable with ambiguity in a fast-paced and ever-changing environment, and able to think big while paying careful attention to detail.

Responsibilities:

Design, implement, and support an analytical data infrastructure providing ad hoc access to large datasets and computing powerManaging AWS resources including EC2, RDS, Redshift, et ceteraInterface with other technology teams to extract, transform, and load data from a wide variety of data sources using SQL and AWS big data technologiesExplore and learn the latest AWS technologies to provide new capabilities and increase efficiencyCollaborate with Business Intelligence Engineers (BIEs) to recognize and help adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentationCollaborate with Data Scientists to implement advanced analytics algorithms that exploit our rich data sets for statistical analysis, prediction, clustering and machine learningHelp continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers

Graduate degree in computer science, business, mathematics, statistics, economics, or other quantitative field10 or more years' of prior experience in a Data Engineer role with a technology company or financial institutionBoth technically deep and business savvy enough to interface with all levels and disciplines within the organizationKnowledge of Advanced SQL and scripting for automation (e.g. Python, Perl or Ruby)Familiarity with statistical models and data mining algorithmsExperience with Hadoop or other map/reduce ""big data"" systems and services
Amazon is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age"
160,Data Engineer,"Kent, WA",Kent,WA,None Found,None Found,"5+ years of data engineering, ETL and/or data warehouse development
Master’s Degree in Computer Science (or similar area of study)
Technical expertise and experience both SQL and NOSQL databases
Advanced understanding of a wide array of data models including relational, dimensional, document-based, object oriented, object-relational, and graphical
Advanced experience in database interrogation of SQL and NOSQL databases
Experience implementing High Availability systems requirement
Experience with web based APIs (e.g. REST, SOAP)
Experience with AWS Stack (RDS, Kinesis, Lambda, Redshift, SQS, etc)
Proficiency in scripting languages (e.g. Python, Bash)
Strong analytic skill set and a high degree of proficiency in data mining
Excellent written communication and presentation skills
Must be a U.S. citizen or national, U.S. permanent resident (current Green Card holder), or lawfully admitted into the U.S. as a refugee or granted asylum.
",None Found,"Collaborate with departments and technical product managers to collect, transform and aggregate information that leads to business insights
Build and maintain tools, data pipelines, analytics, reports to highlight technical performance metrics and other key information identified by programs and functional leadership
Work with application developers to collect data from custom applications
Establish processes and tools for monitoring and improving performance and effectivity of new and existing data integrations and pipelines
Perform quality assurance and code reviews to ensure both functional and non-functional requirements are being met
",None Found,None Found,"Description:
As part of a small, passionate and accomplished team of experts, you will work with stakeholders and technical product managers to create a world class decision support system. To successfully accomplish this task, you will design and implement data pipelines from scores of source systems, create flexible and powerful data models and pathways to allow reliable and timely information to be securely delivered downstream to systems and people. This position requires a commitment to quality and attention to detail that will directly impact the history of space exploration and will require your dedicated commitment and detailed attention towards safe and repeatable spaceflight.
Responsibilities:
Collaborate with departments and technical product managers to collect, transform and aggregate information that leads to business insights
Build and maintain tools, data pipelines, analytics, reports to highlight technical performance metrics and other key information identified by programs and functional leadership
Work with application developers to collect data from custom applications
Establish processes and tools for monitoring and improving performance and effectivity of new and existing data integrations and pipelines
Perform quality assurance and code reviews to ensure both functional and non-functional requirements are being met
Qualifications:
5+ years of data engineering, ETL and/or data warehouse development
Master’s Degree in Computer Science (or similar area of study)
Technical expertise and experience both SQL and NOSQL databases
Advanced understanding of a wide array of data models including relational, dimensional, document-based, object oriented, object-relational, and graphical
Advanced experience in database interrogation of SQL and NOSQL databases
Experience implementing High Availability systems requirement
Experience with web based APIs (e.g. REST, SOAP)
Experience with AWS Stack (RDS, Kinesis, Lambda, Redshift, SQS, etc)
Proficiency in scripting languages (e.g. Python, Bash)
Strong analytic skill set and a high degree of proficiency in data mining
Excellent written communication and presentation skills
Must be a U.S. citizen or national, U.S. permanent resident (current Green Card holder), or lawfully admitted into the U.S. as a refugee or granted asylum.
Desired:
Experience with and knowledge of project management principles and practices
Experience in manufacturing processes such as Integrated Supply Chain
Experience with OLAP Cubes or similar BI constructs
Experience with Kafka, Spark and other big data pipeline technologies
Experience with IoT / Smart Factory data collection and aggregation
Blue Origin offers a phenomenal work environment and awesome culture with competitive compensation, benefits, 401K, and relocation.


Blue Origin is an equal opportunity employer . In addition to EEO being the law, it is a policy that is fully consistent with Blue's principles. All qualified applicants will receive consideration for employment without regard to status as a protected veteran or a qualified individual with a disability, or other protected status such as race, religion, color, national origin, sex, sexual orientation, gender identity, genetic information, pregnancy or age. Blue Origin prohibits any form of workplace harassment."
161,Data Engineer In Test,"Seattle, WA",Seattle,WA,None Found,None Found,"Bachelor's in Computer Science or related degree
","Bachelor's in Computer Science or related degree
",None Found,None Found,None Found,"Homesite Insurance was founded in 1997 and was one of the first companies to enable customers to purchase home insurance directly online, during a single visit. Since then, we've continued to innovate rapidly to meet the needs of our customers and their changing expectations.
One thing that's stayed the same since our founding: our commitment to our customers, partners and employees.
Join us on our journey as we continue to grow into a powerful contender in the field of insurance.
This position contributes to developing, implementing, and sustaining manual & automation testing including performance testing processes, practices, and controls in support of application and system requirement throughout the software development and sustainment lifecycles. Provides direction on the development and implementation of test automation and performance testing processes, methods and tools.

The position requires understanding & experience in AWS Data Platform

Experience is required in creating test plans/test cases, executing tests for applications & validating data using Tableau.
Skills Required:
Hands-on Engineer with experience in development/testing software with big data components in AWS Cloud infrastructure
Experience in testing AWS data pipelines using S3, AWS GLUE, Athena, PySpark, AWS Code Pipeline, Jupyter Notebooks, XML/JSON, Redshift, Tableau, etc.
Skills in SQL, Python, pytest, Git, Code deployment & CI/CD practices
Experience scripting, running ETL jobs, troubleshooting errors, analyzing data and performance testing.
Experience working with Agile SDLC frameworks i.e. SCRUM, Kanban, DevOps.
Experience developing or working with commercial or open source automation tools and frameworks
Demonstrate knowledge using version control and defect tracking methods, including an understanding of associated tools
Demonstrated collaboration working with diverse teams including project managers, business analysts, and Engineers related to quality assurance roles and responsibilities
Qualifications:
Bachelor's in Computer Science or related degree
3-5 years of experience in Data Engineering in Test
3+ years of experience with SQL, Python & Tableau
Understanding of key QA metrics and defect management"
162,Data Engineer,"Seattle, WA",Seattle,WA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"This position is full time and based at our Seattle, U.S. office.


WHO YOU ARE
The ideal candidate has extensive experience designing and building data solutions with the open-source technology stack including: Hadoop, Spark, Hive, Airflow, or any other. Experience developing and maintaining a commercial quality B2B SaaS platform is highly preferred as well as involvement on AWS (Amazon Web Services). You must enjoy collaborating with team members and acting as scrum master to successfully deliver projects using an agile methodology. Even if you do not possess skill in these technologies and architectures, but you are a knowledgeable, experienced data management profession, please do apply!


RESPONSIBILITIES
Define, develop, and maintain the TenPoint7 Cloud platform including the technology components that provide: data ingestion, data integration, data modeling, data processing and data visualization
Provide data related consulting to clients for the creation of custom analytics apps or the implementation of packaged analytics apps
Gather, analyze, and document project functional requirements
Define epics, user stories, tasks, and subtasks for projects
Design and develop new features for the SaaS platform
Maintain and enhance existing features of the SaaS platform
Create unit tests, perform unit testing and fix bugs
Assist in project management responsibilities including scope, schedule, issues and risks
Help validate that solutions meet requirements and service/quality level agreements
Communicate project status to team members
Maintain quality standards of excellence and ensure compliance with TenPoint7 delivery standards and best practices


TECHNICAL REQUIREMENTS
Python, Java or JavaScript, SQL
Spark, Spark is nice to have
Experience with AWS, EMR or SageMaker is preferred


PERSONAL ATTRIBUTES
Drive – determined to work hard and get things done
Integrity – always reliable and professional for our clients and our team members
Team Oriented – Collaboratively create productive, cohesive, intercontinental teams
Innovative – solve complex problems in new and unique ways
Analytical – Understand data and all its potential
Self-Reliant and self-confident
Persistent and fearless
Powerfully passionate


QUALIFICATIONS
Bachelor of Science degree in computer science
Experience in back-end web application development
Experience in managing projects, and providing clarity and transparency on project status to all stakeholders
Very good verbal and written English language with strong communication skills


ABOUT TENPOINT7
TenPoint7 is an Analytics Software-as-a-Service company based in Seattle, WA with a global development office located in Ho Chi Minh City, Vietnam. We deliver high value analytics apps hosted in the cloud that are infused with Data Science based algorithms. We are driven by these 3 simple things: Data, People & Value. If you find interest, please send your resume in English to careers@tenpoint7.com."
163,Senior Cloud Solutions Architect,"Seattle, WA",Seattle,WA,None Found,None Found,"
Mastery in at least one of the following domain areas:
Infrastructure Modernization: migrating n-tiered workloads from on-prem and other clouds to GCP with near-zero-downtime (includes full spectrum of lift and shift to complete re-platforming scenarios), or building hybrid-cloud solutions based on Anthos and containerization technologies, such as Docker, Kubernetes, and Istio
Application Development: building custom web and mobile applications on top of the GCP stack
Data Engineering: data warehouse modernization (including technical architectures, star/snowflake schema designs, infrastructure components, ETL/ELT pipelines and reporting/analytic tools), OLTP/OLAP data migrations, or backup, restore and disaster recovery solutions.
Experience providing oversight and direction of cloud projects
Experience leading technical design sessions, architecting and documenting technical solutions that are aligned with client business objectives, and identifying gaps between the client's current and desired end states
Experience strategizing, designing, architecting and leading the deployment of scalable solutions on GCP
Experience across multiple cloud platforms: GCP, AWS, Azure
Experience with container engines: Kubernetes, Docker, AWS Elastic Container Service
Experience with automation technologies including Terraform, Google Cloud Deployment Manager, AWS Cloud Formation or Microsoft Azure Automation
Experience working with engineering and sales teams to elicit customer requirements
Ability to communicate across business units and the ability to interface with and communicate complex technical concepts to a broad range of internal and external stakeholders
Time management skills with the ability to manage multiple streams and lead less experienced architects
Experience as a technical consultant or another customer-facing technical role
",None Found,None Found,None Found,None Found,"Join SADA as a Sr. Cloud Solutions Architect!

Your Mission

As a Sr. Cloud Solutions Architect at SADA, you will work collaboratively with other architects and engineers to design, prototype and lead the deployment of scalable Google Cloud Platform (GCP) architectures. You will work with engineering teams, customers and sales teams to qualify potential engagements, craft robust architectural proposals, and deliver Statements of Work (SOWs) that engineering teams can successfully execute. You’re also hands-on, able to conduct experiments and build functioning prototypes that prove out ideas and build confidence in the solutions you advocate.

You will be a recognized expert within SADA and will develop a reputation with customers as well as the Google Cloud sales and professional services organizations for the quality of your work. You will demonstrate repeated delivery of project architectures that other engineers and architects demur to you for lack of expertise. You will also lead early-stage opportunity technical qualification calls, as well as lead client-facing technical discussions.

Pathway to Success

#BeAChangeAgent: You are a rainmaker! You are way out in front of our delivery organization, meeting with the spectrum of corporate and enterprise customers that need our consultative services. You have your finger on the pulse of their technical needs and take pride in helping them solve their real-world problems on GCP.

You will be measured quarterly by a combination of (a) the volume of signed SOWs that you shepherd through the sales funnel, and (b) the level of customer satisfaction measured at the end of each engagement.

As you continue to execute successfully, we will build a customized development plan together that leads you through the solution architecture or management growth tracks.

Expectations

Required Travel - 30% travel to customer sites, conferences, and other related events.
Customer Facing - You will interact with customers on a regular basis, sometimes daily, other times weekly/bi-weekly. Common touchpoints occur when qualifying potential opportunities, at project kickoff, throughout the engagement as progress is communicated, and at project close. You can expect to interact with a range of customer stakeholders, including engineers, technical project managers, and executives
Training - Ongoing with first-week orientation at HQ followed by a 90-day onboarding schedule. Details of the timeline can be shared.

Job Requirements

Required Credentials:

Google Professional Cloud Architect Certified

[https://cloud.google.com/certification/cloud-architect] and/or Google
Professional Data Engineer Certified
[https://cloud.google.com/certification/data-engineer], or able to complete one of the above within the first 45 days of employment.

Required Qualifications:

Mastery in at least one of the following domain areas:
Infrastructure Modernization: migrating n-tiered workloads from on-prem and other clouds to GCP with near-zero-downtime (includes full spectrum of lift and shift to complete re-platforming scenarios), or building hybrid-cloud solutions based on Anthos and containerization technologies, such as Docker, Kubernetes, and Istio
Application Development: building custom web and mobile applications on top of the GCP stack
Data Engineering: data warehouse modernization (including technical architectures, star/snowflake schema designs, infrastructure components, ETL/ELT pipelines and reporting/analytic tools), OLTP/OLAP data migrations, or backup, restore and disaster recovery solutions.
Experience providing oversight and direction of cloud projects
Experience leading technical design sessions, architecting and documenting technical solutions that are aligned with client business objectives, and identifying gaps between the client's current and desired end states
Experience strategizing, designing, architecting and leading the deployment of scalable solutions on GCP
Experience across multiple cloud platforms: GCP, AWS, Azure
Experience with container engines: Kubernetes, Docker, AWS Elastic Container Service
Experience with automation technologies including Terraform, Google Cloud Deployment Manager, AWS Cloud Formation or Microsoft Azure Automation
Experience working with engineering and sales teams to elicit customer requirements
Ability to communicate across business units and the ability to interface with and communicate complex technical concepts to a broad range of internal and external stakeholders
Time management skills with the ability to manage multiple streams and lead less experienced architects
Experience as a technical consultant or another customer-facing technical role

Useful Qualifications:

Hands-on experience designing and recommending elegant solutions that drive business outcomes
Experience building, designing and migrating complex cloud architectures
Strong aptitude for learning new technologies and techniques with a willingness and capability to skill up the team
Ability to lead an in-depth client meeting/workshop across a broad range of topics including discovery, cloud compliance, and security
Deep understanding of best practices, design patterns, reference and compliance architectures with an uncanny ability to build and recommend these as needed
Knowledge and understanding of industry trends, new technologies and the ability to apply these to customer architectures to drive outcomes
Highly self-motivated and able to work independently as well as in a team environment

Values: We built our core values
[https://sadasystems.com/about/company-overview/] on themes that internally compel us to deliver our best to our partners, our customers and to each other. Ensuring a diverse and inclusive workplace where we learn from each other is core to SADA’s values. We welcome people of different backgrounds, experiences, abilities and perspectives. We are an equal opportunity employer.

1. Make them rave
2. Be data driven
3. Be one step ahead
4. Be a change agent
5. Do the right thing

Work with the best : SADA has been the largest partner in North America for GCP since 2016 and recently announced, at Google NEXT, as the
2018 Global Partner of the Year
[https://sadasystems.com/blog/google-cloud/gcp/sada-wins-2018-google-cloud-partner-award/]. SADA has also been awarded
Best Place to Work
[https://sadasystems.com/blog/news/sada-systems-best-places-work-2019/] by Inc. as well as LA Business Journal!

Benefits : Unlimited PTO
[https://sadasystems.com/blog/news/blogannouncementsblogannouncementsunlimited-pto-yes-unlimited-why-sada-is-the-best-place-to-work/], competitive and attractive compensation, performance-based bonuses, paid holidays, rich medical, dental, vision plans, life, short and long-term disability insurance, 401K with match,
professional development reimbursement program
[https://sadasystems.com/blog/news/blogannouncementsprofessional-development-how-we-do-it-why-it-matters/] as well as Google Certified training programs.

Business Performance: SADA has been named to the INC 5000 Fastest Growing Private Companies list for 12 years in a row garnering Honoree status. CRN has also named SADA on the Top 500 Global Solutions Providers for the past 5 years. The overall culture continues to evolve with engineering at its core: 3200+ projects completed, 3000+ customers served, 10K+ workloads and 25M+ users migrated to the cloud."
