,Title,Location,City,State,Zip,Country,Qualifications,Skills,Responsibilities,Education,Requirement,FullDescriptions
0,"Cloud Data Engineer, Google Professional Services","Atlanta, GA",Atlanta,GA,None Found,None Found,None Found,None Found,"
Act as a trusted technical advisor to customers and solve complex Big Data challenges.
Create and deliver best practices recommendations, tutorials, blog articles, sample code, and technical presentations adapting to different levels of key business and technical stakeholders.
Travel up to 30% of the time.
Communicate effectively via video conferencing for meetings, technical reviews and onsite delivery activities.",None Found,None Found,"Note: By applying to this position your application is automatically submitted to the following locations: Chicago, IL, USA; Atlanta, GA, USA
Minimum qualifications:

BA/BS degree in Computer Science, Mathematics or related technical field, or equivalent practical experience.
Experience with data processing software (such as Hadoop, Spark, Pig, Hive) and with data processing algorithms (MapReduce, Flume).
Experience in writing software in one or more languages such as Java, C++, Python, Go and/or JavaScript.
Experience managing internal or client-facing projects to completion; experience troubleshooting clients' technical issues; experience working with engineering teams, sales, services, and customers.

Preferred qualifications:
Experience working data warehouses, including data warehouse technical architectures, infrastructure components, ETL/ELT and reporting/analytic tools and environments.
Experience in technical consulting.
Experience working with big data, information retrieval, data mining or machine learning as well as experience in building multi-tier high availability applications with modern web technologies (such as NoSQL, MongoDB, SparkML, Tensorflow).
Experience architecting, developing software, or internet scale production-grade Big Data solutions in virtualized environments.
About the job
As a Cloud Data Engineer, you'll guide customers on how to ingest, store, process, analyze and explore/visualize data on the Google Cloud Platform. You will work on data migrations and transformational projects, and with customers to design large-scale data processing systems, develop data pipelines optimized for scaling, and troubleshoot potential platform challenges.
In this role you are the Google Engineer working with Google's most strategic Cloud customers. Together with the team you will support customer implementation of Google Cloud products through: architecture guidance, best practices, data migration, capacity planning, implementation, troubleshooting, monitoring and much more.
The Google Cloud Platform team helps customers transform and evolve their business through the use of Google’s global network, web-scale data centers and software infrastructure. As part of an entrepreneurial team in this rapidly growing business, you will help shape the future of businesses of all sizes use technology to connect with customers, employees and partners.
Responsibilities
Act as a trusted technical advisor to customers and solve complex Big Data challenges.
Create and deliver best practices recommendations, tutorials, blog articles, sample code, and technical presentations adapting to different levels of key business and technical stakeholders.
Travel up to 30% of the time.
Communicate effectively via video conferencing for meetings, technical reviews and onsite delivery activities.
At Google, we don’t just accept difference—we celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form."
1,Sr. Data Engineer,"Atlanta, GA 30328",Atlanta,GA,30328,None Found,None Found,None Found,None Found,None Found,None Found,"We are looking for a Data Engineer for the Enterprise Data Organization to build and manage data pipeline (Data ingest, data transformation, data distribution, quality rules, data storage etc.) for Azure cloud based data platform. The candidate will require to possess strong technical, analytical, programming and critical thinking skills. Ideal candidate will have familiarity with data transformation, data modeling, Master data management, and Meta data management.

KEY RESPONSIBILITIES:

Design, develop and maintain reliable automated data solutions based on the identification, collection and evaluation of business requirements. Including but not limited to data models, database objects, stored procedures and views.
Developing new and enhancing existing data processing (Data Ingest, Data Transformation, Data Store, Data Management, Data Quality ) components
Engage with IT teams such as DBAs, Security, Storage and Networking when their involvement is required to meet the project needs.
Support and troubleshoot the data environment (including periodically on call)
Document technical artifacts for developed solutions
Maintains professional and technical knowledge by attending educational workshops; reviewing professional publications; establishing personal networks; benchmarking state-of-the-art practices; participating in professional societies.
EDUCATION QUALIFICATIONS:

BS in either Information Systems, Finance/Mathematics, or Computer Science or similar field
EXPERIENCE QUALIFICATION:

10+ Years
REQUIRED KNOWLEDGE, SKILLS or ABILITIES:

Good interpersonal skills; comfort and competence in dealing with different teams within the organization. Requires an ability to interface with multiple constituent groups and build sustainable relationships.
Strong and effective communication skills (verbal and written).
Strong analytical, problem solving skills.
Experience of working in a matrix organization, self-driven. A go getter and a problem solver.
Ability to prioritize, work to deadlines, work under pressure. Results oriented, flexible, adaptable.
Work well independently, and be a team player.
Versatile, creative temperament, ability to think out-of-the box while defining sound and practical solutions. Ability to master new skills.
Proactive approach to problem solving with effective influencing skills.
TECHNICAL SKILLS:

Familiar with Agile practices and methodologies
5+ years professional data engineering experience focused on batch and real time data pipelines using Spark, PySpark, Python, SQL, Java
8+ Years of hands-on design and development experience in data space : data processing / data transformation using ETL tools, data warehouse (data modeling, programming), RDBMS
Exposure in Microsoft technologies like SSIS, SQL Server, SSRS
Experience with a DevOps model utilizing a CI/CD tool
PREFERRED KNOWLEDGE, SKILLS, OR ABILITIES:
Hands-on Talend work experience (anyone with this skill will have an advantage over other candidates)
Understanding of data science and visualization technologies (Hadoop, Spark, Databricks)
Experience working on a cloud environment, preferably, Microsoft Azure
Cloud Data Warehouse solutions (Snowflake, Azure DW)
NoSQL databases and modeling (Cassandra, HBase, MongoDB)"
2,AWS Data Engineer,"Atlanta, GA 30303",Atlanta,GA,30303,None Found,"At least 5 years of Consulting or client service delivery experience on Amazon AWS (AWS)At least 5 years of experience in developing data ingestion, data processing and analytical pipelines for big data, relational databases, NoSQL and data warehouse solutionsExtensive experience providing practical direction within the AWS Native and HadoopExperience with private and public cloud architectures, pros/cons, and migration considerations.Minimum of 5 years of hands-on experience in AWS and Big Data technologies such as Java, Node.js, C##, Python, SQL, EC2, S3, Lambda, Spark/SparkSQL, Hive/MR, Pig, Oozie and streaming technologies such as Kafka, Kinesis, NiFI etc.Extensive hands-on experience implementing data migration and data processing using AWS services: VPC/SG, EC2, S3, AutoScaling, CloudFormation, LakeFormation, DMS, Kinesis, Kafka, Nifi, CDC processing Redshift, Snowflake, RDS, Aurora, Neptune, DynamoDB, Hive, NoSQL, Cloudtrail, CloudWatch, Docker, Lambda, Spark,Glue, Sage Maker, AI/ML, API GW, etc.5+ years of hands on experience in programming languages such as Java, c#, node.js, python, pyspark, spark, SQL, Unix shell/Perl scripting etc.Minimum of 5 years of RDBMS experienceExperience in using Hadoop File Formats and compression techniquesExperience working with DevOps tools such as GitLabs, Jenkins, CodeBuild, CoePipeline CodeDeploy, etc.Bachelors or higher degree in Computer Science or a related discipline.","DevOps on an AWS platform. Multi-cloud experience a plus.Experience developing and deploying ETL solutions on AWS using tools like Talend, Informatica, MatillionStrong in Java, C##, Spark, PySpark, Unix shell/Perl scriptingIoT, event-driven, microservices, containers/Kubernetes in the cloud",None Found,None Found," Proven ability to build, manage and foster a team-oriented environment Proven ability to work creatively and analytically in a problem-solving environment Desire to work in an information systems environment Excellent communication (written and oral) and interpersonal skills Excellent leadership and management skills","Are you ready to step up to the New and take your technology expertise to the next level?

Join Accenture and help transform leading organizations and communities around the world. The sheer scale of our capabilities and client engagements, in conjunction with the way we collaborate, operate and deliver value, provides an unparalleled opportunity to grow and advance. Choose Accenture and make delivering innovative work part of your extraordinary career.

People in our Client Delivery & Operations career track drive delivery and capability excellence through the design, development and/ or delivery of a solution, service, capability or offering. They grow into delivery-focused roles, and can progress within their current role, laterally or upward. We partner with our clients to help transform their data into an ‘Appreciating Business Asset.’

As part of our Data Business Group, you will lead technology innovation for our clients through robust delivery of world-class solutions. You will build better software better! There will never be a typical day and that’s why people love it here. The opportunities to make a difference within exciting client initiatives are unlimited in the ever-changing technology landscape. You will be part of a highly collaborative and growing network of technology and data experts, who are taking on today’s biggest, most complex business challenges using the latest data and analytics technologies. We will nurture your talent in an inclusive culture that values diversity. You will have an opportunity to work in roles such as Data Scientist, Data Engineer, or Chief Data Officer covering all aspects of Data including Data Management, Data Governance, Data Intelligence, Knowledge Graphs, and IoT. Come grow your career in Technology at Accenture!

The Amazon AWS Data Engineer is responsible for delivering Data On Cloud projects for Amazon AWS based deals. The ideal candidate would be responsible for developing and delivering AWS cloud solutions to meet today’s high demand in areas such as AIML, IoT, advanced analytics, open source, enterprise collaboration, microservices, serverless, etc. The AWS Data Engineer is a highly performant engineer responsible for delivering Cloud based Big Data and Analytical Solutions at our clients. Responsibilities include building data on cloud solutions at customers, leading Business and IT stakeholders through designing a robust, secure and optimized AWS solutions and ability to be hands-on delivering the target solution. This role will work with customers and leading internal engineering teams in delivering big data soltuions on cloud. Using Amazon AWS public cloud technologies, our AWS Data Engineer professionals implement state of the art, scalable, high performance Data On Cloud solutions that meet the need of today’s corporate and emerging digital applications.

Role & Responsibilities:
Provide subject matter expertise and hands on delivery of data capture, curation and consumption pipelines on AWS and HadoopAbility to build cloud data solutions and provide domain perspective on storage, big data platform services, serverless architectures, hadoop ecosystem, RDBMS, DW/DM, NoSQL databases and security.Participate in deep architectural discussions to build confidence and ensure customer success when building new solutions and migrating existing data applications on the AWS platform.
- Build full technology stack of services required including PaaS (Platform as-a-service), IaaS (Infrastructure as-a-service), SaaS (software as-a-service), operations, management and automation.Apply Accenture methodology, Accenture reusable assets, and previous work experience to delivery consistently high-quality work.Stay educated on new and emerging technologies/patterns/methodologies and market offerings that may be of interest to our clients.Understand the strategic direction set by senior management as it relates to team goals.Use considerable judgment to define solution and seeks guidance on complex problems.Primary upward interaction is with direct supervisor. May interact with peers and/or management levels at a client and/or within Accenture. Establish methods and procedures
on new assignments with guidance.Manage small teams of delivery engineers successfully delivering work efforts (if in an independent contributor role) at a client or within Accenture.Able to travel up to 100% (M-TH)

Basic QualificationsAt least 5 years of Consulting or client service delivery experience on Amazon AWS (AWS)At least 5 years of experience in developing data ingestion, data processing and analytical pipelines for big data, relational databases, NoSQL and data warehouse solutionsExtensive experience providing practical direction within the AWS Native and HadoopExperience with private and public cloud architectures, pros/cons, and migration considerations.Minimum of 5 years of hands-on experience in AWS and Big Data technologies such as Java, Node.js, C##, Python, SQL, EC2, S3, Lambda, Spark/SparkSQL, Hive/MR, Pig, Oozie and streaming technologies such as Kafka, Kinesis, NiFI etc.Extensive hands-on experience implementing data migration and data processing using AWS services: VPC/SG, EC2, S3, AutoScaling, CloudFormation, LakeFormation, DMS, Kinesis, Kafka, Nifi, CDC processing Redshift, Snowflake, RDS, Aurora, Neptune, DynamoDB, Hive, NoSQL, Cloudtrail, CloudWatch, Docker, Lambda, Spark,Glue, Sage Maker, AI/ML, API GW, etc.5+ years of hands on experience in programming languages such as Java, c#, node.js, python, pyspark, spark, SQL, Unix shell/Perl scripting etc.Minimum of 5 years of RDBMS experienceExperience in using Hadoop File Formats and compression techniquesExperience working with DevOps tools such as GitLabs, Jenkins, CodeBuild, CoePipeline CodeDeploy, etc.Bachelors or higher degree in Computer Science or a related discipline.

Candidate Must Have Completed The Following Certifications
§ Certified AWS Developer - Associate
§ Certified AWS DevOps – Professional (Nice to have)
§ Certified AWS Big Data Specialty (Nice to have)

Nice-to-Have Skills/Qualifications:DevOps on an AWS platform. Multi-cloud experience a plus.Experience developing and deploying ETL solutions on AWS using tools like Talend, Informatica, MatillionStrong in Java, C##, Spark, PySpark, Unix shell/Perl scriptingIoT, event-driven, microservices, containers/Kubernetes in the cloud
Experience in Apache Maven a plusUnderstanding and implementation of Data Lake architecturesUnderstanding NoSQL technologies such as MongoDB, Cassandra, Hbase is a plusUnderstanding Solr, Elasticsearch is a plus

Professional Skill Requirements Proven ability to build, manage and foster a team-oriented environment Proven ability to work creatively and analytically in a problem-solving environment Desire to work in an information systems environment Excellent communication (written and oral) and interpersonal skills Excellent leadership and management skills

All of our professionals receive comprehensive training covering business acumen, technical and professional skills development. You'll also have opportunities to hone your functional skills and expertise in an area of specialization. We offer a variety of formal and informal training programs at every level to help you acquire and build specialized skills faster. Learning takes place both on the job and through formal training conducted online, in the classroom, or in collaboration with teammates. The sheer variety of work we do, and the experience it offers, provide an unbeatable platform from which to build a career.

Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status).

Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.

Accenture is a Federal Contractor and an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities.

Equal Employment Opportunity

All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.

Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.

Accenture is committed to providing veteran employment opportunities to our service men and women."
3,Senior Big Data Engineer,"Atlanta, GA",Atlanta,GA,None Found,None Found,None Found,None Found,"
You will design and create multi-tenant systems capable of loading and transforming a large volume of structured and semi-structured fast moving data
Build robust and scalable data infrastructure (both batch processing and real-time) to support needs from internal and external users
Build Data Pipelines
Run ETL into Hadoop/Elastic Search",None Found,None Found,"Location: San Jose, CA or Atlanta, GA
For over 10 years, Zscaler has been disrupting and transforming the security industry. Our 100% purpose built cloud platform delivers the entire gateway security stack as a service through 150 global data centers to securely connect users to their applications, regardless of device, location, or network in over 185 countries protecting over 3,500 companies and 100 Million threats detected a day.
We work in a fast paced, dynamic and make it happen culture. Our people are some of the brightest and passionate in the industry that thrive on being the first to solve problems. We are always looking to hire highly passionate, collaborative and humble people that want to make a difference.
As a Big Data Engineer, you will work on building the next generation of Zscaler's security analytics platform. You will play a crucial role in building a platform to collect and ingest several billion (and growing) log events from Zscaler's globally distributed security infrastructure and provide actionable insights to customers and Zscaler's security researchers.
Responsibilities:
You will design and create multi-tenant systems capable of loading and transforming a large volume of structured and semi-structured fast moving data
Build robust and scalable data infrastructure (both batch processing and real-time) to support needs from internal and external users
Build Data Pipelines
Run ETL into Hadoop/Elastic Search
Required:
3+ years of experience in Python or Java development a must (Strong Scala would skills would be acceptable as well)
3+ years experience in application big data development (Spark, Kafka, Storm, Kinesis, & building data pipelines)
Ability to troubleshoot and find complex performance issues with queries on the Spark platform (Spark SQL)
Familiarity with implementing services following REST model
Excellent interpersonal, technical and communication skills
Ability to learn, evaluate and adopt new technologies
Bachelor's Degree in computer science or equivalent experience
Highly Desirable:
Experience working with data processing infrastructure
Experience with data serialization techniques and data stores for persisting events
What You Can Expect From Us:
An environment where you will be working on cutting edge technologies and architectures
A fun, passionate and collaborative workplace
Competitive salary and benefits, including equity
The pace and excitement of working for a Silicon Valley Unicorn
Why Zscaler?
People who excel at Zscaler are smart, motivated and share our values. Ask yourself: Do you want to team with the best talent in the industry? Do you want to work on disruptive technology? Do you thrive in a fluid work environment? Do you appreciate a company culture that enables individual and group success and celebrates achievement?

If you said yes, we’d love to talk to you about joining our award-winning team!
Learn more at zscaler.com or follow us on Twitter @zscaler. Additional information about Zscaler (NASDAQ : ZS ) is available at http://www.zscaler.com. All qualified applicants will receive consideration for employment without regard to race, sex, color, religion, sexual orientation, gender identity, national origin, protected veteran status, or on the basis of disability.
#LI-JM1"
4,Data Engineer,"Atlanta, GA",Atlanta,GA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"FraudScope - the rapidly growing company that is tackling the problem of healthcare, fraud, waste and abuse - is looking for a full-time Data Engineer to work in their office located at Midtown Atlanta.
We are seeking a talented data engineer with experience in data analytics, building large reservoirs of data, and performing efficient queries. We have built a web-based application that is supported by a large dataset of healthcare data, on which we must frequently perform large queries very efficiently and return results in real time to the user. The role of the data engineer is to bridge the data scientist with the developers and the ingestion of data. Specifically, one of the major tasks is to build and execute new data pipelines on the cloud (AWS).
Required technical skills:

Relational database (PostgreSQL)
Cloud experience (AWS S3, Aurora, EC2)
Python
Linux

Beneficial technical skills:
Apache Spark, Hadoop
AWS Glue, Athena, IAM, KMS
Proven experience processing billions of records and terabytes of data
Table partitioning with PostgreSQL
Shell scripting (e.g., bash)

Other Requirements/Preferences:
Experience with healthcare data, particularly medical claims
Bachelor degree in Computer Science, Engineering or related field - At least 2 years of experience in the software industry
Authorization to work in the USA
Position in Midtown - Atlanta, GA (no remote)"
5,Advanced Data Engineer,"Atlanta, GA 30309",Atlanta,GA,30309,None Found,None Found,"Strong analytical and critical thinking skills
Autonomous personality. We’ll help guide you, but we won’t micromanage you. We expect integrity and results. Your work and deliverables will speak for themselves
Strong written and verbal communication skills
Enjoy challenging and thought-provoking work and have a strong desire to learn and progress
Ability to manage multiple tasks and requests
Must demonstrate a positive, team-focused attitude
Ability to react positively under pressure to meet tight deadlines
You listen to the input of your team members and take diverse perspectives into account to approach challenges from multiple angles
Structured, disciplined approach to work, with attention to detail
Flexible – able to meet changing requirements and priorities
Maintenance of up-to-date knowledge in the appropriate technical areas
Able to work in a global, multicultural environment","Build robust data pipelines on public Cloud using AWS Kinesis, Kafka, Lambda or other technologies
Responsible to collect, process, and compute business metrics from activity & persisted data using Python/Spark
Process, cleanse, and verify the integrity of data used for analysis; optimize data for consumption
Build scalable OLAP backend storage for data in PB scale
Develop data set processes for data discovery, modeling, mining, and archival","
Bachelor’s or Master's Degree of Statistics, Computer Science or other similar advanced degrees from a top tier educational institution preferred",None Found,"Invesco is one of the world's leading global investment managers, entrusted with managing $1.2 trillion* in assets on behalf of clients worldwide. We are the 6th largest US retail asset manager and the 13th largest investment manager globally, and our more than 8,000 employees worldwide are dedicated to delivering an investment experience that helps people get more out of life. We are purely focused on managing a comprehensive range of active, passive and alternative investment capabilities, which we draw on to provide customized solutions aligned to client needs, our most important benchmark. (*As of May 31, 2019)

Job Purpose (Job Summary):

We’re seeking an Advanced Data Engineer to join a fast-paced agile development team building-out enterprise grade data platforms that support Client Experience, Regulatory, and investment teams. You’ll be a part of a dynamic, collaborative team that wants to hear your input because you know the leading methods, tools, and theories in data engineering. The focus of this role will be to source data sets, both internal and external, that support our business clients. You’ll be working alongside our data science and machine learning teams leveraging the Invesco enterprise data lake architecture. Candidates will be expected to ingest, curate, and provide access to structured and unstructured data sets.

Key Responsibilities / Duties:
Build robust data pipelines on public Cloud using AWS Kinesis, Kafka, Lambda or other technologies
Responsible to collect, process, and compute business metrics from activity & persisted data using Python/Spark
Process, cleanse, and verify the integrity of data used for analysis; optimize data for consumption
Build scalable OLAP backend storage for data in PB scale
Develop data set processes for data discovery, modeling, mining, and archival
Work Experience / Knowledge:
2+ years of experience focused in big data engineering
2+ years of experience with ETL/SQL design build and tuning
Experience with data services using Amazon Web Services (AWS), Azure, and / or Google Cloud
Expertise in at least one of the following areas:
Experience with parallel computing, batch processing, and stream processing using tools such as Kinesis or Kafka
Experience with data processing technologies such as Hadoop, Spark, Hive / Pig, and Java / MapReduce
Experience with data warehousing and columnar databases such as Redshift as well as NoSQL databases such as AWS S3, MongoDB, Cassandra, HBase, DynamoDB
Experience with programming languages such as Java, Python or Scala
Experience with micro-services based architecture and design/build of RESTful API’s is a plus
Experience operationalizing data sourcing/loading including automating/scheduling data ingestion
Familiar with Agile software development (Scrum is a plus)
DevOps knowledge is a plus
Skills / Other Personal Attributes Required:
Strong analytical and critical thinking skills
Autonomous personality. We’ll help guide you, but we won’t micromanage you. We expect integrity and results. Your work and deliverables will speak for themselves
Strong written and verbal communication skills
Enjoy challenging and thought-provoking work and have a strong desire to learn and progress
Ability to manage multiple tasks and requests
Must demonstrate a positive, team-focused attitude
Ability to react positively under pressure to meet tight deadlines
You listen to the input of your team members and take diverse perspectives into account to approach challenges from multiple angles
Structured, disciplined approach to work, with attention to detail
Flexible – able to meet changing requirements and priorities
Maintenance of up-to-date knowledge in the appropriate technical areas
Able to work in a global, multicultural environment
Formal Education: (minimum requirement to perform job duties)
Bachelor’s or Master's Degree of Statistics, Computer Science or other similar advanced degrees from a top tier educational institution preferred
Working Conditions:
Normal office environment with little exposure to noise, dust and temperatures
The ability to lift, carry or otherwise move objects of up to 10 pounds is also necessary
Normally works a regular schedule of hours, however hours may vary depending upon the project or assignment
Hours may include evenings and/or weekends and may include 24 hour a day on call support by pager and/or cell phone
Able and willing to travel both domestically and internationally. Frequency and duration to be determined by manager. Estimate: 10-15%
FLSA (US Only): Nonexempt

The above information on this description has been designed to indicate the general nature and level of work performed by employees within this role. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications required of employees assigned to this job. The job holder may be required to perform other duties as deemed appropriate by their manager from time to time.

Invesco's culture of inclusivity and its commitment to diversity in the workplace are demonstrated through our people practices. We are proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, creed, color, religion, sex, gender, gender identity, sexual orientation, marital status, national origin, citizenship status, disability, age, or veteran status. Our equal opportunity employment efforts comply with all applicable U.S. state and federal laws governing non-discrimination in employment."
6,Senior Big Data Engineer,"Atlanta, GA 30309",Atlanta,GA,30309,None Found,None Found,"Strong analytical and critical thinking skills
Autonomous personality. We’ll help guide you, but we won’t micromanage you. We expect integrity and results. Your work and deliverables will speak for themselves
Strong written and verbal communication skills
Enjoy challenging and thought-provoking work and have a strong desire to learn and progress
Ability to manage multiple tasks and requests
Must demonstrate a positive, team-focused attitude
Ability to react positively under pressure to meet tight deadlines
You listen to the input of your team members and take diverse perspectives into account to approach challenges from multiple angles
Structured, disciplined approach to work, with attention to detail
Flexible – able to meet changing requirements and priorities
Maintenance of up-to-date knowledge in the appropriate technical areas
Able to work in a global, multicultural environment","Build robust data pipelines on public Cloud using AWS Kinesis, Kafka, Lambda or other technologies
Responsible to collect, process, and compute business metrics from activity & persisted data using Python/Spark
Process, cleanse, and verify the integrity of data used for analysis; optimize data for consumption
Build scalable OLAP backend storage for data in PB scale
Develop data set processes for data discovery, modeling, mining, and archival","
Bachelor’s or master’s degree of Statistics, Computer Science or other similar advanced degrees from a top tier educational institution preferred",None Found,"Invesco is one of the world’s leading global investment managers, entrusted with managing $1.2 trillion* in assets on behalf of clients worldwide. We are the 6th largest US retail asset manager and the 13th largest investment manager globally, and our more than 8,000 employees worldwide are dedicated to delivering an investment experience that helps people get more out of life. We are purely focused on managing a comprehensive range of active, passive and alternative investment capabilities, which we draw on to provide customized solutions aligned to client needs, our most important benchmark. (*As of May 31,2019)

Job Purpose (Job Summary):

We’re seeking a Senior Data Engineer to join a fast-paced agile development team building-out enterprise grade data platforms that support Client Experience, Regulatory, and investment teams. You’ll be a part of a dynamic, collaborative team that wants to hear your input because you know the leading methods, tools, and theories in data engineering. The focus of this role will be to source data sets, both internal and external, that support our business clients. You’ll be working alongside our data science and machine learning teams leveraging the Invesco enterprise data lake architecture. Candidates will be expected to ingest, curate, and provide access to structured and unstructured data sets.

Key Responsibilities / Duties:
Build robust data pipelines on public Cloud using AWS Kinesis, Kafka, Lambda or other technologies
Responsible to collect, process, and compute business metrics from activity & persisted data using Python/Spark
Process, cleanse, and verify the integrity of data used for analysis; optimize data for consumption
Build scalable OLAP backend storage for data in PB scale
Develop data set processes for data discovery, modeling, mining, and archival
Work Experience / Knowledge:
3+ years of experience focused in big data engineering with 6+ years overall working experience
3+ years of experience with ETL/SQL including fundamental and optimization query techniques, normal forms, and processing semi-structured data such as CSV, XML, XPath, XQuery
3+ years of experience with data services using Amazon Web Services (AWS), Azure, and / or Google Cloud
Expertise in at least one of the following areas:
Experience with parallel computing, batch processing, and stream processing using tools such as Kinesis or Kafka
Experience with data processing technologies such as Hadoop, Spark, Hive / Pig, and Java / MapReduce
Experience with data warehousing and columnar databases such as Redshift as well as NoSQL databases such as AWS S3, MongoDB, Cassandra, HBase, DynamoDB
3-5 years of experience with programming languages such as Java, Python or Scala
Experience with micro-services-based architecture and design/build of RESTful API’s is a plus
Experience operationalizing data sourcing/loading including automating/scheduling data ingestion
Familiar with Agile software development (Scrum is a plus)
Expertise in building out DevOps pipelines is a plus
Skills / Other Personal Attributes Required:
Strong analytical and critical thinking skills
Autonomous personality. We’ll help guide you, but we won’t micromanage you. We expect integrity and results. Your work and deliverables will speak for themselves
Strong written and verbal communication skills
Enjoy challenging and thought-provoking work and have a strong desire to learn and progress
Ability to manage multiple tasks and requests
Must demonstrate a positive, team-focused attitude
Ability to react positively under pressure to meet tight deadlines
You listen to the input of your team members and take diverse perspectives into account to approach challenges from multiple angles
Structured, disciplined approach to work, with attention to detail
Flexible – able to meet changing requirements and priorities
Maintenance of up-to-date knowledge in the appropriate technical areas
Able to work in a global, multicultural environment
Formal Education: (minimum requirement to perform job duties)
Bachelor’s or master’s degree of Statistics, Computer Science or other similar advanced degrees from a top tier educational institution preferred
Working Conditions:
Normal office environment with little exposure to noise, dust and temperatures
The ability to lift, carry or otherwise move objects of up to 10 pounds is also necessary
Normally works a regular schedule of hours, however hours may vary depending upon the project or assignment
Hours may include evenings and/or weekends and may include 24 hour a day on call support by pager and/or cell phone
Able and willing to travel both domestically and internationally. Frequency and duration to be determined by manager. Estimate: 10-15%
FLSA (US Only): Exempt

The above information on this description has been designed to indicate the general nature and level of work performed by employees within this role. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications required of employees assigned to this job. The job holder may be required to perform other duties as deemed appropriate by their manager from time to time.

Invesco's culture of inclusivity and its commitment to diversity in the workplace are demonstrated through our people practices. We are proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, creed, color, religion, sex, gender, gender identity, sexual orientation, marital status, national origin, citizenship status, disability, age, or veteran status. Our equal opportunity employment efforts comply with all applicable U.S. state and federal laws governing non-discrimination in employment."
7,Lead Big Data Engineer,"Atlanta, GA 30308",Atlanta,GA,30308,None Found,"M.S. in Computer Science, Informatics, Mathematics, Electronic/Electrical Engineering or other relevant field with an emphasis on data analytics.Experience with big data technologies such as Hadoop, Apache Spark, NoSQL databases.Strong computer science grounding, with knowledge of data structures, algorithms and computer architectures.Proficiency developing in one or more languages such as C++, Python or Java.Self-starting, requiring minimal supervision with strong problem-solving skills.Excellent communication and teamwork skills.",None Found,None Found,None Found,None Found,"Keysight launched a Software Design Center in Atlanta to create a new software platform for electronic product design and test. The new center is located in Atlanta’s growing Midtown district and features an open environment to foster collaboration and agile software development. We are seeking a lead developer to build upon a solid working knowledge of big data technologies such as MapReduce, Apache Spark and NoSQL databases on both structured and unstructured data. The focus of this position will be implementation of scalable computing technologies for data analytics. Along with a team of researchers and developers, you will help define, investigate, develop and implement, state-of-the-art informatics, data analysis and data visualization technology.
Job Qualifications
REQUIRED QUALIFICATIONS:M.S. in Computer Science, Informatics, Mathematics, Electronic/Electrical Engineering or other relevant field with an emphasis on data analytics.Experience with big data technologies such as Hadoop, Apache Spark, NoSQL databases.Strong computer science grounding, with knowledge of data structures, algorithms and computer architectures.Proficiency developing in one or more languages such as C++, Python or Java.Self-starting, requiring minimal supervision with strong problem-solving skills.Excellent communication and teamwork skills.

DESIRED QUALIFICATIONS:Hands-on experience with Cloud environments, such as AWS, Google Cloud, or AzureExperience with Cloudera
Job Function
R&D
___________________________________________________________________________________
Privacy Statement
***Keysight is an Equal Opportunity Employer.***
Keysight Technologies Inc. is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability or any other protected categories under all applicable laws.

Candidates can be considered to work from the following locations:
Americas : United States : Georgia : Atlanta
Job ID : 391"
8,Data Engineer,"Alpharetta, GA",Alpharetta,GA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Alpharetta, GA.
Full time
$90,000 - $110,000 / year
40h / week
2+ years experience
Master or Bachelor
Job Requirements
1. Responsible for evaluating, developing, maintaining and testing big data solutions for advanced analytics projects
2. The role would involve big data pre-processing & reporting workflows including collecting, parsing, managing, analyzing and visualizing large sets of data to turn information into business insights
3. Responsible for developing, coding, testing and debugging solution related to our Data solutions
4. Develop, enhance and maintain the data pipeline ingestion, transformation, storage, analysis and visualization using combination of open source and paid technology tools
5. Automating data solutions for reporting KPI, trends, etc.

Preferred Qualifications

1. Understanding of data flows, data architecture, ETL and processing of structured and unstructured data
2. Possess strong computer science fundamentals: data structures, algorithms, programming languages, distributed systems, and information retrieval
3. Familiar with data mining concepts
4. Strong Programming Skills in Python / Java / Scala /Node.js
5. Hands on experience working at least one Relational and/or NoSQL Databases
6. Knowledge on SQL Queries and Data Modelling
7. Hands on experience working in ETL Use cases either in On-premise or Cloud
8. Experience in any Cloud Platform (AWS, Azure, GCP, Alibaba)
9. Knowledge in one or more AWS Services like Kinesis, EC2, EMR, Hive Integration, Athena, Firehose, Lambda, S3, Glue Crawler, Redshift, RDS is a plus
10. Good Communication Skills and Self Driven - should be able to deliver the projects with minimum instructions from Client
11. Experience in Spark & Big Data is big plus"
9,Data Engineer (Business Intelligence),"Atlanta, GA",Atlanta,GA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"The Pindrop engineering team solves tough problems and invents new ways to battle fraud using big data and audio science in the cloud. Pindrop creates innovative products to solve global problems, and we are looking for an expert Data Engineer to join the Business Intelligence engineering team as we continue to develop ways to fight fraud and improve security in voice channels.

In this role, you will be working cross-functionally with business intelligence operations, research, analytics, and engineering teams to design and implement our Data platform. You will participate in designing, implementing and scaling our Datalake and data pipelines that transform billions of records into actionable insights.

--------------------
what you'll do
--------------------


Work with a growing team to design, develop, test, deploy, maintain and improve brand new data services
Refactor existing systems and architect new solutions
Develop new and efficient ways to ingest, store and process our billions of records
Work with our research department to build data pipelines that transform raw semi-structured events into structured data, consumable by machine learning pipelines and algorithms
Work with our backend software engineers to build efficient and scalable reporting solutions that tap into our datastores
Deliver production ready code from start to finish -- designed, implemented, tested and deployed
Review code to maintain quality with an eye towards performance, scale, and security
Work with multiple teams to implement company wide solutions

-----------
who you are
-----------


Data Engineer with strong software engineering skills
Strong experience with relational databases and document stores (SQL + NoSQL)
Experience with multiple programming languages, such as Python, Java, and Go
Experience with Big Data technologies such as Spark or Hadoop a big plus
Linux experience
Knowledge of Docker and container orchestration frameworks such as Kubernetes ideal
Experience developing with AWS managed services such as S3, ElastiCache and DynamoDB
Ability to deal with ambiguity in a fast-paced dynamic environment
Proven track record of providing stable, secure code in environments that change and improve rapidly
BS in CS or EE or relevant technical discipline

-------------
what we offer
-------------

As a part of Pindrop, you'll have a direct impact on our growing list of products and thus the future of security in the voice driven economy. We hire great people and take care of them. Here's a snapshot of benefits we offer:


Recognized top employer
AJC Top Workplaces 2017 ( http://topworkplaces.com/publication/ajc/pindrop-security/ )
51 Startups to Bet Your Career On ( http://www.businessinsider.com/51-enterprise-startups-to-bet-your-career-on-in-2018-2017-11/#pindrop-security-for-the-next-big-thing-in-computing-26 )
50 Startups That Will Boom in 2018 ( http://www.businessinsider.com/50-startups-to-boom-in-2018-according-to-vcs-2017-11?IR=T/#pindrop-stopping-voice-fraudsters-3 )
Health plans and 401k
Continued education budget
Flex schedules
Best in class tools
Paid commuter options
Fun outings to celebrate our accomplishments as a team
All the good karma you can rack up for fighting bad guys (our conference rooms are named after the ones we've busted)

----------
who we are
----------

Pindrop is a company founded on research and continues to innovate new ideas to market. Our solutions are leading the way to the future of voice by establishing the standard for security, identity, and trust. Pindrop products secure the future of voice, making technology more human from the call center to IoT devices.

---------------
what we live by
---------------

Pindrop is driven by our DEPTH values. These are reflected in our goals and the base of our team's peer awards.

Act with Deliberate urgency.
Create Evangelical customers.
Passionate about the fight.
Playing for the Team.
Make Hard easy.

Pindrop is an Equal Opportunity Employer ( https://www.eeoc.gov/employers/upload/poster_screen_reader_optimized.pdf ).

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status; and will not be discriminated against on the basis of disability."
10,Big Data Engineer,"Atlanta, GA",Atlanta,GA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Our data platform enables analytics, experimentation, machine learning models, streaming, reporting infrastructure and systems metrics which powers and drives innovation at UserTesting. Our team of data engineers and scientists is focused on creating a competitive advantage for UserTesting and our customers through novel data infrastructure, metrics, insights and data services. We are a small but rapidly growing team that builds and leverages state-of-the-art analytics systems, especially around video and Natural Language Processing (NLP).

As a Big Data Engineer, you’ll design, develop & tune data products, applications and integrations on large scale data platforms with an emphasis on performance, reliability and scalability and most of all quality. You’ll support our Machine Learning efforts by building large-scale distributed infrastructure for rapid experimentation, training, and inference. You are passionate about applying cutting-edge machine learning to real-world problems and building the required frameworks and tools to do so.

You will play a key role in the evolution of our Data Platform, duties include:


Work closely with product and design to discover and build solutions that help our customers build great user experiences
Collaborate with engineers who are both remote and co-located in our Mountain View, San Francisco, and Atlanta offices
Work effectively within a team environment, to regularly solicit and act on feedback, focus on root causes, and continually strive to improve
Enhance our customer-facing platform, tester panel distribution systems, video playback tools, and mobile device recording capabilities
Advocate and lead-by-example best practices for code quality in architecture and design, maintainability, performance, and scalability
Lead on promoting just-right solutions to build for the future while also avoiding costly premature optimizations

Requirements

At least 5 years of software development experience.
At least 3 years of experience of using Big Data systems.
Strong in one or more languages (Python/Ruby/Scala/Java/C++)
Strong experience on a professional software development team building highly scalable, distributed systems in the cloud
Experience in REST API design and implementation
Experience with messaging, queuing, and workflow systems, especially Kafka or Amazon Kinesis
Experience with non-relational, NoSQL databases and various data-storage systems, especially: Cassandra, ElasticSearch/Solr, Neo4j, etc.

Preferred Qualifications

Experience working with Machine Learning, especially NLP
Experience with software development on top of Deep Learning Frameworks, especially Tensorflow/Keras
Data engineering knowledge including ETL, DataWarehouse, Data Visualization, etc.
Data modeling experience with columnar data formats
Experience integrating with CI tools programmatically
Experience with Docker, registries and container deployment services (e.g., AWS ECS, Kubernetes).

Additional Information
Besides a great work environment and the opportunity to change the world, we offer competitive salary, benefits, plenty of perks, as well as equity participation.

UserTesting is an Equal Opportunity Employer and participant in the U.S. Federal E-Verify program. Women, minorities, individuals with disabilities and protected veterans are encouraged to apply. We welcome people of different backgrounds, experiences, abilities and perspectives. UserTesting will consider qualified applicants with criminal histories in a manner consistent with the
San Francisco Fair Chance Ordinance.
[http://sfgsa.org/modules/showdocument.aspx?documentid=11600]

Learn more about what it is like to work at UserTesting at :
https://www.usertesting.com/about-us/jobs
[https://www.usertesting.com/about-us/jobs]"
11,Azure Data Engineer,"Atlanta, GA",Atlanta,GA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"About Avanade

Avanade leads in providing innovative digital services, business solutions and design-led experiences for its clients, delivered through the power of people and the Microsoft ecosystem. Our professionals combine technology, business and industry expertise to build and deploy solutions to realize results for clients and their customers. Avanade has 34,000 digitally connected people across 24 countries, bringing clients the best thinking through a collaborative culture that honors diversity and reflects the communities in which we operate. Majority owned by Accenture, Avanade was founded in 2000 by Accenture LLP and Microsoft Corporation. Learn more at www.avanade.com

Why Avanade?

14-time winner of Microsoft Partner of the Year
24,000+ certifications in Microsoft technology
90+ Microsoft partner awards
17 Gold Competencies
3,500 analytics professionals worldwide
1,000 data engineers
Implemented analytics systems for more than 550 clients
400 AI practitioners
300 cognitive service experts

How We Support You:
We believe in gender equity and an inclusive community. We offer a comprehensive benefits package: generous vacation allowance disability coverage, retirement plans, paid maternity and paternity leave, life insurance, hotel and travel discounts, extended benefits to cover items that support your well-being, health, dental and vision insurance, professional development and paid Microsoft certification opportunities.

Role Overview:
As an Azure Data Engineer you will collect, aggregate, store, and reconcile data in support of Client business decisions. You will help design and build data pipelines, data streams, reporting tools, information dashboards, data service APIs, data generators and other end-user information portals and insight tools. You will be a critical part of the data supply chain, ensuring that business partners can access and manipulate data for routine and ad hoc analysis to drive business outcomes using Advanced Analytics.

Key Role Responsibilities:
Day-to-day, you will:
Translate business requirements to technical solutions using strong business insight.
Analyzes current business practices, processes and procedures as well as identifying future business opportunities for demonstrating Microsoft Azure Data & Analytics PaaS Services.
Support the planning and implementation of data design services, providing sizing and configuration assistance and performing needs assessments.
Delivery of architectures for transformations and modernizations of enterprise data solutions using Azure cloud data technologies.
Design and Build Modern Data Pipelines and Data Streams.
Design and Build Data Service APIs.
Develop and maintain data warehouse schematics, layouts, architectures and relational/non-relational databases for data access and Advanced Analytics.
Expose data to end users using Power BI, Azure API Apps or other modern visualization platform or experience.
Implement effective metrics and monitoring processes.
Able to travel approximately 80%

Key Role Skill & Capability Requirements:
Your technical/non-technical skills include:
Demonstrable experience of turning business use cases and requirements to technical solutions.
Experience in business processing mapping of data and analytics solutions.
Ability to conduct data profiling, cataloging, and mapping for technical design and construction of technical data flows.
The ability to apply such methods to take on business problems using one or more Azure Data and Analytics services in combination with building data pipelines, data streams, and system integration.
T-SQL is required.
Knowledge of Azure Data Factory, Azure Data Lake, Azure SQL DW, and Azure SQL, Azure App Service is required.
Experience preparing data for Data Science and Machine Learning.
Knowledge of Lambda and Kappa architecture patterns.
Knowledge of Master Data Management (MDM) and Data Quality tools and processes.
Strong collaboration ethic and experience working with remote teams.
Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals.
Working experience with Visual Studio, PowerShell Scripting, and ARM templates.
Experience with Git/TFS/VSTS is a requirement.

Preferred Certifications:
MCSA

Preferred Education Background:
You likely possess a Bachelor's degree in Computer Science, Information Technology, Business, or another relevant field. An equivalent combination of education and experience will also suffice.

Preferred Years of Work Experience:
You likely have about 3-5+ years of relevant professional experience."
12,Senior Data Engineer,"Atlanta, GA",Atlanta,GA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"ThoughtWorks is a global software consultancy, made up of around 4,500 passionate technologists across 15 countries. We specialize in strategy, portfolio management, and product design, combined with digital engineering excellence.

As a Senior Data Engineer, here's what we'll be looking for you to bring:
Hands-on Engineering Leadership
Proven track record of Innovation and expertise in Data Engineering
Tenure in coding, architecting and delivering complex projects
Deep understanding and application of modern data processing technology stacks. For example Spark, Kafka, Hadoop, ecosystem technologies, and others
Deep understanding of NoSQL technologies including column family, graph, document, and key-value data storage technologies
Deep understanding of relational database technologies and database development techniques
Understanding of how to architect solutions for data science and analytics
Data management for reporting and BI experience is a plus
Understanding of “Agility”, including core values, guiding principles, and key agile practices
Understanding of the theory and application of Continuous Integration/Delivery
Passion for software craftmanship
A rich breadth of industry experience and background working across different organizations, ranging in size, from start-ups to large corporations..
Strong stakeholder management and interaction experience at different levels
Any experience building and leading an offshore/outsourcing function would be highly beneficial.
There's no typical day or engagement for our Senior Engineers. Here’s what you’ll do:

Be the SME. Develop Big Data architectural approach to meet key business objectives and provide end to end development solution
You might spend a few weeks with a new client on a deep technical review or a complete organizational review, helping them to understand the potential that Big Data has to solve their most pressing problems.
On other projects, you might be acting as the architect, leading the design of technical solutions, or perhaps overseeing a program inception to build a new product.
It could be much more about getting stuck into a delivery project where you're equally happy coding and tech leading the team to implement the solution.
Whatever your role, the team always look to draw on your experience when things get tough and you often handle the difficult client conversations allowing the team to continue delivering without undue pressure.
You have great relationships with our new business team and work collaboratively to support pre-sales, meet prospective clients and ultimately influence and shape our portfolio of work.
You recognize that building your network with a client is absolutely key to enable you to perform in your role. You'll be drawing on all of your passion for technology, hands-on experience and knowledge of latest Big Data and Engineering best practices to help you gain the respect and credibility of those around you.
Regardless of what you do at ThoughtWorks, you’ll always have the opportunity to:

Think through hard problems, and work with a team to make them reality.
Learn something new every day.
Work in a dynamic, collaborative, transparent, non-hierarchal, and ego-free culture where your talent is valued over a role title
Travel the world.
Speak at conferences.
Write blogs and books.
Develop your career outside of the confinements of a traditional career path by focusing on what you’re passionate about rather than a predetermined one-size-fits-all plan
Be part of a company with Social and Economic Justice at the heart of its mission.

A few important things to know:
Projects are almost exclusively on customer site, so candidates should be flexible and open to travel.

Candidates must possess work authorization that does not require H-1B visa sponsorship by ThoughtWorks or dependent EAD.

Not quite ready to apply? Or maybe this isn’t the right role for you? That’s OK, you can stay in touch with AccessThoughtWorks, our learning community (click ""contact me about recruitment opportunities"" to hear about jobs in the future).

It is the policy of ThoughtWorks, Inc. to provide a work environment free of discrimination. The Company will take affirmative action to ensure applicants and ThoughtWorks employees are treated without regard to race, color, religion, sex, national origin, ethnic origin, veteran status, family status, disability, sexual orientation, gender expression or gender identity. This also includes individuals who are perceived to have any of the aforementioned attributes. ThoughtWorks will adhere to all federal, state, and municipal laws and regulations governing employment."
13,Senior Engineer - Data & Analytics,"Atlanta, GA 30326",Atlanta,GA,30326,None Found,3+ years of related work experience in Data Engineering or Data Warehousing,None Found,Work as part of a team to develop Cloud Data and Analytics solutions,None Found,None Found,"About Slalom Build
Slalom Build is a highly-scalable, high-velocity Build as a Service firm. We work with clients to close the distance between dream and reality, imagined possibility and technical realization.

We do this by blending design, product engineering, analytics, and automation to build the modern technology products of tomorrow.

Nearly 1000 builders strong in seven Build Centers across North America, Slalom Build leverages a foundation of innovation inherited from Slalom Consulting. We’re intensely proud to partner with future-focused clients committed to disrupting their industries.

About Slalom
Founded in 2001 and headquartered in Seattle, WA, Slalom has organically grown to over 6,000 employees. We were named one of Fortune’s 100 Best Companies to Work For in 2017 and are regularly recognized by our employees as a best place to work. You can find us in 27 cities across the U.S., U.K., and Canada.

Job Title: Senior Data Engineer
As a Senior Data Engineer for Slalom Build, you’ll work in small teams to deliver innovative solutions on Amazon Web Services, Azure, and Google Cloud using core cloud data warehouse tools, Hadoop, Spark, Event Stream platforms, and other Big Data related technologies. In addition to building the next generation of data platforms, you’ll be working with some of the most forward-thinking organizations in data and analytics.

Responsibilities:Work as part of a team to develop Cloud Data and Analytics solutionsParticipate in development of cloud data warehouses and business intelligence solutionsData wrangling of heterogeneous data and explore and discover new insightsGain hands-on experience with new data platforms and programming languages (e.g. Python, Hive, Spark)Willingness to travel up to 50%, at peak times of projects

Qualifications:3+ years of related work experience in Data Engineering or Data WarehousingHands-on experience with leading commercial Cloud platforms, including AWS, Azure, and GoogleProven experience with data warehousing, data ingestion, and data profilingProficient in SQLStrong aptitude for learning new technologies and analytics techniquesHighly self-motivated and able to work independently as well as in a team environmentUnderstanding of agile project approaches and methodologiesProficient in a source code control system, such as GitProficient in the Linux shell, including utilities such as SSH

Preferred Experience:Familiarity with implementing analytics solutions with one or more Hadoop distributions (Cloudera, Hortonworks, MapR, HDInsight, EMR)Failiarity with streaming data ingestionProficient in Python and/or JavaConsulting experienceFamiliarity or strong desire to learn quantitative analysis techniques (e.g., predictive modeling, machine learning, segmentation, optimization, clustering, regression)

Slalom is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law."
14,AI Model Development Lead for Virtual Channels (Analytic Manager 5),"Atlanta, GA",Atlanta,GA,None Found,None Found,"
8+ years of experience in analytics, modeling, or a combination of both
6+ years of management experience; or 6+ years of leadership experience in an advanced quantitative analytics function
A Master's degree or higher
5 + years of experience using quantitative machine learning techniques",None Found,None Found,None Found,None Found,"Overview:
Wells Fargo technology teams drive innovation to create a more powerful and fulfilling financial experience for our customers and team members. You will join more than 24,000 team members supporting 95 billion transactions annually in 10 countries. Our career opportunities span the technology spectrum: advanced analytics, big data, information security, application development, cloud enablement, project management and more.

SUCCESS PROFILE
Check out the top traits we're looking for and see if you have the right mix. Additional related traits listed below.

Analytical
Detail-oriented
Insightful
Inventive
Problem Solver
Curious
Benefits
Wells Fargo wants to help you get more out of life and take care of things outside the office to make life a little easier. We provide:

Medical, Dental and Vision
Employer Matching 401(k)
Tuition Reimbursment
Maternity and Paternity Leave
Paid Time Off
Responsibilties
Job Description
At Wells Fargo, we want to satisfy our customers’ financial needs and help them succeed financially. We’re looking for talented people who will put our customers at the center of everything we do. Join our diverse and inclusive team where you’ll feel valued and inspired to contribute your unique skills and experience.
Help us build a better Wells Fargo. It all begins with outstanding talent. It all begins with you.
Enterprise Finance drives financial management for the company and maintains and enhances risk and financial controls. Key functions within Enterprise Finance include finance and accounting; Treasury; corporate development, mergers, and acquisitions; Data Management and Insights, the Customer Remediation Center of Excellence, Enterprise Shared Services, Business Process Management, and Corporate Strategy. Enterprise Finance informs shareholders, regulators, taxing authorities, team members, and leaders of the company’s financial performance through earnings releases, investor meetings and conferences, and meetings with regulators and credit rating agencies, following appropriate reporting guidelines. They also maintain and enhance risk and financial controls and lead many of the company’s shared services functions including corporate properties, security, and global services.
As part of the newly formed AI Model Development COE in Enterprise Analytics and Data Science (EADS), which focuses on building, implementing, and monitoring AI models for the enterprise, the AI model development team for personalization, Virtual Channels, and virtual channels is looking for an experienced AI leader to manage the development of AI models for Virtual Channels.

This leader will be responsible for building and managing a team of data scientists to design, develop, and implement AI models focused on Virtual Channels’ AI priorities. Partnering with Wells Fargo AI technology team, Wells Fargo AI business solution team, and Virtual Channels executives, you and your team will deliver and deploy AI models on the Well Fargo AI open source platform to scale these solutions and embed them in our operational processes.

KEY RESPONSIBILITIES INCLUDE:
Build and grow a team of data scientists responsible for AI model development in support of Virtual Channels
Design, develop, and deploy AI models using state of the art AI techniques available in the open stack and/or vendor solutions
Partner with Virtual Channels executives to frame the problem, manage the model development process, and business relationship
Manage a portfolio of the data science projects including the following responsibilities:
Help finalize project scope working with business partners
On-going touch-base with business partners and governance stakeholders
Define priorities in partnership with the business partners during on-going development
Work with AI technology and production teams to operationalize models
Will be called upon to review vendor models and solutions and/or models developed outside of EADS
Divisional Information:
Data Management and Insights (DMI) is transforming the way that Wells Fargo uses and manages data. Our work enables Wells Fargo to empower and inform our team members, deliver exceptional experiences for our customers, and meet the elevated expectations of our regulators. The team is responsible for designing the future data environment, defining data governance and oversight, and partnering with technology to operate the data infrastructure for the company. This team also provides next generation analytic insights to drive business strategies and help meet our commitment to satisfy our customers’ financial needs.
As a Team Member Manager, you are expected to achieve success by leading yourself, your team, and the business. Specifically you will:
Lead your team with integrity and create an environment where your team members feel included, valued, and supported to do work that energizes them.
Accomplish management responsibilities which include sourcing and hiring talented team members, providing ongoing coaching and feedback, recognizing and developing team members, identifying and managing risks, and completing daily management tasks.

Required Qualifications

8+ years of experience in analytics, modeling, or a combination of both
6+ years of management experience; or 6+ years of leadership experience in an advanced quantitative analytics function
A Master's degree or higher
5 + years of experience using quantitative machine learning techniques


Desired Qualifications

Strong analytical skills with high attention to detail and accuracy
Ability to work and influence successfully within a matrix environment and build effective business partnerships with all levels of team members
Meeting facilitation experience in leading discussions that result in consensus and commitment


Other Desired Qualifications
4+ years managing or directing data scientist/ statistician/ data engineer teams
Hands on experience with deep learning toolkits such as Tensorflow, Keras, PyTorch, Dynet
Detail oriented. Experience with model governance requirements. Able to de-mystify AI models to make them transparent and explainable
Experience with agile project management methodologies for data science
Experience with Big Data or Hadoop tools such as Spark, Hive, Kafka and Map

Street Address
NC-Charlotte: 401 S Tryon St - Charlotte, NC
MN-Minneapolis: 600 S 4th St - Minneapolis, MN
NC-Charlotte: 11625 N Community House Road - Charlotte, NC
SC-Fort Mill: 3480 State View Blvd - Fort Mill, SC
TX-Addison: 5080 Spectrum Dr - Addison, TX
TX-DAL-Downtown Dallas: 1445 Ross Ave - Dallas, TX
TX-Irving: 5000 Riverside Drive - Irving, TX
AZ-Tempe: 1150 W Washington St - Tempe, AZ
IA-Des Moines: 6200 Park Ave - Des Moines, IA
IA-Des Moines: 800 Walnut St - Des Moines, IA
GA-Atlanta: 3579 Atlanta Ave - Atlanta, GA


Disclaimer

All offers for employment with Wells Fargo are contingent upon the candidate having successfully completed a criminal background check. Wells Fargo will consider qualified candidates with criminal histories in a manner consistent with the requirements of applicable local, state and Federal law, including Section 19 of the Federal Deposit Insurance Act.

Relevant military experience is considered for veterans and transitioning service men and women.

Wells Fargo is an Affirmative Action and Equal Opportunity Employer, Minority/Female/Disabled/Veteran/Gender Identity/Sexual Orientation.

ENT FINANCE"
15,Senior Big Data Engineer,"Alpharetta, GA",Alpharetta,GA,None Found,None Found,"
A bachelor's degree or related field with at least 3 – 8 years of experience with Big Data or Hadoop tools such as Spark, Hive, Kafka and MapReduce, Spark, R, Python
Experience working within a Linux computing environment, and use of command line tools including knowledge of shell/Python scripting for automating common tasks
Experience in AI/ML on big data platforms preferred:
Slid applied statistics skills, such as identifying distributions, statistical testing, regression, etc.
Prficiency querying both structured and unstructured data
Experience with Pythn and Deep Learning packages (Keras, Tensorflow, mxnet) and NLP packages (nltk, spacy) is a plus
Experience deplying models in production environments
Strong experience in System Integration, Application Development or Data-Warehouse projects, across technologies used in the enterprise space
Hands-on experience with Apache Spark and its components (Streaming, SQL, MLLib) is a strong advantage
Excellent written and oral communication skills; must be able to effectively articulate technical concepts to non-technical audiences
Software development experience using:
Database prgramming using any flavor of SQL
Expertise in relatinal and dimensional modelling",None Found,"
Understand problems from a client's point of view, build and execute solid analytics work plans, gather and organize large and complex data sets, perform relevant analyses (data exploration and statistical modeling), manage priorities and deadlines, foster teamwork in interactions, develop client relationships with client counterparts, and communicate hypotheses and findings in a structured way
Partner with business teams in identifying business requirements and developing advanced analytical solutions to complex problems by utilizing statistical models and machine learning techniques and algorithms",None Found,None Found,"Company Overview
Fractal Analytics is a strategic AI partner to Fortune 500 companies with a vision to power every human decision in the enterprise. Fractal is building a world where individual choices, freedom, and diversity are the greatest assets. An ecosystem where human imagination is at the heart of every decision. Where no possibility is written off, only challenged to get better. We believe that a true Fractalite is the one who empowers imagination with intelligence.
We are seeking for a strong candidate with advanced analytics experience to fill an exciting Big Data Engineer position, in Alpharetta, GA. In this role, you will be a valuable expert and will help design and build analytics methodologies, solutions, and products to deliver value to our clients in collaboration with cross-functional teams. As an exceptional candidate, you will show an analytical curiosity.
Responsibilities
Understand problems from a client's point of view, build and execute solid analytics work plans, gather and organize large and complex data sets, perform relevant analyses (data exploration and statistical modeling), manage priorities and deadlines, foster teamwork in interactions, develop client relationships with client counterparts, and communicate hypotheses and findings in a structured way
Partner with business teams in identifying business requirements and developing advanced analytical solutions to complex problems by utilizing statistical models and machine learning techniques and algorithms
Qualifications
A bachelor's degree or related field with at least 3 – 8 years of experience with Big Data or Hadoop tools such as Spark, Hive, Kafka and MapReduce, Spark, R, Python
Experience working within a Linux computing environment, and use of command line tools including knowledge of shell/Python scripting for automating common tasks
Experience in AI/ML on big data platforms preferred:
Slid applied statistics skills, such as identifying distributions, statistical testing, regression, etc.
Prficiency querying both structured and unstructured data
Experience with Pythn and Deep Learning packages (Keras, Tensorflow, mxnet) and NLP packages (nltk, spacy) is a plus
Experience deplying models in production environments
Strong experience in System Integration, Application Development or Data-Warehouse projects, across technologies used in the enterprise space
Hands-on experience with Apache Spark and its components (Streaming, SQL, MLLib) is a strong advantage
Excellent written and oral communication skills; must be able to effectively articulate technical concepts to non-technical audiences
Software development experience using:
Database prgramming using any flavor of SQL
Expertise in relatinal and dimensional modelling
Nice to Have:
Operating knowledge of cloud computing platforms (AWS, especially EMR, EC2, S3, SWF services and the AWS CLI)
Experience building recommendation engines (both offline and online validation metrics)
z8yMgRjHjP"
16,Sr. Data Engineer,"Atlanta, GA",Atlanta,GA,None Found,None Found,"Qualifications: 7 – 10 (3 years min relevant experience in the role) years experience, Bachelor’s Degree.Must have experience in Software Engineering Techniques, Software Engineering Architecture, Software Engineering Lifecycle and Data Management.Should be proficient in Business Analysis, Business Knowledge, Software Engineering Leadership, Architecture Knowledge and Technical Solution Design.",None Found,None Found,None Found,None Found,"Must Have qualifications: Top tier consultant firm experience 8-10 years building products and architecting solutions. Experience advising clients on Data Modernization initiatives. Ability to deal with structured, semi-structured, unstructured and streaming data. Ability to lead proofs-of-concepts and then effectively transition and scale those concepts into production at scale through, engineering, deployment and commercialization. Serve as an expert; envision and integrate emerging data technologies, anticipate new trends to solve complex business and technical problems. Experience in sales, pre-sales functions, leading pursuits, proposal development, and statement of works. Ability to work in the United States without visa sponsorship now or in the future

TECHNICAL REQUIREMENTS:
 Experience designing, developing, optimizing and troubleshooting complex data-intensive applications using Spark, HDFS, Kafka, MapReduce, MongoDB and other big data related technologies. Must know PySpark, Python and SQL; comfortable with Java and/or Scala. Comfortable designing and implementing data warehouse and pipelines—such as ETL, data integration, and streaming—to support teams focused in Analytics. Experienced in AWS or/and Azure Cloud Platform. Ability to engineer for performance, scalability, latency, & reliability. DevOps and automation experience highly desired
Candidates should be flexible / willing to work across this delivery landscape which includes and not limited to Agile Applications Development, Support and Deployment.
Applicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Capgemini.

Qualifications

Responsible for programming and software development using various programming languages and related tools and frameworks, reviewing code written by other programmers, requirement gathering, bug fixing, testing, documenting and implementing software systems. Experienced programmers are also responsible for interpreting architecture and design, code reviews, mentoring, guiding and monitoring programmers, ensuring adherence to programming and documentation policies, software development, testing and release.

Required Skills and Experience:

You assign, coordinate, and review work and activities of programming personnel. Collaborate with computer manufacturers and other users to develop new programming methods. Supervise, train, mentor junior level programmers in programming and program coding. Represent team in project meetings. Work with business and functional analysts, and software & solution architects in ensuring that programs and systems function as intended Supervise, mentor and manage large teams of programmers in one or more projects. Represent project teams in project/program meetings or in meetings with sponsor.
Qualifications: 7 – 10 (3 years min relevant experience in the role) years experience, Bachelor’s Degree.Must have experience in Software Engineering Techniques, Software Engineering Architecture, Software Engineering Lifecycle and Data Management.Should be proficient in Business Analysis, Business Knowledge, Software Engineering Leadership, Architecture Knowledge and Technical Solution Design.

Capgemini is an Equal Opportunity Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.
This is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.

Click the following link for more information on your rights as an Applicant - http://www.capgemini.com/resources/equal-employment-opportunity-is-the-law


About Capgemini

A global leader in consulting, technology services and digital transformation, Capgemini is at the forefront of innovation to address the entire breadth of clients’ opportunities in the evolving world of cloud, digital and platforms. Building on its strong 50 year heritage and deep industry-specific expertise, Capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations. Capgemini is driven by the conviction that the business value of technology comes from and through people. It is a multicultural company of 200,000 team members in more than 40 countries. The Group reported 2018 global revenues of EUR 13.2 billion.

Visit us at www.capgemini.com. People matter, results count."
17,Senior Big Data Data Engineer,"Alpharetta, GA 30022",Alpharetta,GA,30022,None Found,None Found,None Found,None Found,None Found,None Found,"What you’ll be doing...
Looking for a Senior Data Engineer to work with a small team responsible for building, deploying, and supporting a Big Data solution that will enable operations for a large enterprise environment. Must be able to design, build and maintain Enterprise Level Data Pipe-Lines utilizing the tools available within Big Data Eco-System. As a Senior Big Data Engineer - You will work on Advanced Analytics using Big Data technologies such as Hadoop and Data Warehousing.
Build analytical solutions to enable Data Scientist by manipulating large data sets and integrating diverse data sources.
Perform ad-hoc analysis and develop reproducible analytical approaches to meet business requirements.
Perform exploratory and targeted data analyses using descriptive statistics and other methods.
Use complex algorithms to develop systems & applications that deliver business functions or architectural components.
Typical duties will include the following:
Work closely with the data scientists, and database and systems administrators to create data solutions.
Follow best practices on design and implementation to aid in company-wide data governance.
Improve existing data pipelines by simplifying and increasing performance.
Design, build, and deploy new data pipelines within Big Data Eco-Systems.
Documents new/existing pipelines, Data Sets and Data Sets.
Abides by department development standards and SOP's.
Attends all department meetings.
All other duties as assigned.
Keeps updated on latest technologies relevant to position’s duties.
Has great knowledge of commonly used software concepts and design.
Great knowledge of the development lifecycle.
Keeps management updated on projects and assigned work.
What we’re looking for...
You will need to have:
Bachelor’s degree or four or more years of work experience.
Six or more years of relevant work experience.
Even Better If You Have:
A Degree.
Experience of designing, building, and deploying production-level data pipelines using tools from Hadoop stack (HDFS, Hive, Spark, HBase, Kafka, NiFi, Oozie, Splunk etc).
Experience with various noSQL databases (Hive, MongoDB, Couchbase, Cassandra, and Neo4j).
Experience with analytic or feature engineer programming (python or scala or java).
Experience implementing open source frameworks & exposure to various open source & package software architectures (AngularJS, ReactJS, Node, Elasticsearch, Spark, Scala, Splunk, Apigee, and Jenkins etc.).
Experience troubleshooting JVM-related issues.
Experience with SQL databases and Change Data Capture.
Experience and strategies to deal with mutable data in Hadoop.
Experience with Stream sets.
Experience of Agile and DevOps methodologies.
Experiencewithjudgment to plan and accomplish goals.
Works under general supervision.
Experience in full development life cycle and significant experience in delivering applications and architecture services.
Experience in data visualization tools like Kibana, Grafana, Tableau and associated architectures.
Experience evaluating and implementing cutting-edge digital technologies.
Experience with Cloud technologies (AWS, GCP, PCF, Docker, Kubernetes and application migration.
When you join Verizon...
You’ll have the power to go beyond – doing the work that’s transforming how people, businesses and things connect with each other. Not only do we provide the fastest and most reliable network for our customers, but we were first to 5G - a quantum leap in connectivity. Our connected solutions are making communities stronger and enabling energy efficiency. Here, you’ll have the ability to make an impact and create positive change. Whether you think in code, words, pictures or numbers, join our team of the best and brightest. We offer great pay, amazing benefits and opportunity to learn and grow in every role. Together we’ll go far.
Equal Employment Opportunity
We're proud to be an equal opportunity employer- and celebrate our employees' differences,including race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, and Veteran status. Different makes us better."
18,Lead Data Engineer,"Atlanta, GA 30309",Atlanta,GA,30309,None Found,None Found,"Previous management experience and successfully leading a team of direct reports
Proven track record of effectively leading and managing employees, managing performance, setting goals for team/individuals and provide mentoring.
Strong Tableau, Adobe Analytics other BI solution
Expert Oracle and Vertica skillsets
Experience using JIRA and Agile Project Management software
Experience using GitHub, Bit Bucket, or other code repository solution
Strong written, verbal communication and presentation skills
Ability to explain complex technical issues in a way that non-technical people may understand
Able to work in a global, multicultural environment
Self-motivated. Capable of working with little or no supervision
Ability to react positively under pressure to meet tight deadlines
Able to work independently or as a team player
Enjoy challenging and thought provoking work and have a strong desire to learn and progress","Work with development teams and other project leaders/stakeholders to provide technical solutions that enable business capabilities
Supports the data science community by enabling data availability in environments that provide advanced analytical capabilities
Maintains a broad understanding of implementation, integration, and inter-connectivity issues with emerging technologies to define data strategies
Assist in the decision-making process related to the selection of software architecture solutions
Implement architectures to handle web-scale data and its organization
Execute strategies that inform data design and architecture partnering with enterprise standard
Build robust data pipelines on public Cloud using AWS Kinesis, Kafka, Lambda or other technologies
Assist in creating documents that ensure consistency in development across the online organization. Implements and improves core software infrastructure
Deep expertise in SQL language, Python, Hadoop ecosystem and/or Spark ecosystem. Strong experience with writing complex programs, implementing architectures, and enabling automation in these environments
Develop and maintain business reporting, ensuring reliability and performance, delivery of performance management tools (such as control charts and scorecards), readiness and adoption of data w/in the organization
Consolidate, standardize and control changes to capacity management data and metric definitions, ownership, accountability and taxonomy to ensure alignment in understanding
Serve as strong advocate to improve analytical capability across the organization
Communicate with various business areas and to gather and prioritize their business requirements
Support various reporting and BI solutions (Tableau, Power BI, Salesforce Einstein)
Manage application and data integration platforms (Informatica, Talend)
Manage the full life cycle of development/reporting/integration projects: planning, design, develop, testing and rollout
Manage solution providers, define sourcing approach and manage the providers
Create and manage data, applications and technology architecture documentation and design artifacts
Work across teams to deliver meaningful reference architectures that outline architecture principles and best practices for technology advancement
Gain adoption of architecture processes, standards and procedures","
BS in Computer Science, Applied Mathematics, Physics, Statistics or area of study related to data sciences and data mining or relevant experience",None Found,"Invesco is one of the world’s leading global investment managers, entrusted with managing $1.2 trillion* in assets on behalf of clients worldwide. We are the 6th largest US retail asset manager and the 13th largest investment manager globally, and our more than 8,000 employees worldwide are dedicated to delivering an investment experience that helps people get more out of life. We are purely focused on managing a comprehensive range of active, passive and alternative investment capabilities, which we draw on to provide customized solutions aligned to client needs, our most important benchmark. (*As of May 31,2019)

Job Purpose (Job Summary):

As a Team Lead at Invesco, you would align business outcomes to technology goals and objectives. You will be responsible for managing decision sciences and advanced analytics initiatives, data integration/engineering. Interacts with Data Scientists, Business Owners, Business Data Analysts, Data Modelers, Architects, and Application Developers, to design, build and manage large-scale batch and real-time data pipelines utilizing various data analytics processing frameworks in support of Data Science practice. The position requires building strong technical hands-on-skills and experiences as well as establishing close business relationships across the enterprise. Working closely with marketing and sales stakeholders, you will establish and drive long term advance analytics roadmap manage increasing demands for advance analytics in Sales and Marketing. You will help steer the strategic technology direction, define target state architecture, technology roadmaps and mentor others. A successful candidate must have a demonstrable background with experience in development of high performance, distributed computing tasks using Big Data technologies such as Hadoop (platform level), NoSQL, text mining and other distributed environment technologies based on the needs of the organization. Responsible for analyzing, designing, programing, debugging and modifying software enhancements and/or new products used in distributed, large scale analytics solutions. Strong visualization skills and experience with BI tools (ex. Tableau)

Key Responsibilities / Duties:
Work with development teams and other project leaders/stakeholders to provide technical solutions that enable business capabilities
Supports the data science community by enabling data availability in environments that provide advanced analytical capabilities
Maintains a broad understanding of implementation, integration, and inter-connectivity issues with emerging technologies to define data strategies
Assist in the decision-making process related to the selection of software architecture solutions
Implement architectures to handle web-scale data and its organization
Execute strategies that inform data design and architecture partnering with enterprise standard
Build robust data pipelines on public Cloud using AWS Kinesis, Kafka, Lambda or other technologies
Assist in creating documents that ensure consistency in development across the online organization. Implements and improves core software infrastructure
Deep expertise in SQL language, Python, Hadoop ecosystem and/or Spark ecosystem. Strong experience with writing complex programs, implementing architectures, and enabling automation in these environments
Develop and maintain business reporting, ensuring reliability and performance, delivery of performance management tools (such as control charts and scorecards), readiness and adoption of data w/in the organization
Consolidate, standardize and control changes to capacity management data and metric definitions, ownership, accountability and taxonomy to ensure alignment in understanding
Serve as strong advocate to improve analytical capability across the organization
Communicate with various business areas and to gather and prioritize their business requirements
Support various reporting and BI solutions (Tableau, Power BI, Salesforce Einstein)
Manage application and data integration platforms (Informatica, Talend)
Manage the full life cycle of development/reporting/integration projects: planning, design, develop, testing and rollout
Manage solution providers, define sourcing approach and manage the providers
Create and manage data, applications and technology architecture documentation and design artifacts
Work across teams to deliver meaningful reference architectures that outline architecture principles and best practices for technology advancement
Gain adoption of architecture processes, standards and procedures
Work Experience / Knowledge:
7+ years of experience in data modeling, data warehousing, and big data architectures
5+ years of experience in a data engineering role
Proficient in application/software architecture (Definition, Business Process Modeling, etc.)
Deep expertise in (at least one) SQL language, Python, Hadoop ecosystem and/or Spark ecosystem. Strong experience with writing complex programs, implementing architectures, and enabling automation in these environments
The role will be responsible for providing innovative operational solutions and best practices
Advanced knowledge in SQL/Hive, Spark, NoSQL, (Java/Python is a plus)
Strong programming skills and ability to utilize a variety of software/languages/tools; e.g., Spark, R, Python, Scala, Java, Hive, SQL, SAS, Tableau, etc.
Experience with microservice development, Docker, Kubernetes
Develop software to run on cloud native big data infrastructure built on AWS using Spark, Lambda, S3, and other cloud native services
Designs and develops complex and large-scale data structures and pipelines to organize, collect and standardize data to generate insight
3+ years of experience in data integration platforms (Informatica, Talend)
Strong analytics and reporting skills – hands on experience in BI Tools like Tableau, Power BI, Salesforce Einstein
Hands on experience in self-service data preparation tool like Alteryx
Experience using GitHub, Bit Bucket, or other code repository solution
DevOps experience is a plus
Skills / Other Personal Attributes Required:
Previous management experience and successfully leading a team of direct reports
Proven track record of effectively leading and managing employees, managing performance, setting goals for team/individuals and provide mentoring.
Strong Tableau, Adobe Analytics other BI solution
Expert Oracle and Vertica skillsets
Experience using JIRA and Agile Project Management software
Experience using GitHub, Bit Bucket, or other code repository solution
Strong written, verbal communication and presentation skills
Ability to explain complex technical issues in a way that non-technical people may understand
Able to work in a global, multicultural environment
Self-motivated. Capable of working with little or no supervision
Ability to react positively under pressure to meet tight deadlines
Able to work independently or as a team player
Enjoy challenging and thought provoking work and have a strong desire to learn and progress
Formal Education: (minimum requirement to perform job duties)
BS in Computer Science, Applied Mathematics, Physics, Statistics or area of study related to data sciences and data mining or relevant experience
FLSA (US Only): Exempt

The above information on this description has been designed to indicate the general nature and level of work performed by employees within this role. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications required of employees assigned to this job. The job holder may be required to perform other duties as deemed appropriate by their manager from time to time.

Invesco's culture of inclusivity and its commitment to diversity in the workplace are demonstrated through our people practices. We are proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, creed, color, religion, sex, gender, gender identity, sexual orientation, marital status, national origin, citizenship status, disability, age, or veteran status. Our equal opportunity employment efforts comply with all applicable U.S. state and federal laws governing non-discrimination in employment."
19,Senior Digital Lead Data Engineer,"Atlanta, GA 30309",Atlanta,GA,30309,None Found,None Found,"Exceptional interpersonal skills, including teamwork, facilitation, and negotiation.
Communicates IT requirements and guidelines to vendor partners.
Applies multiple technical solutions to business problems.
Quickly comprehends the functions and capabilities of new technology.
Excellent written and oral communications skills.","Design and work with Agile teams to implement highly scalable Enterprise approaches for metadata, taxonomy, tagging, folder structures providing the lightweight controls to ensure sustainable data quality and efficiencies
Defines non-functional requirements including data cleansing and validation
Mentors and coaches other members of the agile and\or Run team
Interfaces with the Product Owner and Technology partners at the Program level to define and estimate features for agile teams
Works within the SAFe Agile framework and employs ITIL best practices
Client-facing, senior strategic support
Content assessment. Providing content revision/creation recommendations that help the business and its customers achieve their goals (based on brand documentation, competitive assessments, audience segmentation, SEO data, and site metrics)
Generating and/or overseeing an inventory of relevant client content assets
Creating and/or reviewing site structure and nomenclature for the most intuitive presentation of content, usually partnering with UX
Creating taxonomy and tagging strategies
Ensuring content is structured properly for any relevant backend systems including CMS, DAM, eCommerce and/or PIM
Contributing to technical system evaluations (such as CMS, DAM, and/or PIM) from a content perspective in terms of requirements
Establishing and/or maintaining editorial standards and accuracy/quality of content
Overseeing content migration and creating or reviewing associated documentation
Contributing to definition and management of, as well as periodic updates to, content governance and workflow (including content creation, content entry, publication, and decommission) as well as localization strategies
Responsible for management of, as well as periodic updates to, personalization and content tagging strategies for the site
Assists in production support and maintenance of applications as needed","
Bachelor's degree in English, Library Science, Journalism, Technical Writing, Marketing or equivalent military experience preferred",None Found,"Invesco is one of the world's leading global investment managers, entrusted with managing $1.2 trillion* in assets on behalf of clients worldwide. We are the 6th largest US retail asset manager and the 13th largest investment manager globally, and our more than 8,000 employees worldwide are dedicated to delivering an investment experience that helps people get more out of life. We are purely focused on managing a comprehensive range of active, passive and alternative investment capabilities, which we draw on to provide customized solutions aligned to client needs, our most important benchmark. (*As of May 31,2019)

About Invesco Technology
At Invesco Technology, we are strategic problem solvers. Our mission is to create world-class technology solutions to enable global operations, lead in the innovative use of data and emerging technologies to redefine the investment experience, and help our clients “get more out of life."" This mission is fueled by our high-performing teams, which thrive on collaboration, operate on shared trust, and leverage diversity of thought to deliver valuable results every day to Invesco, clients, and partners.

We wholeheartedly believe that our success is driven by our people. That is why we invest heavily in our top talent, providing opportunities for continuous learning and professional development. Our employees are encouraged and supported in taking advantage of development opportunities tied to their goals and are recognized for employing new skills to make an impact beyond the scope of their daily roles.

To continue building our high-performing, OneTech Team, we are seeking candidates who champion innovation, operate effectively in an agile environment, challenge the status quo and are empowered to take risks.

Job Purpose (Job Summary):

Join us in realizing Invesco's Digital Transformation! We are on a journey to reimagine what is into what could be. Think of us as like a tribe of digital activists who focus disruptive innovation who believe that digital operations in Investment Management can be done better. We have MASSIVE aspirations however we are focused on four goals:
Streamline content capture across the enterprise and create a one source of truth
Fully exploit the tremendous re-use potential through seamless accessibility to content
Provide Invesco with a highly scalable and dynamic platform that enables rapid growth
To shake-up the norm by developing new digital operating models to create a ""new world order""
Our vision is simple. To create strategic advantage by being the best at digital operations. We are highly motivated, not your usual financial services stereotype, and thrive within an industry resistant to change. As a team we respect and trust each other and celebrate our successes AND failures. Welcome to the new world order!
Right now, we are transforming the way we operate and to that note, we are looking for a super-strong and super-passionate Digital Lead Data Engineer. In our digital transformation, data is key. In this role, you will build technical solutions to help improve the scalability and performance of our data stores and our overall systems. As a Lead Engineer, you will focus on efforts that will provide increased flexibility and accessibility to our data, such as our cloud-based data lake and digital pipeline initiatives.
The Digital Lead Data Engineer acts as a senior level technical and functional expert, collaborating with business and Tech stakeholders at all levels to identify architectural solution options and map value streams. This position is responsible for using data engineering practices and techniques to deliver measurable business outcomes in a large-scale, complex organization.

Key Responsibilities / Duties:
Design and work with Agile teams to implement highly scalable Enterprise approaches for metadata, taxonomy, tagging, folder structures providing the lightweight controls to ensure sustainable data quality and efficiencies
Defines non-functional requirements including data cleansing and validation
Mentors and coaches other members of the agile and\or Run team
Interfaces with the Product Owner and Technology partners at the Program level to define and estimate features for agile teams
Works within the SAFe Agile framework and employs ITIL best practices
Client-facing, senior strategic support
Content assessment. Providing content revision/creation recommendations that help the business and its customers achieve their goals (based on brand documentation, competitive assessments, audience segmentation, SEO data, and site metrics)
Generating and/or overseeing an inventory of relevant client content assets
Creating and/or reviewing site structure and nomenclature for the most intuitive presentation of content, usually partnering with UX
Creating taxonomy and tagging strategies
Ensuring content is structured properly for any relevant backend systems including CMS, DAM, eCommerce and/or PIM
Contributing to technical system evaluations (such as CMS, DAM, and/or PIM) from a content perspective in terms of requirements
Establishing and/or maintaining editorial standards and accuracy/quality of content
Overseeing content migration and creating or reviewing associated documentation
Contributing to definition and management of, as well as periodic updates to, content governance and workflow (including content creation, content entry, publication, and decommission) as well as localization strategies
Responsible for management of, as well as periodic updates to, personalization and content tagging strategies for the site
Assists in production support and maintenance of applications as needed

Work Experience / Knowledge:
Minimum 8+ years' experience in digital content strategy or similar
Agency or consulting experience a plus
Proven track record of Innovation and expertise in Data Engineering
Understanding of agile development methods including: core values, guiding principles, and key agile practices
Proven ability to get stuff done, driven to see your team succeed.

Skills / Other Personal Attributes Required:
Exceptional interpersonal skills, including teamwork, facilitation, and negotiation.
Communicates IT requirements and guidelines to vendor partners.
Applies multiple technical solutions to business problems.
Quickly comprehends the functions and capabilities of new technology.
Excellent written and oral communications skills.

Formal Education: (minimum requirement to perform job duties)
Bachelor's degree in English, Library Science, Journalism, Technical Writing, Marketing or equivalent military experience preferred

Working Conditions:
An entrepreneurial working environment. If you can make a case for a project that helps achieve our goals or fits within our vision, we would encourage and pave the way for you to deliver it
A team that supports and collaborates with you
A fun environment that is not your typical Financial Services way-of-working
Challenges that will not only positively impact our organization and clients, however will also be a first in our industry
A competitive salary
Training to further your career and development. We want you to stay progressive and relevant and therefore we will invest in you to do just that!

FLSA (US Only): Exempt

The above information on this description has been designed to indicate the general nature and level of work performed by employees within this role. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications required of employees assigned to this job. The job holder may be required to perform other duties as deemed appropriate by their manager from time to time.

Invesco's culture of inclusivity and its commitment to diversity in the workplace are demonstrated through our people practices. We are proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, creed, color, religion, sex, gender, gender identity, sexual orientation, marital status, national origin, citizenship status, disability, age, or veteran status. Our equal opportunity employment efforts comply with all applicable U.S. state and federal laws governing non-discrimination in employment.

#Ll-SD1"
20,Technology Spring 2020 Intern,"Atlanta, GA",Atlanta,GA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Opportunity Overview
About Us

WarnerMedia is a leading media and entertainment company that creates and distributes premium and popular content from a diverse array of talented storytellers and journalists to global audiences through its consumer brands including: HBO, Warner Bros., TNT, TBS, CNN, DC Entertainment, New Line, Cartoon Network, Adult Swim, TCM, truTV and others.

See what it’s like to work at WarnerMedia! Discover more about the program and follow us on Instagram, Twitter and Facebook.

We are looking for a Big Data Engineer Intern interested in data engineering and analytics using large structured, semi-structured, and unstructured datasets. You will be part of a talented team of engineers that are tasked with making sense of the vast resource of data in the Warner Media infrastructure. In addition, as an intern, you will gain practical experience and gain new skills as a result of working in our world class media organization.

The Day-to-Day

Big Data engineering at Warner Media involves one or more of the following:
Designing, implementing, and improving data models, data pipelines, and metadata extractors
Analyzing AWS Cloudwatch or other logs, for example, to optimize resource utilization
Implementing statistical measurement for A/B testing
The Essentials
Students enrolled in a program for computer science, information technology, analytics, math, statistics, or a related field
Solid grasp of programming languages (particularly Python), various operating systems (Linux, Mac, Windows), and some familiarity with public cloud platforms
Demonstrated ability to conduct independent research utilizing large data sets
Strong analytical and quantitative skills, along with curiosity, creativity, and ability to communicate
Passion for seeing projects through from initial conception to eventual application
Empirical, detail-oriented mindset
Sense of ownership of her/his work, working well both independently and within a small collaborative team
What’s so great about this internship?
An opportunity to work with a great team that is passionate about the same thing you are!
Networking opportunities to meet people that you’d like to know!
A speaker series that introduces you to cool executives and what they do for the best brands!
Internship dates are January 21, 2020 – May 8, 2020. All interns are expected to work 20 hours per week and paid competitively based on location (relocation is not provided). Participation in the internship program is reserved for students who are currently enrolled or within 6 months post-graduation. Most positions are targeted to upperclassmen and graduate students. Candidates must be qualified and available to work at the time the application is submitted. Full-time employment is not guaranteed at the end of the program.

WarnerMedia and its subsidiaries are Equal Opportunity Employers and E-Verify users. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability, or protected veteran status."
21,"Data Engineer (Scala, NoSQL) Corp to Corp is also fine","Alpharetta, GA",Alpharetta,GA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Job Description

Title : Data Engineer
Location : Alpharetta, GA
Nature of employment : Full time, Permanent position or Contract (Corp-Corp or W2) is also fine
Job Description:
6 years overall work experience
Expert in Scala coding.
Experience in designing the middle ware integration flows
Expert in security implementation in middle ware integration
Experience implementing RESTful webservices in Scala
Experience with NoSQL and SQL databases
Proficiency with HTML5, CSS3, JavaScript
Familiarity with modern web development frameworks, libraries and tools
Excellent analytical and problem solving skills
Excellent oral and written communication skills
Data Transformation
Preparation Develop ETL scripts to harmonize, filter, aggregate, & correlate data

Qualifications

Scala, NoSQL, SQL, HTML5, CSS3, JavaScript, ETL
Additional Information

All your information will be kept confidential according to EEO guidelines."
22,Data Engineer - Java / Python & Spark,"Atlanta, GA",Atlanta,GA,None Found,None Found,"Qualifications: 3-7 years (2 years min relevant experience in the role) experience; Bachelor’s degreeShould be proficient in Software Engineering Techniques, Software Engineering Architecture, Software Engineering Life cycle and Data Management.Should have progressing skills on Business Analysis, Business Knowledge, Software Engineering Leadership, Architecture Knowledge and Technical Solution Design.",None Found,None Found,None Found,None Found,"Data Engineer
Java/Python + Spark
Overall experience of around 5-8 years with Data integration, data migration
Job description:
Good understanding of ETL/ELT concepts
Hands on working experience with one of the programming languages (Java, Python)
Experience working with big data tools and technologies (Spark, Kafka)
Should be able to interpret business requirements, understand design and identify mechanism to test
Resource should know how to figure out what should be tested, with a focus on data quality
Experience with data reconciliation, testing to ensure quality of migrated data.
Understanding of Cloud Architecture
Experience with NoSQL databases (Cassandra, Couchbase)
Understanding of Cloud Data Warehouse solutions (AWS)
Resource must be comfortable working in an Agile environment


Candidates should be flexible / willing to work across this delivery landscape which includes and not limited to Agile Applications Development, Support and Deployment.

Applicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Capgemini.

Qualifications

Responsible for programming and software development using various programming languages and related tools and frameworks, reviewing code written by other programmers, requirement gathering, bug fixing, testing, documenting and implementing software systems. Experienced programmers are also responsible for interpreting architecture and design, code reviews, mentoring, guiding and monitoring programmers, ensuring adherence to programming and documentation policies, software development, testing and release.
Required Skills and Experience:
Write software programs using specific programming languages/platforms such as Java or MS .NET, and related tools, platform and environment. Write, update, and maintain computer programs or software packages to handle specific jobs, such as tracking inventory, storing or retrieving data, or controlling other equipment. Consult with managerial, engineering, and technical personnel to clarify program intent, identify problems, and suggest changes. Perform or direct revision, repair, or expansion of existing programs to increase operating efficiency or adapt to new requirements. Write, analyze, review, and rewrite programs, using workflow chart and diagram, and applying knowledge of computer capabilities, subject matter, and symbolic logic. Write or contribute to instructions or manuals to guide end users. Correct errors by making appropriate changes and then rechecking the program to ensure that the desired results are produced. Conduct trial runs of programs and software applications to be sure they will produce the desired information and that the instructions are correct. Compile and write documentation of program development and subsequent revisions, inserting comments in the coded instructions so others can understand the program. Investigate whether networks, workstations, the central processing unit of the system, and/or peripheral equipment are responding to a program's instructions. Prepare detailed workflow charts and diagrams that describe input, output, and logical operation, and convert them into a series of instructions coded in a computer language. Perform systems analysis and programming tasks to maintain and control the use of computer systems software as a systems programmer. Consult with and assist computer operators or system analysts to define and resolve problems in running computer programs. Perform unit testing Assist in system and user testing Fix errors and bugs that are identified in the course of testing.
Qualifications: 3-7 years (2 years min relevant experience in the role) experience; Bachelor’s degreeShould be proficient in Software Engineering Techniques, Software Engineering Architecture, Software Engineering Life cycle and Data Management.Should have progressing skills on Business Analysis, Business Knowledge, Software Engineering Leadership, Architecture Knowledge and Technical Solution Design.

Capgemini is an Equal Opportunity Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.

This is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.
Click the following link for more information on your rights as an Applicant - http://www.capgemini.com/resources/equal-employment-opportunity-is-the-law

About Capgemini
A global leader in consulting, technology services and digital transformation, Capgemini is at the forefront of innovation to address the entire breadth of clients’ opportunities in the evolving world of cloud, digital and platforms. Building on its strong 50 year heritage and deep industry-specific expertise, Capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations. Capgemini is driven by the conviction that the business value of technology comes from and through people. It is a multicultural company of 200,000 team members in more than 40 countries. The Group reported 2018 global revenues of EUR 13.2 billion.

Visit us at www.capgemini.com. People matter, results count."
23,Data Engineer,"Atlanta, GA 30340",Atlanta,GA,30340,None Found,Monthly employee social functionsOn premises gymDaily afternoon yoga stretchingFriendly,Monthly employee social functionsOn premises gymDaily afternoon yoga stretchingFriendly,None Found,None Found,None Found,"Job Description

Accountabilities in this Role:
Ø Develop, construct, test and maintain architectures
Ø Data acquisition / verifies it meets business and data privacy regulations
Ø Deploy sophisticated analytics programs, machine learning and statistical methods
Ø Acts as primary backup for ERP (Syspro) Administration
Ø Ownership / support of company intranet (SharePoint) along with workflows
Ø Web Master (Website Development) / Website Support (back-end)

Qualifications

Technical Skills:
Ø Understanding of object-oriented design, client-server architecture and relational database design
Ø Knowledge of .NET Framework and ability to work with C#, ASP.NET, WCF, MVC and ADO.NET
Ø Experience using T-SQL with the ability to write SQL queries and stored procedures
Ø Knowledge of client-side technologies such as JavaScript, jQuery, HTML5 and CSS
Ø Experience with Microsoft Visual Studio and SQL Server Management Studio
Ø Experience using Team Foundation Server for source control and build management
Ø SharePoint development experience with SharePoint 2010 / 2013
Ø Experience with SharePoint Solutions (SharePoint Server 2013, InfoPath, Forms Services, Excel Services, Search, Workflows, Content Management, Metadata, Business Data Catalog and Web Services)
Ø SharePoint experience including SharePoint workflows, effective use of the data view web part (DVWP), content query web part, data form web part, navigation customization, and some branding customization
Ø Web development experience (HTML, CSS, XSL, XSLT, JavaScript, AngularJS).
Ø Experience with SharePoint templates (site templates, list templates, master page customization)
Ø Strong experience in a scripting language such as PowerShell
Ø ERP system support and implementation in the finance, manufacturing and logistics arena. SYSPRO experience
Ø Database architecture and design; optimize T-SQL code and stored procedures
Ø SQL Server Reporting services (SSRS) to write reports not possible using SYSPRO report writer
Ø Use Automate software to print journals and distribution reports from all SYSPRO modules then post in the GL
Ø SYSPRO application administration with MS SQL Server administration and development
Ø Working knowledge of Storage (SAN) platforms, specifically HP.
Ø Understanding of Windows 2012 R2 Microsoft Hyper-V technology
Additional Preferred Qualifications:
Ø Bachelor’s degree in a computer/accounting/finance or related field.
Ø Understands accounting, purchasing, manufacturing and distribution methodologies through an ERP system. The company uses SYSPRO.
Ø Self-starter and requires minimal supervision, but works well in a group.
Ø Ability to interpret what non-computer science personnel need and then develop the ideas to solve the situation.
Additional Information

The Rewards:

Ø Fantastic, casual working environmentMonthly employee social functionsOn premises gymDaily afternoon yoga stretchingFriendly
Ø Comprehensive benefit package401(k) with company matchExtremely competitive health insurance planVacation and Personal DaysCompany paid holidays

All qualified applicants will receive consideration for employment without regard to race, color, gender identity or expression, age, religion, intellectual disability, mental disability, physical disability, including but not limited to blindness, unless it is shown that such disability prevents performance of the work involved, medical condition, handicap, national origin, ancestry, sexual orientation, marital status, domestic partnership status, parental status, military status, veteran or military discharge status, source of income or housing status or any other status protected by applicable law.
GF Health Products, Inc. is a drug free workplace"
24,Big Data Engineer,"Atlanta, GA",Atlanta,GA,None Found,None Found,"Qualification: 3-7 years (2 years min relevant experience in the role) experience, Bachelor’s DegreeCertification: Should have or seeking SE Level 1Should have progressing knowledge in Business Analysis, Business Knowledge, Software Engineering, Testing, Data Management, Architecture Knowledge and Technical Solution Design",None Found,None Found,None Found,None Found,"The big data Senior Technical person (4 to 10 years of experience) responsible for managing the full life-cycle of a Hadoop solution

This includes creating the requirements analysis, the platform selection, design of the technical architecture, design of the application design and development, testing, and deployment of the proposed solution

Analytical and problem solving skills, applied to big data domain

Good communication skill

Worked on Hadoop, Hive, Spark, Scala, Kafka, NiFi, Scoop, Oozie


Candidates should be flexible / willing to work across this delivery landscape which includes and not limited to Agile Applications Development, Support and Deployment.
Applicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Capgemini.
Qualifications
Software Engineers perform requirements analysis. They then design, develop or maintain the physical application (components) or the application environment, based on the Software Architecture (models and principles). Activities include coding, integrating, implementing, installing or changing frameworks and standard components, or technical and functional application management. A Software Engineer also develops languages, methods, frameworks and tools, and/or undertakes activities in support of server-based databases in development, test and production environments.
Required Skills and Experience:
You are an experienced Software Engineer. You have received training and mastered at least one technology environment. You are good at elaborating technology areas and have an ability to position them within the scope of an overall project. You are a member of at least one community.
Qualification: 3-7 years (2 years min relevant experience in the role) experience, Bachelor’s DegreeCertification: Should have or seeking SE Level 1Should have progressing knowledge in Business Analysis, Business Knowledge, Software Engineering, Testing, Data Management, Architecture Knowledge and Technical Solution Design

Capgemini is an Equal Opportunity Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.
This is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.
Click the following link for more information on your rights as an Applicant - http://www.capgemini.com/resources/equal-employment-opportunity-is-the-law
About Capgemini
A global leader in consulting, technology services and digital transformation, Capgemini is at the forefront of innovation to address the entire breadth of clients’ opportunities in the evolving world of cloud, digital and platforms. Building on its strong 50 year heritage and deep industry-specific expertise, Capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations. Capgemini is driven by the conviction that the business value of technology comes from and through people. It is a multicultural company of 200,000 team members in more than 40 countries. The Group reported 2018 global revenues of EUR 13.2 billion.
Visit us at www.capgemini.com. People matter, results count."
25,Lead Data Engineer,"Atlanta, GA",Atlanta,GA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"You are curious, persistent, logical and clever a true techie at heart. You enjoy living by the code of your craft and developing elegant solutions for complex problems. If this sounds like you, this could be the perfect opportunity to join EPAM as a Lead Data Enigneer. Scroll down to learn more about the position’s responsibilities and requirements.
What You’ll Do
Architecture design of holistic Cloud data ecosystem with a focus on Google Cloud Platform capabilities and features
Architecture design of Production, Staging/QA, and Development infrastructures running is 24/7 environments
Robust and consistent Cloud Strategy design aligned with business objectives
Provide guidelines for data migration approaches and techniques including ingest, store, process, analyze and explore/visualize data
Assistance with data migration and transformation
Evangelize Cloud computing expertise internally and externally to drive Cloud Adoption
What You Have
A degree in an associated field and/or other advanced certification along with significant experience
In-depth cloud professional, competent of quickly establishing connections and credibility in how to address the business needs via design and operate cloud-based solutions
Experience in Agile or PMI methodology managed projects
Experience in enterprise applications, and big data solutions
Experience in platform and cloud migrations, including migration factory
In-depth experience with databases and tools analysis
In-depth experience with ETL tools
Processes design and development for the data modeling, mining, and analysis
Extensive experience in methodologies and processes for large-scale databases management on-premises and cloud environment
In-depth understanding and knowledge of distributed version control systems like Git
Strong understanding of concepts and experience with StackDriver and other cloud-based monitoring tools including application level and logging
Nice to have
Google Cloud Certified Professional Data Engineer
Experience Creating automated tooling for cloud platforms
Experience with architecting and handling large datasets, structured and semi-structured data formats
Experience with streaming processing
Experience with messaging platforms
Experience with performance testing and tuning
Experience with GCP based security hardening including IAM, ACL, firewall rules, data traffic encryption
What We Offer
Medical, Dental and Vision Insurance (Subsidized)
Health Savings Account
Flexible Spending Accounts (Healthcare, Dependent Care, Commuter)
Short-Term and Long-Term Disability (Company Provided)
Life and AD&D Insurance (Company Provided)
Employee Assistance Program
Unlimited access to LinkedIn learning solutions
Matched 401(k) Retirement Savings Plan
Paid Time Off
Legal Plan and Identity Theft Protection
Accident Insurance
Employee Discounts
Pet Insurance"
26,Data Engineer,"Atlanta, GA",Atlanta,GA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"AnswerRocket is a leader in AI-powered analytics disrupting the traditional BI and analytics market. Named a Cool Vendor by Gartner, AnswerRocket is changing the way that Fortune 500 and mid-size clients make decisions everyday. Our self-service analytics platform combines machine learning with natural language generation to enable business leaders to make better, faster decisions.

We’re looking for a passionate Data Engineer to join our growing team. This is a great role for a Data Scientist who wants to transition into Data Engineering. You will be an experienced data wrangler who enjoys optimizing our data capabilities and building them from the ground up. You will be a key owner and thought leader in bringing our infrastructure to the next level!

What You’ll Do


Ingest, process, and analyze end-to-end data
Design data warehouses on platforms such as AWS Redshift, Azure SQL Data Warehouse, Snowflake, and other high performance platforms
Design custom ETL processes based on customer needs and their existing data sources
Optimize data warehouses for performance
Contribute to the core design of data architecture, data models and schemas, and implementation plans
Support regular ad-hoc data querying and analysis to better understand customer behaviors
Collaborate with teams across the organization to design, build and improve AnswerRocket’s AI tool and to address and predict data performance bottlenecks

Why We’ll Love You


BS or MS in Computer Science, Engineering, Mathematics or a related technical discipline
At least 2 years of professional experience in data analysis including SQL, database modeling and design
A background in Data Science with an understanding of the principles of machine learning and high-availability datastores
Proficient, or some type of experience, in the following: Python, Java, Javascript, MySQL, Amazon Redshift, and NLP pipelines
Experience with BI and data visualization tools
Excellent communication skills, particularly translating between technical and non-technical stakeholders
We are unable to sponsor visas at this time - can only accept applications from US Citizens and Permanent Greencard holders.

Why You’ll Love Us


Premium health, dental & vision coverage for Rocketeers and their families
401K and long-term disability insurance
Flexible PTO and paid parental leave to sustain energy and creativity
Flex Scheduling
Weekly chef-prepared lunches
Fully stocked kitchen with bottomless snacks and coffee
Easy access to public transit including MARTA
Complimentary onsite gym
Team outings and activities to build community
Casual dress all-day, everyday
Stable startup with a fun culture and approachable leadership

About AnswerRocket

We’re honored to have been named a Best Place to Work in Atlanta! Founded by successful technology entrepreneurs in 2013, our offices are located in metro Atlanta and include a fun work environment with the dynamic vibe of growth. Customers love what we are doing, and Gartner has recently named us a Cool Vendor in analytics.

Our team consists of smart and creative people who are motivated by clear goals to deliver “a ha” moments to our customers. We are breaking away from tired, traditional software and are committed to delivering high quality, well-engineered solutions that fit into modern enterprises. AnswerRocket offers the opportunity to grow immensely, both personally and professionally, as we leverage the latest technology to change how companies use big data.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, protected veteran status, or any other legally protected basis, in accordance with applicable law. We are an Equal Opportunity Employer."
27,Senior Technical Analyst – AWS Data Engineer,"Atlanta, GA 30326",Atlanta,GA,30326,None Found,None Found,None Found,None Found,None Found,None Found,"Job Description:
Carter's, Inc. is the largest branded marketer in North America of apparel exclusively for babies and young children. The Company owns the Carter's and OshKosh B'gosh brands, two of the most recognized brands in the marketplace. These brands are sold in leading department stores, national chains, and specialty retailers domestically and internationally. They are also sold through more than 1,000 Company-operated stores in the United States, Canada, and Mexico and online at www.carters.com, www.oshkoshbgosh.com, and www.cartersoshkosh.ca. The Company's Just One You and Genuine Kids brands are available at Target, its Child of Mine brand is available at Walmart, and its Simple Joys brand is available on Amazon. The Company also owns Skip Hop, a global lifestyle brand for families with young children. Carter's is headquartered in Atlanta, Georgia. Additional information may be found at www.carters.com.
This position will be responsible for the day to day activities and new project initiatives related to our AWS datalake that complements our Retail Merchandising and Planning systems. We have several initiatives to improve our decision support capabilities by enabling advanced analytics on our AWS datalake platform and this position will play a leading role in helping architect and implement these initiatives. Once implemented, this role will lead the effort to support and grow these capabilities alongside the business.
Project and Initiative Delivery - 50%
Utilize extensive knowledge of the AWS platform and related programming languages to contribute to the implementation of new capabilities on the AWS datalake platform
Play a major role in architecting the solutions and developing the required technical components
Proactively drive and facilitate conversations about data needs with stakeholders across the company
Understand, unify and integrate data from internal and third-party data sources using industry best practices for scalability, quality, simplicity, and maintainability
Build and maintain data pipelines and ETL process
Design, develop, maintain and enhance data collection procedures and analytic systems
Support Daily Operations - 50%:
Partner with internal business and external vendors to support daily operations, problem solve and gather business and technical requirements, and implement changes
Create, build, and maintain partnerships with all levels of the organization, ensuring collaboration in system changes and enhancements
Ownership of end-to-end data and analytical solutions including internal and third-party systems and software components
Provide occasional support on weekends when needed
Required Experience:
Minimum of 5 years of work experience in system support, software implementation or IT consulting
Minimum of 4 years of experience architecting data analytics solutions on AWS
Minimum of 4 years of experience with various programming languages (Python, Java, Javascript, GLU, R, SQL, Shell scripting) required
Minimum of 3 years of experience managing ETL with data warehouses (AWS Redshift, Google BigQuery, etc)
Experience working with both structured and unstructured data. Experience building and optimizing data pipelines and big data sets
Work experience in Retail or CPG preferred
Skilled in preparing and/or presenting reports and data; Identifying trends through analysis
Critical Thinking with a drive for process improvement
Strong verbal, written and presentation communication skills
Proficient with Microsoft Excel, Word, and Powerpoint
Bachelors degree in an appropriate Science or Math field (MIS or CIS preferred)
Carters is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity, sexual orientation, national origin, genetics, disability, age, veteran status, or any other status protected by federal, state, or local law.
Visit https://carters.submit4jobs.com/ today"
28,Data Engineer,"Atlanta, GA 30308",Atlanta,GA,30308,None Found,None Found,None Found,None Found,None Found,None Found,"8+ years of hands-on software development and database experience

5+ years programming Python/R or equivalent data science scripting languages

6+ years programming with Java/Scala

4+ years developing with Hadoop, Hive/MapReduce/HDFS

3+ years of experience with Stream Processing Frameworks such as Kafka/Spark

5+ years of experience with Linux/Unix

5+ years of experience with SQL

4+ years of experience with Cassandra or equivalent NoSQL Databases

2+ years of experience with Cloud Engineering and Deployment, Containers and Orchestration

2+ years developing with Spring Framework: Core, Integration, MVC and SpringBoot

Strong understanding of database design, development and data modeling

Exposure to Amazon Web Services, such as S3, Dynamo

Experience working in an Agile/DevOps environment

Thorough knowledge of data partitioning, archival, and retention strategies

Working knowledge of network/transport protocols: TCP/UDP, HTTP, FTP, MQ

Experience with Java/J2EE, Integration frameworks, JavaFX, and building API's for both external and internal consumption

Strong written and verbal skills for communicating technical information to a technical and non-technical community

Ability to work in a dynamic multi-team environment as well as independently

Must be a self-driven, individual contributor, aware of Agile scrum methodology to participate in project activities

Must have excellent communication and presentation skills in English and be equally comfortable in a deep dive technical workshop

Ability to work with geographically dispersed teams yet deliver value

Should have an active GitHub profile

Authorized to work in USA

Other Good to have skills

Experience working in Agile development process and deep understanding of various phases of the Software Development Life Cycle
Experience working in Agile development process and deep understanding of various phases of the Software Development Life Cycle
Experience using Source Code and Version Control systems
Self-starter and a Team player who works with minimal supervision and the ability to work in a team of diverse skill sets
Ability to comprehend customer requests and provide the correct solution
Desire to resolve issues and dive into potential issues
Writing white papers, blogging and participation in Big Data related events and conferences are a definitive plus
Individual contributor with excellent analytical skills and ability to think out of box
Travel: As part of project, willing to travel occasionally within US with prior notice.

Location: Atlanta

Academic Qualification

Bachelor’s degree in Computer Science or similar, advanced degree preferred with outstanding record of academic achievement

Our culture

We thrive for authority. This can only be achieved by working with the best people, offering them the most challenging projects and create a continuous learning environment.

All this is in place so you can accelerate your career.

What can you expect?

Inspiring working environment
The most challenging assignments
Trust
Freedom to accelerate
Much more!

About Us

Xebia is a Dutch headquartered IT company which specializes in Continuous Delivery & DevOps, Full Stack Agile Development, Agile Consulting & Transformation, Big Data/Data Science, Mobile, Cloudification and Data Centre Automation. With core software development offices in Netherlands (Amsterdam, Hilversum), India (Delhi NCR, Bangalore, Pune), France (Paris) and U.S.(Boston, Atlanta) we employ over 1100 people worldwide!

Atlanta is our software development hub and we are looking for smart, consultative, hands-on software developers to be a part of our exclusive team.

Xebia explores and creates new frontiers in IT. We provide innovative products and services and strive to stay one step ahead of our customers’ needs. We turn new technology trends into business advantages. As mainstream front-runners, we create new IT solutions and build the future with our customers.

Passion for in depth technology & software craftsmanship in combination with Lean, Agile and Scrum practices are Xebia's driving factors and competitive edge. True knowledge workers find Xebia to be an inspiring place to work where they are challenged by peers."
29,Data Engineer,"Atlanta, GA",Atlanta,GA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Based in our Atlanta office, we are looking for savvy Data Engineers to join our growing team of analytics experts. You will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up.

The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company's data architecture to support our next generation of products and data initiatives.

Responsibilities


Create and maintain optimal data pipeline architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS 'big data' technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

Qualifications


Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing 'big data' data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable 'big data' data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience using the following software/tools:
Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.
Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.
Experience with AWS cloud services: EC2, EMR, RDS, Redshift
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.

"
30,Senior Azure Data Engineer,"Atlanta, GA 30338",Atlanta,GA,30338,None Found,"3+ years of professional solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (6+ years in total)
2+ years designing and building modern data pipelines and data streams
2+ years designing Azure data storage solutions (SQL Database, SQL Data Warehouse, Cosmos DB, Data Lake Storage)
2+ years developing data ingestion, data processing and data optimization (Databricks, Data Factory, Informatica, PolyBase)
Understating of Master Data Management (MDM) and data quality tools and processes
Understanding of Lambda and Kappa architecture patterns
Understanding of DevOps including CI/CD
Experience developing software architectures and key software components
High-level understanding of common authentication patterns and flow including single sign-on and OAuth
Experience with Agile/Scrum methodology
Ability to apply technology and consulting to solve a client business problem
Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise
Able to communicate and present complex issues with preciseness, assurance, and confidence
A disciplined approach to software development and problem solving
Passion for technology and a high technical aptitude
Insightful and always looking for breakthrough ideas
Self-sufficient, high integrity, more than just competent
Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing
Ability to conduct/lead oral status/technical interchange meetings with clients
Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form
Ability to write relevant components of a proposal document (e.g. participate in RFIs and RFPs including answering specific technology related questions and coming up with initial high-level technical design and architecture including any necessary Visio diagrams and PowerPoint slides)
Ability to translate verbal requirements from face to face client meetings into requirements documents, statements of work, and proposals",None Found,"Technical and thought-leadership of Azure data design and implementation engagements
Contribute to customer elaboration and discovery sessions to inform solution design
Lead data architecture design, solution structures and component design
Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security/authentication of proposed solutions
Ensure that technical software development process is followed on the project, be familiar with industry best practices for software development and agile practices
Understand a broad spectrum of technology in order to provide part or all of a detailed technical design which meets customer requirements
Act as lead or technical architect on customer projects, closely aligned with the Microsoft Azure Practice to deliver a wide-range of PaaS-focused solutions
Provide technical leadership for on-premises and external integration points
Communicate across the client’s community – consistently viewed as adding value
Contribute knowledge, tools, and positivity to the greater Perficient culture and community
Serve as a technical leader and mentor",None Found,None Found,"Overview
At Perficient you’ll deliver mission-critical technology and business solutions to Fortune 500 companies and some of the most recognized brands on the planet. And you’ll do it with cutting-edge technologies, thanks to our close partnerships with the world’s biggest vendors. Our network of offices across North America, as well as locations in India and China, will give you the opportunity to spread your wings, too.

We’re proud to be publicly recognized as a “Top Workplace” year after year. This is due, in no small part, to our entrepreneurial attitude and collaborative spirit that sets us apart and keeps our colleagues impassioned, driven, and fulfilled.

Perficient currently has a career opportunity for a Senior Azure Data Engineer.

Job Overview:
As a Senior Azure Data Engineer, you will technically lead cloud-focused software engineering teams to deliver workloads for our clients. You will participate in all aspects of the software development lifecycle, which includes estimating, technical design, implementation, documentation, testing, and deployment. We are looking for multi-talented professionals with deep technical backgrounds, experience building world-class digital experiences, and excellent team leadership skills.

You will provision and set up data platform technologies that are on-premises and in the cloud. You will manage and secure the flow of structured and unstructured data from multiple sources. The data platforms you use can include relational databases, nonrelational databases, data streams, and file stores. You will also ensure that data services securely and seamlessly integrate with other data platform technologies or application.

As part of our cloud migration, app modernization, and cloud-native development services, you will focus on data-related tasks in Azure. Your primary responsibilities include using services and tools to ingest, egress, and transform data from multiple sources. Azure data engineers collaborate with business stakeholders to identify and meet data requirements. They design and implement solutions, manage, monitor, and ensure the security and privacy of data to satisfy business needs.

Strong experience in designing data centric-systems in Azure leveraging Data Lake Storage, Blob Storage, Azure SQL Database, Azure SQL Data Warehouse, Cosmos DB, Azure Databricks, Azure Data Factory, and Stream Analytics is desired. Comprehension of modern solution architectures, solid .NET development practices, common API / service implementations, cloud/hybrid networking, and Azure IaaS experiences are a plus.

Platform Technologies: Document DBs, Graph Databases, SQL Databases, ELT and ETL tools, Microsoft Azure: Azure SQL Database, Cosmos DB, Data Factory, SQL Data Warehouse, Analysis Services, Power BI, Azure Search, App Services (Web, API, Logic apps), Azure Functions, Azure WebJobs, networking & security, Azure storage, Service Bus, ExpressRoute/VPN, Azure SQL Database, Redis Cache, Azure Search, Application Insights, Azure Active Directory, Visual Studio Team Services, Azure ARM templates, Informatica BDM, Hadoop, HDInsight

Delivery Technologies: SQL, PolyBase, Python, C#, Web API, JavaScript, Entity Framework, RESTful services, microservices, Visual Studio, WCF, PowerShell, Bash
Responsibilities
Technical and thought-leadership of Azure data design and implementation engagements
Contribute to customer elaboration and discovery sessions to inform solution design
Lead data architecture design, solution structures and component design
Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security/authentication of proposed solutions
Ensure that technical software development process is followed on the project, be familiar with industry best practices for software development and agile practices
Understand a broad spectrum of technology in order to provide part or all of a detailed technical design which meets customer requirements
Act as lead or technical architect on customer projects, closely aligned with the Microsoft Azure Practice to deliver a wide-range of PaaS-focused solutions
Provide technical leadership for on-premises and external integration points
Communicate across the client’s community – consistently viewed as adding value
Contribute knowledge, tools, and positivity to the greater Perficient culture and community
Serve as a technical leader and mentor
Qualifications
3+ years of professional solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (6+ years in total)
2+ years designing and building modern data pipelines and data streams
2+ years designing Azure data storage solutions (SQL Database, SQL Data Warehouse, Cosmos DB, Data Lake Storage)
2+ years developing data ingestion, data processing and data optimization (Databricks, Data Factory, Informatica, PolyBase)
Understating of Master Data Management (MDM) and data quality tools and processes
Understanding of Lambda and Kappa architecture patterns
Understanding of DevOps including CI/CD
Experience developing software architectures and key software components
High-level understanding of common authentication patterns and flow including single sign-on and OAuth
Experience with Agile/Scrum methodology
Ability to apply technology and consulting to solve a client business problem
Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise
Able to communicate and present complex issues with preciseness, assurance, and confidence
A disciplined approach to software development and problem solving
Passion for technology and a high technical aptitude
Insightful and always looking for breakthrough ideas
Self-sufficient, high integrity, more than just competent
Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing
Ability to conduct/lead oral status/technical interchange meetings with clients
Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form
Ability to write relevant components of a proposal document (e.g. participate in RFIs and RFPs including answering specific technology related questions and coming up with initial high-level technical design and architecture including any necessary Visio diagrams and PowerPoint slides)
Ability to translate verbal requirements from face to face client meetings into requirements documents, statements of work, and proposals
Perficient full-time employees receive complete and competitive benefits. We offer a collaborative work environment, competitive compensation, generous work/life opportunities and an outstanding benefits package that includes paid time off plus holidays. In addition, all colleagues are eligible for a number of rewards and recognition programs including billable bonus opportunities. Encouraging a healthy work/life balance and providing our colleagues great benefits are just part of what makes Perficient a great place to work.

More About Perficient

Perficient is the leading digital transformation consulting firm serving Global 2000 and enterprise customers throughout North America. With unparalleled information technology, management consulting and creative capabilities, Perficient and its Perficient Digital agency deliver vision, execution and value with outstanding digital experience, business optimization and industry solutions.

Our work enables clients to improve productivity and competitiveness; grow and strengthen relationships with customers, suppliers and partners; and reduce costs. Perficient's professionals serve clients from a network of offices across North America and offshore locations in India and China. Traded on the Nasdaq Global Select Market, Perficient is a member of the Russell 2000 index and the S&P SmallCap 600 index.
Perficient is an award-winning IBM Premier Business Partner, a Microsoft National Service Provider and Gold Certified Partner, an Oracle Platinum Partner, an Adobe Business Solution Partner, and a Salesforce Gold Consulting Partner.

Perficient is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national, origin, disability status, protected veteran status, or any other characteristic protected by law.

Disclaimer: The above statements are not intended to be a complete statement of job content, rather to act as a guide to the essential functions performed by the employee assigned to this classification. Management retains the discretion to add or change the duties of the position at any time.
#LI-KG1"
31,Lead Data Engineer,"Atlanta, GA",Atlanta,GA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"ThoughtWorks is a global software consultancy, made up of around 4,500 passionate technologists across 15 countries. We specialize in strategy, portfolio management and product design, combined with digital engineering excellence.

As a Lead Data Engineer, here's what we'll be looking for you to bring:

Hands-on Engineering Leadership
Proven track record of Innovation and expertise in Data Engineering
Tenure in coding, architecting and delivering complex projects
Deep understanding and application of modern data processing technology stacks. For example Spark, Hadoop ecosystem technologies, and others
Deep understanding of streaming data architectures and technologies for real-time and low-latency data processing
Deep understanding of NoSQL technologies including column family, graph, document, and key-value data storage technologies
Understanding of how to architect solutions for data science and analytics such as productionizing machine learning models and collaborating with data scientists
Understanding of agile development methods including: core values, guiding principles, and key agile practices
Understanding of the theory and application of Continuous Integration/Delivery
Passion for software craftsmanship
A rich breadth of industry experience and background working across different organizations, ranging in size, from start-ups to large corporations..
Strong stakeholder management and interaction experience at different levels


There's no typical day or engagement for our Senior Data Engineers. Here’s what you’ll do:

Be the SME. Develop modern data architectural approaches to meet key business objectives and provide end to end data solutions
You might spend a few weeks with a new client on a deep technical review or a complete organizational review, helping them to understand the potential that data brings to solve their most pressing problems.
On other projects, you might be acting as the architect, leading the design of technical solutions, or perhaps overseeing a program inception to build a new product.
It could be much more about getting stuck into a delivery project where you're equally happy coding and tech leading the team to implement the solution.
Whatever your role, the team always look to draw on your experience when things get tough and you often handle the difficult client conversations allowing the team to continue delivering without undue pressure.
You have great relationships with our new business team and work collaboratively to support pre-sales, meet prospective clients and ultimately influence and shape our portfolio of work.
You recognize that building your network with a client is absolutely key to enable you to perform in your role. You'll be drawing on all of your passion for technology, hands-on experience and knowledge of latest Big Data and Engineering best practices to help you gain the respect and credibility of those around you.


A few important things to know:
Projects are almost exclusively on customer site, so candidates should be flexible and open to extensive travel.

Candidates must possess work authorization that does not require H-1B visa sponsorship by ThoughtWorks or dependent EAD.

Not quite ready to apply? Or maybe this isn’t the right role for you? That’s OK, you can stay in touch with AccessThoughtWorks, our learning community (click ""contact me about recruitment opportunities"" to hear about jobs in the future).

It is the policy of ThoughtWorks, Inc. to provide a work environment free of discrimination. The Company will take affirmative action to ensure applicants and ThoughtWorks employees are treated without regard to race, color, religion, sex, national origin, ethnic origin, veteran status, family status, disability, sexual orientation, gender expression or gender identity. This also includes individuals who are perceived to have any of the aforementioned attributes. ThoughtWorks will adhere to all federal, state, and municipal laws and regulations governing employment."
32,Data Analyst III - Data Engineer,"Atlanta, GA 30328",Atlanta,GA,30328,None Found," 5 or more years of experience required in related field (developing and implementing analytical solutions in Finance, Marketing, Sales or Operations). 3 or more years of experience required if candidate possesses a related advanced degree. Requires strong skills in SQL writing and query optimization. Requires experience building data workflows, manipulation of large data sets, or developing data pipelines in analytical tools such as Informatica, Alteryx, Tableau Prep, SQL, SSIS, etc. Requires strong skills and experience with reporting and data visualization in analytical tools such as Tableau, Prep, SQL, etc. Requires effective proficiency in teamwork, communication, presentation, and time management to work effectively with teams throughout organization, including strong verbal and written communication. Experience manipulating large datasets and the ability to extrapolate conclusions from the data. Demonstrated problem solving and analytical thinking skills. Excellent interpersonal, leadership, presentation, and collaborative skills to work effectively with teams throughout organization. BS/BA degree in related discipline",None Found,None Found,None Found,None Found,"Cox Communications is the largest private telecom company in America, and we proudly serve six million homes and businesses across 18 states. At Cox, we are committed to creating meaningful moments of human connection, not only with our products and services, but also with our career opportunities. Come connect with us, and lets build a better future together.

Role Summary

Looking for a Senior Data Analyst to join an enterprise reporting and analytics team supporting Cox Communications Enterprise Finance and Accounting as well as our business partners. This person should be comfortable in a data engineering role building data pipelines and ETL processes, have enough business acumen to understand context and intent, and apply these concepts to data solutions. This role will assist in data strategy and design, and develop data-sets for the Finance BI ecosystem to support reporting, analysis & analytical modeling.

Recognized as a Subject Matter Expert (SME) and authority on issues related to Business Intelligence applications reporting, analysis, and metrics. This person will exercise an inquisitive mindset to transform business questions into actionable data exploration exercises and data sets using data analysis, modeling, automation, and optimization techniques. Operates with considerable latitude for independent judgment. Provides influence and expertise to cross-functional teams and other stakeholders on ideas and solutions that impact corporate results.

Primary Responsibilities and Essential Functions
 Supports and/or leads discussions with multidisciplinary teams to collect functional business requirements, scoping analytical projects, manage expectations and deadlines, and translate needs into technical specifications. Supports technical development of solutions to expedite delivery of new datasets, process automation, production of complex models and analyses, including gap assessments, and works to deliver strategies. Serves as an organizational consultant on matters relating to data and databases by providing expertise to assist users in meeting their needs. Initiates the identification of actionable insights and contribute to the development of business recommendations through effective presentations and communication of results. Develops processes and solutions to speed up / expedite the development of datasets, report automation, production of dashboards, complex models, and analyses. Extract and manipulate data from a variety of cloud and on-premise based systems for reporting and analytical purposes, including: Oracle databases, Essbase and data cubes, Tableau, SQL Server, and various data sources as needed. Report automation and self-service dashboard solutions using combination of tools such as SQL, Tableau, Prep, Alteryx, Informatica and Python. Develops automated processes that preserve data integrity by managing the alignment of data availability and integration processes. Expertise in creating and optimizing Tableau Datasets and Visualizations. Identifies, researches, and resolves discrepancies in an analytical procedure or cross-functional methods. Establish and maintain design and development best practices including keeping written procedures to document data processes and ensure best data governance practices are maintained. Liaises with CCI Technology/EDS partners for both data-sourcing needs and for “promotion” of data-sets into the enterprise BI layer when/as-needed. Leads data collection, cleansing, and validation. Conducts day-to-day activities with minimum supervision.

Qualifications:
Skills and Qualifications

Minimum
 5 or more years of experience required in related field (developing and implementing analytical solutions in Finance, Marketing, Sales or Operations). 3 or more years of experience required if candidate possesses a related advanced degree. Requires strong skills in SQL writing and query optimization. Requires experience building data workflows, manipulation of large data sets, or developing data pipelines in analytical tools such as Informatica, Alteryx, Tableau Prep, SQL, SSIS, etc. Requires strong skills and experience with reporting and data visualization in analytical tools such as Tableau, Prep, SQL, etc. Requires effective proficiency in teamwork, communication, presentation, and time management to work effectively with teams throughout organization, including strong verbal and written communication. Experience manipulating large datasets and the ability to extrapolate conclusions from the data. Demonstrated problem solving and analytical thinking skills. Excellent interpersonal, leadership, presentation, and collaborative skills to work effectively with teams throughout organization. BS/BA degree in related discipline

Preferred
 Master's degree in a related discipline preferred Working knowledge of Tableau and/or visual analytics software tools and best practices Working knowledge of Alteryx and/or data transformation tools and best practices 3 or more years using Tableau for analysis, visualization & dashboard development 3 or more years of experience in database administration and SQL, including SQL tuning/performance optimization 2 or more years of experience in Data Warehousing, ETL Development, Data Management tools such as SSIS, Informatica, Datastage, etc 1 or more years of experience using Oracle Essbase or integration with data cubes 2 or more years of experience using Alteryx for data preparation & modeling 1 or more years of experience in OBIEE report and RPD development 1 or more years of experience in Java, Python or other programming or scripting languages Knowledge of Big Data querying tools, such as Pig, Hive, and Impala Experience within telecom, consumer package goods, retail, financial services, or consulting industries Operational analytics including application for Call Center, Technical Support, Collections, and Customer Experience Analytics
#LI-355

About Cox Communications
Cox Communications is committed to creating meaningful moments of human connection through broadband applications and services. The largest private telecom company in America, we proudly serve six million homes and businesses across 18 states. We're dedicated to empowering others to build a better future and celebrate diverse products, people, suppliers, communities and the characteristics that makes each one unique. Cox Communications is the largest division of Cox Enterprises, a family-owned business founded in 1898 by Governor James M. Cox.
Cox is an Equal Employment Opportunity employer - All qualified applicants/employees will receive consideration for employment without regard to that individual's age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law.
Statement to ALL Third-Party Agencies and Similar Organizations: Cox accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Cox employees, Cox hiring manager, or send to any Cox facility. Cox is not responsible for any fees or charges associated with unsolicited resumes."
33,Lead Big Data Engineer,"Atlanta, GA 30319",Atlanta,GA,30319,None Found,None Found,None Found,None Found,None Found,None Found,"In some organizations Data Analytics, Data Science, Business Intelligence, and Big Data sit with different teams. We are looking for a Lead Big Data Engineer to work globally across all these areas to help support our core business function: creating the best beverage brands in the world. We care less about your knowledge of a particular technology and care more about your passion and aptitude for utilizing the right tool for the right job, even if that tool hasn't been created yet.
This individual will work as a Lead Engineer coaching, mentoring, doing code review, and sharing best practices with both a team of internal and external engineering resources. He/She will also work as an individual contributor to engineer leading edge analytics solutions and platforms for big data, data science, and business intelligence reporting needs. This role will be responsible for ensuring code is well designed, efficient, and uses best software development practices to build and enhance our big data systems for scale.
Travel: 0-25%
Required:
5+ years of experience working with data (analytics, science, big data, business intelligence, etc.)
Ability to interact and influence senior Leaders
Experience designing, developing and implementing traditional and emerging BI and big data information systems from end-to-end
Background in data modeling and/or data mining
Experience leveraging cloud platforms (AWS or Azure)
Extensive knowledge of database management systems, online analytical processing (OLAP) and ETL (extract, transform, load) frameworks
Experience with NoSQL databases (Azure Cosmos DB, Document DB, Mongo DB, etc.)
Experience with one or more of these: PySpark, Python, Scala, Spark, Hadoop
Experience with one or more of the following Agile development methods: Extreme Programming (XP), Scrum, Crystal, Dynamic Systems Development Method (DSDM), Lean Development, and/or Feature-Driven Development (FDD)
Dev/Ops experience and/or training in Dev/Ops methods and tools such as Jira, GitHub, Docker, Kubernetes, Bamboo, BitBucket
Proven abilities to take initiative and be innovative
Passionate, creative and forward thinking individual
Preferred:
Bachelor’s degree or higher in Computer Science or related field
Azure Data Factory or Informatica
Azure SQL DB
Key responsibilities:
Collaborate with different Corporate Technical (Supply Chain) Process owners to determine and meet their reporting and analytics needs
Design and build MVP traditional BI solutions and big data solutions leveraging the data lake based on business requirements or user stories, architectural requirements, and established coding standards
Collaborate closely and cohesively with Technical Data Intelligence counterparts to maintain the intelligence framework, tools, datasets and standards
Manage the process for connecting key technical data sources, explore and implement artificial intelligence technologies and drive data automation to unlock value and productivity for the Global Technical function
Design and build MVP traditional BI solutions and big data solutions leveraging the data lake based on business requirements or user stories, architectural requirements, and established coding standards
Connect key technical data sources, explore and implement artificial intelligence technologies and drive data automation to unlock value and productivity for the Global Technical function
Maintain and support data analytics platforms (e.g. MS Azure BI / Analytics Platforms & Tools) under Dev/Ops model

Our Growth Culture:
One of the reasons our company continues to thrive after 130+ years is having a company culture that supports and rewards behaviors that lead to growth. Our “Growth Behaviors,” as we call them, are ways of being and working that help to make us successful. Think about how you can bring this to life in your next role at Coca-Cola.

Curious
Keep seeking, never settle. Staying curious about what is outside, and two steps ahead inspires us to challenge the status quo. Having the courage to look and leap is the way we grow. Because asking “what if?” pushes us to the next level as people and as a company.

Empowered
Make it happen. True empowerment is the result of taking responsibility. This means giving yourself permission to see it, say it and do it, and owning the outcomes. Because we move forward faster when we all take action.

Version 1.0, 2.0, 3.0
Push for progress, not perfection. There are very few overnight successes. Greatness is borne of many little victories (and failures). Share v 1.0, test it, and make it better. Then create the next version. Because the moment we think something is perfect, it will be obsolete.

Inclusive
Include, value and trust each other. We are smart alone but together we are genius. This means being inclusive, giving the benefit of the doubt and being responsible for each other. Because, for our company to thrive for the next 100+ years, smart isn’t enough. We need genius.

We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity and/or expression, status as a veteran, and basis of disability or any other federal, state or local protected class."
34,Data Engineer,"Duluth, GA 30097",Duluth,GA,30097,None Found,None Found,"
Technology certifications such as Amazon Certified Solutions Architect
Proficiency in programming in Spark, R and/or ML packages
Exposure to applications developed to support manufacturing quality
Experience with MS Dynamics CRM, MicroStrategy BI tools, SAP ERP
Consulting experience","
Drive design and development of internal data pipeline architecture to service BI and Analytics capabilities
Work with key stakeholders including Product, Sales, Quality Engineering and Marketing to assist with data-related technical needs and support their data infrastructure needs.
Ensure operational resilience, stability, and scalability of our enterprise data platform by conduct continuous hardening activates that increase uptime, data quality and reduce cost
Ensure tight data platform security during data transport and while at rest
Build hybrid cloud/prem data platform to enable self-service Business Intelligence and Analytics functions
Conduct data profiling and analysis of complex data sets to discover how to meet functional / non-functional requirements
Institute data quality monitoring and alerting platform operations
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics
Drive solutions for meta data and data lineage management
Drive innovation by recommending and driving adoption of new technologies that provide competitive data advantages for enterprise
Contributes to agile team alignment and is committed to constant improvement efforts by participating in team ceremonies sprint planning, stand-ups, backlog grooming and retrospectives
Ensure technical delivery of detailed feature/story level solutions that satisfies the IT roadmap’s acceptance criteria
Maintains professional and technical knowledge by attending educational workshops; reviewing professional publications; establishing personal networks; participating in professional societies",None Found,None Found,"The Data Engineer will be responsible for expanding and optimizing our data capabilities for Data Warehousing, Master Data, Data Services as well as Business Intelligence. The ideal candidate is an experienced data wrangler who enjoys optimizing data systems and can build them from the ground up. He/she must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. The ideal candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.
Responsibilities
Drive design and development of internal data pipeline architecture to service BI and Analytics capabilities
Work with key stakeholders including Product, Sales, Quality Engineering and Marketing to assist with data-related technical needs and support their data infrastructure needs.
Ensure operational resilience, stability, and scalability of our enterprise data platform by conduct continuous hardening activates that increase uptime, data quality and reduce cost
Ensure tight data platform security during data transport and while at rest
Build hybrid cloud/prem data platform to enable self-service Business Intelligence and Analytics functions
Conduct data profiling and analysis of complex data sets to discover how to meet functional / non-functional requirements
Institute data quality monitoring and alerting platform operations
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics
Drive solutions for meta data and data lineage management
Drive innovation by recommending and driving adoption of new technologies that provide competitive data advantages for enterprise
Contributes to agile team alignment and is committed to constant improvement efforts by participating in team ceremonies sprint planning, stand-ups, backlog grooming and retrospectives
Ensure technical delivery of detailed feature/story level solutions that satisfies the IT roadmap’s acceptance criteria
Maintains professional and technical knowledge by attending educational workshops; reviewing professional publications; establishing personal networks; participating in professional societies
Minimum Work Experience
8+ years of proven experience in the design, development and deployment of end-to-end data pipeline solutions including data processing (Batch, Micro-Batch, Streaming), data preparation (ETL, ELT), data modeling (STAR, OLAP, MPP)
5+ year of Business Intelligence Development and Administration
Experience of building data solutions for back office applications that source data from CRM and ERP applications
Advanced experience working with SQL Server databases
Strong grasp of master data management, data quality monitoring and metadata management
Proficiency in data centric shell scripting, ETL, Python, and/or .NET Programming skills
A comfortable and confident communicator with technical staff but also able to speak with customers concisely to translate technical concepts into business terminology and impacts
Exposure to continuous integration implementations that utilize DevOps style tools (such as Jenkins, Chef, Docker, Terraform, etc.)
Proven team player with the ability to multi-task in a fast-paced dynamic agile work environment
Has previously supported a metrics-driven data culture to drive accountability and transparency
Passionate problem solver and motivated self-starter including ability to analyze situation and recommend sound solutions and implementation strategies
Additional Desired Skills:
Technology certifications such as Amazon Certified Solutions Architect
Proficiency in programming in Spark, R and/or ML packages
Exposure to applications developed to support manufacturing quality
Experience with MS Dynamics CRM, MicroStrategy BI tools, SAP ERP
Consulting experience
Education: Bachelor’s degree in Computer Science, Information Systems, or combination of education and experience.
Location: Duluth, Georgia
Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities
The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information."
35,"Lead Data Engineer, Assessment Analytics & Visualization","Atlanta, GA 30309",Atlanta,GA,30309,None Found,None Found,"Previous management experience and successfully leading a team of direct reports
Proven track record of effectively leading and managing employees, managing performance, setting goals for team/individuals and provide mentoring.
Strong Tableau, Adobe Analytics other BI solution
Expert Oracle and Vertica skillsets
Experience using JIRA and Agile Project Management software
Experience using GitHub, Bit Bucket, or other code repository solution
Strong written, verbal communication and presentation skills
Ability to explain complex technical issues in a way that non-technical people may understand
Able to work in a global, multicultural environment
Self-motivated. Capable of working with little or no supervision
Ability to react positively under pressure to meet tight deadlines
Able to work independently or as a team player
Enjoy challenging and thought provoking work and have a strong desire to learn and progress","Work with development teams and other project leaders/stakeholders to provide technical solutions that enable business capabilities
Supports the data science community by enabling data availability in environments that provide advanced analytical capabilities
Maintains a broad understanding of implementation, integration, and inter-connectivity issues with emerging technologies to define data strategies
Assist in the decision-making process related to the selection of software architecture solutions
Implement architectures to handle web-scale data and its organization
Execute strategies that inform data design and architecture partnering with enterprise standard
Build robust data pipelines on public Cloud using AWS Kinesis, Kafka, Lambda or other technologies
Assist in creating documents that ensure consistency in development across the online organization. Implements and improves core software infrastructure
Deep expertise in SQL language, Python, Hadoop ecosystem and/or Spark ecosystem. Strong experience with writing complex programs, implementing architectures, and enabling automation in these environments
Develop and maintain business reporting, ensuring reliability and performance, delivery of performance management tools (such as control charts and scorecards), readiness and adoption of data w/in the organization
Consolidate, standardize and control changes to capacity management data and metric definitions, ownership, accountability and taxonomy to ensure alignment in understanding
Serve as strong advocate to improve analytical capability across the organization
Communicate with various business areas and to gather and prioritize their business requirements
Support various reporting and BI solutions (Tableau, Power BI, Salesforce Einstein)
Manage application and data integration platforms (Informatica, Talend)
Manage the full life cycle of development/reporting/integration projects: planning, design, develop, testing and rollout
Manage solution providers, define sourcing approach and manage the providers
Create and manage data, applications and technology architecture documentation and design artifacts
Work across teams to deliver meaningful reference architectures that outline architecture principles and best practices for technology advancement
Gain adoption of architecture processes, standards and procedures","
BS in Computer Science, Applied Mathematics, Physics, Statistics or area of study related to data sciences and data mining or relevant experience",None Found,"Invesco is one of the world’s leading global investment managers, entrusted with managing $1.2 trillion* in assets on behalf of clients worldwide. We are the 6th largest US retail asset manager and the 13th largest investment manager globally, and our more than 8,000 employees worldwide are dedicated to delivering an investment experience that helps people get more out of life. We are purely focused on managing a comprehensive range of active, passive and alternative investment capabilities, which we draw on to provide customized solutions aligned to client needs, our most important benchmark. (*As of May 31,2019)

Job Purpose (Job Summary):

As a Team Lead at Invesco, you would align business outcomes to technology goals and objectives. You will be responsible for managing decision sciences and advanced analytics initiatives, data integration/engineering. Interacts with Data Scientists, Business Owners, Business Data Analysts, Data Modelers, Architects, and Application Developers, to design, build and manage large-scale batch and real-time data pipelines utilizing various data analytics processing frameworks in support of Data Science practice. The position requires building strong technical hands-on-skills and experiences as well as establishing close business relationships across the enterprise. Working closely with marketing and sales stakeholders, you will establish and drive long term advance analytics roadmap manage increasing demands for advance analytics in Sales and Marketing. You will help steer the strategic technology direction, define target state architecture, technology roadmaps and mentor others. A successful candidate must have a demonstrable background with experience in development of high performance, distributed computing tasks using Big Data technologies such as Hadoop (platform level), NoSQL, text mining and other distributed environment technologies based on the needs of the organization. Responsible for analyzing, designing, programing, debugging and modifying software enhancements and/or new products used in distributed, large scale analytics solutions. Strong visualization skills and experience with BI tools (ex. Tableau)

Key Responsibilities / Duties:
Work with development teams and other project leaders/stakeholders to provide technical solutions that enable business capabilities
Supports the data science community by enabling data availability in environments that provide advanced analytical capabilities
Maintains a broad understanding of implementation, integration, and inter-connectivity issues with emerging technologies to define data strategies
Assist in the decision-making process related to the selection of software architecture solutions
Implement architectures to handle web-scale data and its organization
Execute strategies that inform data design and architecture partnering with enterprise standard
Build robust data pipelines on public Cloud using AWS Kinesis, Kafka, Lambda or other technologies
Assist in creating documents that ensure consistency in development across the online organization. Implements and improves core software infrastructure
Deep expertise in SQL language, Python, Hadoop ecosystem and/or Spark ecosystem. Strong experience with writing complex programs, implementing architectures, and enabling automation in these environments
Develop and maintain business reporting, ensuring reliability and performance, delivery of performance management tools (such as control charts and scorecards), readiness and adoption of data w/in the organization
Consolidate, standardize and control changes to capacity management data and metric definitions, ownership, accountability and taxonomy to ensure alignment in understanding
Serve as strong advocate to improve analytical capability across the organization
Communicate with various business areas and to gather and prioritize their business requirements
Support various reporting and BI solutions (Tableau, Power BI, Salesforce Einstein)
Manage application and data integration platforms (Informatica, Talend)
Manage the full life cycle of development/reporting/integration projects: planning, design, develop, testing and rollout
Manage solution providers, define sourcing approach and manage the providers
Create and manage data, applications and technology architecture documentation and design artifacts
Work across teams to deliver meaningful reference architectures that outline architecture principles and best practices for technology advancement
Gain adoption of architecture processes, standards and procedures
Work Experience / Knowledge:
7+ years of experience in data modeling, data warehousing, and big data architectures
5+ years of experience in a data engineering role
Proficient in application/software architecture (Definition, Business Process Modeling, etc.)
Deep expertise in (at least one) SQL language, Python, Hadoop ecosystem and/or Spark ecosystem. Strong experience with writing complex programs, implementing architectures, and enabling automation in these environments
The role will be responsible for providing innovative operational solutions and best practices
Advanced knowledge in SQL/Hive, Spark, NoSQL, (Java/Python is a plus)
Strong programming skills and ability to utilize a variety of software/languages/tools; e.g., Spark, R, Python, Scala, Java, Hive, SQL, SAS, Tableau, etc.
Experience with microservice development, Docker, Kubernetes
Develop software to run on cloud native big data infrastructure built on AWS using Spark, Lambda, S3, and other cloud native services
Designs and develops complex and large-scale data structures and pipelines to organize, collect and standardize data to generate insight
3+ years of experience in data integration platforms (Informatica, Talend)
Strong analytics and reporting skills – hands on experience in BI Tools like Tableau, Power BI, Salesforce Einstein
Hands on experience in self-service data preparation tool like Alteryx
Experience using GitHub, Bit Bucket, or other code repository solution
DevOps experience is a plus
Skills / Other Personal Attributes Required:
Previous management experience and successfully leading a team of direct reports
Proven track record of effectively leading and managing employees, managing performance, setting goals for team/individuals and provide mentoring.
Strong Tableau, Adobe Analytics other BI solution
Expert Oracle and Vertica skillsets
Experience using JIRA and Agile Project Management software
Experience using GitHub, Bit Bucket, or other code repository solution
Strong written, verbal communication and presentation skills
Ability to explain complex technical issues in a way that non-technical people may understand
Able to work in a global, multicultural environment
Self-motivated. Capable of working with little or no supervision
Ability to react positively under pressure to meet tight deadlines
Able to work independently or as a team player
Enjoy challenging and thought provoking work and have a strong desire to learn and progress
Formal Education: (minimum requirement to perform job duties)
BS in Computer Science, Applied Mathematics, Physics, Statistics or area of study related to data sciences and data mining or relevant experience
FLSA (US Only): Exempt

The above information on this description has been designed to indicate the general nature and level of work performed by employees within this role. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications required of employees assigned to this job. The job holder may be required to perform other duties as deemed appropriate by their manager from time to time.

Invesco's culture of inclusivity and its commitment to diversity in the workplace are demonstrated through our people practices. We are proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, creed, color, religion, sex, gender, gender identity, sexual orientation, marital status, national origin, citizenship status, disability, age, or veteran status. Our equal opportunity employment efforts comply with all applicable U.S. state and federal laws governing non-discrimination in employment."
36,Data Engineer,"Atlanta, GA",Atlanta,GA,None Found,None Found,None Found,"
You are passionate about making a difference in the world and the impact technology can have in helping people get better faster
You drive results effectively through cross functional teams
You are flexible and adaptive and can adjust quickly in the face of changing situations and challenges
You are disciplined and able to manage multiple responsibilities simultaneously
You are a strong team player who is happy to share knowledge and mentor others to grow their skills
You work effectively with minimal supervision and can be relied on to deliver on commitments effectively
","
Create data ingestion pipelines and manage and maintain master data specification documents which reflect necessary data elements. Cleanse, analyze, and maintain incoming client data. Develop features relevant to healthcare use cases/vectors.
Generate data visualizations and presentations, including the design of interactive and intuitive dashboards.
Participate in process adherence and continuance through automation of workflow schedules and cyclic support to ensure stable production environment.
","
Bachelor's degree in Information Technology/Computer Engineering
3+ years of experience in development and deployment of Big Data technologies with a focus on Data Engineering (SQL, AWS/Azure Cloud platform tools, Data handling, Shell Scripting, Airflow, Python, etc.)
Expertise in cloud platforms (AWS, Azure)
Experience in data interchange standards like EDI and HL7 is a plus
Familiarity in Agile delivery framework
Awareness of Artificial Intelligence; data science concepts a plus
Experience working in healthcare setting preferred
",None Found,"Company Summary:
Headquartered in Atlanta, Ga, Jvion is the leader in Artificial Intelligence (AI)-enabled prescriptive analytics that helps healthcare organizations lower rates of preventable harm and reduce costs. Charting the future with our proprietary solution, Jvion is partnering with healthcare organizations to empower clinicians with AI that more effectively identifies at risk patients, the factors driving that risk, and the interventions that will lead to better outcomes. As the leader in healthcare AI, Jvion is making healthcare data meaningful, bringing leading edge technology to the front lines of care, tackling socioeconomic barriers to health and ultimately improving patients' lives.

Position Summary:
As a key member of Jvion's technology team, the Data Engineer is responsible for managing, optimizing, analyzing, overseeing, and monitoring data retrieval, storage, and distribution. This individual will prepare the ""big data"" infrastructure to be analyzed by the Jvion Machine. The Data Engineer participates as a member of technical professionals in the development, delivery and support of cutting-edge Artificial Intelligence, cloud-based prescriptive solutions to healthcare clients that deliver high levels of customer satisfaction.

Responsibilities and Essential Functions:

Create data ingestion pipelines and manage and maintain master data specification documents which reflect necessary data elements. Cleanse, analyze, and maintain incoming client data. Develop features relevant to healthcare use cases/vectors.
Generate data visualizations and presentations, including the design of interactive and intuitive dashboards.
Participate in process adherence and continuance through automation of workflow schedules and cyclic support to ensure stable production environment.

Experience/Education:

Bachelor's degree in Information Technology/Computer Engineering
3+ years of experience in development and deployment of Big Data technologies with a focus on Data Engineering (SQL, AWS/Azure Cloud platform tools, Data handling, Shell Scripting, Airflow, Python, etc.)
Expertise in cloud platforms (AWS, Azure)
Experience in data interchange standards like EDI and HL7 is a plus
Familiarity in Agile delivery framework
Awareness of Artificial Intelligence; data science concepts a plus
Experience working in healthcare setting preferred

Work Skills / Personal Characteristics:

You are passionate about making a difference in the world and the impact technology can have in helping people get better faster
You drive results effectively through cross functional teams
You are flexible and adaptive and can adjust quickly in the face of changing situations and challenges
You are disciplined and able to manage multiple responsibilities simultaneously
You are a strong team player who is happy to share knowledge and mentor others to grow their skills
You work effectively with minimal supervision and can be relied on to deliver on commitments effectively

Jvion is proud to be an Equal Employment Opportunity employer. We do not discriminate based upon race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics."
37,Senior Data Engineer,"Atlanta, GA",Atlanta,GA,None Found,None Found,None Found,"
You are passionate about making a difference in the world and the impact technology can have in helping people get better faster
You drive results effectively through cross functional teams
You are flexible and adaptive and can adjust quickly in the face of changing situations and challenges
You are disciplined and able to manage multiple responsibilities simultaneously
You are a strong team player who is happy to share knowledge and mentor others to grow their skills
You work effectively with minimal supervision and can be relied on to deliver on commitments effectively
","
Design and create data ingestion pipelines and manage and maintain master data specification documents which reflect necessary data elements. Cleanse, analyze, and maintain incoming client data. Design and develop features relevant to healthcare use cases/vectors.
Lead in generating data visualizations and presentations, including the design of interactive and intuitive dashboards.
Lead process adherence and continuance through automation of workflow schedules and cyclic support to ensure stable production environment.
","
Bachelor's degree in Information Technology/Computer Engineering
5+ years of experience in development and deployment of Big Data technologies with a focus on Data Engineering (SQL, AWS/Azure Cloud platform tools, Data handling, Shell Scripting, Airflow, Python, etc.)
Expertise in cloud platforms (AWS, Azure)
Experience in data interchange standards like EDI and HL7 is a plus
Familiarity in Agile delivery framework
Awareness of Artificial Intelligence; data science concepts a plus
Experience working in healthcare setting preferred
",None Found,"Company Summary:
Headquartered in Atlanta, GA, Jvion is the leader in Artificial Intelligence (AI)-enabled prescriptive analytics that helps healthcare organizations lower rates of preventable harm and reduce costs. Charting the future with our proprietary solution, Jvion is partnering with healthcare organizations to empower clinicians with AI that more effectively identifies at risk patients, the factors driving that risk, and the interventions that will lead to better outcomes. As the leader in healthcare AI, Jvion is making healthcare data meaningful, bringing leading edge technology to the front lines of care, tackling socioeconomic barriers to health and ultimately improving patients' lives.

Position Summary:
As a key member of Jvion's technology team, the Senior Data Engineer is responsible for managing, optimizing, analyzing, overseeing, and monitoring data retrieval, storage, and distribution. This individual will prepare the ""big data"" infrastructure to be analyzed by the Jvion Machine. The Senior Data Engineer participates as a member of technical professionals in the development, delivery and support of cutting-edge Artificial Intelligence, cloud-based prescriptive solutions to healthcare clients that deliver high levels of customer satisfaction.

Responsibilities and Essential Functions:

Design and create data ingestion pipelines and manage and maintain master data specification documents which reflect necessary data elements. Cleanse, analyze, and maintain incoming client data. Design and develop features relevant to healthcare use cases/vectors.
Lead in generating data visualizations and presentations, including the design of interactive and intuitive dashboards.
Lead process adherence and continuance through automation of workflow schedules and cyclic support to ensure stable production environment.

Experience/Education:

Bachelor's degree in Information Technology/Computer Engineering
5+ years of experience in development and deployment of Big Data technologies with a focus on Data Engineering (SQL, AWS/Azure Cloud platform tools, Data handling, Shell Scripting, Airflow, Python, etc.)
Expertise in cloud platforms (AWS, Azure)
Experience in data interchange standards like EDI and HL7 is a plus
Familiarity in Agile delivery framework
Awareness of Artificial Intelligence; data science concepts a plus
Experience working in healthcare setting preferred

Work Skills / Personal Characteristics:

You are passionate about making a difference in the world and the impact technology can have in helping people get better faster
You drive results effectively through cross functional teams
You are flexible and adaptive and can adjust quickly in the face of changing situations and challenges
You are disciplined and able to manage multiple responsibilities simultaneously
You are a strong team player who is happy to share knowledge and mentor others to grow their skills
You work effectively with minimal supervision and can be relied on to deliver on commitments effectively

Jvion is proud to be an Equal Employment Opportunity employer. We do not discriminate based upon race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics."
38,Senior Data Engineer,"Alpharetta, GA 30009",Alpharetta,GA,30009,None Found,None Found,None Found,None Found,None Found,None Found,"Your responsibilities
thyssenkrupp Elevator Corporation is seeking a Sr. Data Engineer to be responsible for data engineering activities related to business’ information systems, data integration and data warehousing solutions. The candidate must demonstrate strong computer skills and a deep passion for analytics, possess an ability to perform complex data analyses and development with large data volumes, and have expert level knowledge in SQL, data warehousing and ETL. The role of the Senior Data Engineer is responsible for building and maintaining optimized and highly available data solutions that facilitate deeper analysis for reporting and analytics to tkE’s corporate and field organizations in North America. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. • Develop new applications and features within an agile delivery team providing data and data services to the enterprise, other engineering teams, analysts, product, management/executives, and other business teams• Build high performing and scalable data systems to support multiple internal and 3rd party data pipelines • Build and maintain reliable and scalable ETL on data platforms that support critical business functions and analytics’ functions of the organization• Implement new technologies and practices where appropriate to provide the best in class solutions • Responsible for architecture/design and risk analysis/mitigation on a micro level • Develop and maintain solutions on chosen technology landscape (Microsoft Azure, SQL Server, SSIS, Azure Data Factory) • Work with business teams to create technical requirements and deliver within time and scope • Work with IT Operations and Prod Support to ensure solutions are releasable, maintainable, and scalable • Work with Risk & Compliance to ensure necessary logging/security is in place to comply with audits• Ability to design data architecture by studying the solution concept, strategy, and target audience by envisioning architectural scheme, data structure and features, functionality, and user-interface design.• Execute on new development activities and ensures they are consistent and well-integrated with the established ecosystem data architecture• Creates ecosystem models (e.g. conceptual, logical, canonical) that are required for supporting services within the enterprise data• Driven self-starter, with ability to perform research and issue analysis duties with little supervision
Your profile
Required Qualifications:• Bachelor’s degree (B.A. / B.S.) in Information Technology or Computer Science or related field or the equivalent combination of education and experience• 5+ years of data engineering, ETL, and data warehousing experiences in Microsoft Azure, MS SQL Server and SSIS, Azure Data Factory (Must have in-depth knowledge of SQL Server and SSIS). • Extensive experience working in a Agile Environment• Extensive experience working in a Data & Analytics Environment• Proficient knowledge of optimization, concurrency, scale-up vs scale-out • Must have demonstrated experience in building and maintaining reliable and scalable ETL on data platforms• Experience working with varied forms of data infrastructure inclusive of databases such as Azure SQL Database, Azure SQL Datawarehouse, SAP HANA, SAP BW, Azure Data Factory, Hadoop, Spark and column-oriented databases such as Redshift, MySQL, or Oracle• System integration experience, including interface design, and familiarity with web-oriented architecture techniques• Data modeling and information classification expertise at an enterprise level Nice to Have Qualifications: • Familiarity with data science concepts leveraging tools such as Databricks or Cloudera• Experience with Master Data Management, Metadata Management, Data Integration, Data Migration, Data Governance design and implementation techniques leveraging data management tools such as SAP MDG, Informatica or Talend is a plus• Streaming experience and knowledge of bottleneck/queue theory is a plus• Ability to calibrate Machine Learning (ML) models and experience with Artificial Intelligence (AI) preferred• Knowledge of predictive and analytic dashboards and reporting strongly preferred• Experience with designing and implementing self-service models preferred• Hands-on experience with implementing data and analytics management programs is preferred
Our offer to you
Safety at work and Healthcare
Safety at work & Healthcare: Highest standards in occupational safety and health, comprehensive programs and measures for safety at work and preventive healthcare with comprehensive coverage and flexible options.
Security for the future
Financial security for your individual retirement plan.
Collaboration
Respect, recognition and appreciation of the contribution of everyone. Regular team - and social events.
Continuing development
Training and continuing developement options. Help to grow alongside with us, in personality and profession.
Compensation and benefits
We offer a lot: Fair working conditions and a reasonable, competitive compensation are the foundation for many more attractive benefits.
Diversity
Open, tolerant and constructive work environment with a team consistent of diverse views and backgrounds.
We work together closely and respect each other, for over 200 years. If that is just as important to you as it is to us, apply now!

To learn more about thyssenkrupp in North America, please visit our website:
https://www.thyssenkrupp-north-america.com
thyssenkrupp Elevator Corp. is an equal opportunity employer. Applicants will receive consideration for employment without regard to age, sex, race, color, religion, national origin, genetics, disability, gender identity, marital status, sexual orientation, veteran status or any other protected characteristic required by applicable law.

Applicants with disabilities who require reasonable accommodation in connection with the application process are encouraged to contact us directly at 1-844-427-5461."
39,Metavance Developer,"Atlanta, GA 30319",Atlanta,GA,30319,None Found,None Found,"8 or more years experience writing code using languages such as (and not limited to) COBOL, PL/1, Java, C, C++, C#, VB.Net.
Advanced ability to work with Web-development tools for new applications.
Advanced understanding of RDBMS databases such SQL Server and Oracle.
Advanced understanding of modern software design and development methodologies.
Experience on multiple full release project life cycles.
Advanced understanding of modern SCM (software configuration management).
Advanced understanding of testing tools and unit test and integration test scripting, and testing methodologies
Advanced experience using an Integrated Development Environment (e.g., Eclipse, Visual Studio) and development of tool add-ins.
Strong understanding of basic Database Administration. Able to define quality and security standards.
Good verbal and written communication and negotiation skills.
General project management/team leader skills.
Ability to work effectively in a globally dispersed team and with clients and vendors.
Demonstrated technical leadership skills.","Participates as a member of and leads development teams.
Designs units for others.
Completes development to implement complex components.
Designs solutions for others to develop.
Participates in cross-functional teams.
Leads design activities May provide mentoring and guidance to developers.
Designs, prepares and executes unit tests.
Represents team to clients.
Demonstrates technical leadership, and exerts influence outside of immediate team.
Develops innovative team solutions to complex problems.
Contributes to strategic direction for teams.
Applies in-depth or broad technical knowledge to provide maintenance solutions across one or more technology areas (e.g. Web-site Development).
Applies company and 3rd party technologies to complex software solutions of moderate complexity. Independently implements end- user or enterprise solutions of significant complexity.
Integrates technical expertise and business understanding to create superior solutions for clients.
Consults with team members and other organizations, clients and vendors on complex issues.",Typically a technical Bachelor's degree or equivalent experience and a minimum of 8 years of related experience or a Master's degree and a minimum of 8 years of experience.,None Found,"Job Description:
Applies specialized knowledge to conceptualize, design, develop, unit-test, configure, and implement portions of new or enhanced (upgrades or conversions) business and technical software solutions through application of appropriate standard software development life cycle methodologies and processes. Interacts with the Client and project roles (e.g., Project Manager, Business Analyst, Data Engineer) as required, to gain an understanding of the business environment, technical context, and organizational strategic direction. Defines scope, plans, and deliverables for assigned components. Understands and uses appropriate tools to analyze, identify, and resolve business and or technical problems. Applies metrics to monitor performance and measure key project parameters. Prepares system documentation. Conforms to security and quality standards. Stays current on emerging tools, techniques, and technologies.
Responsibilities:
Participates as a member of and leads development teams.
Designs units for others.
Completes development to implement complex components.
Designs solutions for others to develop.
Participates in cross-functional teams.
Leads design activities May provide mentoring and guidance to developers.
Designs, prepares and executes unit tests.
Represents team to clients.
Demonstrates technical leadership, and exerts influence outside of immediate team.
Develops innovative team solutions to complex problems.
Contributes to strategic direction for teams.
Applies in-depth or broad technical knowledge to provide maintenance solutions across one or more technology areas (e.g. Web-site Development).
Applies company and 3rd party technologies to complex software solutions of moderate complexity. Independently implements end- user or enterprise solutions of significant complexity.
Integrates technical expertise and business understanding to create superior solutions for clients.
Consults with team members and other organizations, clients and vendors on complex issues.
Education and Experience Required:
Typically a technical Bachelor's degree or equivalent experience and a minimum of 8 years of related experience or a Master's degree and a minimum of 8 years of experience.
Knowledge and Skills:
8 or more years experience writing code using languages such as (and not limited to) COBOL, PL/1, Java, C, C++, C#, VB.Net.
Advanced ability to work with Web-development tools for new applications.
Advanced understanding of RDBMS databases such SQL Server and Oracle.
Advanced understanding of modern software design and development methodologies.
Experience on multiple full release project life cycles.
Advanced understanding of modern SCM (software configuration management).
Advanced understanding of testing tools and unit test and integration test scripting, and testing methodologies
Advanced experience using an Integrated Development Environment (e.g., Eclipse, Visual Studio) and development of tool add-ins.
Strong understanding of basic Database Administration. Able to define quality and security standards.
Good verbal and written communication and negotiation skills.
General project management/team leader skills.
Ability to work effectively in a globally dispersed team and with clients and vendors.
Demonstrated technical leadership skills."
40,Lead Data Engineer - Buckhead - 8491,"Atlanta, GA",Atlanta,GA,None Found,None Found,"
Degree in Computer Science, Engineering, Mathematics, Statistics or related quantitative field
5+ years’ experience in RDBMS systems, data warehousing, advanced SQL Server Analytical development, and sophisticated data analysis
Expertise with Azure Cloud Technologies (Data Factory, PowerShell, Data Lake and Data Lake Analytics)
Extensive experience with Data Modeling and ETL tools, Business Intelligence platforms, API Integration, and Object-Oriented Programming (OOP)
Ability to thrive in a cross-functional environment utilizing modern technologies (Python, Git, Jenkins, Octopus Deploy, Tensorflow, Domo, ArcGIS, E/R Studio, RedGate DLM Automation and other tools)
Experience with messaging/event processing tooling and frameworks such as Azure Event Hub, Kafka, Kinesis
Working knowledge of Azure HDInsight + Spark, Azure Databricks, Azure Stream Analytics",None Found,None Found,None Found,None Found,"At Cortland, you map the story of your success. We don't adhere to the status quo, we love outside industry perspective, and we thrive on exploring possibilities and reimagining solutions. As an innovative leader in multifamily, our high performance continues to drive exponential growth – and we invite you to join us on our journey towards real estate excellence. With tools and guidance to sharpen your skills, you can forge your own career path, love what you do, and let it show.
Key Responsibilites
Collaborate to architect and implement end-to-end cloud infrastructure (analytics, compute, databases, DevOps, identity, integration, management, networking, security, and storage)
Leverage technologies such as the Azure BI Stack, BI and GIS visualization platforms, and modern developer tools to execute innovative solutions that facilitate data-driven analysis, automation, and data science
Apply dimensional data modeling to solve business problems
Analyze, develop, and maintain data pipelines from internal and external sources, utilizing Python and Azure Data Factory
Profile and analyze data in designing scalable solutions
Apply and build automated test-driven development, continuous integration/delivery, and version control best practices
Preferred Qualifications
Degree in Computer Science, Engineering, Mathematics, Statistics or related quantitative field
5+ years’ experience in RDBMS systems, data warehousing, advanced SQL Server Analytical development, and sophisticated data analysis
Expertise with Azure Cloud Technologies (Data Factory, PowerShell, Data Lake and Data Lake Analytics)
Extensive experience with Data Modeling and ETL tools, Business Intelligence platforms, API Integration, and Object-Oriented Programming (OOP)
Ability to thrive in a cross-functional environment utilizing modern technologies (Python, Git, Jenkins, Octopus Deploy, Tensorflow, Domo, ArcGIS, E/R Studio, RedGate DLM Automation and other tools)
Experience with messaging/event processing tooling and frameworks such as Azure Event Hub, Kafka, Kinesis
Working knowledge of Azure HDInsight + Spark, Azure Databricks, Azure Stream Analytics
At Cortland, we create, reimagine, and manage apartment communities for residents nationwide. Headquartered in Atlanta, GA, we have communities and regional offices all over the country, as well as overseas. From product design and procurement to general contracting and property management, we do it all – to make sure our communities are the perfect setting for living life to its fullest.

Our success is fueled by our belief in a better life – where hospitality is always a given, each detail is worth a second thought, and every open door is a new opportunity to go beyond expectations. We come to work every day to create possibilities for people – possibilities that translate into superior living spaces and experiences designed to inspire our residents, associates, and investors to live a better life focused on what matters most to them.

Cortland is an equal opportunity employer, and we’re proud to support and celebrate diversity in the workplace. We are committed to equal consideration for all qualified applicants regardless of race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, disability, protected veteran status, genetic information, or any other characteristic protected by applicable law. If you have a disability and need an accommodation or assistance with the application process and/or using our website, please email talentresources@cortland.com or call 404.965.3988.

Cortland is a drug-free workplace.

Cortland participates in e-verify to verify the employment status of all persons hired to work in the United States."
41,Senior Data Engineer,"Atlanta, GA",Atlanta,GA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Job Description

Data Engineers work in our Data & Analytics practice area at CapTech. Our DE consultants deliver Data, Pipeline, and Integration and solutions and services to our clients across many industries in support of crucial and diverse data strategies. Our consultants work to bridge the ever-evolving gap between value and technology for our clients. Through our core values of intellectual curiosity, enthusiasm, flexibility, servant leadership, and serving as trusted advisors, CapTech seeks to maintain the premier workplace and destination for technology consultants.
Specific responsibilities for the Data Engineer position include:
Develop data solutions using data storage, integration, and pipeline platforms such as HDFS, Spark, Hive, Impala, Cassandra, Informatica, Ab Initio, SQL Server, Oracle, Python, and Kafka
Design/develop data models and consolidate data into them of various types/formats from various sources
Optimize data solutions for the right mix of performance, reliability, and maintainability
Collaborate with Quality Assurance resources and systems administrators to debug code and ensure the timely delivery of products
Prepare documentation conveying design and support information
Convey complex technical information in a clear, concise manner to all levels of stakeholders, including executives, business users, IT, application developers, and customers
Participate in requirements gathering sessions with business and technical staff
Fully understand clients’ business philosophies and IT Strategies. Recommend process improvements to increase efficiency and reliability of data solutions

Qualifications

Specific qualifications for the Data Engineer, Analytics position include:
Bachelor's Degree in Computer Science, MIS, or equivalent combination of education and experience preferred.
Strong SQL and Python skills
Experience optimizing data solutions for strong performance
Development experience with Hadoop and related platforms
Development experience with database platforms (Redshift, Snowflake, MS or Azure SQL, Teradata, Oracle, etc.)
Development experience building ETL graphs using the Ab Initio GDE, EME and Co-Operating system
Preferred - development experience with programming languages
Preferred - development experience with Unix tools and shell scripts preferred
Minimum of 5 years’ experience designing, developing, and testing software aligned with defined requirements
Experience with version control (Git, TFS, JIRA, etc.) and test driven development
Exposure to Business Intelligence tools such as Tableau, Power BI, Qlik, Domo, Birst, Business Objects, SSRS, Cognos, MicroStrategy, etc.
Additional Information

We offer challenging and impactful jobs with professional career paths. All CapTechers can keep their hands-on technology no matter what position they hold. Our employees find their work exciting and rewarding in a culture filled with opportunities to have fun along the way.
At CapTech we offer a competitive and comprehensive benefits package including, but not limited to:
Competitive salary with performance-based bonus opportunities
Single and Family Health Insurance plans, including Dental coverage
Short-Term and Long-Term disability
Matching 401(k)
Competitive Paid Time Off
Training and Certification opportunities eligible for expense reimbursement
Team building and social activities
Mentor program to help you develop your career
CapTech is an equal opportunity employer committed to fostering a culture of equality, inclusion and fairness — each foundational to our core values. We strive to create a diverse environment where each employee is encouraged to bring their unique ideas, backgrounds and experiences to the workplace.
Candidates must be eligible to work in the U.S. for any employer directly (we are not open to contract or “corp to corp” agreements). At this time, CapTech cannot transfer nor sponsor a work visa for this position. Applicants must be authorized to work directly for any employer in the United States without visa sponsorship.
CapTech is a Drug-Free work place.
Candidates must have the ability to work at CapTech’s client locations.
All positions include the possibility of travel.
CapTech has not contracted/does not contract with any outside vendors in its recruitment process. If you are interested in this position, please apply to CapTech directly."
42,Data Engineer w/ Snowflake,"Atlanta, GA",Atlanta,GA,None Found,None Found,"Qualifications: 3-7 years (2 years min relevant experience in the role) experience; Bachelor’s degreeShould be proficient in Software Engineering Techniques, Software Engineering Architecture, Software Engineering Lifecycle and Data Management.Should have progressing skills on Business Analysis, Business Knowledge, Software Engineering Leadership, Architecture Knowledge and Technical Solution Design.",None Found,None Found,None Found,None Found,"The Snowflake Developer will be responsible for designing and implementing Snowflake data warehouse infrastructure and pipelines.
Strong experience and comfort with relational database concepts (Databases, Schemas, Tabular/Semi-structured Data, Primary/Foreign keys, etc).At least 2 years of experience in data warehouse build projects including data loading, processing and transformationExpert-level Python and SQL (Scala and Java are a plus). At least 2 years of experience is requiredExperience and comfort with ETL/ELT concepts and frameworks and data modelling.Knowledge and hands on experience with Snowflake, familiarity with Snowflake's features and use cases is a plus.Exposure to either AWS or Azure cloud environments in a production settingHands on experience with Apache Airflow is a plus.


Candidates should be flexible / willing to work across this delivery landscape which includes and not limited to Agile Applications Development, Support and Deployment.
Applicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Capgemini.

Qualifications

Responsible for programming and software development using various programming languages and related tools and frameworks, reviewing code written by other programmers, requirement gathering, bug fixing, testing, documenting and implementing software systems. Experienced programmers are also responsible for interpreting architecture and design, code reviews, mentoring, guiding and monitoring programmers, ensuring adherence to programming and documentation policies, software development, testing and release.
Required Skills and Experience:
Write software programs using specific programming languages/platforms such as Java or MS .NET, and related tools, platform and environment. Write, update, and maintain computer programs or software packages to handle specific jobs, such as tracking inventory, storing or retrieving data, or controlling other equipment. Consult with managerial, engineering, and technical personnel to clarify program intent, identify problems, and suggest changes. Perform or direct revision, repair, or expansion of existing programs to increase operating efficiency or adapt to new requirements. Write, analyze, review, and rewrite programs, using workflow chart and diagram, and applying knowledge of computer capabilities, subject matter, and symbolic logic. Write or contribute to instructions or manuals to guide end users. Correct errors by making appropriate changes and then rechecking the program to ensure that the desired results are produced. Conduct trial runs of programs and software applications to be sure they will produce the desired information and that the instructions are correct. Compile and write documentation of program development and subsequent revisions, inserting comments in the coded instructions so others can understand the program. Investigate whether networks, workstations, the central processing unit of the system, and/or peripheral equipment are responding to a program's instructions. Prepare detailed workflow charts and diagrams that describe input, output, and logical operation, and convert them into a series of instructions coded in a computer language. Perform systems analysis and programming tasks to maintain and control the use of computer systems software as a systems programmer. Consult with and assist computer operators or system analysts to define and resolve problems in running computer programs. Perform unit testing Assist in system and user testing Fix errors and bugs that are identified in the course of testing.
Qualifications: 3-7 years (2 years min relevant experience in the role) experience; Bachelor’s degreeShould be proficient in Software Engineering Techniques, Software Engineering Architecture, Software Engineering Lifecycle and Data Management.Should have progressing skills on Business Analysis, Business Knowledge, Software Engineering Leadership, Architecture Knowledge and Technical Solution Design.

Capgemini is an Equal Opportunity Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.

This is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.
Click the following link for more information on your rights as an Applicant - http://www.capgemini.com/resources/equal-employment-opportunity-is-the-law

About Capgemini
A global leader in consulting, technology services and digital transformation, Capgemini is at the forefront of innovation to address the entire breadth of clients’ opportunities in the evolving world of cloud, digital and platforms. Building on its strong 50 year heritage and deep industry-specific expertise, Capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations. Capgemini is driven by the conviction that the business value of technology comes from and through people. It is a multicultural company of 200,000 team members in more than 40 countries. The Group reported 2018 global revenues of EUR 13.2 billion.

Visit us at www.capgemini.com. People matter, results count."
43,Data Engineer,"Atlanta, GA",Atlanta,GA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Requisition Number: 75000
Our Insight Digital Innovation team is searching for an experienced, passionate and professional Data Engineer to join our team.
What our Data Engineer’s Do:
Translate business requirements to technical solutions leveraging strong business acumen.
Analyzes current business practices, processes and procedures as well as identifying future business opportunities for leveraging Microsoft Azure Data & Analytics PaaS Services.
Support the planning and implementation of data design services, providing sizing and configuration assistance and performing needs assessments.
Delivery of architectures for transformations and modernizations of enterprise data solutions using Azure cloud data technologies.
Design and Build Modern Data Pipelines and Data Streams.
Design and Build Data Service APIs.
Develop and maintain data warehouse schematics, layouts, architectures and relational/non-relational databases for data access and Advanced Analytics.
Expose data to end users using PowerBI, Azure API Apps or any other modern visualization platform or experience.
Implement effective metrics and monitoring processes.
What We Look For at Insight:
Demonstrated experience of turning business use cases and requirements to technical solutions.
Experience in business processing mapping of data and analytics solutions.
Ability to conduct data profiling, cataloging, and mapping for technical design and construction of technical data flows.
The ability to apply such methods to solve business problems using one or more Azure Data and Analytics services in combination with building data pipelines, data streams, and system integration.
Knowledge of Azure Data Factory, Azure Data Lake, Azure SQL DW, and Azure SQL, Azure App Service is required.
Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics is a plus.
Experience preparing data for Data Science and Machine Learning.
Demonstrated experience preparing data and building data pipelines for AI Use Cases (text, voice, image, etc.…) is a plus.
Designing and building Data Pipelines using streams of IOT data is a plus.
What can Insight offer?
Client Facing Opportunities
Local Travel
Flex Hours
Remote Work
No Formal Dress Code
Leadership from great Mentors
Unlimited Vacation
Pay for Training
Startup Atmosphere
…and tons of other great Perks!
We have created a team-oriented environment with quality people, career advancement opportunities, great work/life balance and an excellent compensation and benefits package. Our people appreciate that they represent a brand that is invested in growing local relationships while working globally and doing what is right for our co-workers and clients. We are high on supporting each other and hiring/developing the best technical professionals in the industry.
Insight is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, sexual orientation or any other characteristic protected by law.
The position described above provides a summary of some the job duties required and what it would be like to work at Insight. For a comprehensive list of physical demands and work environment for this position, click here.
Today, every business is a technology business. Insight Enterprises, Inc. empowers organizations of all sizes with Insight Intelligent Technology Solutions™ and services to maximize the business value of IT. As a Fortune 500-ranked global provider of digital innovation, cloud/data center transformation, connected workforce, and supply chain optimization solutions and services, we help clients successfully manage their IT today while transforming for tomorrow. From IT strategy and design to implementation and management, our 6,800 employees help clients innovate and optimize their operations to run smarter. Discover more at insight.com.

Founded in 1988 in Tempe, Arizona
7,400+ teammates in 19 countries providing Intelligent Technology Solutions for organizations across the globe
$7.1 billion in revenue in 2018
Ranked #417 on the 2018 Fortune 500, #12 on the 2018 CRN Solution Provider 500
2018 Dell EMC Server Partner of the Year, 2018 Intel Retail Solution Partner of the Year, 2018 Microsoft Worldwide Artificial Intelligence Partner of the Year
Ranked #23 on the 2019 Fortune 50 Best Workplaces in Technology and #5 on the Phoenix Business Journal 2018 list of Best Places to Work (Extra Large Business)
Signatory of the United Nations (UN) Global Compact and Affiliate Member of the Responsible Business Alliance

Today's talent leads tomorrow's success. Learn about careers at Insight: jobs.insight.com.

Insight is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, sexual orientation or any other characteristic protected by law.

Posting Notes: Atlanta || Georgia (US-GA) || United States (US) || None || None || US - Atlanta, GA ||"
44,Data Engineer,"Atlanta, GA 30326",Atlanta,GA,30326,None Found,"
BS or MS degree in Computer Science or a related technical experience
3+ years of experience in custom or structured ETL design, implementation, maintenance and support
3+ years of experience with one or more programming language: Python, Scala, Java, R, etc.
3+ years of experience with SQL, data definition, and data manipulation
3+ years of experience designing, implementing and maintaining SSIS packages
3+ years of experience managing ETL with data warehouses (AWS Redshift, Google BigQuery, etc)
Strong experience working with both structured and unstructured data
Experience building and optimizing data pipelines and big data sets
Fluency running automated jobs to manipulate and store data from APIs via Google Compute Engine, Google App Engine, Google Cloud Storage, EC2, AWS Lambda, S3, etc.
Experience with Spark
Experience with container applications like Docker
Expertise creating and managing dashboards in data visualization platforms such as Tableau, Microsoft PowerBI, Google Data Studio, SSRS, etc.
Excellent written and oral communication skills including facilitation, project management, and working with others in team communicate data-driven insights",None Found,"
Proactively drive and facilitate conversations about data needs with stakeholders across the company
Build and maintain data pipelines and ETL process
Design, develop, maintain and enhance data collection procedures and analytic systems
Understand, unify and integrate data from internal and third-party data sources using industry best practices for scalability, quality, simplicity, and maintainability",None Found,"
BS or MS degree in Computer Science or a related technical experience
3+ years of experience in custom or structured ETL design, implementation, maintenance and support
3+ years of experience with one or more programming language: Python, Scala, Java, R, etc.
3+ years of experience with SQL, data definition, and data manipulation
3+ years of experience designing, implementing and maintaining SSIS packages
3+ years of experience managing ETL with data warehouses (AWS Redshift, Google BigQuery, etc)
Strong experience working with both structured and unstructured data
Experience building and optimizing data pipelines and big data sets
Fluency running automated jobs to manipulate and store data from APIs via Google Compute Engine, Google App Engine, Google Cloud Storage, EC2, AWS Lambda, S3, etc.
Experience with Spark
Experience with container applications like Docker
Expertise creating and managing dashboards in data visualization platforms such as Tableau, Microsoft PowerBI, Google Data Studio, SSRS, etc.
Excellent written and oral communication skills including facilitation, project management, and working with others in team communicate data-driven insights","Data Engineer

Job Description

CoStar Group is currently looking for a Data Engineer to join our Atlanta-based Apartments Network team. This exciting opportunity contributes to the growth of CoStar’s apartment rental brands including Apartments.com, ForRent.com, ApartmentFinder.com, ApartmentHomeLiving.com, Apartamentos.com, Cozy.co, WestsideRentals.com, AFTER55.com, ForRentUniversity.com, and CorporateHousing.com.
The ideal candidate is ambitious, a self-starter, loves challenges and thrives in a fast-paced, dynamic environment. This excellent problem solver takes pride in being best in class at leveraging their technical depth and breadth to design, build and support data solutions. This candidate is never satisfied with the status quo and is strong communicator who can actively engage in conversations about data needs and opportunities.
Responsibilities:
Proactively drive and facilitate conversations about data needs with stakeholders across the company
Build and maintain data pipelines and ETL process
Design, develop, maintain and enhance data collection procedures and analytic systems
Understand, unify and integrate data from internal and third-party data sources using industry best practices for scalability, quality, simplicity, and maintainability
Designing appropriate indexes for new tables, and analyze existing indexes for improvement
Conduct performance analysis and optimize systems to ensure products provide optimal performance
Ownership of end-to-end data and analytical solutions including internal and third-party systems and software components
Design, build and manage the deployment of various big data applications
Drive self-service analytics initiatives
Requirements and Qualifications:
BS or MS degree in Computer Science or a related technical experience
3+ years of experience in custom or structured ETL design, implementation, maintenance and support
3+ years of experience with one or more programming language: Python, Scala, Java, R, etc.
3+ years of experience with SQL, data definition, and data manipulation
3+ years of experience designing, implementing and maintaining SSIS packages
3+ years of experience managing ETL with data warehouses (AWS Redshift, Google BigQuery, etc)
Strong experience working with both structured and unstructured data
Experience building and optimizing data pipelines and big data sets
Fluency running automated jobs to manipulate and store data from APIs via Google Compute Engine, Google App Engine, Google Cloud Storage, EC2, AWS Lambda, S3, etc.
Experience with Spark
Experience with container applications like Docker
Expertise creating and managing dashboards in data visualization platforms such as Tableau, Microsoft PowerBI, Google Data Studio, SSRS, etc.
Excellent written and oral communication skills including facilitation, project management, and working with others in team communicate data-driven insights
Nice to Have
Experience with workflow management tools like Airflow
Understanding of supervised and unsupervised machine learning techniques and algorithms, such as k-NN, K-Means, Naive Bayes, SVM, Decision Forests, Neural Networks, etc.
Experience developing recommendation engines using different techniques like collaborative filtering, content-based filtering, deep learning-based approaches, etc.
What We Offer
You work hard to connect with our customers and communities every day. As part of your total rewards package, CoStar is committed to offering you valuable health, wellness and financial benefits to support you and your family, both now and in the future. At CoStar, we help our clients succeed by providing the most cutting-edge, reliable information and tools in the business. And we want our employees to succeed too. We strive to hire the best talent and reward you with top-notch, market-leading pay, benefits and career opportunities. As an example of our commitment to excellence, CoStar ranks in the 90th percentile of employers who offer competitive and affordable medical plans.
Join the CoStar Team
Join the team that creates CoStar’s winning technology. If you’re an engineer you have an incredible opportunity at CoStar – named one of Forbes’ Most Innovative Growth Companies for four consecutive years. We’re always looking for talent to help build the tools and analytics that harvest our big data and power our research operations and shape the marketplaces that serve tens of millions of people each month. Our culture of innovation and excellence attracts and encourages the best and brightest in a broad range of disciplines, which makes CoStar a fun and supportive place to work.
Company Overview:
CoStar Group, Inc. (NASDAQ: CSGP) is the leading provider of commercial real estate information, analytics and online marketplaces. Founded in 1987, CoStar conducts expansive, ongoing research to produce and maintain the largest and most comprehensive database of commercial real estate information. Our suite of online services enables clients to analyze, interpret and gain unmatched insight on commercial property values, market conditions and current availabilities. LoopNet is the most heavily trafficked commercial real estate marketplace online with approximately 5 million monthly unique visitors per month. Realla is the UK's most comprehensive commercial property digital marketplace. Apartments.com, ApartmentFinder.com, ForRent.com, ApartmentHomeLiving.com, Westside Rentals, AFTER55.com, CorporateHousing.com, ForRentUniversity.com, Cozy and Apartamentos.com form the premier online apartment resource for renters seeking great apartment homes and provide property managers and owners a proven platform for marketing their properties. CoStar Group's websites attracted an average of approximately 45 million unique monthly visitors in aggregate in the third quarter of 2018. Headquartered in Washington, DC, CoStar maintains offices throughout the U.S. and in Europe and Canada with a staff of over 3,600 worldwide, including the industry's largest professional research organization.LI-AM2

CoStar Group is an Equal Employment Opportunity Employer; we maintain a drug-free workplace and perform pre-employment substance abuse testing"
45,"Data Engineer, Decision Sciences","Atlanta, GA 30309",Atlanta,GA,30309,None Found,None Found,"Strong Tableau, Adobe Analytics other BI solution
Expert Oracle and Vertica skillsets
Experience using JIRA and Agile Project Management software
Experience using GitHub, Bit Bucket, or other code repository solution
Strong written, verbal communication and presentation skills
Ability to explain complex technical issues in a way that non-technical people may understand
Able to work in a global, multicultural environment
Self-motivated. Capable of working with little or no supervision
Ability to react positively under pressure to meet tight deadlines
Able to work independently or as a team player
Enjoy challenging and thought provoking work and have a strong desire to learn and progress","Work with development teams and other project leaders/stakeholders to provide technical solutions that enable business capabilities
Serve as a key driver on various new technology initiatives and programs on behalf of IT organization, including big data, machine learning and AI
Supports the data science community by enabling data availability in environments that provide advanced analytical capabilities
Maintains a broad understanding of implementation, integration, and inter-connectivity issues with emerging technologies to define data strategies
Assist in the decision-making process related to the selection of software architecture solutions
Build robust data pipelines on public Cloud using AWS Kinesis, Kafka, Lambda or other technologies
Assist in creating documents that ensure consistency in development across the online organization. Implements and improves core software infrastructure
Deep expertise in SQL language, Python, Hadoop ecosystem and/or Spark ecosystem. Strong experience with writing complex programs, implementing architectures, and enabling automation in these environments
Develop and maintain business reporting, ensuring reliability and performance, delivery of performance management tools (such as control charts and scorecards), readiness and adoption of data w/in the organization
Consolidate, standardize and control changes to capacity management data and metric definitions, ownership, accountability and taxonomy to ensure alignment in understanding
Serve as strong advocate to improve analytical capability across the organization
Support various reporting and BI solutions (Tableau, Power BI, Salesforce Einstein)
Manage application and data integration platforms (Informatica, Talend)
Create and manage data, applications and technology architecture documentation and design artifacts
Work across teams to deliver meaningful reference architectures that outline architecture principles and best practices for technology advancement
Gain adoption of architecture processes, standards and procedures","
BS in Computer Science, Applied Mathematics, Physics, Statistics or area of study related to data sciences and data mining or relevant experience",None Found,"Invesco is one of the world’s leading global investment managers, entrusted with managing $1.2 trillion* in assets on behalf of clients worldwide. We are the 6th largest US retail asset manager and the 13th largest investment manager globally, and our more than 8,000 employees worldwide are dedicated to delivering an investment experience that helps people get more out of life. We are purely focused on managing a comprehensive range of active, passive and alternative investment capabilities, which we draw on to provide customized solutions aligned to client needs, our most important benchmark. (*As of May 31,2019)

Job Purpose (Job Summary):

As a Data Engineer at Invesco, you would align business outcomes to technology goals and objectives. You will be responsible for managing decision sciences and advanced analytics initiatives, data integration/engineering. Interacts with Data Scientists, Business Owners, Business Data Analysts, Data Modelers, Architects, and Application Developers, to design, build and manage large-scale batch and real-time data pipelines utilizing various data analytics processing frameworks in support of Data Science practice. The position requires building strong technical hands-on-skills and experiences as well as establishing close business relationships across the enterprise. Working closely with marketing and sales stakeholders, you will execute long term advance analytics roadmap manage increasing demands for advance analytics in Sales and Marketing. A successful candidate must have a demonstrable background with experience in development of high performance, distributed computing tasks using Big Data technologies such as Hadoop (platform level), NoSQL, text mining and other distributed environment technologies based on the needs of the organization. Responsible for analyzing, designing, programing, debugging and modifying software enhancements and/or new products used in distributed, large scale analytics solutions. Strong visualization skills and experience with BI tools (ex. Tableau)

Key Responsibilities / Duties:
Work with development teams and other project leaders/stakeholders to provide technical solutions that enable business capabilities
Serve as a key driver on various new technology initiatives and programs on behalf of IT organization, including big data, machine learning and AI
Supports the data science community by enabling data availability in environments that provide advanced analytical capabilities
Maintains a broad understanding of implementation, integration, and inter-connectivity issues with emerging technologies to define data strategies
Assist in the decision-making process related to the selection of software architecture solutions
Build robust data pipelines on public Cloud using AWS Kinesis, Kafka, Lambda or other technologies
Assist in creating documents that ensure consistency in development across the online organization. Implements and improves core software infrastructure
Deep expertise in SQL language, Python, Hadoop ecosystem and/or Spark ecosystem. Strong experience with writing complex programs, implementing architectures, and enabling automation in these environments
Develop and maintain business reporting, ensuring reliability and performance, delivery of performance management tools (such as control charts and scorecards), readiness and adoption of data w/in the organization
Consolidate, standardize and control changes to capacity management data and metric definitions, ownership, accountability and taxonomy to ensure alignment in understanding
Serve as strong advocate to improve analytical capability across the organization
Support various reporting and BI solutions (Tableau, Power BI, Salesforce Einstein)
Manage application and data integration platforms (Informatica, Talend)
Create and manage data, applications and technology architecture documentation and design artifacts
Work across teams to deliver meaningful reference architectures that outline architecture principles and best practices for technology advancement
Gain adoption of architecture processes, standards and procedures
Work Experience / Knowledge:
2+ years of experience in data modeling, data warehousing, and big data architectures
2+ years of experience in a data engineering role
Proficient in application/software architecture (Definition, Business Process Modeling, etc.)
Deep expertise in (at least one) SQL language, Python, Hadoop ecosystem and/or Spark ecosystem. Strong experience with writing complex programs, implementing architectures, and enabling automation in these environments
The role will be responsible for providing innovative operational solutions and best practices
Advanced knowledge in SQL/Hive, Spark, NoSQL, (Java/Python is a plus)
Strong programming skills and ability to utilize a variety of software/languages/tools; e.g., Spark, R, Python, Scala, Java, Hive, SQL, SAS, Tableau, etc.
Experience with microservice development, Docker, Kubernetes
Develop software to run on cloud native big data infrastructure built on AWS using Spark, Lambda, S3, and other cloud native services
Designs and develops complex and large-scale data structures and pipelines to organize, collect and standardize data to generate insight
2+ years of experience in data integration platforms (Informatica, Talend)
Strong analytics and reporting skills – hands on experience in BI Tools like Tableau, Power BI, Salesforce Einstein
Experience using JIRA and Agile Project Management software
Experience using GitHub, Bit Bucket, or other code repository solution
DevOps experience is a plus
Skills / Other Personal Attributes Required:
Strong Tableau, Adobe Analytics other BI solution
Expert Oracle and Vertica skillsets
Experience using JIRA and Agile Project Management software
Experience using GitHub, Bit Bucket, or other code repository solution
Strong written, verbal communication and presentation skills
Ability to explain complex technical issues in a way that non-technical people may understand
Able to work in a global, multicultural environment
Self-motivated. Capable of working with little or no supervision
Ability to react positively under pressure to meet tight deadlines
Able to work independently or as a team player
Enjoy challenging and thought provoking work and have a strong desire to learn and progress
Formal Education: (minimum requirement to perform job duties)
BS in Computer Science, Applied Mathematics, Physics, Statistics or area of study related to data sciences and data mining or relevant experience
FLSA (US Only): Nonexempt

The above information on this description has been designed to indicate the general nature and level of work performed by employees within this role. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications required of employees assigned to this job. The job holder may be required to perform other duties as deemed appropriate by their manager from time to time.

Invesco's culture of inclusivity and its commitment to diversity in the workplace are demonstrated through our people practices. We are proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, creed, color, religion, sex, gender, gender identity, sexual orientation, marital status, national origin, citizenship status, disability, age, or veteran status. Our equal opportunity employment efforts comply with all applicable U.S. state and federal laws governing non-discrimination in employment."
46,Data Engineer,"Atlanta, GA 30303",Atlanta,GA,30303,None Found,None Found,None Found,None Found,None Found,None Found,"Challengers Wanted.
See how we're embracing the challenges of tomorrow!

Are you interested in working with an excellent team of Data-focused professionals focused on opportunities to enable and enhance BI and Analytics capabilities? Here at Koch Business Solutions (KBS), we place a high value on innovation and thinking creatively in a real way. KBS serves as a technology arm to various Koch Industries companies, and the Data Services team provides real-world solutions that deliver data across systems and to end-user BI and Analytics users. If you're excited about a shift to cloud-based BI and Analytics platforms, guess what…so are we! If you have a passion for productionizing the tribal knowledge that exists in the minds of business subject matter experts, and then backing that knowledge up with real data to help business make the best decisions possible through self-service analytics and dashboards, this could be the place for you. Come grow with us!
A Day In The Life Typically Includes:
Team collaboration in development and maintenance of scalable data warehouse architecture that supports business/technical requirements
Participation in all phases of SDLC related to data delivery: Logical and physical data modeling
ETL development/management
Multidimensional Cube and Tabular model development
Platform to platform data integrations
Identifying data quality issues and supporting data governance initiatives by participating in necessary activities including data profiling, data mining, and clean up
Performing support and troubleshooting tasks for Data Services products and platforms
Tasks include: Performing work on service requests, incidents, and run and maintain activities
Providing estimates for development work needed to support break-fix, new projects, and enhancements
Providing after hours support for mission critical applications and platforms when needed
What You Will Need:

Basic Qualifications:
2+ years of experience in applied data warehousing methodology, analysis, and development
2+ years of experience developing ETL packages, including scheduling and automation
2+ years of SQL coding and tuning experience
Proven experience transforming business requirements to technical solutions
What Will Put You Ahead?

Preferred Qualifications:
Experience with both Multi-Dimensional and Tabular Analysis Services development
Bachelor's Degree in Computer Science, Information Systems, Math or other related field
Experience with AWS Cloud data platforms
Working knowledge of data platforms such as: Redshift, Glue, Matillion, Snowflake, Tableau, Alteryx and Power BI
Understanding of and experience in ETL performance tuning
Experience working in agile development environment
Solid understanding of SDLC
Experience using Source Control systems
This role is not eligible for visa sponsorship.
Learn more about us

Salary and benefits commensurate with experience.
Equal Opportunity Employer.

Except where prohibited by state law, all offers of employment are conditioned upon successfully passing a drug test.

This employer uses E-Verify. Please visit the following website for additional information: www.kochcareers.com/doc/Everify.pdf"
47,Data Architect,"Atlanta, GA",Atlanta,GA,None Found,None Found,"
Authority in everything data related. Know exactly how data is collected, analyzed, and delivered. Also familiar with both the technical and user-facing sides of databases.
5+ years work experience as a Data Architect or Data Engineer or similar role
In-depth understanding of database structure principles used for analytics such as star schemas and SCD
Expertise in database performance optimization
Expertise in building processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Experience using the following software/tools:
Expertise in Redshift, Snowflake, or similar cloud databases
Experience with object-oriented/object function scripting languages
Experience with ETL tools: Alooma, Matillion, Fivetran, Talend, etc.
Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.
Experience with data pipeline and workflow management tools: Airflow, Data Factory, etc.
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Familiarity with data visualization tools (e.g. Tableau, Looker, Power BI)
Demonstrated analytical skills
Problem-solving attitude
B.S. in Computer Science, Information Systems or another quantitative field",None Found,None Found,None Found,None Found,"Your Opportunity
We are looking for a Data Architect to run and evolve our data practice within the Go-To-Market Data & Analytics Team. We use data to (i) define and measure performance and productivity metrics across Go-To-Market Functions (ii) identify and monitor leading indicators and predictive models, and (iii) deliver insights to Go-To-Market teams to ultimately improve core business processes and outcomes. The team partners with Executives and their teams within Sales, Marketing, Pre-and-Post Technical Sales, Customer Success, and Alliances & Channels. We also partner on multi-functional projects with Product and G&A.

Who You Are:
A creative and forward-thinking data professional
An experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up
You thrive in a fast-paced growth environment
Results and Team oriented
What You'll Do
Design, develop and build database design and architecture to power Go-To-Market analytics products
Build, optimize and maintain conceptual and logical database models
Design data pipeline architecture and ensure successful creation of the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and other technologies.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Create data monitoring models for each product and work with business and analytics teams to create models ahead of new releases
Examine and identify database structural necessities by evaluating operations, applications, and programming.
Monitor the system performance by performing regular tests, fixing performance issues, and integrating new features.
Work with business partners to assist with data-related technical issues and support their data infrastructure needs
Recommend solutions to improve new and existing database systems.
Educate staff members through training and individual support.
Your Qualifications
Authority in everything data related. Know exactly how data is collected, analyzed, and delivered. Also familiar with both the technical and user-facing sides of databases.
5+ years work experience as a Data Architect or Data Engineer or similar role
In-depth understanding of database structure principles used for analytics such as star schemas and SCD
Expertise in database performance optimization
Expertise in building processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Experience using the following software/tools:
Expertise in Redshift, Snowflake, or similar cloud databases
Experience with object-oriented/object function scripting languages
Experience with ETL tools: Alooma, Matillion, Fivetran, Talend, etc.
Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.
Experience with data pipeline and workflow management tools: Airflow, Data Factory, etc.
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Familiarity with data visualization tools (e.g. Tableau, Looker, Power BI)
Demonstrated analytical skills
Problem-solving attitude
B.S. in Computer Science, Information Systems or another quantitative field
Please note that visa sponsorship is not available for this position.
Our Office
Our office is in the tech-rich urban center of San Francisco, with easy commute access and a plethora of good eats. We provide competitive compensation, equity and big-company benefits (medical, dental, etc.)—all while maintaining the energy, agility, and fun of a start-up.
About Us
New Relic (NYSE: NEWR) is the industry’s largest and most comprehensive cloud-based instrumentation platform built to create more perfect software. The world’s best software and DevOps teams rely on New Relic to move faster, make better decisions and create best-in-class digital experiences. If you run software, you need to run New Relic. We’re proudly trusted by more than 50% of the Fortune 100.
Founded in 2008, we’re a global company focused on building a culture where all employees feel a deep sense of belonging, where every ‘Relic’ can bring their whole self to work and feel supported and empowered to thrive. We’re consistently recognized as a distinguished employer and are committed to building world-class products and an award winning culture. For more information, visit newrelic.com.
Our Hiring Process
In compliance with applicable law, all persons hired will be required to verify identity and eligibility to work and to complete employment eligibility verification. Note: Our stewardship of the data of thousands of customers’ means that a criminal background check is required to join New Relic.
We will consider qualified applicants with arrest and conviction records based on individual circumstances and in accordance with applicable law including, but not limited to, the San Francisco Fair Chance Ordinance.
Headhunters and recruitment agencies may not submit resumes/CVs through this website or directly to managers. New Relic does not accept unsolicited headhunter and agency resumes, and will not pay fees to any third-party agency or company that does not have a signed agreement with New Relic.
New Relic is an equal opportunity employer. We eagerly seek applicants of diverse background and hire without regard to race, color, gender identity, religion, national origin, ancestry, citizenship, physical abilities (or disability), age, sexual orientation, veteran status, or any other characteristic protected by law.

Interested in the details of our privacy policy? Read more here: https://newrelic.com/termsandconditions/applicant-privacy-policy

#LI-SP2"
48,Google Data Engineer,"Atlanta, GA 30303",Atlanta,GA,30303,None Found,"Minimum of 3 years previous Consulting or client service delivery experience on Google GCP
",DevOps on an GCP platform. Multi-cloud experience a plus.,None Found,None Found,"Proven ability to build, manage and foster a team-oriented environment
Proven ability to work creatively and analytically in a problem-solving environment
Desire to work in an information systems environment
Excellent communication (written and oral) and interpersonal skills
Excellent leadership and management skills","Are you ready to step up to the New and take your technology expertise to the next level?
Join Accenture and help transform leading organizations and communities around the world. The sheer scale of our capabilities and client engagements, in conjunction with the way we collaborate, operate and deliver value, provides an unparalleled opportunity to grow and advance. Choose Accenture and make delivering innovative work part of your extraordinary career.
People in our Client Delivery & Operations career track drive delivery and capability excellence through the design, development and/ or delivery of a solution, service, capability or offering. They grow into delivery-focused roles, and can progress within their current role, laterally or upward. We partner with our clients to help transform their data into an ‘Appreciating Business Asset.’

As part of our Data Business Group, you will lead technology innovation for our clients through robust delivery of world-class solutions. You will build better software better! There will never be a typical day and that’s why people love it here. The opportunities to make a difference within exciting client initiatives are unlimited in the ever-changing technology landscape. You will be part of a highly collaborative and growing network of technology and data experts, who are taking on today’s biggest, most complex business challenges using the latest data and analytics technologies. We will nurture your talent in an inclusive culture that values diversity. You will have an opportunity to work in roles such as Data Scientist, Data Engineer, or Chief Data Officer covering all aspects of Data including Data Management, Data Governance, Data Intelligence, Knowledge Graphs, and IoT. Come grow your career in Technology at Accenture!

The Google GCP Data Engineer is responsible for delivering Data On Cloud projects for Google GCP based deals. The ideal candidate would be responsible for developing and delivering GCP cloud solutions to meet today’s high demand in areas such as AI/ML, IoT, advanced analytics, open source, enterprise collaboration, microservices, serverless, etc. The GCP Data Engineer is a highly performant engineer responsible for delivering Cloud based Big Data and Analytical Solutions for our clients. Responsibilities include building data on cloud solutions for customers, leading Business and IT stakeholders through designing a robust, secure and optimized GCP solutions and ability to be hands-on delivering the target solution. This role will work with customers and leading internal engineering teams in delivering big data solutions on cloud. Using Google GCP cloud technologies, our GCP Data Engineer professionals implement state of the art, scalable, high performance Data On Cloud solutions that meet the need of today’s corporate and emerging digital applications.

Role & Responsibilities:
Provide subject matter expertise and hands on delivery of data capture, curation and consumption pipelines on GCP and HadoopAbility to build cloud data solutions and provide domain perspective on storage, big data platform services, serverless architectures, hadoop ecosystem, RDBMS, DW/DM, NoSQL databases and security (Cloud IAM, Data Loss Prevention API, etc)Participate in deep architectural discussions to build confidence and ensure customer success when building new solutions and migrating existing data applications on the GCP platform.
- Build full technology stack of services required including PaaS (Platform as-a-service), IaaS (Infrastructure as-a-service), SaaS (software as-a-service), operations, management and automation.Apply Accenture methodology, Accenture reusable assets, and previous work experience to delivery consistently high-quality work.Stay educated on new and emerging technologies/patterns/methodologies and market offerings that may be of interest to our clients.Understand the strategic direction set by senior management as it relates to team goals.Use considerable judgment to define solution and seeks guidance on complex problems.Primary upward interaction is with direct supervisor. May interact with peers and/or management levels at a client and/or within Accenture. Establish methods and procedures
on new assignments with guidance.
Manage small teams of delivery engineers successfully delivering work efforts (if in an independent contributor role) at a client or within Accenture.
Extensive travel may be required

Basic Qualifications
Minimum of 3 years previous Consulting or client service delivery experience on Google GCP
Minimum of 3 years of RDBMS experience
Minimum pf 3 years of experience in developing data ingestion, data processing and analytical pipelines for big data, relational databases, NoSQL, data lake and data warehouse solutionsMinimum of 3 years of hands-on experience in GCP and Big Data technologies such as Java, Node.js, C##, Python, PySpark, Spark/SparkSQL, Hadoop, Hive, Pig, Oozie and streaming technologies such as Kafka, Stream Ingestion API, Unix shell/Perl scripting etc.
Extensive experience providing practical direction with the GCP Native and Hadoop ecosystem
Experience with private and public cloud architectures, pros/cons, and migration considerations.
Extensive hands-on experience implementing data migration and data processing using GCP services etc:
Data Ingestion : Cloud Pub/Sub, Data Transfer Service, Cloud IoT Core
Data Storage : Cloud Spanner, Cloud Storage, Cloud Datastore, Cloud SQL, Cloud Bigtable, Cloud Memorystore
Streaming Data Pipeline : Cloud Dataflow, Cloud Dataproc, Cloud Dataprep, Apache Beam
Data Warehousing & Data Lake : BigQuery, Cloud Storage
Advanced Analytics : Cloud ML engine, Google Data Studio, Google Datalab, Tensorflow & Sheets
Experience working with DevOps tools such as GitLabs, Jenkins, CodeBuild, CoePipeline CodeDeploy, etc.
Bachelors or higher degree in Computer Science or a related discipline.
Able to trval 100% M-TH

Candidate Must Have Completed The Following Certifications
Certified GCP Developer - Associate
Certified GCP DevOps – Professional (Nice to have)
Certified GCP Big Data Specialty (Nice to have)

Nice-to-Have Skills/Qualifications:
DevOps on an GCP platform. Multi-cloud experience a plus.
Experience developing and deploying ETL solutions on GCP using tools like Talend, Informatica, Matillion
IoT, event-driven, microservices, containers/Kubernetes in the cloud
Experience in Apache Maven a plus
Understanding and implementation of Data Lake architecturesUnderstanding NoSQL technologies such as MongoDB, Cassandra, Hbase is a plusUnderstanding Solr, Elasticsearch is a plus


Professional Skill Requirements
Proven ability to build, manage and foster a team-oriented environment
Proven ability to work creatively and analytically in a problem-solving environment
Desire to work in an information systems environment
Excellent communication (written and oral) and interpersonal skills
Excellent leadership and management skills

All of our professionals receive comprehensive training covering business acumen, technical and professional skills development. You'll also have opportunities to hone your functional skills and expertise in an area of specialization. We offer a variety of formal and informal training programs at every level to help you acquire and build specialized skills faster. Learning takes place both on the job and through formal training conducted online, in the classroom, or in collaboration with teammates. The sheer variety of work we do, and the experience it offers, provide an unbeatable platform from which to build a career.

Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status).

Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.

Accenture is a Federal Contractor and an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities.

Equal Employment Opportunity

All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.

Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.

Accenture is committed to providing veteran employment opportunities to our service men and women."
49,Senior Cloud Solutions Architect,"Atlanta, GA",Atlanta,GA,None Found,None Found,"
Mastery in at least one of the following domain areas:
Infrastructure Modernization: migrating n-tiered workloads from on-prem and other clouds to GCP with near-zero-downtime (includes full spectrum of lift and shift to complete re-platforming scenarios), or building hybrid-cloud solutions based on Anthos and containerization technologies, such as Docker, Kubernetes, and Istio
Application Development: building custom web and mobile applications on top of the GCP stack
Data Engineering: data warehouse modernization (including technical architectures, star/snowflake schema designs, infrastructure components, ETL/ELT pipelines and reporting/analytic tools), OLTP/OLAP data migrations, or backup, restore and disaster recovery solutions.
Experience providing oversight and direction of cloud projects
Experience leading technical design sessions, architecting and documenting technical solutions that are aligned with client business objectives, and identifying gaps between the client's current and desired end states
Experience strategizing, designing, architecting and leading the deployment of scalable solutions on GCP
Experience across multiple cloud platforms: GCP, AWS, Azure
Experience with container engines: Kubernetes, Docker, AWS Elastic Container Service
Experience with automation technologies including Terraform, Google Cloud Deployment Manager, AWS Cloud Formation or Microsoft Azure Automation
Experience working with engineering and sales teams to elicit customer requirements
Ability to communicate across business units and the ability to interface with and communicate complex technical concepts to a broad range of internal and external stakeholders
Time management skills with the ability to manage multiple streams and lead less experienced architects
Experience as a technical consultant or another customer-facing technical role
",None Found,None Found,None Found,None Found,"Join SADA as a Sr. Cloud Solutions Architect!

Your Mission

As a Sr. Cloud Solutions Architect at SADA, you will work collaboratively with other architects and engineers to design, prototype and lead the deployment of scalable Google Cloud Platform (GCP) architectures. You will work with engineering teams, customers and sales teams to qualify potential engagements, craft robust architectural proposals, and deliver Statements of Work (SOWs) that engineering teams can successfully execute. You’re also hands-on, able to conduct experiments and build functioning prototypes that prove out ideas and build confidence in the solutions you advocate.

You will be a recognized expert within SADA and will develop a reputation with customers as well as the Google Cloud sales and professional services organizations for the quality of your work. You will demonstrate repeated delivery of project architectures that other engineers and architects demur to you for lack of expertise. You will also lead early-stage opportunity technical qualification calls, as well as lead client-facing technical discussions.

Pathway to Success

#BeAChangeAgent: You are a rainmaker! You are way out in front of our delivery organization, meeting with the spectrum of corporate and enterprise customers that need our consultative services. You have your finger on the pulse of their technical needs and take pride in helping them solve their real-world problems on GCP.

You will be measured quarterly by a combination of (a) the volume of signed SOWs that you shepherd through the sales funnel, and (b) the level of customer satisfaction measured at the end of each engagement.

As you continue to execute successfully, we will build a customized development plan together that leads you through the solution architecture or management growth tracks.

Expectations

Required Travel - 30% travel to customer sites, conferences, and other related events.
Customer Facing - You will interact with customers on a regular basis, sometimes daily, other times weekly/bi-weekly. Common touchpoints occur when qualifying potential opportunities, at project kickoff, throughout the engagement as progress is communicated, and at project close. You can expect to interact with a range of customer stakeholders, including engineers, technical project managers, and executives
Training - Ongoing with first-week orientation at HQ followed by a 90-day onboarding schedule. Details of the timeline can be shared.

Job Requirements

Required Credentials:

Google Professional Cloud Architect Certified

[https://cloud.google.com/certification/cloud-architect] and/or Google
Professional Data Engineer Certified
[https://cloud.google.com/certification/data-engineer], or able to complete one of the above within the first 45 days of employment.

Required Qualifications:

Mastery in at least one of the following domain areas:
Infrastructure Modernization: migrating n-tiered workloads from on-prem and other clouds to GCP with near-zero-downtime (includes full spectrum of lift and shift to complete re-platforming scenarios), or building hybrid-cloud solutions based on Anthos and containerization technologies, such as Docker, Kubernetes, and Istio
Application Development: building custom web and mobile applications on top of the GCP stack
Data Engineering: data warehouse modernization (including technical architectures, star/snowflake schema designs, infrastructure components, ETL/ELT pipelines and reporting/analytic tools), OLTP/OLAP data migrations, or backup, restore and disaster recovery solutions.
Experience providing oversight and direction of cloud projects
Experience leading technical design sessions, architecting and documenting technical solutions that are aligned with client business objectives, and identifying gaps between the client's current and desired end states
Experience strategizing, designing, architecting and leading the deployment of scalable solutions on GCP
Experience across multiple cloud platforms: GCP, AWS, Azure
Experience with container engines: Kubernetes, Docker, AWS Elastic Container Service
Experience with automation technologies including Terraform, Google Cloud Deployment Manager, AWS Cloud Formation or Microsoft Azure Automation
Experience working with engineering and sales teams to elicit customer requirements
Ability to communicate across business units and the ability to interface with and communicate complex technical concepts to a broad range of internal and external stakeholders
Time management skills with the ability to manage multiple streams and lead less experienced architects
Experience as a technical consultant or another customer-facing technical role

Useful Qualifications:

Hands-on experience designing and recommending elegant solutions that drive business outcomes
Experience building, designing and migrating complex cloud architectures
Strong aptitude for learning new technologies and techniques with a willingness and capability to skill up the team
Ability to lead an in-depth client meeting/workshop across a broad range of topics including discovery, cloud compliance, and security
Deep understanding of best practices, design patterns, reference and compliance architectures with an uncanny ability to build and recommend these as needed
Knowledge and understanding of industry trends, new technologies and the ability to apply these to customer architectures to drive outcomes
Highly self-motivated and able to work independently as well as in a team environment

About SADA

Values: We built our core values
[https://sadasystems.com/about/company-overview/] on themes that internally compel us to deliver our best to our partners, our customers and to each other. Ensuring a diverse and inclusive workplace where we learn from each other is core to SADA’s values. We welcome people of different backgrounds, experiences, abilities and perspectives. We are an equal opportunity employer.

1. Make them rave
2. Be data driven
3. Be one step ahead
4. Be a change agent
5. Do the right thing

Work with the best : SADA has been the largest partner in North America for GCP since 2016 and recently announced, at Google NEXT, as the
2018 Global Partner of the Year
[https://sadasystems.com/blog/google-cloud/gcp/sada-wins-2018-google-cloud-partner-award/]. SADA has also been awarded
Best Place to Work
[https://sadasystems.com/blog/news/sada-systems-best-places-work-2019/] by Inc. as well as LA Business Journal!

Benefits : Unlimited PTO
[https://sadasystems.com/blog/news/blogannouncementsblogannouncementsunlimited-pto-yes-unlimited-why-sada-is-the-best-place-to-work/], competitive and attractive compensation, performance-based bonuses, paid holidays, rich medical, dental, vision plans, life, short and long-term disability insurance, 401K with match,
professional development reimbursement program
[https://sadasystems.com/blog/news/blogannouncementsprofessional-development-how-we-do-it-why-it-matters/] as well as Google Certified training programs.

Business Performance: SADA has been named to the INC 5000 Fastest Growing Private Companies list for 12 years in a row garnering Honoree status. CRN has also named SADA on the Top 500 Global Solutions Providers for the past 5 years. The overall culture continues to evolve with engineering at its core: 3200+ projects completed, 3000+ customers served, 10K+ workloads and 25M+ users migrated to the cloud."
50,Senior Big Data Engineer- Java/Scala/Python,"Atlanta, GA 30327",Atlanta,GA,30327,None Found,"
Bachelors/Master/PHD in computer science, engineering, information technology, or related degree and/or equivalent work experience
4+ years of Java development experience in large scale enterprise development for Undergraduates
2+ years of Java development experience in large scale enterprise development for Masters or PHD
Knowledge of multiple threading development and performance tuning
Knowledge of implementing efficient logic using collections and data structures
Knowledge of one or more Big Data Technologies like Elastic Search, Spark, Kafka, Map-Reduce, HDFS and Hive
Knowledge in Design Patterns, OOP/OOD, Software Architecture
Knowledge of how to assess the performance of data solutions, how to diagnose performance problems, and tools used to monitor and tune performance.
Excellent communication skills with both Technical and Business audience",None Found,None Found,None Found,None Found,"Travelport are the only true travel commerce platform in the world. We are specialist solution providers and are committed to building leading technology that makes the experience of buying and managing travel continually better for the global travel and tourism industry. Come and be part of our mission to make sure that every trip is powered by Travelport…
Role & Team
You will come on board at a truly exciting time, and as a member of the Big Data Team, you will play a pivotal and crucial part in finding unrivaled and creative ways to use the massive amount of data that we generate.
Travelport’s Big Data Engineers are tasked with designing and implementing big data solutions with terabytes and petabytes daily transaction volume. Travelport employees enjoy a collaborative environment and have many opportunities to learn from and share knowledge with other Travelport developers, architects, and business architects.
Main Accountabilities:
Lead, design, develop, document, and test big data solutions.
Install and integrate various technologies in the big data echo system
Configure and troubleshoot issues in big data framework
Aid in the implementation of and implementing analytical models
Deliver solutions for using an Agile Development model
Create quality deliverables to communicate technical solutions to appropriate audiences.
Understand issues, problem solving and design/architect solutions
Build and collaborate with business and technical teams to deliver software
Learn continuously, leveraging training resources and self-directed training, sharing knowledge and skills with others.
Provide mentoring and leadership to more junior resources.
Passion for technology and willingness to learn is required
Have ability to work in a fast paced and dynamic work environment and be able to produce efficient and robust solution
High energy, confidence, and agility to drive a team
Candid and direct communication
A creative thinker who can bring in new ideas and innovations to the company.
Required Qualifications:
Bachelors/Master/PHD in computer science, engineering, information technology, or related degree and/or equivalent work experience
4+ years of Java development experience in large scale enterprise development for Undergraduates
2+ years of Java development experience in large scale enterprise development for Masters or PHD
Knowledge of multiple threading development and performance tuning
Knowledge of implementing efficient logic using collections and data structures
Knowledge of one or more Big Data Technologies like Elastic Search, Spark, Kafka, Map-Reduce, HDFS and Hive
Knowledge in Design Patterns, OOP/OOD, Software Architecture
Knowledge of how to assess the performance of data solutions, how to diagnose performance problems, and tools used to monitor and tune performance.
Excellent communication skills with both Technical and Business audience
Preferred Qualifications:
Strong programming skills in standard programming and/or algorithms
1+ years of Scala or Python programming
1+ years of development experience in the field of big data on Large Scale environment (e.g. Hadoop, MongoDB, Couch Base, Cassandra)
1+ years of Spark Based Technologies (e.g. Spark Dataframes, Spark Streaming and Spark SQL)
Knowledge of Big Data querying tools (e.g. Spark, Pig, Hive, and Impala)
Aid in the modeling and implementation of machine learning and deep learning solutions
Real time analytics using stream processing frameworks such like Spark / Storm
Experience in the following: C, C++, Perl, or PHP
Knowledge of designing and developing reusable components
Experience in web frontend development (e.g. Javascript, Jquery, AngularJS, ReactJS)
If this sounds like you, we’d love for you to get in touch.
What’s in it for you...
You will receive a competitive salary & benefits package accompanied by the opportunity to work in a fast-paced, dynamic and progressive organisation that cares about its people and promotes innovation.
We are an equal opportunity employer and value diversity at our company. We do not discriminate based on race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status."
51,Data Engineer,"Peachtree Corners, GA",Peachtree Corners,GA,None Found,None Found,None Found,None Found,"Development and implementation of Master Data Web services/APIs as part of the Crawford Master Data Services Framework
Responsible for developing solutions in the Informatica MDM platform (also Salesforce and/or Mulesoft) by converting business requirements into quality technical solutions
Assist with the development and enforcement architecture standards
Serve as an expert developer, proficient in configuring, staging, loading, matching and merging processes and overseeing and promoting quality development standards
Capture and rationalize key business requirements data definitions for attributes in conceptual and logical models
Performing data extraction from legacy systems to map/load data into Informatica MDM performing validation routines and reviewing that all data was appropriately loaded
Engage with business partners to understand functional requirements to design best possible global solutions
Analyze business and data requirements and help define the best solution keeping our long term goal in mind of reducing data redundancy
Provide business and technical input in project activities and decision making processes
Performs analysis of cross-functional and complex business requirements.
Follow project management methodologies and ensure the timely delivery of project deliverables
Understand, influence and provide feedback on technical solution in support of end-to-end data, processes and assets
Flexibility and ability to work in a global and multi-cultural environment. Team members are in multiple geographies, resulting in time constraints due to time zones differences",None Found,"Bachelor's/Master’s degree or equivalent in Information Technology, Computer Science, Engineering or related field.
1 – 3 years prior experience
Certified Data Management Professional (CDMP) preferred
Some experienced in extracting and loading large data volumes to-and-from platforms such a Microsoft Azure and Amazon Web Services (AWS)
Hands on experience working on UI development and configuration
Must have a minimum of exposure to tools such as and not limited to Java, C,C++, C#,VB, Sql Server/Oracle.
Experience with analysis and business intelligence tools (Tableau, Cognos, etc.)
Basic understanding of databases (RDBMSs) and database scripting.
Have some performance tuning and SQL query skills
Some experience with 3rd party package software (Oracle, Informatica, SAP)
Some knowledge and experience in software development life cycle (SDLC), software development methodologies and standards","Excellence In Everything We Touch
Position Summary
Translating business requirements into callable data services, which may focus on issues such as reducing redundancy of data within the Crawford environment and improving the way in which it moves from one system to another. Will contribute technical and business knowledge expertise to design, develop, and implement integrated IT / business solutions focused primarily around the linkage to/from the Master Data Management (MDM) platform. Contributions will be on both next-generation and legacy solutions.
Responsibilities
Development and implementation of Master Data Web services/APIs as part of the Crawford Master Data Services Framework
Responsible for developing solutions in the Informatica MDM platform (also Salesforce and/or Mulesoft) by converting business requirements into quality technical solutions
Assist with the development and enforcement architecture standards
Serve as an expert developer, proficient in configuring, staging, loading, matching and merging processes and overseeing and promoting quality development standards
Capture and rationalize key business requirements data definitions for attributes in conceptual and logical models
Performing data extraction from legacy systems to map/load data into Informatica MDM performing validation routines and reviewing that all data was appropriately loaded
Engage with business partners to understand functional requirements to design best possible global solutions
Analyze business and data requirements and help define the best solution keeping our long term goal in mind of reducing data redundancy
Provide business and technical input in project activities and decision making processes
Performs analysis of cross-functional and complex business requirements.
Follow project management methodologies and ensure the timely delivery of project deliverables
Understand, influence and provide feedback on technical solution in support of end-to-end data, processes and assets
Flexibility and ability to work in a global and multi-cultural environment. Team members are in multiple geographies, resulting in time constraints due to time zones differences
Requirements
Bachelor's/Master’s degree or equivalent in Information Technology, Computer Science, Engineering or related field.
1 – 3 years prior experience
Certified Data Management Professional (CDMP) preferred
Some experienced in extracting and loading large data volumes to-and-from platforms such a Microsoft Azure and Amazon Web Services (AWS)
Hands on experience working on UI development and configuration
Must have a minimum of exposure to tools such as and not limited to Java, C,C++, C#,VB, Sql Server/Oracle.
Experience with analysis and business intelligence tools (Tableau, Cognos, etc.)
Basic understanding of databases (RDBMSs) and database scripting.
Have some performance tuning and SQL query skills
Some experience with 3rd party package software (Oracle, Informatica, SAP)
Some knowledge and experience in software development life cycle (SDLC), software development methodologies and standards
About Us
People taking care of people. It’s that simple. At Crawford & Company, we treat our clients’ policyholders like our own, helping to restore and enhance lives, businesses and communities at all points of the claims management process. Combining a legacy of nearly 80 years of unmatched experience with global capabilities and industry-leading technology, Crawford is at the forefront of change, while also staying firmly rooted to our commitment to putting people first.
We are guided by our collective value system: RESTORE.
At Crawford, we:
Respect our culture of integrity and ethical behavior, while embracing the unique talents of the individual and encouraging an ownership mentality among everyone.
Are Empowered to advance the company mission and take ownership of our individual career progression.
Promote Sustainability through a corporate culture in which employees are good stewards of their communities.
Emphasize Training and an environment where employees continually seek and share knowledge and are engaged and satisfied with their work.
Are One Crawford, embracing a global mindset that’s inclusive, agile, mission-focused, and customer-focused.
Give Recognition, participating in an environment where people are rewarded for jobs well done.
Embody an Entrepreneurial Spirit, sharing a passion to succeed, innovate, and outpace our competitors.
We believe in leading by example – at work and in our communities. We hail from more than 70 countries and speak dozens of languages, reflecting the global fabric of the audience we serve. Though our reach is vast, we proudly operate as One Crawford: united in mission, vision and values. Learn more at www.crawfordandcompany.com.
In addition to a competitive salary, Crawford offers you:
Career advancement potential locally, nationally and internationally. Crawford & Company has more than 700 locations in 70 countries
On-going training opportunities through every stage of your career
Strong benefits package including matching 401k; health, dental, and life insurance; employee stock purchase plans; tuition reimbursement and so much more.
Crawford & Company participates in E-Verify and is an Equal Opportunity Employer. M/F/D/V Crawford & Company is not accepting unsolicited assistance from search firms for this employment opportunity. All resumes submitted by search firms to any employee at Crawford via-email, the Internet or in any form and/or method without a valid written Statement of Work in place for this position from Crawford HR/Recruitment will be deemed the sole property of Crawford. No fee will be paid in the event the candidate is hired by Crawford as a result of the referral or through other means."
52,Data Engineer,"Atlanta, GA",Atlanta,GA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Do you enjoy helping business teams make good decisions with data? The work you do will be instrumental in developing the Clutch platform especially around building technology and products that makes it possible for us to create, launch and manage mobility service offerings. This is a technical role with strong software engineering experience.

What You'll Do

Lead the technical efforts to build the Data Warehouse at Clutch leveraging mainly Open source and Cloud technologies
Architect data pipelines and ETL jobs to injest data from different sources into a queryable format for Analytics and Business Intelligence
Deliver gold standard dashboards providing key metrics to both internal and external customers
Define and implement architecture to enable outflow of data to our customers
Must Haves

2-5 years experience working with data
Strong programming skills in Python or other high level languages like Java
Strong SQL query writing skills including ability to address query performance issues
Experience identifying the right tools and designing a data warehouse from scratch
Experience communicating with business users and helping them articulate requirements
Nice to Haves

Delivering software working in an Agile environment
Exposure to machine learning algorithms and data science
Familiarity with NoSQL databases and Big Data technologies
Experience with best in class commercial BI tools
BS in Computer Science or equivalent Analytics background
About Clutch
Clutch Technologies is the leader in subscription and mobility services software to the automotive industry. Utilizing Clutch’s end-to-end platform, automotive dealers, OEM’s, car rental companies and fleet operators can increase asset utilization, offer new revenue streams and deliver innovative consumer experiences. Clutch, a Cox Automotive company, is recognized as a pioneer in the subscription category and has been chosen, trusted and recommended by more than 45 signed dealers and manufacturers across the U.S. and Canada.

If you'd like to be considered for the position write to the email below with the job title as the subject.
engineeringjobs@driveclutch.com"
53,AI Model Development Lead For Marketing (Analytics Manager 5),"Atlanta, GA",Atlanta,GA,None Found,None Found,"
8+ years of experience in analytics, modeling, or a combination of both
6+ years of management experience; or 6+ years of leadership experience in an advanced quantitative analytics function
A Master's degree or higher
5 + years of experience using quantitative machine learning techniques
4+ years of experience working with digital data science including analyzing cookie-level data",None Found,None Found,None Found,None Found,"Overview:
Wells Fargo technology teams drive innovation to create a more powerful and fulfilling financial experience for our customers and team members. You will join more than 24,000 team members supporting 95 billion transactions annually in 10 countries. Our career opportunities span the technology spectrum: advanced analytics, big data, information security, application development, cloud enablement, project management and more.

SUCCESS PROFILE
Check out the top traits we're looking for and see if you have the right mix. Additional related traits listed below.

Analytical
Detail-oriented
Insightful
Inventive
Problem Solver
Curious
Benefits
Wells Fargo wants to help you get more out of life and take care of things outside the office to make life a little easier. We provide:

Medical, Dental and Vision
Employer Matching 401(k)
Tuition Reimbursment
Maternity and Paternity Leave
Paid Time Off
Responsibilties
Job Description
At Wells Fargo, we want to satisfy our customers’ financial needs and help them succeed financially. We’re looking for talented people who will put our customers at the center of everything we do. Join our diverse and inclusive team where you’ll feel valued and inspired to contribute your unique skills and experience.
Help us build a better Wells Fargo. It all begins with outstanding talent. It all begins with you.
Enterprise Finance drives financial management for the company and maintains and enhances risk and financial controls. Key functions within Enterprise Finance include finance and accounting; Treasury; corporate development, mergers, and acquisitions; Data Management and Insights, the Customer Remediation Center of Excellence, Enterprise Shared Services, Business Process Management, and Corporate Strategy. Enterprise Finance informs shareholders, regulators, taxing authorities, team members, and leaders of the company’s financial performance through earnings releases, investor meetings and conferences, and meetings with regulators and credit rating agencies, following appropriate reporting guidelines. They also maintain and enhance risk and financial controls and lead many of the company’s shared services functions including corporate properties, security, and global services.
As part of the newly formed AI Model Development COE in Enterprise Analytics and Data Science (EADS), which focuses on building, implementing, and monitoring AI models for the enterprise, the AI model development team for personalization, marketing, and virtual channels is looking for an experienced AI leader to manage the development of AI models for marketing.

This leader will be responsible for building and managing a team of data scientists to design, develop, and implement AI models focused on marketing’s AI priorities. Partnering with Wells Fargo AI technology team, Wells Fargo AI business solution team, and marketing executives, you and your team will deliver and deploy AI models on the Well Fargo AI open source platform to scale these solutions and embed them in our operational processes.
KEY RESPONSIBILITIES INCLUDE:
Build and grow a team of data scientists responsible for AI model development in support of marketing
Design, develop, and deploy AI models using state of the art AI techniques available in the open stack and/or vendor solutions
Partner with marketing executives to frame the problem, manage the model development process, and business relationship
Manage a portfolio of the data science projects including the following responsibilities:
Help finalize project scope working with business partners
On-going touch-base with business partners and governance stakeholders
Define priorities in partnership with the business partners during on-going development
Work with AI technology and production teams to operationalize models
May be called upon to review vendor models and solutions and/or models developed outside of EADS
Divisional Information:
Data Management and Insights (DMI) is transforming the way that Wells Fargo uses and manages data. Our work enables Wells Fargo to empower and inform our team members, deliver exceptional experiences for our customers, and meet the elevated expectations of our regulators. The team is responsible for designing the future data environment, defining data governance and oversight, and partnering with technology to operate the data infrastructure for the company. This team also provides next generation analytic insights to drive business strategies and help meet our commitment to satisfy our customers’ financial needs.
As a Team Member Manager, you are expected to achieve success by leading yourself, your team, and the business. Specifically you will:
Lead your team with integrity and create an environment where your team members feel included, valued, and supported to do work that energizes them.
Accomplish management responsibilities which include sourcing and hiring talented team members, providing ongoing coaching and feedback, recognizing and developing team members, identifying and managing risks, and completing daily management tasks.

Required Qualifications

8+ years of experience in analytics, modeling, or a combination of both
6+ years of management experience; or 6+ years of leadership experience in an advanced quantitative analytics function
A Master's degree or higher
5 + years of experience using quantitative machine learning techniques
4+ years of experience working with digital data science including analyzing cookie-level data


Desired Qualifications

Strong analytical skills with high attention to detail and accuracy
Ability to work and influence successfully within a matrix environment and build effective business partnerships with all levels of team members
Meeting facilitation experience in leading discussions that result in consensus and commitment


Other Desired Qualifications
Data science experience in the ad tech space (DMPs, DSPs, Google and/or Adobe Cloud, digital attribution)
4+ years managing or directing data scientist/ statistician/ data engineer teams
Hands on experience with deep learning toolkits such as Tensorflow, Keras, PyTorch, Dynet
Detail oriented. Experience with model governance requirements. Able to de-mystify AI models to make them transparent and explainable
Experience with agile project management methodologies for data science

Disclaimer

All offers for employment with Wells Fargo are contingent upon the candidate having successfully completed a criminal background check. Wells Fargo will consider qualified candidates with criminal histories in a manner consistent with the requirements of applicable local, state and Federal law, including Section 19 of the Federal Deposit Insurance Act.

Relevant military experience is considered for veterans and transitioning service men and women.

Wells Fargo is an Affirmative Action and Equal Opportunity Employer, Minority/Female/Disabled/Veteran/Gender Identity/Sexual Orientation.

ENT FINANCE"
54,Data Engineer,"Duluth, GA 30095",Duluth,GA,30095,None Found,None Found,"
Technology certifications such as Amazon Certified Solutions Architect
Proficiency in programming in Spark, R and/or ML packages
Exposure to applications developed to support manufacturing quality
Experience with MS Dynamics CRM, MicroStrategy BI tools, SAP ERP
Consulting experience
",None Found,None Found,None Found,"If you have these 7 bullet points we are interested in talking to you, please read the entire JD as well.


SSIS
ETL
Data analysis and profiling
Data Model
PowerBI
Reporting
Data Warehouse.

Here is the complete Job Description.

Job Details

Description

The Data Engineer will be responsible for expanding and optimizing our data capabilities for Data Warehousing, Master Data, Data Services as well as Business Intelligence. The ideal candidate is an experienced data wrangler who enjoys optimizing data systems and can build them from the ground up. He/she must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. The ideal candidate will be excited by the prospect of optimizing or even re-designing our companys data architecture to support our next generation of products and data initiatives.

Responsibilities


Drive design and development of internal data pipeline architecture to service BI and Analytics capabilities
Work with key stakeholders including Product, Sales, Quality Engineering and Marketing to assist with data-related technical needs and support their data infrastructure needs.
Ensure operational resilience, stability, and scalability of our enterprise data platform by conduct continuous hardening activates that increase uptime, data quality and reduce cost
Ensure tight data platform security during data transport and while at rest
Build hybrid cloud/prem data platform to enable self-service Business Intelligence and Analytics functions
Conduct data profiling and analysis of complex data sets to discover how to meet functional / non-functional requirements
Institute data quality monitoring and alerting platform operations
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics
Drive solutions for meta data and data lineage management
Drive innovation by recommending and driving adoption of new technologies that provide competitive data advantages for enterprise
Contributes to agile team alignment and is committed to constant improvement efforts by participating in team ceremonies sprint planning, stand-ups, backlog grooming and retrospectives
Ensure technical delivery of detailed feature/story level solutions that satisfies the IT roadmaps acceptance criteria
Maintains professional and technical knowledge by attending educational workshops; reviewing professional publications; establishing personal networks; participating in professional societies

Minimum Work Experience


8+ years of proven experience in the design, development and deployment of end-to-end data pipeline solutions including data processing (Batch, Micro-Batch, Streaming), data preparation (ETL, ELT), data modeling (STAR, OLAP, MPP)
5+ year of Business Intelligence Development and Administration
Experience of building data solutions for back office applications that source data from CRM and ERP applications
Advanced experience working with SQL Server databases
Strong grasp of master data management, data quality monitoring and metadata management
Proficiency in data centric shell scripting, ETL, Python, and/or .NET Programming skills
A comfortable and confident communicator with technical staff but also able to speak with customers concisely to translate technical concepts into business terminology and impacts
Exposure to continuous integration implementations that utilize DevOps style tools (such as Jenkins, Chef, Docker, Terraform, etc.)
Proven team player with the ability to multi-task in a fast-paced dynamic agile work environment
Has previously supported a metrics-driven data culture to drive accountability and transparency
Passionate problem solver and motivated self-starter including ability to analyze situation and recommend sound solutions and implementation strategies

Additional Desired Skills:

Technology certifications such as Amazon Certified Solutions Architect
Proficiency in programming in Spark, R and/or ML packages
Exposure to applications developed to support manufacturing quality
Experience with MS Dynamics CRM, MicroStrategy BI tools, SAP ERP
Consulting experience

Education: Bachelors degree in Computer Science, Information Systems, or combination of education and experience.

Location: Duluth, Georgia"
55,Data Engineer,"Atlanta, GA",Atlanta,GA,None Found,None Found,None Found,None Found,None Found,None Found,None Found,"Who is Georgia-Pacific?Watch to find out!
Data Engineer
Atlanta, GA or Green Bay, WI
Georgia-Pacific is a known industry leader with roughly 200 facilities and 35,000 world-class employees who strive for excellence, challenge the status quo, and create value.
GP makes products that are part of your everyday life. We are one of the world’s leading producers of tissue, pulp, paper, packaging, building products, and related chemicals. If you are self-driven with a commitment to safety, manufacturing excellence, and product quality, we’re looking for people like you.
Georgia-Pacific (GP) is seeking several motivated and inquisitive individuals with skills in data engineering to help start-up and run a brand-new centralized support center
A Day In The Life Typically Includes:
Georgia-Pacific is looking for a Data Engineer on its Data Historian team in Atlanta, GA who will work closely with a highly leveraged team of system experts that provide project resources and troubleshooting support for data collection and process visualizations systems. Duties include:
Working with Manufacturing Big Data, Machine Learning Models, AWS, Data Visualization, and Edge devices
Stream / Transfer data from manufacturing equipment to Data Lake and Data Historian tools residing in AWS
Design and maintain a technical environment that enables development of Machine Learning and other Analytical Models
Deployment and monitoring of Analytical Models to AWS, Edge Server, Edge Gateways devices for 40+ manufacturing sites
Develop data visualization for analytical models in PI Vision, Tableau, custom web page
Daily collaboration with Data Scientist, Manufacturing Equipment SMEs, Remote Support Engineers, and IT peers
Position reports thru Information Technology

What You Will Need:
Basic Qualifications:
Bachelor's Degree in IT, Engineering, or Data Science
Proven ability to collaboratively work with peers and internal customers
Experience in programming in at least one object-oriented programming language such as Java, C#, C++, or Python
Knowledge of software engineering best practices and software project lifecycles
Experience with data integration ETL techniques and frameworks
Ability and desire to learn new technologies
Ability to create and maintain clearly written technical, user, and system documentation

What Will Put You Ahead?
Preferred Qualifications:
Experience with Python, Amazon Web Services, OSIsoft PI Data Historian software, Tableau, SAS, Dataiku
Experience in deploying Analytical models to the Cloud and Edge environments
Experience working in multi-site manufacturing environment
Understanding of the Purdue model, IT/OT network segmentation, and PLC/DCS communication
Want to learn more about Georgia-Pacific?
Salary and benefits commensurate with experience.
We are an equal opportunity employer. Minority/Female/Disabled/Veteran
Except where prohibited by state law, all offers of employment are conditioned upon successfully passing a drug test.

This employer uses E-Verify. Please visit the following website for additional information: www.kochcareers.com/doc/Everify.pdf"
56,Senior Data Engineer,"Atlanta, GA 30309",Atlanta,GA,30309,None Found,None Found,"Previous management experience and successfully leading a team of direct reports
Proven track record of effectively leading and managing employees, managing performance, setting goals for team/individuals and provide mentoring.
Strong Tableau, Adobe Analytics other BI solution
Expert Oracle and Vertica skillsets
Experience using JIRA and Agile Project Management software
Experience using GitHub, Bit Bucket, or other code repository solution
Strong written, verbal communication and presentation skills
Ability to explain complex technical issues in a way that non-technical people may understand
Able to work in a global, multicultural environment
Self-motivated. Capable of working with little or no supervision
Ability to react positively under pressure to meet tight deadlines
Able to work independently or as a team player
Enjoy challenging and thought provoking work and have a strong desire to learn and progress","Work with development teams and other project leaders/stakeholders to provide technical solutions that enable business capabilities
Supports the data science community by enabling data availability in environments that provide advanced analytical capabilities
Maintains a broad understanding of implementation, integration, and inter-connectivity issues with emerging technologies to define data strategies
Assist in the decision-making process related to the selection of software architecture solutions
Implement architectures to handle web-scale data and its organization
Execute strategies that inform data design and architecture partnering with enterprise standard
Build robust data pipelines on public Cloud using AWS Kinesis, Kafka, Lambda or other technologies
Assist in creating documents that ensure consistency in development across the online organization. Implements and improves core software infrastructure
Deep expertise in SQL language, Python, Hadoop ecosystem and/or Spark ecosystem. Strong experience with writing complex programs, implementing architectures, and enabling automation in these environments
Develop and maintain business reporting, ensuring reliability and performance, delivery of performance management tools (such as control charts and scorecards), readiness and adoption of data w/in the organization
Consolidate, standardize and control changes to capacity management data and metric definitions, ownership, accountability and taxonomy to ensure alignment in understanding
Serve as strong advocate to improve analytical capability across the organization
Communicate with various business areas and to gather and prioritize their business requirements
Support various reporting and BI solutions (Tableau, Power BI, Salesforce Einstein)
Manage application and data integration platforms (Informatica, Talend)
Manage the full life cycle of development/reporting/integration projects: planning, design, develop, testing and rollout
Manage solution providers, define sourcing approach and manage the providers
Create and manage data, applications and technology architecture documentation and design artifacts
Work across teams to deliver meaningful reference architectures that outline architecture principles and best practices for technology advancement
Gain adoption of architecture processes, standards and procedures","
BS in Computer Science, Applied Mathematics, Physics, Statistics or area of study related to data sciences and data mining or relevant experience",None Found,"Invesco is one of the world’s leading global investment managers, entrusted with managing $1.2 trillion* in assets on behalf of clients worldwide. We are the 6th largest US retail asset manager and the 13th largest investment manager globally, and our more than 8,000 employees worldwide are dedicated to delivering an investment experience that helps people get more out of life. We are purely focused on managing a comprehensive range of active, passive and alternative investment capabilities, which we draw on to provide customized solutions aligned to client needs, our most important benchmark. (*As of May 31,2019)

Job Purpose (Job Summary):

As a Senior Data Engineer at Invesco, you would align business outcomes to technology goals and objectives. You will be responsible for managing decision sciences and advanced analytics initiatives, data integration/engineering. Interacts with Data Scientists, Business Owners, Business Data Analysts, Data Modelers, Architects, and Application Developers, to design, build and manage large-scale batch and real-time data pipelines utilizing various data analytics processing frameworks in support of Data Science practice. The position requires building strong technical hands-on-skills and experiences as well as establishing close business relationships across the enterprise. Working closely with marketing and sales stakeholders, you will establish and drive long term advance analytics roadmap manage increasing demands for advance analytics in Sales and Marketing. You will help steer the strategic technology direction, define target state architecture, technology roadmaps and mentor others. A successful candidate must have a demonstrable background with experience in development of high performance, distributed computing tasks using Big Data technologies such as Hadoop (platform level), NoSQL, text mining and other distributed environment technologies based on the needs of the organization. Responsible for analyzing, designing, programing, debugging and modifying software enhancements and/or new products used in distributed, large scale analytics solutions. Strong visualization skills and experience with BI tools (ex. Tableau)

Key Responsibilities / Duties:
Work with development teams and other project leaders/stakeholders to provide technical solutions that enable business capabilities
Supports the data science community by enabling data availability in environments that provide advanced analytical capabilities
Maintains a broad understanding of implementation, integration, and inter-connectivity issues with emerging technologies to define data strategies
Assist in the decision-making process related to the selection of software architecture solutions
Implement architectures to handle web-scale data and its organization
Execute strategies that inform data design and architecture partnering with enterprise standard
Build robust data pipelines on public Cloud using AWS Kinesis, Kafka, Lambda or other technologies
Assist in creating documents that ensure consistency in development across the online organization. Implements and improves core software infrastructure
Deep expertise in SQL language, Python, Hadoop ecosystem and/or Spark ecosystem. Strong experience with writing complex programs, implementing architectures, and enabling automation in these environments
Develop and maintain business reporting, ensuring reliability and performance, delivery of performance management tools (such as control charts and scorecards), readiness and adoption of data w/in the organization
Consolidate, standardize and control changes to capacity management data and metric definitions, ownership, accountability and taxonomy to ensure alignment in understanding
Serve as strong advocate to improve analytical capability across the organization
Communicate with various business areas and to gather and prioritize their business requirements
Support various reporting and BI solutions (Tableau, Power BI, Salesforce Einstein)
Manage application and data integration platforms (Informatica, Talend)
Manage the full life cycle of development/reporting/integration projects: planning, design, develop, testing and rollout
Manage solution providers, define sourcing approach and manage the providers
Create and manage data, applications and technology architecture documentation and design artifacts
Work across teams to deliver meaningful reference architectures that outline architecture principles and best practices for technology advancement
Gain adoption of architecture processes, standards and procedures
Work Experience / Knowledge:
5+ years of experience in data modeling, data warehousing, and big data architectures
3+ years of experience in a data engineering role
Proficient in application/software architecture (Definition, Business Process Modeling, etc.)
Strong analytics and reporting skills – hands on experience in BI Tools like Tableau, Power BI, Salesforce Einstein
Deep expertise in (at least one) SQL language, Python, Hadoop ecosystem and/or Spark ecosystem. Strong experience with writing complex programs, implementing architectures, and enabling automation in these environments
The role will be responsible for providing innovative operational solutions and best practices
Advanced knowledge in SQL/Hive, Spark, NoSQL, (Java/Python is a plus
Strong programming skills and ability to utilize a variety of software/languages/tools; e.g., Spark, R, Python, Scala, Java, Hive, SQL, SAS, Tableau, etc.
Experience with microservice development, Docker, Kubernetes
Develop software to run on cloud native big data infrastructure built on AWS using Spark, Lambda, S3, and other cloud native services
Designs and develops complex and large-scale data structures and pipelines to organize, collect and standardize data to generate insight
3+ years of experience in data integration platforms (Informatica, Talend)
Hands on experience in self-service data preparation tool like Alteryx
Experience using GitHub, Bit Bucket, or other code repository solution
DevOps experience is a plus
Skills / Other Personal Attributes Required:
Previous management experience and successfully leading a team of direct reports
Proven track record of effectively leading and managing employees, managing performance, setting goals for team/individuals and provide mentoring.
Strong Tableau, Adobe Analytics other BI solution
Expert Oracle and Vertica skillsets
Experience using JIRA and Agile Project Management software
Experience using GitHub, Bit Bucket, or other code repository solution
Strong written, verbal communication and presentation skills
Ability to explain complex technical issues in a way that non-technical people may understand
Able to work in a global, multicultural environment
Self-motivated. Capable of working with little or no supervision
Ability to react positively under pressure to meet tight deadlines
Able to work independently or as a team player
Enjoy challenging and thought provoking work and have a strong desire to learn and progress
Formal Education: (minimum requirement to perform job duties)
BS in Computer Science, Applied Mathematics, Physics, Statistics or area of study related to data sciences and data mining or relevant experience
FLSA (US Only): Exempt

The above information on this description has been designed to indicate the general nature and level of work performed by employees within this role. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications required of employees assigned to this job. The job holder may be required to perform other duties as deemed appropriate by their manager from time to time.

Invesco's culture of inclusivity and its commitment to diversity in the workplace are demonstrated through our people practices. We are proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, creed, color, religion, sex, gender, gender identity, sexual orientation, marital status, national origin, citizenship status, disability, age, or veteran status. Our equal opportunity employment efforts comply with all applicable U.S. state and federal laws governing non-discrimination in employment."
57,Senior Data Engineer - Governance,"Alpharetta, GA 30009",Alpharetta,GA,30009,None Found,None Found,None Found,None Found,None Found,None Found,"Your responsibilities
thyssenkrupp Elevator Corporation is seeking a Sr. Data Engineer - Governance in Alpharetta, GA. The Sr. Data Engineer to be responsible for data engineering activities and aiding in building the business’ information systems, data governance, data management, data integration and data warehouse for key business areas including but not limited to Manufacturing, Engineering, Spare Parts and Supply Chain. The role of the Senior Data Engineer is responsible for building and maintaining optimized and highly available data that facilitate deeper analysis, quality data, metadata and reporting for the various systems and Analytics groups which supports relevant tkE. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. RESPONSIBILITIES:
Partner with Data Owners and Data Stewards to design solutions that align to data governance and data management principles and best practices
Design data models for key program processes and data entities and ensure integration of logical data model into the enterprise conceptual data model and physical data models
Build and maintain reliable and scalable ETL on data platforms that support critical business functions and analytics’ functions of the organization
Ensures regulatory issues are considered surrounding data assets (such as consumer privacy laws, data retention policies
Recognize and resolve conflicts between models, ensuring that data models are consistent with the enterprise model (e.g., entity names, relationships and definitions).
Partner with Quality Teams on Six Sigma methodology to ensure data and processes are properly aligned and efficient
Creates the principles, models, designs and systems that strengthen the network effect of sharing such data across the enterprise
Plans data architecture and design by studying the solution concept, strategy, and target audience and by envisioning architectural scheme, data structure and features, functionality, and user-interface design.
Implements a discipline and approach to managing data assets and converting the principles of the architecture into a technology solution
Required to draft reports and prepare presentations for senior leadership. These reports and presentation must be clear, concise, unambiguous, engaging and convincing, which will demand exceptional communication skills
Leads the design of the data architecture, across multiple data domains and sub-domains.
Coordinates new development activities and ensures they are consistent and well-integrated with the established ecosystem data architecture
Creates ecosystem models (e.g. conceptual, logical, canonical) that are required for supporting services within the enterprise data
Reviews and approves data model designs with a focus on those areas influencing interoperability, analytics including compliance with the portfolio information model
Your profile
QUALIFICATIONS:
Bachelor’s degree (B.A. / B.S.) in Information Technology or Computer Science or related field or the equivalent combination of education and experience
Must have had at least 5 years of working experience working in a data engineering department, preferably as a Data Engineer in a fast-paced environment and complex business setting
Business domain, data/content and process understanding of Manufacturing, Engineering, Spare Parts and Supply Chain
System integration experience, including interface design, and familiarity with web-oriented architecture techniques
Data modeling and information classification expertise at an enterprise level
Experience with Master Data Management, Metadata Management, Data Integration, Data Migration, Data Governance design and implementation techniques leveraging data management tools such as SAP MDG, Informatica or Talend
Experience with distributed management and analytics in cloud and hybrid environments with an understanding of a variety of data access and analytics approaches such as micro-services and event-based architectures
PREFERRED QUALIFICATIONS:
Experience with designing and implementing self-service models
Hands-on experience with implementing data and analytics management programs
Our offer to you
Safety at work and Healthcare
Safety at work & Healthcare: Highest standards in occupational safety and health, comprehensive programs and measures for safety at work and preventive healthcare with comprehensive coverage and flexible options.
Security for the future
Financial security for your individual retirement plan.
Collaboration
Respect, recognition and appreciation of the contribution of everyone. Regular team - and social events.
Continuing development
Training and continuing developement options. Help to grow alongside with us, in personality and profession.
Compensation and benefits
We offer a lot: Fair working conditions and a reasonable, competitive compensation are the foundation for many more attractive benefits.
Diversity
Open, tolerant and constructive work environment with a team consistent of diverse views and backgrounds.
We work together closely and respect each other, for over 200 years. If that is just as important to you as it is to us, apply now!

To learn more about thyssenkrupp in North America, please visit our website:
https://www.thyssenkrupp-north-america.com
thyssenkrupp Elevator Corp. is an equal opportunity employer. Applicants will receive consideration for employment without regard to age, sex, race, color, religion, national origin, genetics, disability, gender identity, marital status, sexual orientation, veteran status or any other protected characteristic required by applicable law.

Applicants with disabilities who require reasonable accommodation in connection with the application process are encouraged to contact us directly at 1-844-427-5461."
58,Data Engineer,"Kennesaw, GA 30144",Kennesaw,GA,30144,None Found,"Experience with JavaScript/Java/ Python or Jitterbit and other developer languages.
Experience with Data Analytics.
Experience with Web Services and APIs.
Experience in the development of batch and real-time data integration and data consolidation processes.
Experience with machine learning, AI, and data lakes.
Proficiency in TSQL/PLSQL query-writing, stored procedure development, and views.
Strong analytical skills with ability for problem-solving.
Understands the importance of data provenance and the ability to demonstrate it to clients.
Detail oriented, organized, self-motivated.

",None Found,"Develop strategy for new multi-platform data integration and analytics.
Develop strategy for new multi-platform-sourced data lake.
Contribute to API strategy to facilitate application connectivity and analytics.
Contribute to the maintenance and evolution of best practices.
Contribute to process documentation.
Perform multiple proofs of concept (POCs).
Contribute to implementation plan for decided-upon solution(s).

",None Found,None Found,"Riskonnect is the leading integrated risk management software solution provider that empowers organizations to anticipate, manage and respond in real-time to strategic and operational risks across the extended enterprise. Riskonnect is the only provider ranked in the leadership and visionary quadrants by world renowned industry analysts - Gartner, Forrester and Advisen RMIS Review. We employ more than 500 risk professionals in the Americas, EMEA and Asia Pacific and serve over 900 customers across 6 continents. The combination of innovative risk technology, a customer success mindset, and employee-first belief makes Riskonnect a sought after place to work.
Responsibilities:
Develop strategy for new multi-platform data integration and analytics.
Develop strategy for new multi-platform-sourced data lake.
Contribute to API strategy to facilitate application connectivity and analytics.
Contribute to the maintenance and evolution of best practices.
Contribute to process documentation.
Perform multiple proofs of concept (POCs).
Contribute to implementation plan for decided-upon solution(s).

Required Qualifications:
Experience with JavaScript/Java/ Python or Jitterbit and other developer languages.
Experience with Data Analytics.
Experience with Web Services and APIs.
Experience in the development of batch and real-time data integration and data consolidation processes.
Experience with machine learning, AI, and data lakes.
Proficiency in TSQL/PLSQL query-writing, stored procedure development, and views.
Strong analytical skills with ability for problem-solving.
Understands the importance of data provenance and the ability to demonstrate it to clients.
Detail oriented, organized, self-motivated.

Preferred Qualifications:
Experience with Salesforce.
Experience in the Risk Management, Healthcare, Financial, and/or Insurance industries is recommended.
Experience with Financial data sets, involving financial validation."
59,Google Cloud Architect,"Alpharetta, GA 30005",Alpharetta,GA,30005,None Found,None Found,None Found,None Found,None Found,None Found,"Job Description

Merkle is looking for experienced Google Cloud professional to be part of its Cloud practice. You will be working on industry leading Google Cloud Platform (GCP) to design, develop, and implement next generation Marketing solutions leveraging Cloud native and Commercial/Open Source Big Data technologies.
Key Responsibilities
As a Senior Google Cloud Architect, you will
Be the force behind shaping the future of our Cloud strategy practice by leading innovation efforts and developing Intellectual Property
Be client facing in advising them on GCP optimized architectures for data management, help develop roadmaps for on-prem to Cloud migration efforts
Be hands-on in developing prototypes and conducting Proof of Concepts
Act as a trusted advisor to client on all things GCP
Lead team members on project involving data migration and implementation of new solutions on cloud platforms
Participate in crafting customer facing proposal responses
Participate in technical interactions with client’s executives and senior management
Mentor client/Merkle resources on GCP and its services
Evaluate and analyze new commercial/open-source services/technologies offered by public Cloud providers, and Big Data technology vendors
Interface with Cloud/Technology provider’s Product Managers, and Engineers
Develop reference architectures and design pattern library for typical Cloud based Marketing solutions implementations
Participate in creating new services capabilities, productized solution offerings and document implementation handbooks
Advise on Cloud project set up, security and role based access implementation, and network optimizations
Merkle is looking for experienced Google Cloud professional to be part of its Cloud practice. You will be working on industry leading Google Cloud Platform (GCP) to design, develop, and implement next generation Marketing solutions leveraging Cloud native and Commercial/Open Source Big Data technologies.
Key Responsibilities
As a Senior Google Cloud Architect, you will
Be the force behind shaping the future of our Cloud strategy practice by leading innovation efforts and developing Intellectual Property
Be client facing in advising them on GCP optimized architectures for data management, help develop roadmaps for on-prem to Cloud migration efforts
Be hands-on in developing prototypes and conducting Proof of Concepts
Act as a trusted advisor to client on all things GCP
Lead team members on project involving data migration and implementation of new solutions on cloud platforms
Participate in crafting customer facing proposal responses
Participate in technical interactions with client’s executives and senior management
Mentor client/Merkle resources on GCP and its services
Evaluate and analyze new commercial/open-source services/technologies offered by public Cloud providers, and Big Data technology vendors
Interface with Cloud/Technology provider’s Product Managers, and Engineers
Develop reference architectures and design pattern library for typical Cloud based Marketing solutions implementations
Participate in creating new services capabilities, productized solution offerings and document implementation handbooks
Advise on Cloud project set up, security and role based access implementation, and network optimizations

Qualifications

Key Skills and Experience
Be hands-on
Understanding of Google cloud computing technologies, business drivers, and emerging computing trends
Certified Google Cloud Data Engineer
Minimum 10 years experience in data warehouse/data engineering with strong hands-on experience in ETL
Proven track record of building technical and business relationships with senior executives
Proven track record of driving decisions collaboratively, resolving conflicts and ensuring follow up
Problem-solving mentality leveraging internal and/or external resources, where and when needed, to do what’s right for the customer
Exceptional verbal and written communication
Ability to coordinate across geographically dispersed team members and consolidate status for stakeholders
Ability to connect technology with measurable business value
Demonstrated technical thought leadership in customer facing situations

Requirements:
Certified Google Cloud Data Engineer
5+ years of technical management and though leadership role delivering success in complex data analytics environment, managing various stakeholders relationships to get consensus on solution
5+ year’s design and/or implementation of highly distributed applications
2+ years’ experience in “migrating” on premise workloads to one or more industry leading public cloud(s)
Demonstrated experience of designing and building Big Data solutions on GCP stack leveraging BigQuery, Dataproc, Dataflow, BigTable, Data Prep, etc.
5+ years experience using Python for building data pipelines
Technical architectural and development experience on Massively Parallel Processing technologies, such as Hadoop, Spark, Teradata, Netezza, Hadoop
Technical architectural and development experience on one or more Data Integration technologies, such as Ab Initio, Talend, Pentaho, Informatica, Data Stage, Map Reduce
Technical architectural experience on Data Visualization technologies, such as Tableau, Qlik, etc.
Technical architectural experience on data modeling, designing data structures for business reporting
Deep understanding of Advanced Analytics, such as predictive, prescriptive, etc.
Working knowledge of cloud components: Software design and development, Systems Operations / Management, Database architecture, Virtualization, IP Networking, Storage, IT Security
Technical prowess and passion-especially for public Cloud, modern Application design practices and principles. Certifications on Cloud Platform preferred.
Oversight experience on major transformation projects and successful transitions to operations support teams
Presentation skills with a high degree of comfort to both large and small audiences
Additional Information

Merkle fosters adiverse environment that encourages original thinking about our business andempowers us to communicate with a global world of customers. We embracedifferences of opinion and diversity of thought as they help us challenge andrefine our solutions. Merkle, as a best-in-class marketing agency, welcomes bigideas, and believes they can come from anywhere."
60,Azure Data Engineer,"Atlanta, GA 30303",Atlanta,GA,30303,None Found,"At least 5 years of consulting or client service delivery experience on Azure
",DevOps on an Azure platform,None Found,None Found," Proven ability to build, manage and foster a team-oriented environment
","Are you ready to step up to the New and take your technology expertise to the next level?
 Join Accenture and help transform leading organizations and communities around the world. The sheer scale of our capabilities and client engagements, in conjunction with the way we collaborate, operate and deliver value, provides an unparalleled opportunity to grow and advance. Choose Accenture and make delivering innovative work part of your extraordinary career.
 People in our Client Delivery & Operations career track drive delivery and capability excellence through the design, development and/ or delivery of a solution, service, capability or offering. They grow into delivery-focused roles, and can progress within their current role, laterally or upward. We partner with our clients to help transform their data into an ‘Appreciating Business Asset.’

As part of our Data Business Group, you will lead technology innovation for our clients through robust delivery of world-class solutions. You will build better software better! There will never be a typical day and that’s why people love it here. The opportunities to make a difference within exciting client initiatives are unlimited in the ever-changing technology landscape. You will be part of a highly collaborative and growing network of technology and data experts, who are taking on today’s biggest, most complex business challenges using the latest data and analytics technologies. We will nurture your talent in an inclusive culture that values diversity. You will have an opportunity to work in roles such as Data Scientist, Data Engineer, or Chief Data Officer covering all aspects of Data including Data Management, Data Governance, Data Intelligence, Knowledge Graphs, and IoT. Come grow your career in Technology at Accenture!

The Azure Technical Architect Delivery is responsible for delivering Data On Cloud projects for Azure based deals. The ideal candidate would also be responsible for developing and delivering Azure cloud solutions to meet todays high demand in areas such as AIML, IoT, advanced analytics, open source, enterprise collaboration, microservices, serverless, etc. The Azure Data Engineer is a highly performant engineer responsible for delivering Cloud based Big Data and Analytical Solutions at our clients. Responsibilities include evangelizing data on cloud solutions with customers, leading Business and IT stakeholders through designing a robust, secure and optimized Azure architectures and ability to be hands-on delivering the target solution. This role will work with customers and leading internal engineering teams in delivering big data soltuions on cloud. Using Azure public cloud technologies, our Data Engineer professionals implement state of the art, scalable, high performance Data On Cloud solutions that meet the need of todays corporate and emerging digital applications

 Role & Responsibilities:Provide subject matter expertise and hands on delivery of data capture, curation and consumption pipelines on Azure and HadoopAbility to build cloud data solutions and provide domain perspective on storage, big data platform services, serverless architectures, hadoop ecosystem, vendor products, RDBMS, DW/DM, NoSQL databases and security.Participate in deep architectural discussions to build confidence and ensure customer success when building new solutions and migrating existing data applications on the Azure platform.Conduct full technical discovery, identifying pain points, business and technical requirements, “as is” and “to be” scenarios.
- Build full technology stack of services required including PaaS (Platform as-a-service), IaaS (Infrastructure as-a-service), SaaS (software as-a-service), operations, management and automation.Apply Accenture methodology, Accenture reusable assets, and previous work experience to delivery consistently high-quality work.Stay educated on new and emerging technologies/patterns/methodologies and market offerings that may be of interest to our clients.Adapt to existing methods and procedures to create possible alternative solutions to moderately complex problems.Understand the strategic direction set by senior management as it relates to team goals.Use considerable judgment to define solution and seeks guidance on complex problems.Primary upward interaction is with direct supervisor. May interact with peers and/or management levels at a client and/or within Accenture. Establish methods and procedures
on new assignments with guidance.
Manage small teams of deliver engineers successfully delivering work efforts

 (if in an independent contributor role) at a client or within Accenture.
Extensive travel may be required

Basic Qualifications
At least 5 years of consulting or client service delivery experience on Azure
At least 5 years of experience in developing data ingestion, data processing and analytical pipelines for big data, relational databases, NoSQL and data warehouse solutions
Extensive experience providing practical direction within the Azure Native and HadoopMinimum of 5 years of hands-on experience in Azure and Big Data technologies such as Powershell, C#, Java, Node.js, Python, SQL, ADLS/Blob, Spark/SparkSQL, Hive/MR, Pig, Oozie and streaming technologies such as Kafka, EventHub, NiFI etc.
Extensive hands-on experience implementing data migration and data processing using Azure services: Networking, Windows/Linux virtual machines, Container, Storage, ELB, AutoScaling, Azure Functions, Serverless Architecture, ARM Templates, Azure SQL DB/DW, Data Factory, Azure Stream Analytics, Azure Analysis Service, HDInsight, Databricks Azure Data Catalog, Cosmo Db, ML Studio, AI/ML, etc.
 Cloud migration methodologies and processes including tools like Azure Data Factory, Event Hub, etc.
5+ years of hands on experience in programming languages such as Java, c#, node.js, python, pyspark, spark, SQL, Unix shell/Perl scripting etc.
Minimum of 5 years of RDBMS experience
Experience in using Hadoop File Formats and compression techniquesExperience working with Developer tools such as Visual Studio, GitLabs, Jenkins, etc.
Experience with private and public cloud architectures, pros/cons, and migration considerations.
Bachelors or higher degree in Computer Science or a related discipline.

Candidate Must Have Completed The Following Certifications
MCSA Cloud Platform (Azure) Training & Certification
MCSE Cloud Platform & Infratsructiure Training & Certification
MCSD Azure Solutions Architect Training & Certification

Nice-to-Have Skills/Qualifications:
DevOps on an Azure platform
Experience developing and deploying ETL solutions on Azure
IoT, event-driven, microservices, containers/Kubernetes in the cloud
Familiarity with the technology stack available in the industry for metadata management: Data Governance, Data Quality, MDM, Lineage, Data Catalog etc.
Familiarity with the Technology stack available in the industry for data management, data ingestion, capture, processing and curation: Kafka, StreamSets, Attunity, GoldenGate, Map Reduce, Hadoop, Hive, Hbase, Cassandra, Spark, Flume, Hive, Impala, etc.
- Multi-cloud experience a plus - Azure, AWS, Google

Professional Skill Requirements
 Proven ability to build, manage and foster a team-oriented environment
 Proven ability to work creatively and analytically in a problem-solving environment
 Desire to work in an information systems environment
 Excellent communication (written and oral) and interpersonal skills
 Excellent leadership and management skills
 Excellent organizational, multi-tasking, and time-management skills
 Proven ability to work independently

All of our professionals receive comprehensive training covering business acumen, technical and professional skills development. You'll also have opportunities to hone your functional skills and expertise in an area of specialization. We offer a variety of formal and informal training programs at every level to help you acquire and build specialized skills faster. Learning takes place both on the job and through formal training conducted online, in the classroom, or in collaboration with teammates. The sheer variety of work we do, and the experience it offers, provide an unbeatable platform from which to build a career.

Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status).

Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.

Accenture is a Federal Contractor and an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities.

Equal Employment Opportunity

All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.

Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.

Accenture is committed to providing veteran employment opportunities to our service men and women."
