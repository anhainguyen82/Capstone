{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "import pandas as pd\n",
    "import requests\n",
    "from requests import get\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pulling all links off of the search pages (up to 3000) and putting them in a dataframe to scrape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_template=\"http://www.indeed.com/jobs?q=%22Data+Engineer%22&l=Houston%2C+TX&start={}\"\n",
    "max_results=250\n",
    "Linkdf=[]\n",
    "\n",
    "for start in range(0, max_results, 7):\n",
    "    url=url_template.format(start)\n",
    "    html=requests.get(url)\n",
    "    soup=BeautifulSoup(html.content,'html.parser', from_encoding=\"utf-8\")\n",
    "    \n",
    "    #for each in soup.find_all(a_=\"href\"):\n",
    "    page_links=soup.find_all('a',{'href':re.compile(\"/rc/\")})\n",
    "    for items in page_links:\n",
    "        Linkdf.append(items['href'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity Check\n",
    "len(Linkdf)\n",
    "#print(Linkdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This code allows the code to display the full website instead of truncating\n",
    "pd.set_option('display.max_colwidth',-1)\n",
    "\n",
    "#Moving it to a data frame\n",
    "data = {'links':Linkdf}\n",
    "df = pd.DataFrame(data, columns=['links'])\n",
    "\n",
    "#append indeed.com to the front of each\n",
    "df['Web'] = 'https://www.indeed.com'\n",
    "df['URL'] = df.Web.str.cat(df.links)\n",
    "\n",
    "#pull out just a list of the websites.\n",
    "websites=list(df['URL'])\n",
    "\n",
    "#Sanity Check\n",
    "#print(websites)\n",
    "len(websites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "websites1=set(websites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(websites1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looping through websites...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Title=[]\n",
    "Descriptions=[]\n",
    "Location=[]\n",
    "FullDescriptions=[]\n",
    "\n",
    "for url in websites1:\n",
    "    response=get(url)\n",
    "    soup=BeautifulSoup(response.text,'html.parser')\n",
    "    \n",
    "    description_containers= soup.find(class_='jobsearch-jobDescriptionText')\n",
    "    title_containers=soup.find('h3')\n",
    "    try:\n",
    "        location_containers=soup.find('',{'class':'jobsearch-CompanyInfoWithoutHeaderImage'}).find_all('div')[-1]\n",
    "    except:\n",
    "        location_containers='None Found'\n",
    "    \n",
    "    job_descriptions=str(description_containers)\n",
    "    job_title=str(title_containers.text)\n",
    "    try:\n",
    "        locations=str(location_containers.text)\n",
    "    except AttributeError:\n",
    "        locations = 'None Found'\n",
    "    try:\n",
    "        full_descriptions = str(description_containers.text)\n",
    "    except AttributeError:\n",
    "        full_descriptions= 'None Found'\n",
    "    \n",
    "    Descriptions.append(job_descriptions)\n",
    "    Title.append(job_title)\n",
    "    Location.append(locations)\n",
    "    FullDescriptions.append(full_descriptions)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting what we want from the Descriptions Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'Location' left in for sanity check. Should be removed once code is confirmed to work\n",
    "Descriptions_df = pd.DataFrame(columns = ['Title', 'Location','City', 'State', 'Zip', 'Country', 'Qualifications', 'Skills', 'Responsibilities', 'Education', 'Requirement', 'FullDescriptions'])\n",
    "Country = ['US', 'USA', 'United States', 'United States of Americal']\n",
    "States = ['AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', 'IA',\n",
    "          'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND',\n",
    "          'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY']\n",
    "\n",
    "for index, element in enumerate(Descriptions):\n",
    "    soup=BeautifulSoup(element,'lxml')\n",
    "    for values in list(Descriptions_df):\n",
    "        temp_tag = soup.find('b', text=re.compile(values))\n",
    "        try:\n",
    "            ul_tag = temp_tag.find_next('ul')\n",
    "            Descriptions_df.at[index,values] = ul_tag.text\n",
    "        except AttributeError:\n",
    "            Descriptions_df.at[index,values]=\"None Found\"\n",
    "        Descriptions_df.at[index,\"Title\"]=Title[index]\n",
    "        Descriptions_df.at[index,\"Location\"]=Location[index]\n",
    "        Descriptions_df.at[index,\"FullDescriptions\"]=FullDescriptions[index]\n",
    "        words = '|'.join(Country)\n",
    "        temp = re.findall(words, Location[index])\n",
    "        if len(temp) != 0:\n",
    "            Descriptions_df.at[index,\"Country\"] = temp[0]\n",
    "        words = '|'.join(States)\n",
    "        temp = re.findall(words, Location[index])\n",
    "        if len(temp) != 0:\n",
    "            Descriptions_df.at[index,\"State\"] = temp[0]\n",
    "        temp = re.findall(r'\\d+', Location[index])\n",
    "        if len(temp) != 0:\n",
    "            Descriptions_df.at[index,\"Zip\"] = temp[0]  \n",
    "            \n",
    "        temp = re.findall(r'[\\w w]+,', Location[index])\n",
    "        if len(temp) != 0:\n",
    "            Descriptions_df.at[index,\"City\"] = re.sub(',', '', temp[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Country</th>\n",
       "      <th>Qualifications</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Responsibilities</th>\n",
       "      <th>Education</th>\n",
       "      <th>Requirement</th>\n",
       "      <th>FullDescriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Delivery Director</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>The Company\\n-----------\\n\\nArundo is a software company based in Oslo, Norway; Houston, TX; and Palo Alto, CA, with presence in 7 locations in Europe and the Americas. Our software enables advanced analytics, machine learning, and IoT applications for more efficient, safer, and more effective physical systems in heavy industries such as energy, chemicals, and shipping. Founded in 2015, Arundo consists of around 100 software engineers, data scientists, designers, and industrial domain experts.\\n\\nOur team members are passionate about being part of a company that can solve tough problems and create innovative solutions. We believe in a fun environment, where our people can be fearless and feel empowered to always do the right thing. Arundites come from many different backgrounds including academia, industry, and even a submarine! We look for smart, creative thinkers with a player-coach mindset who can wear multiple hats and contribute to our exciting future!\\n\\nThe Role\\n--------\\n\\nOur Delivery Director is responsible for the delivery of Arundo SaaS software and data science solutions to our strategic customers -- enabling sustained business value capture. The Delivery Director is responsible for our portfolio of customers in the Americas region, including direct leadership of one or more customer deliveries. In addition, the role will have oversight of the regional Delivery function. Leading our Delivery function includes working with, data scientists, solution architects, software engineers, and field engineers to scope, develop and operationalize state-of-the-art machine learning and other analytical solutions. Moreover, the position includes direct management and mentorship of Delivery Leads, Field Engineers and Solution Architects. The position reports to the VP of Delivery for the Americas but will also have regular access and support from the General Manager Americas as well as Head of Data Science Americas.\\n\\nThe ideal Delivery Director combines industrial and enterprise software experience with a proven record in technology consulting and/or enterprise software implementation. Common for all is a passion for working with highly talented people in delivering customer value through advanced technical solutions.\\n\\nAs a Delivery Director, you work closely with your team to shape process, execution and solution design for customer projects and the implementation of a growing product portfolio, as well as working to improve our overall Delivery processes and standards.\\n\\nA key element of the position includes support of presales activities -- partnering with our sales team and our data science leadership to assess opportunities, manage risks and guide the prospective customer towards positive outcomes. In this role, you are a peer of the VP of Sales for the Americas and a trusted advisor of the sales executives as well as the prospective customer.\\n\\nWe value critical thinking, self-motivation, and the ability to deal with ambiguity. You should bring a cool head, have strong project management skills and a strong technological interest and background. You enjoy solving complex problems, you are a good communicator, and enjoy working closely with customers and talented people to deliver extraordinary results. And you will enjoy getting 'hands on' and learning our product/platform -- and even give product/solution demos to our customers. We love people who innovate, use data to make decisions, and can express themselves thoughtfully. We want you to be passionate about delivering a great customer experience and love contributing to achieve excellence in all you do.\\n\\nResponsibilities\\n----------------\\n\\nCustomer project delivery leadership\\n\\n\\nResponsible for shaping projects and product implementation in the Americas through mentorship of your direct reports\\nConsulted for continued process and template refinement in a global fashion\\nResponsible for successful project delivery, leading a delivery team consisting of data scientists, solution architects, software engineers, and field engineers\\nResponsible for collecting and providing product feedback to our Product Management and Product Engineering teams\\nWorks with customers to identify and quantify opportunities to create business value through the use of machine learning and IoT technologies\\nConsulted on project scoping, scheduling, and delivery according to plan\\nHiring, weekly 1-on-1s, coaching and feedback\\nMentors team on collaborative design, development, and delivery efforts of customer solutions\\nIn some projects, leads project workshops such as kick-offs, executive touchpoints and key go-live activities in order to demonstrate excellence to your direct reports\\nBuilds professional rapport with customers and partners\\nMentors and cultivates excellence in customer reports and slide development and presentation\\n\\nPresales leadership\\n\\n\\nResponsible as an individual contributor and senior leader/mentor for executing presales activities such as discovery workshops and demos\\nResponsible for production and quality control of statements of work\\nConsulted on proposal templates and quality reviews for specific proposals\\nParticipation and presentation at external conferences and events; as well as writing blog articles and whitepapers\\n\\nQualifications\\n--------------\\n\\nEducation\\n\\n\\nBachelor's degree in Science, Technology, Engineering, Math or equivalent experience\\n\\nNeeded Work Experience\\n\\n\\n7 or more years leading complex, technology-oriented projects in technology or industrial companies, or equivalent experience from management or technology consulting\\n3 or more years as an individual contributor in technical/presales activities conducting discovery, assessing/shaping scopes of work, demoing software and explaining project scoping (i.e. phases, assumptions, risk, roles/responsibilities)\\nDirect management experience: hiring, 1-on-1s, feedback, coaching and delegation\\nConsistent track record of strong results and impact in customer facing role for more than 5 years\\nOperational domain knowledge from an industrial environment (oil and gas E&amp;P or process manufacturing); ideally, as a practitioner but a technologist or consultant into those industries are considered as well\\n\\nPreferred Work Experience\\n\\n\\nExperience with I0T, cloud technology and/or development of machine learning models\\nConceptual, end-user or installation knowledge of industrial technology such as HMI, PLC, DCS, process historians, alarm management &amp; other such applications\\nExperience as a software or data engineer using modern languages and PaaS development is an advantage; as is having lead software-related transformations\\n\\nPersonal Skills and Capabilities\\n\\n\\nStrong people leadership skills with the ability to motivate and inspire others to achieve great results\\nHighly analytical and strong problem-solving skills\\nWritten and verbal communication skills\\nEnjoys crafting beautiful and clear customer presentations\\nEnjoys working in a dynamic and customer-focused environment\\nStrong listening skills and the ability to identify and resolve issues\\nAbility to maintain composure in complex and stressful situations\\nResponds to customer needs quickly and effectively, and is able to adapt to changes to deliver results\\nAble to lead complex customer and stakeholder relationships\\n\\nWho are we?\\n-----------\\n\\n\\nWe are a values driven company with an inclusive and autonomous culture\\nWe have highly talented and dedicated people\\nWe work in a collaborative environment with our offices in the US and EMEA\\nYou'll have the opportunity to work with cutting edge technology\\nWe have a FUN environment - we take fun seriously and have appointed a VP of Fun\\nWe have regular team building activities\\nWe have several social clubs of own choice (Data Science Club, Running Club, Females@Arundo)\\nWe collaboration with Stanford/StartX and MIT/STEX25\\nWe're at a prime location with nice facilities in Downtown Houston\\nWe have a free snack bar and Old-school arcade games in the office\\nCompetitive salary, and participation in our employee stock option plan\\nBenefits plan including 401k retirement plan\\n\\nWe are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\\n\\nLocation\\n--------\\n\\nHouston, TX\\n\\nTravel\\n------\\n\\n\\nIn general, most work is conducted from Arundo offices\\nRequired travel may approach 2-3 days per week during key phases in customer projects. But in general, Arundo does not favor a full on-site presence in our projects.\\n\\nAdditional Information\\n----------------------\\n\\n\\nYou must successfully pass a pre-employment background check and drug screen\\nYou are able to work for any US employer without requiring sponsorship\\n\\nThis job description is intended to describe the general nature and level of the work being performed by individuals in the position. It is not intended to include every job duty and responsibility specific to the position. Arundo reserves the right to amend and change responsibilities to meet business and organizational needs as necessary.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Azure Data Engineer</td>\n",
       "      <td>Houston, TX 77006</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>77006</td>\n",
       "      <td>None Found</td>\n",
       "      <td>At least 5 years of consulting or client service delivery experience on Azure\\n</td>\n",
       "      <td>DevOps on an Azure platform</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Proven ability to build, manage and foster a team-oriented environment\\n</td>\n",
       "      <td>Are you ready to step up to the New and take your technology expertise to the next level?\\n Join Accenture and help transform leading organizations and communities around the world. The sheer scale of our capabilities and client engagements, in conjunction with the way we collaborate, operate and deliver value, provides an unparalleled opportunity to grow and advance. Choose Accenture and make delivering innovative work part of your extraordinary career.\\n People in our Client Delivery &amp; Operations career track drive delivery and capability excellence through the design, development and/ or delivery of a solution, service, capability or offering. They grow into delivery-focused roles, and can progress within their current role, laterally or upward. We partner with our clients to help transform their data into an ‘Appreciating Business Asset.’\\n\\nAs part of our Data Business Group, you will lead technology innovation for our clients through robust delivery of world-class solutions. You will build better software better! There will never be a typical day and that’s why people love it here. The opportunities to make a difference within exciting client initiatives are unlimited in the ever-changing technology landscape. You will be part of a highly collaborative and growing network of technology and data experts, who are taking on today’s biggest, most complex business challenges using the latest data and analytics technologies. We will nurture your talent in an inclusive culture that values diversity. You will have an opportunity to work in roles such as Data Scientist, Data Engineer, or Chief Data Officer covering all aspects of Data including Data Management, Data Governance, Data Intelligence, Knowledge Graphs, and IoT. Come grow your career in Technology at Accenture!\\n\\nThe Azure Technical Architect Delivery is responsible for delivering Data On Cloud projects for Azure based deals. The ideal candidate would also be responsible for developing and delivering Azure cloud solutions to meet todays high demand in areas such as AIML, IoT, advanced analytics, open source, enterprise collaboration, microservices, serverless, etc. The Azure Data Engineer is a highly performant engineer responsible for delivering Cloud based Big Data and Analytical Solutions at our clients. Responsibilities include evangelizing data on cloud solutions with customers, leading Business and IT stakeholders through designing a robust, secure and optimized Azure architectures and ability to be hands-on delivering the target solution. This role will work with customers and leading internal engineering teams in delivering big data soltuions on cloud. Using Azure public cloud technologies, our Data Engineer professionals implement state of the art, scalable, high performance Data On Cloud solutions that meet the need of todays corporate and emerging digital applications\\n\\n Role &amp; Responsibilities:Provide subject matter expertise and hands on delivery of data capture, curation and consumption pipelines on Azure and HadoopAbility to build cloud data solutions and provide domain perspective on storage, big data platform services, serverless architectures, hadoop ecosystem, vendor products, RDBMS, DW/DM, NoSQL databases and security.Participate in deep architectural discussions to build confidence and ensure customer success when building new solutions and migrating existing data applications on the Azure platform.Conduct full technical discovery, identifying pain points, business and technical requirements, “as is” and “to be” scenarios.\\n- Build full technology stack of services required including PaaS (Platform as-a-service), IaaS (Infrastructure as-a-service), SaaS (software as-a-service), operations, management and automation.Apply Accenture methodology, Accenture reusable assets, and previous work experience to delivery consistently high-quality work.Stay educated on new and emerging technologies/patterns/methodologies and market offerings that may be of interest to our clients.Adapt to existing methods and procedures to create possible alternative solutions to moderately complex problems.Understand the strategic direction set by senior management as it relates to team goals.Use considerable judgment to define solution and seeks guidance on complex problems.Primary upward interaction is with direct supervisor. May interact with peers and/or management levels at a client and/or within Accenture. Establish methods and procedures\\non new assignments with guidance.\\nManage small teams of deliver engineers successfully delivering work efforts\\n\\n (if in an independent contributor role) at a client or within Accenture.\\nExtensive travel may be required\\n\\nBasic Qualifications\\nAt least 5 years of consulting or client service delivery experience on Azure\\nAt least 5 years of experience in developing data ingestion, data processing and analytical pipelines for big data, relational databases, NoSQL and data warehouse solutions\\nExtensive experience providing practical direction within the Azure Native and HadoopMinimum of 5 years of hands-on experience in Azure and Big Data technologies such as Powershell, C#, Java, Node.js, Python, SQL, ADLS/Blob, Spark/SparkSQL, Hive/MR, Pig, Oozie and streaming technologies such as Kafka, EventHub, NiFI etc.\\nExtensive hands-on experience implementing data migration and data processing using Azure services: Networking, Windows/Linux virtual machines, Container, Storage, ELB, AutoScaling, Azure Functions, Serverless Architecture, ARM Templates, Azure SQL DB/DW, Data Factory, Azure Stream Analytics, Azure Analysis Service, HDInsight, Databricks Azure Data Catalog, Cosmo Db, ML Studio, AI/ML, etc.\\n Cloud migration methodologies and processes including tools like Azure Data Factory, Event Hub, etc.\\n5+ years of hands on experience in programming languages such as Java, c#, node.js, python, pyspark, spark, SQL, Unix shell/Perl scripting etc.\\nMinimum of 5 years of RDBMS experience\\nExperience in using Hadoop File Formats and compression techniquesExperience working with Developer tools such as Visual Studio, GitLabs, Jenkins, etc.\\nExperience with private and public cloud architectures, pros/cons, and migration considerations.\\nBachelors or higher degree in Computer Science or a related discipline.\\n\\nCandidate Must Have Completed The Following Certifications\\nMCSA Cloud Platform (Azure) Training &amp; Certification\\nMCSE Cloud Platform &amp; Infratsructiure Training &amp; Certification\\nMCSD Azure Solutions Architect Training &amp; Certification\\n\\nNice-to-Have Skills/Qualifications:\\nDevOps on an Azure platform\\nExperience developing and deploying ETL solutions on Azure\\nIoT, event-driven, microservices, containers/Kubernetes in the cloud\\nFamiliarity with the technology stack available in the industry for metadata management: Data Governance, Data Quality, MDM, Lineage, Data Catalog etc.\\nFamiliarity with the Technology stack available in the industry for data management, data ingestion, capture, processing and curation: Kafka, StreamSets, Attunity, GoldenGate, Map Reduce, Hadoop, Hive, Hbase, Cassandra, Spark, Flume, Hive, Impala, etc.\\n- Multi-cloud experience a plus - Azure, AWS, Google\\n\\nProfessional Skill Requirements\\n Proven ability to build, manage and foster a team-oriented environment\\n Proven ability to work creatively and analytically in a problem-solving environment\\n Desire to work in an information systems environment\\n Excellent communication (written and oral) and interpersonal skills\\n Excellent leadership and management skills\\n Excellent organizational, multi-tasking, and time-management skills\\n Proven ability to work independently\\n\\nAll of our professionals receive comprehensive training covering business acumen, technical and professional skills development. You'll also have opportunities to hone your functional skills and expertise in an area of specialization. We offer a variety of formal and informal training programs at every level to help you acquire and build specialized skills faster. Learning takes place both on the job and through formal training conducted online, in the classroom, or in collaboration with teammates. The sheer variety of work we do, and the experience it offers, provide an unbeatable platform from which to build a career.\\n\\nApplicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status).\\n\\nCandidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.\\n\\nAccenture is a Federal Contractor and an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities.\\n\\nEqual Employment Opportunity\\n\\nAll employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.\\n\\nJob candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.\\n\\nAccenture is committed to providing veteran employment opportunities to our service men and women.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sr Data Engineer</td>\n",
       "      <td>Houston, TX 77021</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>77021</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>MAJOR RESPONSIBILITIES:\\nDevelop and optimize the bioinformatics pipeline systems at Baylor Genetics.\\nDevelop and Install software and assist in administration of Linux systems in a virtualized environment, optimizing storage access and managing scientific software.\\nAssist in managing systems for the bioinformatics group.\\nDevelop software and modify existing software as needed.\\nHave deep experience with programming languages.\\nVast experience with using databases including relational and NoSQL structures.\\nJOB QUALIFICATIONS (REQUIRED):\\nComputer systems administration and programming background.\\n\\nSKILLS:\\nSenior Bioinformatics software Engineer (10+ years) with strong background in genomics.\\nGreat communication skills\\nExperience with building, optimizing, and architecting bioinformatic data pipelines\\nExperience with administration of Linux systems and software installation.\\nStrong experience with compiled programming languages (e.g. Java, C++, etc.) and interpreted programming languages (Python, Perl, bash etc.)\\nDeep knowledge of SQL and NoSQL databases and big data.\\nBackground with genomic cluster e.g. SLURM a plus.\\nExperience with optimizing a distributed system based on solr a plus.\\nWorking previously in health care related company a plus.\\nKnowledge of Agile methodology and frameworks like Scrum and Kanban a plus.\\n\\nBACKGROUND:\\nBachelor’s degree and ten (10) years background in bioinformatics software engineering and Linux/Unix Administration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AWS Data Engineer</td>\n",
       "      <td>Houston, TX 77006</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>77006</td>\n",
       "      <td>None Found</td>\n",
       "      <td>At least 5 years of Consulting or client service delivery experience on Amazon AWS (AWS)At least 5 years of experience in developing data ingestion, data processing and analytical pipelines for big data, relational databases, NoSQL and data warehouse solutionsExtensive experience providing practical direction within the AWS Native and HadoopExperience with private and public cloud architectures, pros/cons, and migration considerations.Minimum of 5 years of hands-on experience in AWS and Big Data technologies such as Java, Node.js, C##, Python, SQL, EC2, S3, Lambda, Spark/SparkSQL, Hive/MR, Pig, Oozie and streaming technologies such as Kafka, Kinesis, NiFI etc.Extensive hands-on experience implementing data migration and data processing using AWS services: VPC/SG, EC2, S3, AutoScaling, CloudFormation, LakeFormation, DMS, Kinesis, Kafka, Nifi, CDC processing Redshift, Snowflake, RDS, Aurora, Neptune, DynamoDB, Hive, NoSQL, Cloudtrail, CloudWatch, Docker, Lambda, Spark,Glue, Sage Maker, AI/ML, API GW, etc.5+ years of hands on experience in programming languages such as Java, c#, node.js, python, pyspark, spark, SQL, Unix shell/Perl scripting etc.Minimum of 5 years of RDBMS experienceExperience in using Hadoop File Formats and compression techniquesExperience working with DevOps tools such as GitLabs, Jenkins, CodeBuild, CoePipeline CodeDeploy, etc.Bachelors or higher degree in Computer Science or a related discipline.</td>\n",
       "      <td>DevOps on an AWS platform. Multi-cloud experience a plus.Experience developing and deploying ETL solutions on AWS using tools like Talend, Informatica, MatillionStrong in Java, C##, Spark, PySpark, Unix shell/Perl scriptingIoT, event-driven, microservices, containers/Kubernetes in the cloud</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Proven ability to build, manage and foster a team-oriented environment Proven ability to work creatively and analytically in a problem-solving environment Desire to work in an information systems environment Excellent communication (written and oral) and interpersonal skills Excellent leadership and management skills</td>\n",
       "      <td>Are you ready to step up to the New and take your technology expertise to the next level?\\n\\nJoin Accenture and help transform leading organizations and communities around the world. The sheer scale of our capabilities and client engagements, in conjunction with the way we collaborate, operate and deliver value, provides an unparalleled opportunity to grow and advance. Choose Accenture and make delivering innovative work part of your extraordinary career.\\n\\nPeople in our Client Delivery &amp; Operations career track drive delivery and capability excellence through the design, development and/ or delivery of a solution, service, capability or offering. They grow into delivery-focused roles, and can progress within their current role, laterally or upward. We partner with our clients to help transform their data into an ‘Appreciating Business Asset.’\\n\\nAs part of our Data Business Group, you will lead technology innovation for our clients through robust delivery of world-class solutions. You will build better software better! There will never be a typical day and that’s why people love it here. The opportunities to make a difference within exciting client initiatives are unlimited in the ever-changing technology landscape. You will be part of a highly collaborative and growing network of technology and data experts, who are taking on today’s biggest, most complex business challenges using the latest data and analytics technologies. We will nurture your talent in an inclusive culture that values diversity. You will have an opportunity to work in roles such as Data Scientist, Data Engineer, or Chief Data Officer covering all aspects of Data including Data Management, Data Governance, Data Intelligence, Knowledge Graphs, and IoT. Come grow your career in Technology at Accenture!\\n\\nThe Amazon AWS Data Engineer is responsible for delivering Data On Cloud projects for Amazon AWS based deals. The ideal candidate would be responsible for developing and delivering AWS cloud solutions to meet today’s high demand in areas such as AIML, IoT, advanced analytics, open source, enterprise collaboration, microservices, serverless, etc. The AWS Data Engineer is a highly performant engineer responsible for delivering Cloud based Big Data and Analytical Solutions at our clients. Responsibilities include building data on cloud solutions at customers, leading Business and IT stakeholders through designing a robust, secure and optimized AWS solutions and ability to be hands-on delivering the target solution. This role will work with customers and leading internal engineering teams in delivering big data soltuions on cloud. Using Amazon AWS public cloud technologies, our AWS Data Engineer professionals implement state of the art, scalable, high performance Data On Cloud solutions that meet the need of today’s corporate and emerging digital applications.\\n\\nRole &amp; Responsibilities:\\nProvide subject matter expertise and hands on delivery of data capture, curation and consumption pipelines on AWS and HadoopAbility to build cloud data solutions and provide domain perspective on storage, big data platform services, serverless architectures, hadoop ecosystem, RDBMS, DW/DM, NoSQL databases and security.Participate in deep architectural discussions to build confidence and ensure customer success when building new solutions and migrating existing data applications on the AWS platform.\\n- Build full technology stack of services required including PaaS (Platform as-a-service), IaaS (Infrastructure as-a-service), SaaS (software as-a-service), operations, management and automation.Apply Accenture methodology, Accenture reusable assets, and previous work experience to delivery consistently high-quality work.Stay educated on new and emerging technologies/patterns/methodologies and market offerings that may be of interest to our clients.Understand the strategic direction set by senior management as it relates to team goals.Use considerable judgment to define solution and seeks guidance on complex problems.Primary upward interaction is with direct supervisor. May interact with peers and/or management levels at a client and/or within Accenture. Establish methods and procedures\\non new assignments with guidance.Manage small teams of delivery engineers successfully delivering work efforts (if in an independent contributor role) at a client or within Accenture.Able to travel up to 100% (M-TH)\\n\\nBasic QualificationsAt least 5 years of Consulting or client service delivery experience on Amazon AWS (AWS)At least 5 years of experience in developing data ingestion, data processing and analytical pipelines for big data, relational databases, NoSQL and data warehouse solutionsExtensive experience providing practical direction within the AWS Native and HadoopExperience with private and public cloud architectures, pros/cons, and migration considerations.Minimum of 5 years of hands-on experience in AWS and Big Data technologies such as Java, Node.js, C##, Python, SQL, EC2, S3, Lambda, Spark/SparkSQL, Hive/MR, Pig, Oozie and streaming technologies such as Kafka, Kinesis, NiFI etc.Extensive hands-on experience implementing data migration and data processing using AWS services: VPC/SG, EC2, S3, AutoScaling, CloudFormation, LakeFormation, DMS, Kinesis, Kafka, Nifi, CDC processing Redshift, Snowflake, RDS, Aurora, Neptune, DynamoDB, Hive, NoSQL, Cloudtrail, CloudWatch, Docker, Lambda, Spark,Glue, Sage Maker, AI/ML, API GW, etc.5+ years of hands on experience in programming languages such as Java, c#, node.js, python, pyspark, spark, SQL, Unix shell/Perl scripting etc.Minimum of 5 years of RDBMS experienceExperience in using Hadoop File Formats and compression techniquesExperience working with DevOps tools such as GitLabs, Jenkins, CodeBuild, CoePipeline CodeDeploy, etc.Bachelors or higher degree in Computer Science or a related discipline.\\n\\nCandidate Must Have Completed The Following Certifications\\n§ Certified AWS Developer - Associate\\n§ Certified AWS DevOps – Professional (Nice to have)\\n§ Certified AWS Big Data Specialty (Nice to have)\\n\\nNice-to-Have Skills/Qualifications:DevOps on an AWS platform. Multi-cloud experience a plus.Experience developing and deploying ETL solutions on AWS using tools like Talend, Informatica, MatillionStrong in Java, C##, Spark, PySpark, Unix shell/Perl scriptingIoT, event-driven, microservices, containers/Kubernetes in the cloud\\nExperience in Apache Maven a plusUnderstanding and implementation of Data Lake architecturesUnderstanding NoSQL technologies such as MongoDB, Cassandra, Hbase is a plusUnderstanding Solr, Elasticsearch is a plus\\n\\nProfessional Skill Requirements Proven ability to build, manage and foster a team-oriented environment Proven ability to work creatively and analytically in a problem-solving environment Desire to work in an information systems environment Excellent communication (written and oral) and interpersonal skills Excellent leadership and management skills\\n\\nAll of our professionals receive comprehensive training covering business acumen, technical and professional skills development. You'll also have opportunities to hone your functional skills and expertise in an area of specialization. We offer a variety of formal and informal training programs at every level to help you acquire and build specialized skills faster. Learning takes place both on the job and through formal training conducted online, in the classroom, or in collaboration with teammates. The sheer variety of work we do, and the experience it offers, provide an unbeatable platform from which to build a career.\\n\\nApplicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status).\\n\\nCandidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.\\n\\nAccenture is a Federal Contractor and an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities.\\n\\nEqual Employment Opportunity\\n\\nAll employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.\\n\\nJob candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.\\n\\nAccenture is committed to providing veteran employment opportunities to our service men and women.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020 University New Hire - Data Engineer</td>\n",
       "      <td>Houston, TX 77042</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>77042</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>JOIN US IN PROVIDING ENERGY AND IMPROVING LIVES.\\n\\nAt Phillips 66, we Provide Energy and Improve Lives, guided by our values of Safety, Honor and Commitment. Phillips 66 is dedicated to helping University New Hires make a smooth transition into the professional world. That is why we have developed career-specific programs designed to give you the tools you need to maximize your potential and succeed in your new career.\\n\\nInformation Technology (IT) is a valued business partner inside Phillips 66, driving digital transformation through the use of new technologies and delivery processes to impact the bottom line. By using agile product management and a DevOps approach to delivery, IT at Phillips 66 works directly with the businesses on their highest priorities. We believe in continuous learning and through our Digital University, we commit to making the latest skills training available throughout your career.\\n\\nAs a Phillips 66 IT University New Hire , you will have the unique opportunity to undergo a rigorous and exciting six-week program, Experience 66. The program provides you with a solid foundation to help jump start your career at Phillips 66 before beginning your new role.\\n\\nFollowing this program, you will move into the role of Data Engineer New Hire where you will play a key role in contributing to the success of advanced analytics and artificial intelligence projects across the company, by partnering with respective business owners and leveraging data to identify areas of improvement &amp; optimization. The role sits in the sweet spot between technology and business worlds and provides opportunity for high business impact and working with seasoned business leaders. Start your career at our headquarters in Houston, TX.\\n\\nResponsibilities:\\nCreate systems for storing, extracting, transferring, loading, and modeling big data to be used for both production systems and machine learning projects\\n\\nImplement data engineering systems in Microsoft Azure, AWS, HANA and other systems, including open source data science tools to meet the needs of our internal customer.\\n\\nBuild end-to-end solutions to solve high value business needs in a sustainable, innovative manner\\n\\nEngage in constant process improvement, always looking for opportunities to increase efficiency and reduce failures\\n\\nRequirements for a Phillips 66 Data Engineer University New Hire:\\n\\nBasic/Required:\\nLegally authorized to work in the job posting country\\n\\nPursuing a Bachelor’s or Master’s degree in Computer Science, Analytics, Data Science, Engineering, Mathematics, or equivalent field of study\\n\\nGraduating in Winter 2019 or Spring/Summer 2020\\n\\nPreferred:\\nA minimum cumulative GPA of 3.0 on a 4.0 scale\\n\\nPrevious internship or co-op participant in related industry\\n\\nPrevious internship with Phillips 66\\n\\nPhillips 66 SHIELD Scholar recipient\\n\\nWilling to work in any of our operating locations\\n\\nProficiency in R or Python and familiarity with data science packages in that language\\n\\nUnderstanding of Computer Science fundamentals in object-oriented design, data structures, algorithm design, cloud technologies and problem solving\\n\\nFamiliarity with Agile Development\\n\\nTo apply and be considered:\\nYou must apply through your university prior to university deadlines (if applicable) AND\\n\\nApply online by going to http://www.p66oncampus.jobs and complete the entire application process\\n\\nAttach an electronic copy of your resume and unofficial transcript\\n\\nAnswer all prescreening questions and provide your eSignature\\n\\nCandidates for regular U.S. positions must be a U.S. citizen or national, or an alien admitted as permanent resident, refugee, asylee or temporary resident under 8 U.S.C. 1160(a)(1). Individuals with temporary visas such as E, F-1, H-1, H-2, L, B, J, or TN or who need sponsorship for work authorization now or in the future, are not eligible for hire.\\n\\nAbout Phillips 66\\n\\nPhillips 66 is a diversified energy manufacturing and logistics company. With a portfolio of Midstream, Chemicals, Refining, and Marketing and Specialties businesses, the company processes, transports, stores and markets fuels and products globally. Phillips 66 Partners, the company’s master limited partnership, is integral to the portfolio. Headquartered in Houston, the company has 14,300 employees committed to safety and operating excellence. Phillips 66 had $58 billion of assets as of March 31, 2019. For more information, visit http://www.phillips66.com/ or follow us on Twitter @Phillips66Co and @P66oncampus.\\n\\nPhillips 66 is an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities\\n\\nRequisition ID: 51351\\n\\nLocation: Texas - Houston\\n\\nJob Field: Internships, Graduate Positions, and Student Programs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Houston, TX 77072</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>77072</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Enhance and further develop Big Data processing pipelines for data sources containing structured and unstructured data\\nData Warehousing with Data modeler experience\\nMonitor and optimize key infrastructure components such as Databases, EC2 Clusters, and other aspects of the stack\\nHelp promote best practices for Big Data development\\nAct as a bridge between the infrastructure and application engineering teams\\nProvide infrastructure support with a focus on cloud based computing\\nBuild and support visualization and exploration capabilities around our Data Sets\\nWork with the Data Extraction and Data Science engineers on normalization and analytical processes\\nWork in an Agile manner with business users and data scientists to understand and discover the potential business value of new and existing Data Sets and help productize those discoveries\\nHelp design and implement disaster recovery efforts\\nAnalyze requirements and architecture specifications to create detailed design\\nResearch areas of interest to the team and help facilitate solutions\\nDesign Cloud Architecture, SaaS, PaaS, and SaaS\\n</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Tailored Brands, Inc.’s purpose is to help our customers love how they look. We accomplish this by providing a personal, convenient, one-of-a-kind shopping experience with compelling products and world-class service. We help fulfill this mission by providing our employees with an engaging and inclusive workplace focused on teamwork, growth and respect.\\n\\n\\nTailored Brands currently has an exciting opportunity to join our engineering team consisting of developers from a wide array of backgrounds. Our data team primarily focuses on Java, SQL and Python. Our team is a tight knit, friendly group of engineers that are dedicated to learning from and teaching to each other. Team members regularly contribute to and optimize our engineering practices and processes.\\n\\n\\nKey Responsibilities:\\nEnhance and further develop Big Data processing pipelines for data sources containing structured and unstructured data\\nData Warehousing with Data modeler experience\\nMonitor and optimize key infrastructure components such as Databases, EC2 Clusters, and other aspects of the stack\\nHelp promote best practices for Big Data development\\nAct as a bridge between the infrastructure and application engineering teams\\nProvide infrastructure support with a focus on cloud based computing\\nBuild and support visualization and exploration capabilities around our Data Sets\\nWork with the Data Extraction and Data Science engineers on normalization and analytical processes\\nWork in an Agile manner with business users and data scientists to understand and discover the potential business value of new and existing Data Sets and help productize those discoveries\\nHelp design and implement disaster recovery efforts\\nAnalyze requirements and architecture specifications to create detailed design\\nResearch areas of interest to the team and help facilitate solutions\\nDesign Cloud Architecture, SaaS, PaaS, and SaaS\\n\\nRequired Experience:\\nBachelor’s degree in Computer Science or Information Systems required; Masters preferred\\n3-5 years minimum retail work experience (preferred) with:\\nProduction deployments\\nTraditional ETL, SQL and RDBMS: Oracle, MSSQL, MySQL, DataStage, and Talend\\nObject Oriented programming languages development (Java/Python preferred) as well as SQL and Unix Shell scripting\\nModern data technical stack experience such as: Hadoop, Hive, Pig, Sqoop, Flume, MapReduce, Spark, Storm, Apex, Kafka, NiFi, HBase, and MongoDB\\nKnowledge and experience with:\\nDatalakes design, Teradata and/or Snowflake (preferred)\\nNice to have AWS and Azure Cloud\\nBigData technologies and techniques, NoSQL systems (Hortonworks/Hadoop Ecosystem, Cassandra, Couchbase)\\n\\n\\nRequired Experience, continued:\\nExposure working with:\\nRest/SOAP clients\\nRelational and Non-relational Data Modeling\\nData Warehousing concepts\\nFamiliarity with:\\nGit/SVN\\nUC4 and BMC Control-M\\nJboss/JavaEE\\nObject Oriented Design Patterns\\nSerialization technologies such as Apache Avro\\nMicroStrategy and Tableau Data Visualization concepts\\n#LI-JE1\\nWork Environment, Physical &amp; Mental Demands\\nAbility to sit and work at a computer keyboard for extended periods of time\\nAbility to stoop, kneel, bend at the waist, and reach on a daily basis\\nAble to lift and move up to 25 pounds occasionally\\nMust utilize visual acuity, speech and hearing, hand and eye coordination and manual dexterity necessary to operate a computer and office equipment\\nHours may exceed 40 hours per week+\\n\\nNote: To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed are representative of the knowledge, skill, and/or ability required and is not intended to be an exhaustive list of all duties, responsibilities or qualifications associated with this job.\\n\\n\\n\\nWork Locations: 01099I IT Dept. 6380 Rogerdale Rd Houston 77072\\nJob: Information Technology (IT)\\nOrganization: Tailored Shared Services\\nShift: Day Job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Engineer, Energy Platform - Houston, TX</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Legal authorization to work in the US on a full-time basis for anyone other than current employer\\nBachelor's degree in a relevant technical discipline.\\n5+ years of experience with demonstrable proficiency in one or more DB and data pipeline tooling: mySQL, PostgreSQL, OSI Pi historian, TimescaleDB, Streamsets, Apache Drill, Apache Parquet, Dremio …\\nYou are passionate about building scalable, high performing, data pipelines, and analytic catalogs.\\nExperience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc\\nProficient with Containerized environments and workloads\\nExcellent analytical, problem-solving, and troubleshooting skills.\\nExperience architecting, deploying, and supporting production applications.\\nYou care deeply about performance, accessibility and API design.\\nGreat communication skills.\\nWork locations may include Houston, TX or San Francisco, CA</td>\n",
       "      <td>Job Description\\nIf you want to bring your technical expertise, ‘challenge-accepted!’ mentality and passion for building amazing products with real-world impact for hundreds of millions of people come join our group! We have been looking for you! We have an amazing team with deep backgrounds across technology and energy.\\n\\nShell New Energies\\n\\nShell is leading the transition towards a low-carbon future. We aim to cut the net carbon footprint of our energy products in half by 2050. Our New Energies business, set up in 2016, supports this ambition. New Energies is an emerging opportunity, in which we plan to invest on average $1-2 billion a year until 2020 as we look for commercial investments in new and fast-growing segments of the energy industry.\\n\\nShell New Energies focuses on two areas: new fuels and power. New Fuels consists of investments in hydrogen, biofuels, and electric vehicle charging. In Power, we are building up positions across the full electricity value chain, including in renewable generation, retail energy, distributed energy resources, power trading and marketing, and grid services. Within these focus areas, we look for ways to connect customers with new business models for mobility and energy services, enabled by digital technologies and decentralization of energy systems. Development of our IoT platform for Shell New Energy will be paramount in achieving these goals.\\n\\nEnergy Platform Team\\n\\nThe Energy Platform team is a nimble, cross-functional, deeply technical and passionate group that embodies the speed and agility of a startup while embracing the scale of one of the largest companies in the world. Achieving a balance between agility and global scale provides unique opportunities, and the Energy Platform Team borrows from best-in-class product development, continuous delivery, and commercialization techniques while adapting them to the unique global context within Shell.\\n\\nThe Energy Platform team is empowered to coordinate and align Shell’s energy management platform objectives, strategies, and execution approaches across the company, as well as to design, deliver and maintain a mission-critical component of Shell’s ability to deliver differentiated products, offerings,and capabilities across its expanding global footprint.\\n\\nWe are looking for a Data Engineer with the ability to bring their expertise and excitement for solving complex problems while building one of the largest IoT platforms in the world. There will be no shortage of opportunities to lead, eat, drink, and be merry with the most dynamic team ever assembled in the energy industry.\\n\\nBuild, on a daily basis, real-time and big data processing pipelines, optimizing for scalability and performance, under multiple datastore concepts (Relational, NoSQL, Graph).\\nProficient in building large scale ETL jobs, leveraging big data infrastructure (Hadoop, Spark, Kafka) and modern container orchestration environments (Kubernetes).\\nComfortable working in a fast-paced environment building, running, testing and shipping data pipelines to serve ML/AI workloads under a common API.\\nWilling to work with a cross-functional team of market analysts, data scientists &amp; software developers to translate their data needs into features inside the Energy Platform.\\nCreate data tooling that assists data scientists and analysts in building low latency, scalable and resilient pipelines for machine learning and optimization workloads.\\nEnthusiast of data quality, lifecycle and provenance management, helping establish a DataOps centric culture within Engineering teams.\\nAdvanced working knowledge of query authoring and tooling for cross source data aggregation: APIs, 3rd party DB, Object Storages, messaging bus.\\nYou have a proven history of working on large scale ETL jobs for data wrangling and cleansing of IoT time-series &amp; telemetry data, as well as IIoT unstructured datasets, focusing on serving machine learning orchestrations.\\nYou have experience with Analytical Expression Compiling languages, for runtime analytics during SQL querying.\\nRequirements\\nLegal authorization to work in the US on a full-time basis for anyone other than current employer\\nBachelor's degree in a relevant technical discipline.\\n5+ years of experience with demonstrable proficiency in one or more DB and data pipeline tooling: mySQL, PostgreSQL, OSI Pi historian, TimescaleDB, Streamsets, Apache Drill, Apache Parquet, Dremio …\\nYou are passionate about building scalable, high performing, data pipelines, and analytic catalogs.\\nExperience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc\\nProficient with Containerized environments and workloads\\nExcellent analytical, problem-solving, and troubleshooting skills.\\nExperience architecting, deploying, and supporting production applications.\\nYou care deeply about performance, accessibility and API design.\\nGreat communication skills.\\nWork locations may include Houston, TX or San Francisco, CA\\nCompany Description\\nShell is a global group of energy and petrochemical companies with about 84,000 employees across more than 70 countries. We aim to meet the world’s growing need for more and cleaner energy solutions in ways that are economically, environmentally and socially responsible. We have expertise in exploration, production, refining and marketing of oil and natural gas, and the manufacturing and marketing of chemicals. As a global energy company operating in a challenging world, we set high standards of performance and ethical behaviors. We are judged by how we act and how we live up to our core values of honesty, integrity and respect for people. Our Business Principles are based on these. They promote trust, openness, teamwork and professionalism, as well as pride in what we do and how we conduct business.Building on our core values, we aspire to sustain a diverse and inclusive culture where everyone feels respected and valued, from our employees to our customers and partners. A diverse workforce and an inclusive work environment are vital to our success, leading to greater innovation and better energy solutions.\\nDisclaimer\\nPlease note: We occasionally amend or withdraw Shell jobs and reserve the right to do so at any time, including prior to the advertised closing date.\\n\\nBefore applying, you are advised to read our data protection policy. This policy describes the processing that may be associated with your personal data and informs you that your personal data may be transferred to Royal Dutch/Shell Group companies around the world.\\n\\nThe Shell Group and its approved recruitment consultants will never ask you for a fee to process or consider your application for a career with Shell. Anyone who demands such a fee is not an authorised Shell representative and you are strongly advised to refuse any such demand.\\n\\nShell participates in E-Verify.\\n\\nAll qualified applicants will receive consideration for employment without regard to race, color, sex, national origin, age, religion, disability, sexual orientation, gender identity, protected veteran status, citizenship, genetic information or other protected status under federal, state or local laws.\\n\\nShell is an Equal Opportunity Employer - Minorities/Females/Veterans/Disability.\\nEmployment TypeFull Time\\nSkillpool\\nIT Data and Analytics, Information\\nWork LocationHouston\\nNo. of Positions\\n1\\nJob Expires01-Nov-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\n3+ years experience in data/software engineering or related field\\nFluency in Python and SQL, experience with Golang, C, C++, Java, or Scala is a plus\\nDemonstrated experience with distributed computing (Kafka, Storm, Spark, Hadoop, etc.)\\nExperience with NoSQL databases\\nProficiency in using and managing cloud infrastructure, preferably AWS\\nLinux and Bash competence\\nExperience integrating with Salesforce a plus</td>\n",
       "      <td>\\nEstablish and maintain best practices for our data infrastructure\\nDevelop next-gen data pipelining and ETL based on open source data pipeline tools and cloud-based ecosystems that can deal with varied data types from disparate sources\\nDevelop and tune data storage and processing systems at scale\\nBuild real-time data processing systems\\nBuild automated systems to continually monitor data quality and integrity\\nWork closely with stakeholders across Vroom to ensure data is accurate, timely, and useful</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Vroom.com is a venture-backed, fast-growing start-up focused on revolutionizing the car buying experience. Our approach is unique in that we recondition pre-owned vehicles to a high standard, sell online, and deliver anywhere across the US. We have experienced tremendous growth in our first 5 years of operation and have become a disruptive force in the automotive industry. Vroom is an exciting, accelerating workplace, and there's no better time to join the team than right now.\\n\\nWe are building a team of experienced Data Engineers to ensure that our data infrastructure supports and helps drive the dramatic growth that we expect! We're looking for an exceptional data engineer to help us organize, test, and operationalize our data. Our business depends on putting the right data in front of the right people at the right time. As a Data Engineer in this dynamic environment, you will be instrumental in pulling data from multiple sources, performing extensive analysis, and applying a variety of data science models to provide our internal customers with recommendations and feedback.\\nResponsibilities\\nEstablish and maintain best practices for our data infrastructure\\nDevelop next-gen data pipelining and ETL based on open source data pipeline tools and cloud-based ecosystems that can deal with varied data types from disparate sources\\nDevelop and tune data storage and processing systems at scale\\nBuild real-time data processing systems\\nBuild automated systems to continually monitor data quality and integrity\\nWork closely with stakeholders across Vroom to ensure data is accurate, timely, and useful\\nSkills\\n3+ years experience in data/software engineering or related field\\nFluency in Python and SQL, experience with Golang, C, C++, Java, or Scala is a plus\\nDemonstrated experience with distributed computing (Kafka, Storm, Spark, Hadoop, etc.)\\nExperience with NoSQL databases\\nProficiency in using and managing cloud infrastructure, preferably AWS\\nLinux and Bash competence\\nExperience integrating with Salesforce a plus\\nBenefits\\n\\nThis full-time role offers competitive compensation; health, dental, and vision insurance through United Healthcare; a 401k plan; fully company-paid short term disability, long term disability, and life insurance; access to a healthcare concierge service with virtual visits; and 15 annualized days of paid vacation.\\n\\nBut our biggest benefit is being part of a low-ego, high performing team that's transforming the used car market into a modern, online and data-driven industry. We are looking for people who want to be a part of a contemporary startup culture. What gets us out of bed is working with talented people on a mission that matters.\\n\\nTo Apply\\n\\nIf you think you might be who we’re looking for, apply below with your resume and a cover letter telling us why you think you’d be a great addition to the team.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Manager Azure Data Engineer</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nLead, design, develop, and deliver large-scale Azure data systems, data processing, and data transformation projects.\\nExecute technical feasibility assessments and project estimates for moving databases and data processing to Azure.\\nDesign and advocate solutions using modern cloud technologies, design principles, integration points, and automation methods.\\nMentor and share knowledge with customers as well as provide architecture reviews, discussions, and prototypes.\\nParticipate in overall engagement from strategy, assessment, migration, and implementations.\\nWork with customers to deploy, manage, and audit best practices for cloud products.</td>\n",
       "      <td>\\n5 to 10 years of professional experience in the information technology industry.\\nBS in Computer Science or equivalent education/professional experience is required.</td>\n",
       "      <td>\\nDemonstrated experience designing, implementing, and supporting enterprise-grade technical solutions in the cloud for meeting complex business data requirements.\\nExperience with Databricks and using Spark for data processing.\\nExperience with Azure Data Factory – ADF.\\nAdvanced experience with different query languages (i.e. T-SQL, PostgreSQL, PL-SQL).\\nExperience designing and building data marts, warehouses, customer profile databases, etc.\\nExperience with data modeling, table design, and mapping business needs to data structures.\\nExperience with Azure Data Lake, Azure SQL Data Warehouse, and Cosmos DB are a plus.\\nExperience with Data Management Gateway, Azure Storage Options, Stream Analytics, and Event Hubs is a plus.\\nExperience with other cloud based big data architectures is a plus.</td>\n",
       "      <td>This position is for a Senior Azure Data Engineer within our North American team who will be designing and implementing Azure data projects for our clients. This qualified individual will work closely with clients to ensure that data technologies meet their needs and keep pace with the rapid changes in Publicis Sapient’s operations and policies/procedures.\\n\\nResponsibilities:\\nLead, design, develop, and deliver large-scale Azure data systems, data processing, and data transformation projects.\\nExecute technical feasibility assessments and project estimates for moving databases and data processing to Azure.\\nDesign and advocate solutions using modern cloud technologies, design principles, integration points, and automation methods.\\nMentor and share knowledge with customers as well as provide architecture reviews, discussions, and prototypes.\\nParticipate in overall engagement from strategy, assessment, migration, and implementations.\\nWork with customers to deploy, manage, and audit best practices for cloud products.\\nRequirements:\\nDemonstrated experience designing, implementing, and supporting enterprise-grade technical solutions in the cloud for meeting complex business data requirements.\\nExperience with Databricks and using Spark for data processing.\\nExperience with Azure Data Factory – ADF.\\nAdvanced experience with different query languages (i.e. T-SQL, PostgreSQL, PL-SQL).\\nExperience designing and building data marts, warehouses, customer profile databases, etc.\\nExperience with data modeling, table design, and mapping business needs to data structures.\\nExperience with Azure Data Lake, Azure SQL Data Warehouse, and Cosmos DB are a plus.\\nExperience with Data Management Gateway, Azure Storage Options, Stream Analytics, and Event Hubs is a plus.\\nExperience with other cloud based big data architectures is a plus.\\nExperience/Education:\\n5 to 10 years of professional experience in the information technology industry.\\nBS in Computer Science or equivalent education/professional experience is required.\\nPersonal Attributes:\\nStrong and innovative approach to problem solving and finding solutions.\\nExcellent communicator (written and verbal, formal, and informal).\\nFlexible and proactive/self-motivated working style with strong personal ownership.\\nAbility to multi-task and prioritize under pressure.\\nAbility to work independently with minimal supervision as well as in a team environment.\\nFlexibility and mobility is required to deliver this role as there may be requirements to spend time onsite with our clients to enable delivery of the first class services we pride ourselves in.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Azure Data Architect</td>\n",
       "      <td>Houston, TX 77006</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>77006</td>\n",
       "      <td>None Found</td>\n",
       "      <td>At least 5 years of consulting or client service delivery experience on Azure\\n</td>\n",
       "      <td>DevOps on an Azure platform</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Proven ability to build, manage and foster a team-oriented environment\\n</td>\n",
       "      <td>Are you ready to step up to the New and take your technology expertise to the next level?\\nJoin Accenture and help transform leading organizations and communities around the world. The sheer scale of our capabilities and client engagements, in conjunction with the way we collaborate, operate and deliver value, provides an unparalleled opportunity to grow and advance. Choose Accenture and make delivering innovative work part of your extraordinary career.\\nPeople in our Client Delivery &amp; Operations career track drive delivery and capability excellence through the design, development and/ or delivery of a solution, service, capability or offering. They grow into delivery-focused roles, and can progress within their current role, laterally or upward. We partner with our clients to help transform their data into an ‘Appreciating Business Asset.’\\n\\nAs part of our Data Business Group, you will lead technology innovation for our clients through robust delivery of world-class solutions. You will build better software better! There will never be a typical day and that’s why people love it here. The opportunities to make a difference within exciting client initiatives are unlimited in the ever-changing technology landscape. You will be part of a highly collaborative and growing network of technology and data experts, who are taking on today’s biggest, most complex business challenges using the latest data and analytics technologies. We will nurture your talent in an inclusive culture that values diversity. You will have an opportunity to work in roles such as Data Scientist, Data Engineer, or Chief Data Officer covering all aspects of Data including Data Management, Data Governance, Data Intelligence, Knowledge Graphs, and IoT. Come grow your career in Technology at Accenture!\\n\\nThe Azure Technical Architect Delivery is responsible for delivering Data On Cloud projects for Azure based deals. The ideal candidate would also be responsible for developing and delivering Azure cloud solutions to meet todays high demand in areas such as AIML, IoT, advanced analytics, open source, enterprise collaboration, microservices, serverless, etc. The Regional Azure Technical Architect is a highly performant Azure Architect responsible for delivering Cloud based Big Data and Analytical Solutions to our clients. Responsibilities include evangelizing data on cloud solutions with customers, leading Business and IT stakeholders through designing a robust, secure and optimized Azure architectures and ability to be hands-on delivering the target solution. This role will work with customers and leading internal data engineers in delivering big data solutions on cloud. Using Azure public cloud technologies, our Technical Architect professionals implement state of the art, scalable, high performance Data On Cloud solutions that meet the need of today's corporate and emerging digital applications.\\n\\nRole &amp; Responsibilities:Work with Sales and Bus Dev teams in providing Azure Technical Architecture expertise while pursuing client opportunities.Ability to build cloud architectures and provide prescriptive guidance across network, storage, Big Data Platform Services, serverless architectures, hadoop ecosystem, vendor products, RDBMS &amp; NoSQL databases and security.Participate in deep architectural discussions to build confidence and ensure customer success when building new solutions and migrating existing data applications on the Azure platform.Conduct full technical discovery, identifying pain points, business and technical requirements, “as is” and “to be” scenarios.\\n- Assess the full technology stack of services required including PaaS (Platform as-a-service), IaaS (Infrastructure as-a-service), SaaS (software as-a-service), operations, management and automation.Lead the discussions and early analysis of the cloud concepts as it relates to Clients’s Journey to Cloud methodology so that clear use cases are developed and prioritized as well as transitioning these concepts from ideas to proof-of-concepts all the way to production delivery with the full support of the appropriate teams.Compare solution alternatives across both technical and business parameters which support the define cost and service requirements.Apply Accenture methodology, Accenture reusable assets, and previous work experience to delivery consistently high-quality work.Stay educated on new and emerging technologies/patterns/methodologies and market offerings that may be of interest to our clients.Adapt to existing methods and procedures to create possible alternative solutions to moderately complex problems.Understand the strategic direction set by senior management as it relates to team goals.Use considerable judgment to define solution and seeks guidance on complex problems.Prepare and deliver product messaging in an effort to highlight value proposition and unique differentiators.Primary upward interaction is with direct supervisor. May interact with peers and/or management levels at a client and/or within Accenture. Establish methods and procedures\\non new assignments with guidance.\\nManage small teams of deliver engineers successfully delivering work efforts (if in an independent contributor role) at a client or within Accenture.\\nExtensive travel may be required\\n\\nQualifications\\nBasic Qualifications\\nAt least 5 years of consulting or client service delivery experience on Azure\\nAt least 10 years of experience in big data, database and data warehouse architecture and delivery\\nMinimum of 5 years of professional experience in 2 of the following areas:\\n§ Solution/technical architecture in the cloud\\n§ Big Data/analytics/information analysis/database management in the cloud\\n§ IoT/event-driven/microservices in the cloud\\nExperience with private and public cloud architectures, pros/cons, and migration considerations.\\nExtensive hands-on experience implementing data migration and data processing using Azure services: Networking, Windows/Linux virtual machines, Container, Storage, ELB, AutoScaling, Azure Functions, Serverless Architecture, ARM Templates, Azure SQL DB/DW, Data Factory, Azure Stream Analytics, Azure Analysis Service, HDInsight, Databricks Azure Data Catalog, Cosmo Db, ML Studio, AI/ML, etc.\\n Cloud migration methodologies and processes including tools like Azure Data Factory, Event Hub, etc.\\n - Familiarity with the Technology stack available in the industry for data management, data ingestion, capture, processing and curation: Kafka, StreamSets, Attunity, GoldenGate, Map Reduce, Hadoop, Hive, Hbase, Cassandra, Spark, Flume, Hive, Impala, etc.\\nBachelors or higher degree in Computer Science or a related discipline.\\n\\nCandidate Must Have Completed The Following Certifications\\nMCSA Cloud Platform (Azure) Training &amp; Certification\\nMCSE Cloud Platform &amp; Infratsructiure Training &amp; Certification\\nMCSD Azure Solutions Architect Training &amp; Certification\\n\\nNice-to-Have Skills/Qualifications:\\nDevOps on an Azure platform\\nExperience developing and deploying ETL solutions on Azure\\nStrong in Power BI, Java, C##, Spark, PySpark, Unix shell/Perl scripting\\nFamiliarity with the technology stack available in the industry for metadata management: Data Governance, Data Quality, MDM, Lineage, Data Catalog etc.\\n- Multi-cloud experience a plus - Azure, AWS, Google\\n\\nProfessional Skill Requirements\\n Proven ability to build, manage and foster a team-oriented environment\\n Proven ability to work creatively and analytically in a problem-solving environment\\n Desire to work in an information systems environment\\n Excellent communication (written and oral) and interpersonal skills\\n Excellent leadership and management skills\\n Excellent organizational, multi-tasking, and time-management skills\\n Proven ability to work independently\\n\\nAll of our professionals receive comprehensive training covering business acumen, technical and professional skills development. You'll also have opportunities to hone your functional skills and expertise in an area of specialization. We offer a variety of formal and informal training programs at every level to help you acquire and build specialized skills faster. Learning takes place both on the job and through formal training conducted online, in the classroom, or in collaboration with teammates. The sheer variety of work we do, and the experience it offers, provide an unbeatable platform from which to build a career.\\n\\nApplicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status).\\n\\nCandidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.\\n\\nAccenture is a Federal Contractor and an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities.\\n\\nEqual Employment Opportunity\\n\\nAll employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.\\n\\nJob candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.\\n\\nAccenture is committed to providing veteran employment opportunities to our service men and women.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Engineer M/F - Houston Office</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Passionate about tech? Interested in Energy? Come work for Kayrros, a fast-growing start-up using artificial intelligence to transform the world’s biggest industry.\\n\\nKayrros is headquartered in Paris, with offices in New York, Houston, London, and Singapore. By working for Kayrros, you will join an energetic team of 150 people, with diverse professional backgrounds—from data science and petroleum engineering to sales and marketing—and over 15 different nationalities and 10 spoken languages.\\n\\nOur team of energy experts and tech wizards are working to bring transparency to the global energy market. We employ innovative technologies, like satellite imagery processing and artificial intelligence, to capture and analyse data across the energy sector. Combined with our expert analysis, we give our clients valuable information on global market movements to make better business decisions—whether that’s trading, investing or managing their operations.\\n\\nIn September 2018, Kayrros received €21M in Serie B funding to continue breaking the boundaries of the energy market.\\n\\nWe are currently recruiting for our Houston office,\\n\\na Data Engineer M/F\\n\\nData Engineers play a central role in Kayrros. Working hand in hand with Data Scientists and Analysts they gather and process raw data at scale and work closely with Software Engineers to integrate innovations and algorithms into our production system.\\n\\nAs a data engineer, you will therefore have to:\\n\\nArchitect, build and test industry-grade geospatial data pipelines leveraging Kayrros existing technologies.\\n\\nWork collaboratively with data scientists and software engineers to deploy data science models at scale in a production environment.\\n\\nAs the first Data Engineer of the Houston office, be able to work autonomously with the remote support of the Paris headquarter infrastructure and data teams.\\n\\nProvide technical support to Data Scientists during exploratory analysis\\n\\nEvaluate performance and optimize all parts of the stack\\n\\nContinuously provide ideas to improve products\\n\\nWork in a creative, fast-pace environment.\\nTechnology stack\\n\\n\\nLanguages: mainly Python (pypark, airflow). Knowledge in Java and/or C is a plus.\\n\\nTools : Message brokers (RabbitMQ, Kafka), machine learning packages (Sci-kit learn, Pandas), tests\\n\\n(Unittest...)\\n\\nStack data: Hadoop (Apache Spark, Hbase...), Elasticsearch\\n\\nInfrastructure : Docker, Rancher, AWS S3/OpenIO, GitlabProfile\\n\\nProfile\\nMinimum three years of industry experience building successful data pipelines at scale with an emphasis on software engineering, software architecture, code quality, best practices\\nBachelor's or Masters in Math, Engineering, Computer Science, or other quantitative field preferred.\\nStrong Python 3 skills to write reusable, testable and efficient code and coach others in doing so.\\nExperience with some of the following components: Spark, Docker, Elasticsearch, Pandas, Scikit-learn is a must.\\nExperience with geospatial and geolocation data is a plus.\\nAbility to work in a fast-paced environment\\nPlease note that we do not sponsor US visa.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Lead Data Engineer</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>You are curious, persistent, logical and clever a true techie at heart. You enjoy living by the code of your craft and developing elegant solutions for complex problems. If this sounds like you, this could be the perfect opportunity to join EPAM as a Lead Data Enigneer. Scroll down to learn more about the position’s responsibilities and requirements.\\nWhat You’ll Do\\nArchitecture design of holistic Cloud data ecosystem with a focus on Google Cloud Platform capabilities and features\\nArchitecture design of Production, Staging/QA, and Development infrastructures running is 24/7 environments\\nRobust and consistent Cloud Strategy design aligned with business objectives\\nProvide guidelines for data migration approaches and techniques including ingest, store, process, analyze and explore/visualize data\\nAssistance with data migration and transformation\\nEvangelize Cloud computing expertise internally and externally to drive Cloud Adoption\\nWhat You Have\\nA degree in an associated field and/or other advanced certification along with significant experience\\nIn-depth cloud professional, competent of quickly establishing connections and credibility in how to address the business needs via design and operate cloud-based solutions\\nExperience in Agile or PMI methodology managed projects\\nExperience in enterprise applications, and big data solutions\\nExperience in platform and cloud migrations, including migration factory\\nIn-depth experience with databases and tools analysis\\nIn-depth experience with ETL tools\\nProcesses design and development for the data modeling, mining, and analysis\\nExtensive experience in methodologies and processes for large-scale databases management on-premises and cloud environment\\nIn-depth understanding and knowledge of distributed version control systems like Git\\nStrong understanding of concepts and experience with StackDriver and other cloud-based monitoring tools including application level and logging\\nNice to have\\nGoogle Cloud Certified Professional Data Engineer\\nExperience Creating automated tooling for cloud platforms\\nExperience with architecting and handling large datasets, structured and semi-structured data formats\\nExperience with streaming processing\\nExperience with messaging platforms\\nExperience with performance testing and tuning\\nExperience with GCP based security hardening including IAM, ACL, firewall rules, data traffic encryption\\nWhat We Offer\\nMedical, Dental and Vision Insurance (Subsidized)\\nHealth Savings Account\\nFlexible Spending Accounts (Healthcare, Dependent Care, Commuter)\\nShort-Term and Long-Term Disability (Company Provided)\\nLife and AD&amp;D Insurance (Company Provided)\\nEmployee Assistance Program\\nUnlimited access to LinkedIn learning solutions\\nMatched 401(k) Retirement Savings Plan\\nPaid Time Off\\nLegal Plan and Identity Theft Protection\\nAccident Insurance\\nEmployee Discounts\\nPet Insurance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Big Data Engineer</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Equal Opportunity Employer: Minority/Female/Disability/Veteran\\nWM Logistics, LLC seeks a Big Data Engineer at our facility in Houston, Texas to create software solutions focused on large scale data analytics leveraging big data tools &amp; technology. Position requires Bachelor’s Degree in Computer Science, Electrical Engineering, MIS, or related field. Must have 10 years of previous experience related to software development, software engineering, coding, and working with enterprise data warehouse databases, large databases or big data solutions and technologies. Must have experience with software development project life cycles, experience with large or enterprise databases, and SQL programming. Must also have experience with JavaScript, Angular, HTML 5, or jQuery. Must have experience using Amazon web services, Scala, and Oracle. Job location: Houston, TX. To apply, go to www.wm.com\\nI understand that applying to this job indicates that I have the legal right to work in the United States. I agree to perform physical duties of this position as outlined in the job with or without reasonable accommodations. I understand that if offered the position, I will be required to pass a drug screen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Strategy Specialist - Business &amp; Data Analysis, Cloud, AWS, Azure, Big Data</td>\n",
       "      <td>Houston, TX 77006</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>77006</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>3+ years with business responsibilities (Business Analyst or Project Lead) of data and analytics solutions spanning:</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Are you ready to step up to the New and take your technology expertise to the next level?\\n\\nJoin Accenture and help transform leading organizations and communities around the world. The sheer scale of our capabilities and client engagements, in conjunction with the way we collaborate, operate and deliver value, provides an unparalleled opportunity to grow and advance. Choose Accenture and make delivering innovative work part of your extraordinary career.\\n\\nPeople in our Client Delivery &amp; Operations career track drive delivery and capability excellence through the design, development and/ or delivery of a solution, service, capability or offering. They grow into delivery-focused roles, and can progress within their current role, laterally or upward. We partner with our clients to help transform their data into an ‘Appreciating Business Asset.’\\n\\nAs part of our Data Business Group, you will lead technology innovation for our clients through robust delivery of world-class solutions. You will build better software better! There will never be a typical day and that’s why people love it here. The opportunities to make a difference within exciting client initiatives are unlimited in the ever-changing technology landscape. You will be part of a highly collaborative and growing network of technology and data experts, who are taking on today’s biggest, most complex business challenges using the latest data and analytics technologies. We will nurture your talent in an inclusive culture that values diversity. You will have an opportunity to work in roles such as Data Scientist, Data Engineer, or Chief Data Officer covering all aspects of Data including Data Management, Data Governance, Data Intelligence, Knowledge Graphs, and IoT. Come grow your career in Technology at Accenture!\\n\\nThe North America Data Strategy &amp; Architecture capability is part of the Data Business Group (DBG) within Accenture Technology. This team provides advisory services to clients that create an architecture blueprint and an execution roadmap to rotate to “Data in the New” and become intelligent data driven enterprises.\\n\\n Connect business vision and current state problems with data, analytics and technology solutions and architectural patterns Interview business stakeholders to understand their vision and challenges Understand and document current state pain points including limitations caused by existing data, analytics and technology gaps Identify and detail business ‘use cases’, or ways that stakeholders would like to drive business value (e.g. increase revenue, decrease expenses, increase efficiency) through data and analytics Aggregate use cases into business consumption patterns detailing the data and technology designs that would support the execution of multiple use cases Ensure alignment between the client’s business needs of the future state with data and technology architecture, operating model and governance recommendations Synthesize business needs with enabling target state recommendations into a vision that client executives, department heads, business and technical resources can understand and align around Develop an execution roadmap detailing a strategic journey from current state to realization of the future state vision with incremental release of technical and operational features and business value Analyze business case for execution against the strategy, including the collection of business case inputs (costs, value drivers) as well as the calculation of return on investment Present data strategy to clients and gain buy in Participate in defining data governance strategy and operating model\\n\\nRequired Skills 3+ years with business responsibilities (Business Analyst or Project Lead) of data and analytics solutions spanning:\\no Data Management solutions with capabilities, such as Data Ingestion, Data Curation, Metadata and Catalog, Data Security, Data Modeling, Data Wrangling\\no Data Warehousing / BI / Reporting solutions that generate business value using platforms and technologies such as Hadoop, Teradata, Netezza, Greenplum, MapReduce, Spark, etc.\\no Data Science, AI / ML, Advanced Analytic solutions that meet business problems 3+ years of consulting experience, interviewing business stakeholders and developing relationships within client organizations Strong communication, presentation, written and facilitation skills Superior critical thinking, analytical and problem-solving skills Ability to interface with client at any level, executive to engineer Competent in leveraging Microsoft Office tools, specifically PowerPoint, Word, and Excel\\n Able to travel up to 100% (Mon-Thu)\\n\\nOptional Skills (Plus): Industry knowledge in Life Sciences, Financial Services or Healthcare Experience in data governance and operating model\\n Experience in compiling business cases and roadmaps for data, analytics and technology investments\\n\\nAll of our professionals receive comprehensive training covering business acumen, technical and professional skills development. You'll also have opportunities to hone your functional skills and expertise in an area of specialization. We offer a variety of formal and informal training programs at every level to help you acquire and build specialized skills faster. Learning takes place both on the job and through formal training conducted online, in the classroom, or in collaboration with teammates. The sheer variety of work we do, and the experience it offers, provide an unbeatable platform from which to build a career.\\n\\nApplicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status).\\n\\nCandidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.\\n\\nAccenture is a Federal Contractor and an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities.\\n\\nEqual Employment Opportunity\\n\\nAll employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.\\n\\nJob candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.\\n\\nAccenture is committed to providing veteran employment opportunities to our service men and women.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Google Data Engineer</td>\n",
       "      <td>Houston, TX 77006</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>77006</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Minimum of 3 years previous Consulting or client service delivery experience on Google GCP\\n</td>\n",
       "      <td>DevOps on an GCP platform. Multi-cloud experience a plus.</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Proven ability to build, manage and foster a team-oriented environment\\nProven ability to work creatively and analytically in a problem-solving environment\\nDesire to work in an information systems environment\\nExcellent communication (written and oral) and interpersonal skills\\nExcellent leadership and management skills</td>\n",
       "      <td>Are you ready to step up to the New and take your technology expertise to the next level?\\nJoin Accenture and help transform leading organizations and communities around the world. The sheer scale of our capabilities and client engagements, in conjunction with the way we collaborate, operate and deliver value, provides an unparalleled opportunity to grow and advance. Choose Accenture and make delivering innovative work part of your extraordinary career.\\nPeople in our Client Delivery &amp; Operations career track drive delivery and capability excellence through the design, development and/ or delivery of a solution, service, capability or offering. They grow into delivery-focused roles, and can progress within their current role, laterally or upward. We partner with our clients to help transform their data into an ‘Appreciating Business Asset.’\\n\\nAs part of our Data Business Group, you will lead technology innovation for our clients through robust delivery of world-class solutions. You will build better software better! There will never be a typical day and that’s why people love it here. The opportunities to make a difference within exciting client initiatives are unlimited in the ever-changing technology landscape. You will be part of a highly collaborative and growing network of technology and data experts, who are taking on today’s biggest, most complex business challenges using the latest data and analytics technologies. We will nurture your talent in an inclusive culture that values diversity. You will have an opportunity to work in roles such as Data Scientist, Data Engineer, or Chief Data Officer covering all aspects of Data including Data Management, Data Governance, Data Intelligence, Knowledge Graphs, and IoT. Come grow your career in Technology at Accenture!\\n\\nThe Google GCP Data Engineer is responsible for delivering Data On Cloud projects for Google GCP based deals. The ideal candidate would be responsible for developing and delivering GCP cloud solutions to meet today’s high demand in areas such as AI/ML, IoT, advanced analytics, open source, enterprise collaboration, microservices, serverless, etc. The GCP Data Engineer is a highly performant engineer responsible for delivering Cloud based Big Data and Analytical Solutions for our clients. Responsibilities include building data on cloud solutions for customers, leading Business and IT stakeholders through designing a robust, secure and optimized GCP solutions and ability to be hands-on delivering the target solution. This role will work with customers and leading internal engineering teams in delivering big data solutions on cloud. Using Google GCP cloud technologies, our GCP Data Engineer professionals implement state of the art, scalable, high performance Data On Cloud solutions that meet the need of today’s corporate and emerging digital applications.\\n\\nBasic Qualifications\\nMinimum of 3 years previous Consulting or client service delivery experience on Google GCP\\nMinimum of 3 years of RDBMS experience\\nMinimum pf 3 years of experience in developing data ingestion, data processing and analytical pipelines for big data, relational databases, NoSQL, data lake and data warehouse solutions\\nExperience with private and public cloud architectures, pros/cons, and migration considerations.\\nExtensive hands-on experience implementing data migration and data processing using GCP services etc:\\nData Ingestion : Cloud Pub/Sub, Data Transfer Service, Cloud IoT Core\\nData Storage : Cloud Spanner, Cloud Storage, Cloud Datastore, Cloud SQL, Cloud Bigtable, Cloud Memorystore\\nStreaming Data Pipeline : Cloud Dataflow, Cloud Dataproc, Cloud Dataprep, Apache Beam\\nData Warehousing &amp; Data Lake : BigQuery, Cloud Storage\\nAdvanced Analytics : Cloud ML engine, Google Data Studio, Google Datalab, Tensorflow &amp; Sheets\\nBachelors or higher degree in Computer Science or a related discipline.\\nAble to trval 100% M-TH\\n\\nCandidate Must Have Completed The Following Certifications\\nCertified GCP Developer - Associate\\nCertified GCP DevOps – Professional (Nice to have)\\nCertified GCP Big Data Specialty (Nice to have)\\n\\nNice-to-Have Skills/Qualifications:\\nDevOps on an GCP platform. Multi-cloud experience a plus.\\nExperience developing and deploying ETL solutions on GCP using tools like Talend, Informatica, Matillion\\nIoT, event-driven, microservices, containers/Kubernetes in the cloud\\n\\nProfessional Skill Requirements\\nProven ability to build, manage and foster a team-oriented environment\\nProven ability to work creatively and analytically in a problem-solving environment\\nDesire to work in an information systems environment\\nExcellent communication (written and oral) and interpersonal skills\\nExcellent leadership and management skills\\n\\nAll of our professionals receive comprehensive training covering business acumen, technical and professional skills development. You'll also have opportunities to hone your functional skills and expertise in an area of specialization. We offer a variety of formal and informal training programs at every level to help you acquire and build specialized skills faster. Learning takes place both on the job and through formal training conducted online, in the classroom, or in collaboration with teammates. The sheer variety of work we do, and the experience it offers, provide an unbeatable platform from which to build a career.\\n\\nApplicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status).\\n\\nCandidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.\\n\\nAccenture is a Federal Contractor and an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities.\\n\\nEqual Employment Opportunity\\n\\nAll employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.\\n\\nJob candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.\\n\\nAccenture is committed to providing veteran employment opportunities to our service men and women.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Senior Data Engineer - Information Technology</td>\n",
       "      <td>Houston, TX 77002</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>77002</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Seeking a Senior Data Engineer\\nThis exciting role will deepen and broaden your skills with leading edge technologies in the data and analytics space. Team members have a chance to make a difference in operational efficiency and help to improve customer experiences through data-driven insights. Let’s explore!\\n\\nJob overview and responsibilities\\nUnited Airlines is seeking talented people to join the Data Engineering team. Data Engineering organization is responsible for driving data driven insights &amp; innovation to support the data needs for commercial and operational projects with a digital focus. As a Data Engineer on the team:\\n You will partner with various teams to define and execute data acquisition, transformation, processing and make data actionable for operational and analytics initiatives that create sustainable revenue and share growth\\n Design, develop, and implement streaming and near-real time data pipelines that feed systems that are the operational backbone of our business.\\n Execute unit tests and validating expected results to ensure accuracy &amp; integrity of data and applications through analysis, coding, writing clear documentation and problem resolution.\\n This role will also drive the adoption of data processing and analysis within the Hadoop environment and help cross train other members of the team\\n Leverage strategic and analytical skills to understand and solve customer and business centric questions\\n Coordinate and guide cross-functional projects that involve team members across all areas of the enterprise, vendors, external agencies and partners\\n Leverage data from a variety of sources to develop data marts and insights that provide a comprehensive understanding of the business\\n Develop and implement innovative solutions leading to automation\\n Use of Agile methodologies to manage projects\\n Mentor and train junior engineers\\n\\nRequired\\n BS/BA, in computer science or related STEM field\\n We are seeking creative, driven, detail-oriented individuals who enjoy tackling tough problems with data and insights. Individuals who have a natural curiosity and desire to solve problems are encouraged to apply\\n 10+ years of IT experience in software development\\n 5+ years of development experience using Java, Python, Scala\\n 5+ years of experience with Big Data technologies like Hadoop, Hive, HBASE, Kafka, Nifi\\n 5+ years of experience with relational database systems like MS SQL Server, Oracle, Teradata\\n Must be legally authorized to work in the country of employment for any employer without sponsorship\\nPreferred\\n Masters in computer science or related STEM field\\n Experience with cloud based systems like AWS, AZURE or Google Cloud\\n Certified Developer / Architect on AWS\\n Strong experience with continuous integration &amp; delivery using Agile methodologies\\n Data engineering experience with transportation/airline industry\\n Strong problem-solving skills\\n Strong knowledge in Big Data\\n\\n\\nEqual Opportunity Employer – Minorities/Women/Veterans/Disabled/LGBT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Experience working on Hadoop platform components\\nKnowledge of Big Data tools, such as zookeeper, Kafka Streaming.\\nShell scripting experience\\nExperience with integration of data from multiple data sources (NoSQL, Mongo, SQL)\\nExperience working with Structured/Unstructured data.\\nExperience creating ETL pipelines\\nExperience in Docker builds and Git file versioning\\nDemonstrated ability to quickly learn new tools and paradigms to deploy cutting edge solutions.\\nKnowledge of programming in Python\\nKnowledge of MapR\\nKnowledge of Scala framework\\nExperience with Spark, Storm or Flink</td>\n",
       "      <td>Integrate Data from multiple data sources\\nCreate ETL Pipelines\\nWork under the guidance of Lead to develop based on design/architecture.</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Need for a well-demonstrated Data Engineer who will work with the Data Science team to complete a major data project.\\nMode of Interview : Telephonic/F2F\\nJob Skills:\\nExperience working on Hadoop platform components\\nKnowledge of Big Data tools, such as zookeeper, Kafka Streaming.\\nShell scripting experience\\nExperience with integration of data from multiple data sources (NoSQL, Mongo, SQL)\\nExperience working with Structured/Unstructured data.\\nExperience creating ETL pipelines\\nExperience in Docker builds and Git file versioning\\nDemonstrated ability to quickly learn new tools and paradigms to deploy cutting edge solutions.\\nKnowledge of programming in Python\\nKnowledge of MapR\\nKnowledge of Scala framework\\nExperience with Spark, Storm or Flink\\nMinimum Experience: 8 Yrs\\nRoles &amp; Responsibilities:\\nIntegrate Data from multiple data sources\\nCreate ETL Pipelines\\nWork under the guidance of Lead to develop based on design/architecture.\\nEducation:\\nBachelor’s Degree in Computer Science or equivalent work experience. Masters preferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Data Engineer-Full Stack-Houston, TX-1535</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>DirectViz Solutions DVS, is a high-level strategic consulting services firm that meets mission needs for Government clients, is seeking a full-time Data Engineer-Full Stack. This position is located in Houston, TX. U.S. citizenship is required with the ability to obtain and maintain a government security clearance.\\n\\nData Engineer-Full Stack\\nWe are currently seeking a Data Engineer Full Stack to contribute to an exciting federal project to create, transform, and modernize applications and data platforms. This is an exciting opportunity which will allow qualified candidates to further develop their skills and expand their area of expertise.\\n\\nRESPONSIBILITIES:\\nWork closely with the Project Manager, Technical Lead, and development team to provide overall data-engineering support and to understand project and application requirements.\\nLead technical efforts and development teams in the creation of customized infrastructure, applications, and tools designed to meet user requirements.\\nAs an engineer, build and deliver data storage, integrate with existing data, and migrate the built big data applications to cloud computing platform by leveraging new technologies.\\nCollect, build, cleanse, assemble and refine datasets to support the variety of data analytics needs put forward by business stakeholders including data scientists, law enforcement officials, and agency analysts.\\nBuild data ingestion and pipeline processes for innovative analytics platforms using best practices and open source tools such as, NiFi.\\nDevelop and apply quantitative and qualitative analytic methods to identify, collect, process and analyze large data sets for specified purposes.\\nDevelop analytical solutions that are scalable, repeatable, effective, and meet the expectations of the decision-makers and stakeholders.\\nNetworking, database, cloud engineering, security engineering teams to comply with the data security policies and procedures and trouble-shoot and resolve any issues in data engineering deliveries.\\n\\nREQUIREMENTS:\\nEducation and Tools/Technology\\nBachelor's Degree in Information Technology, Computer Science, quantitatively-focused social sciences, or other quantitative fields.\\n4+ years of experience working with large and varying data sets, applying qualitative and quantitative analysis to interpret the data.\\nExperience developing complex data ingestion, analysis, and visualization pipelines from disparate data sources in varying formats.\\n4+ years of experience utilizing open source tools and programming languages at least 2: Python, R, Java, Groovy, and/or SQL.\\n2+ years of experience with at least 2 AWS Cloud/Storage/ETL, NiFi, HBase, ElasticSearch, Kibana, Janus Graph, PostgreSQL, Kafka.\\n\\nSubject Matter Expertise and Knowledge\\nKnowledge and experience with Agile, Scrum and DevOps principles and practices and working on collaborative development teams. Experience acting as the technical lead for development teams.\\nDemonstrated extensive experience working in large-scale data environments which includes real time and batch processing requirements, as well as graph databases.\\nExtensive knowledge and experience with Agile, Scrum and DevOps principles and practices and working on collaborative development teams.\\nOutstanding interpersonal and communication skills with the ability to effectively communicate with diverse audiences and influence cross functionally.\\nStrong writing skills and experience conveying highly technical material to non-technical audiences.\\nExperience designing and delivering large scale, 24-7, mission-critical data pipelines and features using modern big data architectures.\\nWorking knowledge of data security management policies and procedures.\\nMust be a U.S. Citizen with the ability to obtain and maintain a government suitability clearance.\\nDirectViz Solutions, LLC provides equal employment opportunity to all individuals regardless of race, color, creed, religion, gender, age, sexual orientation, national origin or ancestry, disability, genetic information, veteran status, gender identification or any other characteristic protected by state, federal or local law.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Senior Data Engineer-Strategy, Innovation and Planning</td>\n",
       "      <td>Houston, TX 77046</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>77046</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Duties:\\n\\n\\nSource data sets, both internal and external, that support machine learning and AI use cases. Leverage enterprise data lake architecture.\\n\\nIngest, curate, and provide access to structured and unstructured data sets\\n\\nBuild robust data pipelines on public Cloud using AWS Kinesis, Kafka or other Lambda technologies.\\n\\nResponsible to collect, process, and compute business metrics from activity &amp; persisted data using Python/Spark.\\n\\nProcess, cleanse, and verify the integrity of data used for analysis; optimize data for consumption.\\n\\nBuild scalable OLAP backend storage for data in PB scale.\\n\\nDevelop data set processes for data discovery, modeling, mining, and archival.\\n\\n\\nRequirements:\\n\\n\\nMust have a Master's Degree in Computer Science, Software Engineering, or related field.\\n\\nMust have 3 years of experience in software or data engineering positions performing the following:\\n\\nBig data engineering\\n\\nWorking with data processing technologies such as Hadoop, Spark, Hive / Pig, and Java / MapReduce\\n\\nWorking with ETL/SQL including fundamental and optimization query techniques, normal forms, and processing semi-structured data, including CSV, XML, XQuery, JSON, and Parquet.\\n\\nData services using Amazon Web Services (AWS), Azure, and / or Google Cloud\\n\\nUtilizing programming languages such as Java, Python or Scala\\n\\nOperationalizing data sourcing/loading including automating/scheduling data ingestion.\\n\\nUtilizing experience with: Parallel computing, batch processing, and stream processing using tools such as Kinesis or Kafka; data warehousing and columnar databases such as Redshift; and NoSQL databases including AWS S3, MongoDB, Cassandra, HBase, and DynamoDB.\\n\\nSend resume to: Stephanie Nagy, HR Global Mobility Specialist, Invesco Group Services, Inc., 11 Greenway Plaza, Suite 1000, Houston, TX 77046.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data Specialist</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Regular-Full time\\nUnion/Non:\\nThis is a non-union position\\nW E= unlimited potential\\nWe didn’t get to be a leader in energy delivery or ranked on the Global 100 Most Sustainable Corporations index on our own. We did it in partnership with outstanding individuals who work together as a team to fuel people’s quality of life. Individuals like you. And now we’re looking for just such an individual to join our team.\\nTo learn more about us, visit www.enbridge.com .\\nLife takes energy. The Enbridge Technology + Innovation Lab works with data that powers our products to improve safety and reliability. By working hands-on with ground-breaking technology, the lab pioneers the development of innovative products through small agile teams. Our teams incorporate a variety of multidisciplinary skills, including industrial predictive algorithms, machine learning, and sentiment analysis.\\nAs a Data Engineer, you’ll help ingest, transform and store clean and enriched data in ready for business intelligence consumption.\\nWho you are\\nYou’ll have experience in a Data Engineer role (5+ years), with a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field\\nYou build and maintain optimal data pipeline architecture.\\nYou assemble large, complex data sets that meet functional / non-functional business requirements.\\nYou identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, data quality checks, minimize Cloud cost, etc.\\nYou build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL, Data Bricks, No-SQL\\nYou build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.\\nYou document and communicate standard methods and tools used.\\nYou work with other data engineers, data ingestion specialists, and experts across the company to consolidate methods and tool standards where practical.\\nYou’re experienced using the following software/tools:\\nBig data tools: Hadoop, HDI, &amp; Spark\\nRelational SQL and NoSQL databases, including COSMOS\\nData pipeline and workflow management tools: Data Bricks (Spark), ADF, Dataflow\\nMicrosoft Azure\\nStream-processing systems: Storm, Streaming-Analytics, IoT Hub, Event Hub\\nObject-oriented/object function scripting languages: Python, Scala, SQL\\nWhat you’ll do\\nYou’ll work independently on complex data engineering problems to support data science strategy of products\\nYou’ll use broad and deep technical knowledge in the data engineering space to tackle complex data problems for product teams, with a core focus on using technical expertise\\nYou’ll improve the data availability by acting as a liaison between Lab teams and source systems\\nYou’ll collect, blend, and transform data using ETL tools, database management system tools, and code development\\nYou’ll implement data models and structures data in ready-for business consumption formats\\nYou’ll aggregate data across various warehousing models (e.g. OLAP cubes, star schemas, etc.) for BI purposes\\nYou’ll collaborate with business teams and understand how data needs to be structured for consumption\\nWe build advanced technology products to deliver energy in a safe and reliable way to fuel a rapidly innovating world. Here in our new Technology + Innovation Lab we believe in Agile way of working, focus on our people and value craftsmanship, in a ‘work is play’ environment where we offer a flexible, fun, and modern working style to support individual needs.\\nApply now to start a career with unlimited potential!\\nWe accept applications submitted via our online recruiting system only ( https://careers.enbridge.com ).\\nEnbridge is an Equal Opportunity and Affirmative Action Employer and is committed to provide employment opportunities to all individuals, without regard to race, religion, age, sex, color, national origin, sexual orientation, gender identity, veteran status, or disability. Accommodation for applicants with disabilities is available on request during the recruitment process. Applicants with disabilities can request accessible formats or communication supports by contacting careers@enbridge.com .\\nWe appreciate your interest in working with us; however, only those applicants selected for interviews will be contacted.\\nFinal candidates for this position may be required to undergo a security screening, including a criminal records check.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Data Engineer, Agile Hub - Houston, TX</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Must have legal authorization to work in the US on a full-time basis for anyone other than current employer\\nBachelor's Degree preferably higher, in mathematics, statistics, computer science, or another relevant discipline\\nMinimum five (5) years of relevant experience with a strong background in data and software engineering, with experience of writing code.\\nStrong experience with Python and relevant libraries.\\nThe ability to work across structured, semi-structured, and unstructured data, extracting information and identifying irregularities and linkages across disparate data sets.\\nMeaningful experience in distributed processing.\\nDeep understanding of information security principles to ensure compliant handling and management of client data.\\nExperience in traditional data warehousing / ETL tools.\\nExperience and interest in cloud infrastructure and containerization.\\nPreferably some experience programming with Julia.\\nExperience or interest in building robust and practical data pipelines on top of cloud infrastructure will also be an advantage.</td>\n",
       "      <td>Job Description\\nThe Data Engineer collects data from source systems, cleans data and adds metadata for context. Builds data pipelines and ensures that there is appropriate automation in the end-to-end process of gathering and loading data for advanced analytical processing. Builds a robust, fault-tolerant data pipeline that cleans, transforms and aggregates unorganized and messy data from multiple sources into a consolidated data model. This enables the deployment of analytical models and helps data scientists develop models and generate insights more quickly. Develops understanding of data availability, content and quality across a domain and uses this to support product owners and data scientists with feasibility assessments for new features and use cases.\\n\\nWe’re looking to you to bring your strong technical expertise in data engineering to help us find ways of increasing customer value and assist in the setup of a best-practice data science process, including determining the direction of future tooling, and how the company engages overall in data science.\\n\\nCalling on your expertise in software engineering and writing code, you’ll be pivotal to the drive to build products, working within small product teams across multiple projects that rely on data from a range of locations and systems.\\n\\nPlus, you’ll use your strong people skills to easily nurture and influence trustworthy, collaborative relationships with a range of virtual stakeholders, confidently and clearly communicating complex solutions.\\n\\nRequirements\\nMust have legal authorization to work in the US on a full-time basis for anyone other than current employer\\nBachelor's Degree preferably higher, in mathematics, statistics, computer science, or another relevant discipline\\nMinimum five (5) years of relevant experience with a strong background in data and software engineering, with experience of writing code.\\nStrong experience with Python and relevant libraries.\\nThe ability to work across structured, semi-structured, and unstructured data, extracting information and identifying irregularities and linkages across disparate data sets.\\nMeaningful experience in distributed processing.\\nDeep understanding of information security principles to ensure compliant handling and management of client data.\\nExperience in traditional data warehousing / ETL tools.\\nExperience and interest in cloud infrastructure and containerization.\\nPreferably some experience programming with Julia.\\nExperience or interest in building robust and practical data pipelines on top of cloud infrastructure will also be an advantage.\\nCompany Description\\nShell is a global group of energy and petrochemical companies with about 84,000 employees across more than 70 countries. We aim to meet the world’s growing need for more and cleaner energy solutions in ways that are economically, environmentally and socially responsible. We have expertise in exploration, production, refining and marketing of oil and natural gas, and the manufacturing and marketing of chemicals.\\n\\nAs a global energy company operating in a challenging world, we set high standards of performance and ethical behaviors. We are judged by how we act and how we live up to our core values of honesty, integrity and respect for people. Our Business Principles are based on these. They promote trust, openness, teamwork and professionalism, as well as pride in what we do and how we conduct business.\\n\\nBuilding on our core values, we aspire to sustain a diverse and inclusive culture where everyone feels respected and valued, from our employees to our customers and partners. A diverse workforce and an inclusive work environment are vital to our success, leading to greater innovation and better energy solutions.\\nDisclaimer\\nPlease note: We occasionally amend or withdraw Shell jobs and reserve the right to do so at any time, including prior to the advertised closing date.\\n\\nBefore applying, you are advised to read our data protection policy. This policy describes the processing that may be associated with your personal data and informs you that your personal data may be transferred to Royal Dutch/Shell Group companies around the world.\\n\\nThe Shell Group and its approved recruitment consultants will never ask you for a fee to process or consider your application for a career with Shell. Anyone who demands such a fee is not an authorised Shell representative and you are strongly advised to refuse any such demand.\\n\\nShell participates in E-Verify.\\n\\nAll qualified applicants will receive consideration for employment without regard to race, color, sex, national origin, age, religion, disability, sexual orientation, gender identity, protected veteran status, citizenship, genetic information or other protected status under federal, state or local laws.\\n\\nShell is an Equal Opportunity Employer - Minorities/Females/Veterans/Disability.\\nEmployment TypeFull Time\\nSkillpool\\nIT Service Management &amp; Delivery\\nWork LocationHouston - EP Center Americas\\nNo. of Positions\\n1\\nJob Expires01-Nov-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Houston, TX 77046</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>77046</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Comfortable working with ambiguity (e.g. imperfect data, loosely defined concepts, ideas, or goals) and translating these into more tangible outputs\\nStrong analytical and critical thinking skills\\nSelf-motivated. Capable of working with little or no supervision\\nStrong written and verbal communication skills\\nEnjoy challenging and thought-provoking work and have a strong desire to learn and progress\\nAbility to manage multiple tasks and requests\\nMust demonstrate a positive, team-focused attitude\\nAbility to react positively under pressure to meet tight deadlines\\nGood inter-personal skills combined with willingness to listen\\nStructured, disciplined approach to work, with attention to detail\\nFlexible – able to meet changing requirements and priorities\\nMaintenance of up-to-date knowledge in the appropriate technical areas\\nAble to work in a global, multicultural environment</td>\n",
       "      <td>Work on new and innovative portfolio construction and analytics applications along with other experienced developers.\\nIdentify, ingest, and enrich a diverse set of structured and unstructured big data into datasets for analysis.\\nOperate and extend the data research platform to deliver production-quality data on time for analysis.\\nOwn end-to-end data workflows and develop deep domain expertise to ensure data quality and completeness\\nExperiment with new technologies and acquire new skills to find creative solutions to the unique challenges we will encounter along the way</td>\n",
       "      <td>\\nMasters in Statistics, Computer Science or other similar advanced degrees from a top tier educational institution preferred\\nCFA, CPA, CIPM, CAIA, and/or FRM preferred, but not required.</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Invesco is a leading global asset management firm with more than $888.2 billion* in assets under management. We provide our retail and institutional clients a diverse and comprehensive range of investment capabilities to help people get more out of life. Invesco is publicly traded on the New York Stock Exchange (IVZ) and has about 7,000 employees in over 20 countries.\\n(*As of December 31, 2018)\\n\\n\\nAbout Invesco Technology\\n\\nAt Invesco Technology, we are strategic problem solvers. Our mission is to create world-class technology solutions to enable global operations, lead in the innovative use of data and emerging technologies to redefine the investment experience, and help our clients “get more out of life.\" This mission is fueled by our high-performing teams, which thrive on collaboration, operate on shared trust, and leverage diversity of thought to deliver valuable results every day to Invesco, clients, and partners.\\n\\nWe wholeheartedly believe that our success is driven by our people. That is why we invest heavily in our top talent, providing opportunities for continuous learning and professional development. Our employees are encouraged and supported in taking advantage of development opportunities tied to their goals and are recognized for employing new skills to make an impact beyond the scope of their daily roles.\\n\\nTo continue building our high-performing, OneTech Team, we are seeking candidates who champion innovation, operate effectively in an agile environment, challenge the status quo and are empowered to take risks\\n\\n\\nJob Purpose (Job Summary):\\nWe’re seeking a Senior Data Engineer to join a fast-paced agile development team using the latest technologies to build portfolio construction and analysis applications. In this position, you will work closely with the Invesco Global Solutions group to envision, design, and deploy scalable technology solutions. You’ll be expected to have basic to intermediate investments knowledge to quickly and accurately collect and visualize investment processes. The environment is demanding, and you will be challenged. We expect that you are fluent in all things data, and you also understand the nuances of financial services and our investment capabilities. You’ll be a part of a dynamic, collaborative team that wants to hear your input because you have a sound foundation in technology and investments. The ideal candidate is passionate about speed, quality, automation, and continuous delivery. We’re actively cultivating a culture of innovation and excellence, and while not for everyone, this environment will be challenging and rewarding for the right individual who welcomes dynamism and solving complex problems. Our team is sensitive to an ever-evolving technological landscape where thirst for knowledge and learning is mandatory, and the mastery of new skills and best practices is essential.\\n\\nKey Responsibilities / Duties:\\nWork on new and innovative portfolio construction and analytics applications along with other experienced developers.\\nIdentify, ingest, and enrich a diverse set of structured and unstructured big data into datasets for analysis.\\nOperate and extend the data research platform to deliver production-quality data on time for analysis.\\nOwn end-to-end data workflows and develop deep domain expertise to ensure data quality and completeness\\nExperiment with new technologies and acquire new skills to find creative solutions to the unique challenges we will encounter along the way\\n\\nWork Experience / Knowledge:\\nMinimum 2 - 4 years of proven experience developing data analytics and visualization software and workflows\\nIntermediate experience with Python and libraries like numpy, pandas, scipy, and matplotlib\\nIntermediate database programming experience with both SQL (e.g. Oracle, SQL Server, PostgreSQL, MySQL) and noSQL (e.g. MongoDB, Parquet) data stores.\\nBasic to Intermediate experience with data visualization tools (e.g. Plotly, PowerBI, Tableau, Plotly Dash, or RShiny)\\nBasic to intermediate experience with HTML, CSS, React.js, and other front-end technologies.\\nIntermediate to advanced experience with Microsoft Excel\\nBasic to intermediate experience with Linux server administration\\nContainerized environments (Docker or LXC), git, continuous integration (e.g. Bamboo, Jenkins, Travis-CI, or CircleCI), documentation (e.g. Sphinx), IT security, distributed computing, and parallel computation\\nBasic to Intermediate understanding of Equity, Fixed Income, and Derivative instruments\\n\\nSkills / Other Personal Attributes Required:\\nComfortable working with ambiguity (e.g. imperfect data, loosely defined concepts, ideas, or goals) and translating these into more tangible outputs\\nStrong analytical and critical thinking skills\\nSelf-motivated. Capable of working with little or no supervision\\nStrong written and verbal communication skills\\nEnjoy challenging and thought-provoking work and have a strong desire to learn and progress\\nAbility to manage multiple tasks and requests\\nMust demonstrate a positive, team-focused attitude\\nAbility to react positively under pressure to meet tight deadlines\\nGood inter-personal skills combined with willingness to listen\\nStructured, disciplined approach to work, with attention to detail\\nFlexible – able to meet changing requirements and priorities\\nMaintenance of up-to-date knowledge in the appropriate technical areas\\nAble to work in a global, multicultural environment\\n\\nFormal Education: (minimum requirement to perform job duties)\\n\\nMasters in Statistics, Computer Science or other similar advanced degrees from a top tier educational institution preferred\\nCFA, CPA, CIPM, CAIA, and/or FRM preferred, but not required.\\n\\nWorking Conditions:\\nNormal office environment with little exposure to noise, dust and temperatures\\nThe ability to lift, carry or otherwise move objects of up to 10 pounds is also necessary\\nNormally works a regular schedule of hours, however hours may vary depending upon the project or assignment\\n\\nFLSA (US Only): Nonexempt\\n\\nThe above information on this description has been designed to indicate the general nature and level of work performed by employees within this role. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications required of employees assigned to this job. The job holder may be required to perform other duties as deemed appropriate by their manager from time to time.\\n\\nInvesco's culture of inclusivity and its commitment to diversity in the workplace are demonstrated through our people practices. We are proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, creed, color, religion, sex, gender, gender identity, sexual orientation, marital status, national origin, citizenship status, disability, age, or veteran status. Our equal opportunity employment efforts comply with all applicable U.S. state and federal laws governing non-discrimination in employment.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2020 University Intern - Data Engineer</td>\n",
       "      <td>Houston, TX 77042</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>77042</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>JOIN US IN PROVIDING ENERGY AND IMPROVING LIVES.\\n\\nAt Phillips 66, we Provide Energy and Improve Lives guided by our values of Safety, Honor and Commitment. Internships are a great way for us to get to know you and for you to get to know our company. We will offer you the same types of challenging assignments as our full-time hires, and you will participate in our company-wide internship program.\\n\\nInternship activities may include the following:\\nOrientation and training events, field trips, social activities, weekly seminars and opportunities to meet and interact with functional leaders\\n\\nParticipating in continuous coaching conversations with your manager, who will provide guidance throughout your internship\\n\\nAn assigned mentor to provide further guidance. Your mentor will help you navigate both technical challenges of your role and give assistance in navigating through the day-to-day questions on working in the corporate world\\n\\nGiving a presentation at the end of your assignment to senior leaders in the IT organization. This presentation is an opportunity to share what you achieved in your work assignment and projects and provide feedback on what you learned from the internship program.\\n\\nThe Data Engineer will play a key role in contributing to the success of advanced analytics and artificial intelligence projects across the company, by partnering with respective business owners and leveraging data to identify areas of improvement &amp; optimization. The role sits in the sweet spot between technology and business worlds and provides opportunity for high business impact and working with seasoned business leaders.\\n\\nAn internship with Phillips 66 Data Engineering is more than a summer job that will look good on your resume. It’s an excellent opportunity to roll up your sleeves and make important contributions as a valued member of our team. You will not only enhance your knowledge but will also learn how it applies and impacts the energy business daily. You’ll gain first-hand experience in the energy industry and participate in other activities that are based on service, networking, and learning. Your summer experience will include:\\n\\nCreate systems for storing, extracting, transferring, loading, and modeling big data to be used for both production systems and machine learning projects\\n\\nImplement data engineering systems in Microsoft Azure, AWS, HANA and other systems, including open source data science tools to meet the needs of our internal customer\\n\\nBuild end-to-end solutions to solve high value business needs in a sustainable, innovative manner\\n\\nNetwork with professionals at all levels in the company\\n\\nLearn about the Oil &amp; Gas industry and the extensive use of technology that makes it possible\\n\\nInternship opportunities are located at our headquarters in Houston, Texas\\n\\nRequirements for a Phillips 66 Data Engineer Internship:\\nBasic/Required:\\nLegally authorized to work in the job posting country\\n\\nPursuing a Bachelor’s or Master’s degree in Computer Science, Analytics, Data Science, Engineering, Mathematics, or equivalent field of study\\n\\nCurrently enrolled in an undergraduate or postgraduate program as a Sophomore or higher\\n\\nScheduled to graduate from a Bachelor’s or Master’s degree program August 2020 or later\\n\\nAvailable for a minimum of ten continuous weeks\\n\\nPreferred:\\nA minimum cumulative GPA of 3.0 on a 4.0 scale\\n\\nPrevious internship or co-op participant in related industry\\n\\nPrevious internship with Phillips 66\\n\\nPhillips 66 SHIELD Scholar recipient\\n\\nWilling to work in any of our operating locations\\n\\nProficiency in R or Python and familiarity with data science packages in that language\\n\\nUnderstanding of Computer Science fundamentals in object-oriented design, data structures, algorithm design, cloud technologies and problem solving\\n\\nFamiliarity with Agile Development\\n\\nTo apply and be considered:\\nYou must apply through your university prior to university deadlines (if applicable) AND\\n\\nApply online by going to http://www.p66oncampus.jobs and complete the entire application process\\n\\nAttach an electronic copy of your resume and unofficial transcript\\n\\nAnswer all prescreening questions and provide your eSignature\\n\\nCandidates for regular U.S. positions must be a U.S. citizen or national, or an alien admitted as permanent resident, refugee, asylee or temporary resident under 8 U.S.C. 1160(a)(1). Individuals with temporary visas such as E, F-1, H-1, H-2, L, B, J, or TN or who need sponsorship for work authorization now or in the future, are not eligible for hire.\\n\\nAbout Phillips 66\\n\\nPhillips 66 is a diversified energy manufacturing and logistics company. With a portfolio of Midstream, Chemicals, Refining, and Marketing and Specialties businesses, the company processes, transports, stores and markets fuels and products globally. Phillips 66 Partners, the company’s master limited partnership, is integral to the portfolio. Headquartered in Houston, the company has 14,300 employees committed to safety and operating excellence. Phillips 66 had $58 billion of assets as of March 31, 2019. For more information, visit http://www.phillips66.com/ or follow us on Twitter @Phillips66Co and @P66oncampus.\\n\\nPhillips 66 is an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities\\n\\nRequisition ID: 51207\\n\\nLocation: Texas - Houston\\n\\nJob Field: Internships, Graduate Positions, and Student Programs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Big Data Engineer</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Onica is one of the fastest growing AWS Premier Partners in North America. As a full spectrum AWS integrator, we assist hundreds of companies to realize the value, efficiency, and productivity of the cloud. We take customers on their journey to enable, operate, and innovate using cloud technologies – from migration strategy to operational excellence and immersive transformation.\\n\\nIf you like a challenge, you'll love it here, because we're solving complex business problems every day, building and promoting great technology solutions that impact our customers' success. The best part is, we're committed to you and your growth, both professionally and personally.\\n\\nLocation: Texas or California\\n\\nOverview\\n\\nOur Data Engineers are experienced technologists with technical depth and breadth, along with strong interpersonal skills. In this role, you will work directly with customers and our team to help enable innovation through continuous, hands-on, deployment across technology stacks. You will work to build data pipelines and by developing data engineering code ( as well as writing complex data queries and algorithms.\\n\\nWhat You'll Be Doing\\n\\n\\nBuild complex ETL code\\nBuild complex SQL queries using MongoDB, Oracle, SQL Server, MariaDB, MySQL\\nWork on Data and Analytics Tools in the Cloud\\nDevelop code using Python, Scala, R languages\\nWork with technologies such as Spark, Hadoop, Kafka, etc.\\nBuild complex Data Engineering workflows\\nCreate complex data solutions and build data pipelines\\nEstablish credibility and build impactful relationships with our customers to enable them to be cloud advocates\\nCapture and share industry best practices amongst the Onica community\\nAttend and present valuable information at Industry Events\\nTraveling up to 50% of the time\\n\\nQualifications &amp; Experience\\n\\n\\n3+ years design &amp; implementation experience with distributed applications\\n2+ years of experience in database architectures and data pipeline development\\nDemonstrated knowledge of software development tools and methodologies\\nPresentation skills with a high degree of comfort speaking with executives, IT management, and developers\\nExcellent communication skills with an ability to right level conversations\\nTechnical degree required; Computer Science or Math background desired\\nDemonstrated ability to adapt to new technologies and learn quickly\\n\\nWhat's in It for You\\n\\n\\nCloud community-minded, meetups/conferences around North America\\nGenerous vacation policy\\nProfessional development and training\\nCell reimbursement and wellness program\\nRetirement plan\\nRecognition program\\nPet-friendly\\nFlexible work environment\\nCommunity involvement and activities\\nUnlimited snacks and beverages!\\n\\nIf you get a thrill working with cutting-edge technology and love to help solve customers' problems, we'd love to hear from you. It's time to rethink the possible. Are you ready?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Houston, TX 77021</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>77021</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>MAJOR RESPONSIBILITIES:\\nDevelop, Operate and help administer the bioinformatics pipeline systems at Baylor Genetics.\\nInstall software and assist in administration of linux systems in a virtualized environment, optimizing storage access and managing scientific software installations.\\nAssist in managing systems for the bioinformatics group.\\nDevelop software and modify existing software as needed.\\nHave familiarity with programming languages.\\nFamiliarity with database activities including relational and NoSQL structures.\\nJOB QUALIFICATIONS (REQUIRED):\\nComputer systems administration and programming background.\\n\\nSKILLS:\\nBioinformatics Pipeline Engineer\\nGreat communication skills\\nExperience with administration of Linux systems and software installation\\nExperience or exposure to one or more compiled programming languages (e.g. Java, C++, etc.) and one or more interpreted programming languages (Python, Perl, bash etc.)\\nWorking knowledge of SQL; Experience with big data, NoSQL databases, and health care a plus.\\nKnowledge of Agile methodology and frameworks like Scrum and Kanban a plus.\\n\\nBACKGROUND:\\nBachelor's degree in Computer Science or a related field or scientific degree AND two (2) years background in Linux/Unix Administration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Senior Azure Data Engineer</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>The data engineer will collaborate within a team of technologists to produce enterprise scale solutions for our clients’ needs. They will utilize deep understanding of data integration and big data design principles in creating custom solutions or implementing package solutions. You will independently drive design decisions to insure the necessary health of the overall solution.\\n\\nRoles &amp; Responsibilities:\\nLead, design, develop, and deliver large-scale Azure data systems, data processing, and data transformation projects.\\nExecute technical feasibility assessments and project estimates for moving databases and data processing to Azure.\\nDesign and advocate solutions using modern cloud technologies, design principles, integration points, and automation methods.\\nMentor and share knowledge with customers as well as provide architecture reviews, discussions, and prototypes.\\nParticipate in overall engagement from strategy, assessment, migration, and implementations.\\nWork with customers to deploy, manage, and audit best practices for cloud products.\\n\\nRequirements\\nDemonstrated experience designing, implementing, and supporting enterprise-grade technical solutions in the cloud for meeting complex business data requirements. Experience with Databricks and using Spark for data processing.\\nExperience with Azure Data Factory – ADF.\\nAdvanced experience with different query languages (i.e. T-SQL, PostgreSQL, PL-SQL). Experience designing and building data marts, warehouses, customer profile databases, etc.\\nExperience with data modeling, table design, and mapping business needs to data structures.\\nExperience with Azure Data Lake, Azure SQL Data Warehouse, and Cosmos DB are a plus. Experience with Data Management Gateway, Azure Storage Options, Stream Analytics, and Event Hubs is a plus.\\nExperience with other cloud based big data architectures is a plus.\\n\\nExperience/Education\\n5 to 10 years of professional experience in the information technology industry.\\nBS in Computer Science or equivalent education/professional experience is required.\\nPersonal Attributes\\nStrong and innovative approach to problem solving and finding solutions.\\nExcellent communicator (written and verbal, formal, and informal).\\nFlexible and proactive/self-motivated working style with strong personal ownership.\\nAbility to multi-task and prioritize under pressure.\\nAbility to work independently with minimal supervision as well as in a team environment. Flexibility and mobility are required to deliver this role as there may be requirements to spend time onsite with our clients to enable delivery of the first class services, we pride ourselves in.\\nGD-POST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Senior Associate, Data Engineering</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>This position is for a Senior Associate Data Engineer within our North American team who will be designing and implementing data projects for our clients.\\nThe qualified individual will work closely with clients to ensure that data technologies meet their needs and keep pace with the rapid changes in Publicis Sapient’s operations and policies/procedures.\\nRESPONSIBILITIES:\\nLead, design, develop, and deliver large-scale Azure data systems, data processing, and data transformation projects.\\nExecute technical feasibility assessments and project estimates for moving databases and data processing to Azure.\\nDesign and advocate solutions using modern cloud technologies, design principles, integration points, and automation methods.\\nMentor and share knowledge with customers as well as provide architecture reviews, discussions, and prototypes.\\nParticipate in overall engagement from strategy, assessment, migration, and implementations.\\nWork with customers to deploy, manage, and audit best practices for cloud products.\\nREQUIREMENTS:\\nDemonstrated experience designing, implementing, and supporting enterprise-grade technical solutions in the cloud for meeting complex business data requirements.\\nExperience with Databricks and using Spark for data processing.\\nExperience with Azure Data Factory – ADF.\\nAdvanced experience with different query languages (i.e. T-SQL, PostgreSQL, PL-SQL).\\nExperience designing and building data marts, warehouses, customer profile databases, etc.\\nExperience with data modeling, table design, and mapping business needs to data structures.\\nExperience with Azure Data Lake, Azure SQL Data Warehouse, and Cosmos DB are a plus.\\nExperience with Data Management Gateway, Azure Storage Options, Stream Analytics, and Event Hubs is a plus.\\nExperience with other cloud based big data architectures is a plus.\\nEXPERIENCE/EDUCATION:\\n5 to 10 years of professional experience in the information technology industry.\\nBS in Computer Science or equivalent education/professional experience is required.\\nPERSONAL ATTRIBUTES:\\nStrong and innovative approach to problem solving and finding solutions.\\nExcellent communicator (written and verbal, formal, and informal).\\nFlexible and proactive/self-motivated working style with strong personal ownership.\\nAbility to multi-task and prioritize under pressure.\\nAbility to work independently with minimal supervision as well as in a team environment.\\nFlexibility and mobility is required to deliver this role as there may be requirements to spend time onsite with our clients to enable delivery of the first class services we pride ourselves in.\\n\\nLI-SNNA*\\nGD-POST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Senior Associate, Data Engineering (Azure)</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>This position is for a Senior Associate Data Engineer within our North American team who will be designing and implementing data projects for our clients.\\nThe qualified individual will work closely with clients to ensure that data technologies meet their needs and keep pace with the rapid changes in Publicis Sapient’s operations and policies/procedures.\\nRESPONSIBILITIES:\\nLead, design, develop, and deliver large-scale Azure data systems, data processing, and data transformation projects.\\nExecute technical feasibility assessments and project estimates for moving databases and data processing to Azure.\\nDesign and advocate solutions using modern cloud technologies, design principles, integration points, and automation methods.\\nMentor and share knowledge with customers as well as provide architecture reviews, discussions, and prototypes.\\nParticipate in overall engagement from strategy, assessment, migration, and implementations.\\nWork with customers to deploy, manage, and audit best practices for cloud products.\\nREQUIREMENTS:\\nDemonstrated experience designing, implementing, and supporting enterprise-grade technical solutions in the cloud for meeting complex business data requirements.\\nExperience with Databricks and using Spark for data processing.\\nExperience with Azure Data Factory – ADF.\\nAdvanced experience with different query languages (i.e. T-SQL, PostgreSQL, PL-SQL).\\nExperience designing and building data marts, warehouses, customer profile databases, etc.\\nExperience with data modeling, table design, and mapping business needs to data structures.\\nExperience with Azure Data Lake, Azure SQL Data Warehouse, and Cosmos DB are a plus.\\nExperience with Data Management Gateway, Azure Storage Options, Stream Analytics, and Event Hubs is a plus.\\nExperience with other cloud based big data architectures is a plus.\\nEXPERIENCE/EDUCATION:\\n5 to 10 years of professional experience in the information technology industry.\\nBS in Computer Science or equivalent education/professional experience is required.\\nPERSONAL ATTRIBUTES:\\nStrong and innovative approach to problem solving and finding solutions.\\nExcellent communicator (written and verbal, formal, and informal).\\nFlexible and proactive/self-motivated working style with strong personal ownership.\\nAbility to multi-task and prioritize under pressure.\\nAbility to work independently with minimal supervision as well as in a team environment.\\nFlexibility and mobility is required to deliver this role as there may be requirements to spend time onsite with our clients to enable delivery of the first class services we pride ourselves in.\\n\\nLI-SNNA*\\nGD-POST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Data Engineer - Spark Data Engineer</td>\n",
       "      <td>Spring, TX</td>\n",
       "      <td>Spring</td>\n",
       "      <td>TX</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nExtensive experience using statistics, mathematics, algorithms and programming languages to solve big data challenges.\\nFluent in structured and unstructured data, its management, and modern data transformation methodologies.\\nAbility to define and create complex models to pull valuable insights, predictions and innovation from data.\\nEffectively and creatively tell stories and create visualizations to describe and communicate data insights.\\nStrong analytical and problem-solving skills.\\nExcellent written and verbal communication skills; mastery in English and local language.\\nAbility to effectively communicate data insights and negotiate options at senior management levels.</td>\n",
       "      <td>\\nMines data using modern tools and programming languages.\\nDefines and implements models to uncover patterns and predictions creating business value and innovation.\\nManages relationships with business partners to evaluate and foster data driven innovation, provide domain-specific expertise in cross-organization projects/initiatives.\\nTies insights into effective visualizations communicating business value and innovation potential.\\nMaintains proficiency within the data science domain by keeping up with technology and trend shifts. Contributes to industry data science domain initiatives.\\nLeads project team(s) of data science professionals, assuring insights are communicated regularly and effectively, reviewing designs, models and accuracy and data compliance.\\nCollaborates and communicates with project team regarding project progress and issue resolution.\\nCommunicates and drives data insights/innovation into the business.\\nRepresents the data science team for all phases of larger and more-complex development projects.\\nProvides guidance, training and mentoring to less experienced staff members.\\nStrong Scala, Python programming experience is a must\\nDatabricks Spark experience</td>\n",
       "      <td>\\nBachelor's, Master's or PHD degree in Mathematics, Economics, Physics, Computer Science, or equivalent.\\n6-10 years’ professional experience.</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Overview\\nHP Engineering entails utilizing established engineering disciplines to test and safeguard the manufacturing standards for new and existing HP products. Working with internal stakeholders and outsourced development partners, you will develop and execute solutions to resolve any existing issues, ensuring that our operating processes are cost-effective and uphold the highest quality.\\nFull Time\\nLevel: Middle\\nTravel: Minimal (if any)\\nSuccess profile\\nWhat makes a successful Engineer at HP? Check out the top traits we’re looking for and see if you have the right mix.\\n\\nCommunicator\\nDeadline-oriented\\nEntrepreneurial\\nOpen-minded\\nProblem-solver\\nTeam Player\\nRewards\\nMedical\\nHolidays\\nFlex Time\\nLife and Disability Insurance\\nWork/Life Balance\\nOnsite Gym/ Fitness Center\\nWe are looking for a talented Spark Data Engineer, to join a great team at HP! In this role, you'll bring advanced subject matter knowledge to solve complex business issues, and we'll look to your Spark data engineering subject matter expertise! In this role, you will frequently contribute to the development of new ideas and methods. You will also get to work on complex, interesting problems, where analysis of situations or data requires an in-depth evaluation of multiple factors. We'd love for you to lead and/or provide expertise to functional project teams, and you may also participate in cross-functional initiatives.\\nWe'll rely on your experience and expertise to provide direction and guidance to process improvements, including in helping to establish/advise on policies. You'll have the opportunity to work with a number of external clients, helping to provide them with effective solutions and insights. We'll trust you to utilize significant independent judgment within broadly defined policies and practices, including determining the best method for accomplishing work and achieving objectives. We'd love for you to also use your deep experience to occasionally help mentor and guide less experienced employees. Key skills will by Python, Scala, and Databricks Spark, as applied in a data engineering capacity. If you love data engineering as much as we do, we'd love to learn more about you!\\nResponsibilities\\nMines data using modern tools and programming languages.\\nDefines and implements models to uncover patterns and predictions creating business value and innovation.\\nManages relationships with business partners to evaluate and foster data driven innovation, provide domain-specific expertise in cross-organization projects/initiatives.\\nTies insights into effective visualizations communicating business value and innovation potential.\\nMaintains proficiency within the data science domain by keeping up with technology and trend shifts. Contributes to industry data science domain initiatives.\\nLeads project team(s) of data science professionals, assuring insights are communicated regularly and effectively, reviewing designs, models and accuracy and data compliance.\\nCollaborates and communicates with project team regarding project progress and issue resolution.\\nCommunicates and drives data insights/innovation into the business.\\nRepresents the data science team for all phases of larger and more-complex development projects.\\nProvides guidance, training and mentoring to less experienced staff members.\\nStrong Scala, Python programming experience is a must\\nDatabricks Spark experience\\nKnowledge &amp; Skills\\nExtensive experience using statistics, mathematics, algorithms and programming languages to solve big data challenges.\\nFluent in structured and unstructured data, its management, and modern data transformation methodologies.\\nAbility to define and create complex models to pull valuable insights, predictions and innovation from data.\\nEffectively and creatively tell stories and create visualizations to describe and communicate data insights.\\nStrong analytical and problem-solving skills.\\nExcellent written and verbal communication skills; mastery in English and local language.\\nAbility to effectively communicate data insights and negotiate options at senior management levels.\\nScope &amp; Impact\\nCollaborates with peers, junior engineers, data scientists and project team.\\nTypically interacts with high- level Individual Contributors, Managers, Directors and Program Core Teams.\\nLeads multiple projects requiring data engineering solutions development.\\nDrives design innovation.\\nEducation &amp; Experience\\nBachelor's, Master's or PHD degree in Mathematics, Economics, Physics, Computer Science, or equivalent.\\n6-10 years’ professional experience.\\n#Li-Post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sr. Data Engineer (Houston)</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Darby Consulting is looking for an experienced Sr. Data Engineer with Azure experience to support our client in the oil and gas industry. The Sr. Data Engineer will have a minimum of four years working with big data processing utilizing Azure Dev Ops, Azure Data Factory and Azure Data Warehouse in an Agile development environment. This position is offered to candidates based in the Houston-area on a 1099 Independent Contractor or W2-Hourly Employee basis. Excellent pay, relocation assistance, top-tier client, excellent work environment, long-term assignment and flexible work schedule are just a few of the many perks for this opportunity.\\n\\nWORK HOURS AND LOCATION\\nServices to be provided in Houston, TX during normal business hours (typically Monday through Friday from 8:00AM to 5:00PM, excluding holidays when the client office is closed).\\n\\nABOUT DARBY CONSULTING\\n\\nIf you've worked for a few consulting firms by now, you know there's a lot of \"great\" places to work. We've worked with many of them too. But, let's be honest: if everyone claims to be great, then great really is just the new average.\\n\\nOur goal is to build an amazing place to work. That means designing and building a company that goes beyond average. We want amazing. For us, Amazing is the opportunity to join a growing company of highly talented and experienced professionals. It's about learning and working alongside great people who care as much about you and your success as they do about their clients. Amazing is about flexibility, work-life balance and opportunities to deliver solutions for respected companies who value your knowledge, skills and experience. If you want great, there's a lot of companies out there. But if you want amazing, welcome to Darby Consulting!\\n\\nWHAT WE DO\\n\\nDarby Consulting is a full-service IT consulting firm specializing in IT project management, systems design and deployment of software and hardware-related projects. Supporting clients in the energy, government and education sectors, Darby helps growing organizations to maximize the value from their IT projects by integrating experienced and specialized IT project professionals, success-based methodology and cloud-based project management tools at affordable rates for growing organizations.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Google Technical Architect</td>\n",
       "      <td>Houston, TX 77006</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>77006</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Minimum 5 years of Consulting or client service delivery experience on Google GCP\\n</td>\n",
       "      <td>DevOps on an GCP platform. Multi-cloud experience a plus.</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>Proven ability to build, manage and foster a team-oriented environment\\nProven ability to work creatively and analytically in a problem-solving environment\\nDesire to work in an information systems environment\\nExcellent communication (written and oral) and interpersonal skills\\nExcellent leadership and management skills</td>\n",
       "      <td>Are you ready to step up to the New and take your technology expertise to the next level?\\nJoin Accenture and help transform leading organizations and communities around the world. The sheer scale of our capabilities and client engagements, in conjunction with the way we collaborate, operate and deliver value, provides an unparalleled opportunity to grow and advance. Choose Accenture and make delivering innovative work part of your extraordinary career.\\nPeople in our Client Delivery &amp; Operations career track drive delivery and capability excellence through the design, development and/ or delivery of a solution, service, capability or offering. They grow into delivery-focused roles, and can progress within their current role, laterally or upward. We partner with our clients to help transform their data into an ‘Appreciating Business Asset.’\\n\\nAs part of our Data Business Group, you will lead technology innovation for our clients through robust delivery of world-class solutions. You will build better software better! There will never be a typical day and that’s why people love it here. The opportunities to make a difference within exciting client initiatives are unlimited in the ever-changing technology landscape. You will be part of a highly collaborative and growing network of technology and data experts, who are taking on today’s biggest, most complex business challenges using the latest data and analytics technologies. We will nurture your talent in an inclusive culture that values diversity. You will have an opportunity to work in roles such as Data Scientist, Data Engineer, or Chief Data Officer covering all aspects of Data including Data Management, Data Governance, Data Intelligence, Knowledge Graphs, and IoT. Come grow your career in Technology at Accenture!\\n\\nThe Google Cloud Platform (GCP) Technical Architect Delivery is responsible for delivering Data On Cloud projects for Google GCP based deals. The ideal candidate would also be responsible for developing and delivering Google GCP cloud solutions to meet todays high demand in areas such as AI/ML, IoT, advanced analytics, open source, enterprise collaboration, microservices, serverless, etc. The Regional Google GCP Technical Architect is a highly performant GCP Architect responsible for delivering Cloud based Big Data and Analytical Solutions to our clients. Responsibilities include evangelizing data on cloud solutions with customers, leading Business and IT stakeholders through designing a robust, secure and optimized GCP architectures and ability to be hands-on delivering the target solution. This role will work with customers and leading internal data engineers in delivering big data soltuions on cloud. Using Google GCP public cloud technologies, our Technical Architect professionals implement state of the art, scalable, high performance Data On Cloud solutions that meet the need of todays corporate and emerging digital applications.\\n\\nRole &amp; Responsibilities:Work with Sales and Bus Dev teams in providing Data and GCP Technical Architecture expertise while pursuing client opportunities.Ability to build cloud architectures and provide prescriptive guidance across network, storage, Big Data Platform Services, serverless architectures, hadoop ecosystem, vendor products, RDBMS &amp; NoSQL databases and security.Participate in deep architectural discussions to build confidence and ensure customer success when building new solutions and migrating existing data applications on the GCP platform.Conduct full technical discovery, identifying pain points, business and technical requirements, “as is” and “to be” scenarios.\\n- Assess the full technology stack of services required including PaaS (Platform as-a-service), IaaS (Infrastructure as-a-service), SaaS (software as-a-service), operations, management and automation.Lead the discussions and early analysis of the cloud concepts as it relates to Clients’s Journey to Cloud methodology so that clear use cases are developed and prioritized as well as transitioning these concepts from ideas to proof-of-concepts all the way to production delivery with the full support of the appropriate teams.Compare solution alternatives across both technical and business parameters which support the define cost and service requirements.Apply Accenture methodology, Accenture reusable assets, and previous work experience to delivery consistently high-quality work.Stay educated on new and emerging technologies/patterns/methodologies and market offerings that may be of interest to our clients.Adapt to existing methods and procedures to create possible alternative solutions to moderately complex problems.Understand the strategic direction set by senior management as it relates to team goals.Use considerable judgment to define solution and seeks guidance on complex problems.Prepare and deliver product messaging in an effort to highlight value proposition and unique differentiators.Primary upward interaction is with direct supervisor. May interact with peers and/or management levels at a client and/or within Accenture. Establish methods and procedures\\non new assignments with guidance.\\nManage small teams of delivery engineers successfully delivering work efforts (if in an independent contributor role) at a client or within Accenture.\\nExtensive travel may be required\\n\\nBasic Qualifications\\nMinimum 5 years of Consulting or client service delivery experience on Google GCP\\nMinimum 10 years of experience in big data, database and data warehouse architecture and delivery\\nBachelors degree or 12 years previous professional experience\\nAble to travel 100% (M-TH)\\nMinimum of 5 years of professional experience in 2 of the following areas:\\nSolution/technical architecture in the cloud\\nBig Data/analytics/information analysis/database management in the cloud\\nIoT/event-driven/microservices in the cloud\\nExperience with private and public cloud architectures, pros/cons, and migration considerations.\\nExtensive hands-on experience implementing data migration and data processing using GCP services etc.:\\nData Ingestion : Cloud Pub/Sub, Data Transfer Service, Cloud IoT Core\\nStreaming Data Pipeline : Cloud Dataflow, Cloud Dataproc, Cloud Dataprep, Apache Beam\\nData Warehousing &amp; Data Lake : BigQuery, Cloud Storage\\nAdvanced Analytics : Cloud ML engine, Google Data Studio, Tensorflow &amp; Sheets\\n\\nFamiliarity with the Technology stack available in the industry for data management, data ingestion, capture, processing and curation: Kafka, StreamSets, Attunity, GoldenGate, Map Reduce, Hadoop, Hive, Hbase, Cassandra, Spark, Flume, Hive, Impala, etc.\\nBachelors or higher degree in Computer Science or a related discipline.\\n\\nCandidate Must Have Completed The Following Certifications\\nCertified GCP Solutions Architect - Associate\\nCertified GCP Solutions Architect – Professional (Nice to have)\\nCertified GCP Big Data Specialty (Nice to have)\\nCertified GCP AI/ML Specialty (Nice to have)\\n\\nNice-to-Have Skills/Qualifications:\\nDevOps on an GCP platform. Multi-cloud experience a plus.\\nExperience developing and deploying ETL solutions on GCP\\nStrong in Java, C##, Spark, PySpark, Unix shell/Perl scripting\\nFamiliarity with the technology stack available in the industry for metadata management: Data Governance, Data Quality, MDM, Lineage, Data Catalog etc.\\n- Multi-cloud experience beyond GCP a plus - AWS and Azure\\n\\nProfessional Skill Requirements\\nProven ability to build, manage and foster a team-oriented environment\\nProven ability to work creatively and analytically in a problem-solving environment\\nDesire to work in an information systems environment\\nExcellent communication (written and oral) and interpersonal skills\\nExcellent leadership and management skills\\n\\nAll of our professionals receive comprehensive training covering business acumen, technical and professional skills development. You'll also have opportunities to hone your functional skills and expertise in an area of specialization. We offer a variety of formal and informal training programs at every level to help you acquire and build specialized skills faster. Learning takes place both on the job and through formal training conducted online, in the classroom, or in collaboration with teammates. The sheer variety of work we do, and the experience it offers, provide an unbeatable platform from which to build a career.\\n\\nApplicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status).\\n\\nCandidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.\\n\\nAccenture is a Federal Contractor and an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities.\\n\\nEqual Employment Opportunity\\n\\nAll employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.\\n\\nJob candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.\\n\\nAccenture is committed to providing veteran employment opportunities to our service men and women.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Data Engineer Southwest</td>\n",
       "      <td>Houston, TX 77006</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>77006</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>We are:\\nApplied Intelligence, the people who love using data to tell a story. We’re also the world’s largest team of data scientists, data engineers, and experts in machine learning and AI. A great day for us? Solving big problems using the latest tech, serious brain power, and deep knowledge of just about every industry. We believe a mix of data, analytics, automation, and responsible AI can do almost anything—spark digital metamorphoses, widen the range of what humans can do, and breathe life into smart products and services. Want to join our crew of sharp analytical minds? Visit us here to find out more about Applied Intelligence.\\n\\nYou are:\\nAn expert engineer with an eye for AI. You want to change how the world works and lives by taking AI out of the lab and into everyday life.\\n\\nThe work:\\nYou’ll be part of a team with incredible end-to-end digital transformation capabilities that shares your passion for digital technology and takes pride in making a tangible difference. If you want to contribute on an incredible array of the biggest and most complex projects in the digital space, consider a career with Accenture Digital.\\n\\nHere’s what you need:\\nMinimum 2+ years of experience in designing, implementing large scale data pipelines for data curation and analysis, operating in production environments using Spark, pySpark, SparkSQL, with Java, Scala or Python on premise or on Cloud (AWS, Google or Azure)\\nMinimum 1 year of designing and building performant data tiers (or refactoring existing ones), that supports scaled AI and Analytics, using different Cloud native data stores on AWS (Kinesis, S3. GLUE, DynamoDB etc.) or Azure (HDInsights, AzureData Factory) or GCP (DataProc, PubSub, BigQuery) as well as using NoSQL and Graph Stores.\\nMinimum 1 year of designing and building streaming data ingestion, analysis and processing pipelines using Kafka, Kafka Streams, Spark Streaming and similar cloud native technologies\\nMinimum 1-year performance engineering, profiling, debugging very large big data and ML production solutions on Spark and native Cloud technologies\\nBonus points if:\\n\\nMinimum 6 months of experience in implementation with Databricks.\\nMinimum 1 year of designing and building secured and governed Big Data ETL pipelines, using Talend or Informatica technologies; for data curation and analysis of large le production deployed solutions.\\nExperience implementing smart data preparation tools such as Palate, Trifacta, Tamr for enhancing analytics solutions.\\nMinimum 1 year of building Business Data Catalogs or Data Marketplaces for powering business analytics using technologies such as Alation, Collibra, Informatica or custom solutions\\n\\n\\nImportant information\\n\\nApplicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture.\\n\\nAccenture is an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities.\\n\\nEqual Employment Opportunity\\n\\nAll employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.\\n\\nJob candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.\\n\\nAccenture is committed to providing veteran employment opportunities to our service men and women.\\n\\nCandidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nThrives in a fast-paced, startup environment, is adaptable and versatile\\n3+ years of python\\nExperience in python data libraries (pandas, luigi, dask, etc)\\nSolid understanding of data structures and algorithms\\nBuilding distributed data systems\\n</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>None Found</td>\n",
       "      <td>\\nHouston, TX\\nData department\\n\\nAlice helps small business owners launch and grow. Since launching in May 2017, our goal is to help 6 million owners succeed through our free digital platform,\\nhelloalice.com [http://www.helloalice.com]. Alice serves all entrepreneurs and we wholeheartedly believe that if underserved business owners -- women, people of color, veterans, the LGBTQ+ community, entrepreneurs with disabilities, people in small towns, and immigrants -- are provided better access to resources, they can change the world. Our vision is to be financially successful while making a positive impact on economies and job creation.\\n\\nAlice is growing a diverse team, and we’re looking for a Data Engineer to help us fulfill our mission of connecting all entrepreneurs to the resources they need to grow and scale their businesses. We’re leading a movement to connect every founder, regardless of geography, capitalization, prior experience, or cultural constraints, to the experts, tools, knowledge, and communities that will propel their companies forward. Alice is a Series A-backed company with teams in Houston, TX and San Francisco, CA. We are helping hundreds of thousands of owners a week in all fifty states. Led by co-founders Elizabeth Gore and Carolyn Rodz, we are hiring self-starters who can build the plane while flying it.\\n\\nEngineering is key to scaling our mission, and we’re growing our data engineering team to build new features, improve our AI, and better serve entrepreneurs from around the world. We believe in working fast, but smart, and work toward measurable results. As the first member of the data team you will be able to have a huge impact on the technologies, architecture, and tools we use. Data is key to Alice’s success and this position will have big visibility throughout the organization.\\n\\nRequired Skills/Experiences:\\n\\nThrives in a fast-paced, startup environment, is adaptable and versatile\\n3+ years of python\\nExperience in python data libraries (pandas, luigi, dask, etc)\\nSolid understanding of data structures and algorithms\\nBuilding distributed data systems\\n\\nDesired Skills / Experiences\\n\\nAWS and Google Cloud management\\nAnsible, Terraform or other cloud orchestration libraries\\nRabbitMQ, Kafka or other queuing systems\\ngRPC or other RPC libraries\\nProtobufs\\nMachine learning and statistics libraries\\nScraping websites for relevant information\\n\\nOur company values are important to us. We thought we would share them with you as someone interested in joining our team.\\n\\nINNOVATE ALWAYS. Seek out unique perspectives, diverse experiences, and disconnected dots. These are the seeds of big ideas and exceeded expectations, made even better through constant collaboration.\\nEMBRACE FAILURE. Learn from the inevitable failures that result from innovation, and move forward quickly with a pioneering spirit. Champion the doers, celebrate their contributions to the team, and don't shy away from difficult conversations.\\nDRIVE THE MISSION FORWARD. Everything we do is through the inclusive lens of helping all business owners launch and grow, regardless of who they are or where they come from. Hold yourself to the highest standards of quality and equality in everything you do.\\nEVERYONE TAKES OUT THE TRASH. No task is too small for the success of our company or our owners. Always be thoughtful and practice extreme kindness toward our team, partners, and owners.\\nSIMPLIFY AND COMMIT. Maintain a bias toward efficiency, acting quickly and testing often. Recognize the opportunity cost of every decision, commit to deadlines, be on time, and search for simple, smart solutions.\\n\\nAlice is an Equal Employment Opportunity employer that will consider all qualified applicants, regardless of race, color, religion, gender, sexual orientation, marital status, gender identity or expression, national origin, genetics, age, disability status, protected veteran status, or any other characteristic protected by applicable law.\\n\\nwww.helloalice.com [http://www.helloalice.com/] // Twitter\\n[https://twitter.com/HelloAlice] // Facebook\\n[http://www.facebook.com/aliceconnects] // Instagram\\n[https://www.instagram.com/helloalice_com/] // LinkedIn\\n[https://www.linkedin.com/company/25067438/]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                               Title  \\\n",
       "0   Delivery Director                                                                  \n",
       "1   Azure Data Engineer                                                                \n",
       "2   Sr Data Engineer                                                                   \n",
       "3   AWS Data Engineer                                                                  \n",
       "4   2020 University New Hire - Data Engineer                                           \n",
       "5   Data Engineer                                                                      \n",
       "6   Data Engineer, Energy Platform - Houston, TX                                       \n",
       "7   Data Engineer                                                                      \n",
       "8   Manager Azure Data Engineer                                                        \n",
       "9   Azure Data Architect                                                               \n",
       "10  Data Engineer M/F - Houston Office                                                 \n",
       "11  Lead Data Engineer                                                                 \n",
       "12  Big Data Engineer                                                                  \n",
       "13  Data Strategy Specialist - Business & Data Analysis, Cloud, AWS, Azure, Big Data   \n",
       "14  Google Data Engineer                                                               \n",
       "15  Senior Data Engineer - Information Technology                                      \n",
       "16  Data Engineer                                                                      \n",
       "17  Data Engineer-Full Stack-Houston, TX-1535                                          \n",
       "18  Senior Data Engineer-Strategy, Innovation and Planning                             \n",
       "19  Data Specialist                                                                    \n",
       "20  Data Engineer, Agile Hub - Houston, TX                                             \n",
       "21  Data Engineer                                                                      \n",
       "22  2020 University Intern - Data Engineer                                             \n",
       "23  Big Data Engineer                                                                  \n",
       "24  Data Engineer                                                                      \n",
       "25  Senior Azure Data Engineer                                                         \n",
       "26  Senior Associate, Data Engineering                                                 \n",
       "27  Senior Associate, Data Engineering (Azure)                                         \n",
       "28  Data Engineer - Spark Data Engineer                                                \n",
       "29  Sr. Data Engineer (Houston)                                                        \n",
       "30  Google Technical Architect                                                         \n",
       "31  Data Engineer Southwest                                                            \n",
       "32  Data Engineer                                                                      \n",
       "\n",
       "             Location     City State         Zip     Country  \\\n",
       "0   Houston, TX        Houston  TX    None Found  None Found   \n",
       "1   Houston, TX 77006  Houston  TX    77006       None Found   \n",
       "2   Houston, TX 77021  Houston  TX    77021       None Found   \n",
       "3   Houston, TX 77006  Houston  TX    77006       None Found   \n",
       "4   Houston, TX 77042  Houston  TX    77042       None Found   \n",
       "5   Houston, TX 77072  Houston  TX    77072       None Found   \n",
       "6   Houston, TX        Houston  TX    None Found  None Found   \n",
       "7   Houston, TX        Houston  TX    None Found  None Found   \n",
       "8   Houston, TX        Houston  TX    None Found  None Found   \n",
       "9   Houston, TX 77006  Houston  TX    77006       None Found   \n",
       "10  Houston, TX        Houston  TX    None Found  None Found   \n",
       "11  Houston, TX        Houston  TX    None Found  None Found   \n",
       "12  Houston, TX        Houston  TX    None Found  None Found   \n",
       "13  Houston, TX 77006  Houston  TX    77006       None Found   \n",
       "14  Houston, TX 77006  Houston  TX    77006       None Found   \n",
       "15  Houston, TX 77002  Houston  TX    77002       None Found   \n",
       "16  Houston, TX        Houston  TX    None Found  None Found   \n",
       "17  Houston, TX        Houston  TX    None Found  None Found   \n",
       "18  Houston, TX 77046  Houston  TX    77046       None Found   \n",
       "19  Houston, TX        Houston  TX    None Found  None Found   \n",
       "20  Houston, TX        Houston  TX    None Found  None Found   \n",
       "21  Houston, TX 77046  Houston  TX    77046       None Found   \n",
       "22  Houston, TX 77042  Houston  TX    77042       None Found   \n",
       "23  Houston, TX        Houston  TX    None Found  None Found   \n",
       "24  Houston, TX 77021  Houston  TX    77021       None Found   \n",
       "25  Houston, TX        Houston  TX    None Found  None Found   \n",
       "26  Houston, TX        Houston  TX    None Found  None Found   \n",
       "27  Houston, TX        Houston  TX    None Found  None Found   \n",
       "28  Spring, TX         Spring   TX    None Found  None Found   \n",
       "29  Houston, TX        Houston  TX    None Found  None Found   \n",
       "30  Houston, TX 77006  Houston  TX    77006       None Found   \n",
       "31  Houston, TX 77006  Houston  TX    77006       None Found   \n",
       "32  Houston, TX        Houston  TX    None Found  None Found   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Qualifications  \\\n",
       "0   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "1   At least 5 years of consulting or client service delivery experience on Azure\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "2   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "3   At least 5 years of Consulting or client service delivery experience on Amazon AWS (AWS)At least 5 years of experience in developing data ingestion, data processing and analytical pipelines for big data, relational databases, NoSQL and data warehouse solutionsExtensive experience providing practical direction within the AWS Native and HadoopExperience with private and public cloud architectures, pros/cons, and migration considerations.Minimum of 5 years of hands-on experience in AWS and Big Data technologies such as Java, Node.js, C##, Python, SQL, EC2, S3, Lambda, Spark/SparkSQL, Hive/MR, Pig, Oozie and streaming technologies such as Kafka, Kinesis, NiFI etc.Extensive hands-on experience implementing data migration and data processing using AWS services: VPC/SG, EC2, S3, AutoScaling, CloudFormation, LakeFormation, DMS, Kinesis, Kafka, Nifi, CDC processing Redshift, Snowflake, RDS, Aurora, Neptune, DynamoDB, Hive, NoSQL, Cloudtrail, CloudWatch, Docker, Lambda, Spark,Glue, Sage Maker, AI/ML, API GW, etc.5+ years of hands on experience in programming languages such as Java, c#, node.js, python, pyspark, spark, SQL, Unix shell/Perl scripting etc.Minimum of 5 years of RDBMS experienceExperience in using Hadoop File Formats and compression techniquesExperience working with DevOps tools such as GitLabs, Jenkins, CodeBuild, CoePipeline CodeDeploy, etc.Bachelors or higher degree in Computer Science or a related discipline.   \n",
       "4   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "5   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "6   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "7   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "8   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "9   At least 5 years of consulting or client service delivery experience on Azure\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "10  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "11  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "12  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "13  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "14  Minimum of 3 years previous Consulting or client service delivery experience on Google GCP\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "15  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "16  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "17  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "18  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "19  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "20  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "21  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "22  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "23  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "24  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "25  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "26  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "27  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "28  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "29  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "30  Minimum 5 years of Consulting or client service delivery experience on Google GCP\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "31  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "32  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Skills  \\\n",
       "0   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "1   DevOps on an Azure platform                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "2   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "3   DevOps on an AWS platform. Multi-cloud experience a plus.Experience developing and deploying ETL solutions on AWS using tools like Talend, Informatica, MatillionStrong in Java, C##, Spark, PySpark, Unix shell/Perl scriptingIoT, event-driven, microservices, containers/Kubernetes in the cloud                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "4   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "5   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "6   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "7   \\n3+ years experience in data/software engineering or related field\\nFluency in Python and SQL, experience with Golang, C, C++, Java, or Scala is a plus\\nDemonstrated experience with distributed computing (Kafka, Storm, Spark, Hadoop, etc.)\\nExperience with NoSQL databases\\nProficiency in using and managing cloud infrastructure, preferably AWS\\nLinux and Bash competence\\nExperience integrating with Salesforce a plus                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "8   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "9   DevOps on an Azure platform                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "10  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "11  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "12  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "13   3+ years with business responsibilities (Business Analyst or Project Lead) of data and analytics solutions spanning:                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "14  DevOps on an GCP platform. Multi-cloud experience a plus.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "15  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "16  Experience working on Hadoop platform components\\nKnowledge of Big Data tools, such as zookeeper, Kafka Streaming.\\nShell scripting experience\\nExperience with integration of data from multiple data sources (NoSQL, Mongo, SQL)\\nExperience working with Structured/Unstructured data.\\nExperience creating ETL pipelines\\nExperience in Docker builds and Git file versioning\\nDemonstrated ability to quickly learn new tools and paradigms to deploy cutting edge solutions.\\nKnowledge of programming in Python\\nKnowledge of MapR\\nKnowledge of Scala framework\\nExperience with Spark, Storm or Flink                                                                                                                                                                                                                                                                                                              \n",
       "17  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "18  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "19  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "20  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "21  Comfortable working with ambiguity (e.g. imperfect data, loosely defined concepts, ideas, or goals) and translating these into more tangible outputs\\nStrong analytical and critical thinking skills\\nSelf-motivated. Capable of working with little or no supervision\\nStrong written and verbal communication skills\\nEnjoy challenging and thought-provoking work and have a strong desire to learn and progress\\nAbility to manage multiple tasks and requests\\nMust demonstrate a positive, team-focused attitude\\nAbility to react positively under pressure to meet tight deadlines\\nGood inter-personal skills combined with willingness to listen\\nStructured, disciplined approach to work, with attention to detail\\nFlexible – able to meet changing requirements and priorities\\nMaintenance of up-to-date knowledge in the appropriate technical areas\\nAble to work in a global, multicultural environment   \n",
       "22  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "23  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "24  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "25  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "26  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "27  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "28  \\nExtensive experience using statistics, mathematics, algorithms and programming languages to solve big data challenges.\\nFluent in structured and unstructured data, its management, and modern data transformation methodologies.\\nAbility to define and create complex models to pull valuable insights, predictions and innovation from data.\\nEffectively and creatively tell stories and create visualizations to describe and communicate data insights.\\nStrong analytical and problem-solving skills.\\nExcellent written and verbal communication skills; mastery in English and local language.\\nAbility to effectively communicate data insights and negotiate options at senior management levels.                                                                                                                                                                                                              \n",
       "29  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "30  DevOps on an GCP platform. Multi-cloud experience a plus.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "31  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "32  \\nThrives in a fast-paced, startup environment, is adaptable and versatile\\n3+ years of python\\nExperience in python data libraries (pandas, luigi, dask, etc)\\nSolid understanding of data structures and algorithms\\nBuilding distributed data systems\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Responsibilities  \\\n",
       "0   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "1   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "2   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "3   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "4   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "5   Enhance and further develop Big Data processing pipelines for data sources containing structured and unstructured data\\nData Warehousing with Data modeler experience\\nMonitor and optimize key infrastructure components such as Databases, EC2 Clusters, and other aspects of the stack\\nHelp promote best practices for Big Data development\\nAct as a bridge between the infrastructure and application engineering teams\\nProvide infrastructure support with a focus on cloud based computing\\nBuild and support visualization and exploration capabilities around our Data Sets\\nWork with the Data Extraction and Data Science engineers on normalization and analytical processes\\nWork in an Agile manner with business users and data scientists to understand and discover the potential business value of new and existing Data Sets and help productize those discoveries\\nHelp design and implement disaster recovery efforts\\nAnalyze requirements and architecture specifications to create detailed design\\nResearch areas of interest to the team and help facilitate solutions\\nDesign Cloud Architecture, SaaS, PaaS, and SaaS\\n                                                                                            \n",
       "6   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "7   \\nEstablish and maintain best practices for our data infrastructure\\nDevelop next-gen data pipelining and ETL based on open source data pipeline tools and cloud-based ecosystems that can deal with varied data types from disparate sources\\nDevelop and tune data storage and processing systems at scale\\nBuild real-time data processing systems\\nBuild automated systems to continually monitor data quality and integrity\\nWork closely with stakeholders across Vroom to ensure data is accurate, timely, and useful                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "8   \\nLead, design, develop, and deliver large-scale Azure data systems, data processing, and data transformation projects.\\nExecute technical feasibility assessments and project estimates for moving databases and data processing to Azure.\\nDesign and advocate solutions using modern cloud technologies, design principles, integration points, and automation methods.\\nMentor and share knowledge with customers as well as provide architecture reviews, discussions, and prototypes.\\nParticipate in overall engagement from strategy, assessment, migration, and implementations.\\nWork with customers to deploy, manage, and audit best practices for cloud products.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "9   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "10  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "11  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "12  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "13  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "14  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "15  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "16  Integrate Data from multiple data sources\\nCreate ETL Pipelines\\nWork under the guidance of Lead to develop based on design/architecture.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "17  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "18  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "19  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "20  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "21  Work on new and innovative portfolio construction and analytics applications along with other experienced developers.\\nIdentify, ingest, and enrich a diverse set of structured and unstructured big data into datasets for analysis.\\nOperate and extend the data research platform to deliver production-quality data on time for analysis.\\nOwn end-to-end data workflows and develop deep domain expertise to ensure data quality and completeness\\nExperiment with new technologies and acquire new skills to find creative solutions to the unique challenges we will encounter along the way                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "22  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "23  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "24  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "25  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "26  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "27  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "28  \\nMines data using modern tools and programming languages.\\nDefines and implements models to uncover patterns and predictions creating business value and innovation.\\nManages relationships with business partners to evaluate and foster data driven innovation, provide domain-specific expertise in cross-organization projects/initiatives.\\nTies insights into effective visualizations communicating business value and innovation potential.\\nMaintains proficiency within the data science domain by keeping up with technology and trend shifts. Contributes to industry data science domain initiatives.\\nLeads project team(s) of data science professionals, assuring insights are communicated regularly and effectively, reviewing designs, models and accuracy and data compliance.\\nCollaborates and communicates with project team regarding project progress and issue resolution.\\nCommunicates and drives data insights/innovation into the business.\\nRepresents the data science team for all phases of larger and more-complex development projects.\\nProvides guidance, training and mentoring to less experienced staff members.\\nStrong Scala, Python programming experience is a must\\nDatabricks Spark experience   \n",
       "29  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "30  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "31  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "32  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "\n",
       "                                                                                                                                                                                       Education  \\\n",
       "0   None Found                                                                                                                                                                                     \n",
       "1   None Found                                                                                                                                                                                     \n",
       "2   None Found                                                                                                                                                                                     \n",
       "3   None Found                                                                                                                                                                                     \n",
       "4   None Found                                                                                                                                                                                     \n",
       "5   None Found                                                                                                                                                                                     \n",
       "6   None Found                                                                                                                                                                                     \n",
       "7   None Found                                                                                                                                                                                     \n",
       "8   \\n5 to 10 years of professional experience in the information technology industry.\\nBS in Computer Science or equivalent education/professional experience is required.                        \n",
       "9   None Found                                                                                                                                                                                     \n",
       "10  None Found                                                                                                                                                                                     \n",
       "11  None Found                                                                                                                                                                                     \n",
       "12  None Found                                                                                                                                                                                     \n",
       "13  None Found                                                                                                                                                                                     \n",
       "14  None Found                                                                                                                                                                                     \n",
       "15  None Found                                                                                                                                                                                     \n",
       "16  None Found                                                                                                                                                                                     \n",
       "17  None Found                                                                                                                                                                                     \n",
       "18  None Found                                                                                                                                                                                     \n",
       "19  None Found                                                                                                                                                                                     \n",
       "20  None Found                                                                                                                                                                                     \n",
       "21  \\nMasters in Statistics, Computer Science or other similar advanced degrees from a top tier educational institution preferred\\nCFA, CPA, CIPM, CAIA, and/or FRM preferred, but not required.   \n",
       "22  None Found                                                                                                                                                                                     \n",
       "23  None Found                                                                                                                                                                                     \n",
       "24  None Found                                                                                                                                                                                     \n",
       "25  None Found                                                                                                                                                                                     \n",
       "26  None Found                                                                                                                                                                                     \n",
       "27  None Found                                                                                                                                                                                     \n",
       "28  \\nBachelor's, Master's or PHD degree in Mathematics, Economics, Physics, Computer Science, or equivalent.\\n6-10 years’ professional experience.                                                \n",
       "29  None Found                                                                                                                                                                                     \n",
       "30  None Found                                                                                                                                                                                     \n",
       "31  None Found                                                                                                                                                                                     \n",
       "32  None Found                                                                                                                                                                                     \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Requirement  \\\n",
       "0   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "1    Proven ability to build, manage and foster a team-oriented environment\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "2   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "3    Proven ability to build, manage and foster a team-oriented environment Proven ability to work creatively and analytically in a problem-solving environment Desire to work in an information systems environment Excellent communication (written and oral) and interpersonal skills Excellent leadership and management skills                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "4   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "5   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "6   Legal authorization to work in the US on a full-time basis for anyone other than current employer\\nBachelor's degree in a relevant technical discipline.\\n5+ years of experience with demonstrable proficiency in one or more DB and data pipeline tooling: mySQL, PostgreSQL, OSI Pi historian, TimescaleDB, Streamsets, Apache Drill, Apache Parquet, Dremio …\\nYou are passionate about building scalable, high performing, data pipelines, and analytic catalogs.\\nExperience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc\\nProficient with Containerized environments and workloads\\nExcellent analytical, problem-solving, and troubleshooting skills.\\nExperience architecting, deploying, and supporting production applications.\\nYou care deeply about performance, accessibility and API design.\\nGreat communication skills.\\nWork locations may include Houston, TX or San Francisco, CA                                                                                                                                                             \n",
       "7   None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "8   \\nDemonstrated experience designing, implementing, and supporting enterprise-grade technical solutions in the cloud for meeting complex business data requirements.\\nExperience with Databricks and using Spark for data processing.\\nExperience with Azure Data Factory – ADF.\\nAdvanced experience with different query languages (i.e. T-SQL, PostgreSQL, PL-SQL).\\nExperience designing and building data marts, warehouses, customer profile databases, etc.\\nExperience with data modeling, table design, and mapping business needs to data structures.\\nExperience with Azure Data Lake, Azure SQL Data Warehouse, and Cosmos DB are a plus.\\nExperience with Data Management Gateway, Azure Storage Options, Stream Analytics, and Event Hubs is a plus.\\nExperience with other cloud based big data architectures is a plus.                                                                                                                                                                                                                                                                       \n",
       "9    Proven ability to build, manage and foster a team-oriented environment\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "10  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "11  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "12  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "13  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "14  Proven ability to build, manage and foster a team-oriented environment\\nProven ability to work creatively and analytically in a problem-solving environment\\nDesire to work in an information systems environment\\nExcellent communication (written and oral) and interpersonal skills\\nExcellent leadership and management skills                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "15  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "16  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "17  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "18  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "19  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "20  Must have legal authorization to work in the US on a full-time basis for anyone other than current employer\\nBachelor's Degree preferably higher, in mathematics, statistics, computer science, or another relevant discipline\\nMinimum five (5) years of relevant experience with a strong background in data and software engineering, with experience of writing code.\\nStrong experience with Python and relevant libraries.\\nThe ability to work across structured, semi-structured, and unstructured data, extracting information and identifying irregularities and linkages across disparate data sets.\\nMeaningful experience in distributed processing.\\nDeep understanding of information security principles to ensure compliant handling and management of client data.\\nExperience in traditional data warehousing / ETL tools.\\nExperience and interest in cloud infrastructure and containerization.\\nPreferably some experience programming with Julia.\\nExperience or interest in building robust and practical data pipelines on top of cloud infrastructure will also be an advantage.   \n",
       "21  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "22  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "23  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "24  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "25  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "26  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "27  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "28  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "29  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "30  Proven ability to build, manage and foster a team-oriented environment\\nProven ability to work creatively and analytically in a problem-solving environment\\nDesire to work in an information systems environment\\nExcellent communication (written and oral) and interpersonal skills\\nExcellent leadership and management skills                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "31  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "32  None Found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          FullDescriptions  \n",
       "0   The Company\\n-----------\\n\\nArundo is a software company based in Oslo, Norway; Houston, TX; and Palo Alto, CA, with presence in 7 locations in Europe and the Americas. Our software enables advanced analytics, machine learning, and IoT applications for more efficient, safer, and more effective physical systems in heavy industries such as energy, chemicals, and shipping. Founded in 2015, Arundo consists of around 100 software engineers, data scientists, designers, and industrial domain experts.\\n\\nOur team members are passionate about being part of a company that can solve tough problems and create innovative solutions. We believe in a fun environment, where our people can be fearless and feel empowered to always do the right thing. Arundites come from many different backgrounds including academia, industry, and even a submarine! We look for smart, creative thinkers with a player-coach mindset who can wear multiple hats and contribute to our exciting future!\\n\\nThe Role\\n--------\\n\\nOur Delivery Director is responsible for the delivery of Arundo SaaS software and data science solutions to our strategic customers -- enabling sustained business value capture. The Delivery Director is responsible for our portfolio of customers in the Americas region, including direct leadership of one or more customer deliveries. In addition, the role will have oversight of the regional Delivery function. Leading our Delivery function includes working with, data scientists, solution architects, software engineers, and field engineers to scope, develop and operationalize state-of-the-art machine learning and other analytical solutions. Moreover, the position includes direct management and mentorship of Delivery Leads, Field Engineers and Solution Architects. The position reports to the VP of Delivery for the Americas but will also have regular access and support from the General Manager Americas as well as Head of Data Science Americas.\\n\\nThe ideal Delivery Director combines industrial and enterprise software experience with a proven record in technology consulting and/or enterprise software implementation. Common for all is a passion for working with highly talented people in delivering customer value through advanced technical solutions.\\n\\nAs a Delivery Director, you work closely with your team to shape process, execution and solution design for customer projects and the implementation of a growing product portfolio, as well as working to improve our overall Delivery processes and standards.\\n\\nA key element of the position includes support of presales activities -- partnering with our sales team and our data science leadership to assess opportunities, manage risks and guide the prospective customer towards positive outcomes. In this role, you are a peer of the VP of Sales for the Americas and a trusted advisor of the sales executives as well as the prospective customer.\\n\\nWe value critical thinking, self-motivation, and the ability to deal with ambiguity. You should bring a cool head, have strong project management skills and a strong technological interest and background. You enjoy solving complex problems, you are a good communicator, and enjoy working closely with customers and talented people to deliver extraordinary results. And you will enjoy getting 'hands on' and learning our product/platform -- and even give product/solution demos to our customers. We love people who innovate, use data to make decisions, and can express themselves thoughtfully. We want you to be passionate about delivering a great customer experience and love contributing to achieve excellence in all you do.\\n\\nResponsibilities\\n----------------\\n\\nCustomer project delivery leadership\\n\\n\\nResponsible for shaping projects and product implementation in the Americas through mentorship of your direct reports\\nConsulted for continued process and template refinement in a global fashion\\nResponsible for successful project delivery, leading a delivery team consisting of data scientists, solution architects, software engineers, and field engineers\\nResponsible for collecting and providing product feedback to our Product Management and Product Engineering teams\\nWorks with customers to identify and quantify opportunities to create business value through the use of machine learning and IoT technologies\\nConsulted on project scoping, scheduling, and delivery according to plan\\nHiring, weekly 1-on-1s, coaching and feedback\\nMentors team on collaborative design, development, and delivery efforts of customer solutions\\nIn some projects, leads project workshops such as kick-offs, executive touchpoints and key go-live activities in order to demonstrate excellence to your direct reports\\nBuilds professional rapport with customers and partners\\nMentors and cultivates excellence in customer reports and slide development and presentation\\n\\nPresales leadership\\n\\n\\nResponsible as an individual contributor and senior leader/mentor for executing presales activities such as discovery workshops and demos\\nResponsible for production and quality control of statements of work\\nConsulted on proposal templates and quality reviews for specific proposals\\nParticipation and presentation at external conferences and events; as well as writing blog articles and whitepapers\\n\\nQualifications\\n--------------\\n\\nEducation\\n\\n\\nBachelor's degree in Science, Technology, Engineering, Math or equivalent experience\\n\\nNeeded Work Experience\\n\\n\\n7 or more years leading complex, technology-oriented projects in technology or industrial companies, or equivalent experience from management or technology consulting\\n3 or more years as an individual contributor in technical/presales activities conducting discovery, assessing/shaping scopes of work, demoing software and explaining project scoping (i.e. phases, assumptions, risk, roles/responsibilities)\\nDirect management experience: hiring, 1-on-1s, feedback, coaching and delegation\\nConsistent track record of strong results and impact in customer facing role for more than 5 years\\nOperational domain knowledge from an industrial environment (oil and gas E&P or process manufacturing); ideally, as a practitioner but a technologist or consultant into those industries are considered as well\\n\\nPreferred Work Experience\\n\\n\\nExperience with I0T, cloud technology and/or development of machine learning models\\nConceptual, end-user or installation knowledge of industrial technology such as HMI, PLC, DCS, process historians, alarm management & other such applications\\nExperience as a software or data engineer using modern languages and PaaS development is an advantage; as is having lead software-related transformations\\n\\nPersonal Skills and Capabilities\\n\\n\\nStrong people leadership skills with the ability to motivate and inspire others to achieve great results\\nHighly analytical and strong problem-solving skills\\nWritten and verbal communication skills\\nEnjoys crafting beautiful and clear customer presentations\\nEnjoys working in a dynamic and customer-focused environment\\nStrong listening skills and the ability to identify and resolve issues\\nAbility to maintain composure in complex and stressful situations\\nResponds to customer needs quickly and effectively, and is able to adapt to changes to deliver results\\nAble to lead complex customer and stakeholder relationships\\n\\nWho are we?\\n-----------\\n\\n\\nWe are a values driven company with an inclusive and autonomous culture\\nWe have highly talented and dedicated people\\nWe work in a collaborative environment with our offices in the US and EMEA\\nYou'll have the opportunity to work with cutting edge technology\\nWe have a FUN environment - we take fun seriously and have appointed a VP of Fun\\nWe have regular team building activities\\nWe have several social clubs of own choice (Data Science Club, Running Club, Females@Arundo)\\nWe collaboration with Stanford/StartX and MIT/STEX25\\nWe're at a prime location with nice facilities in Downtown Houston\\nWe have a free snack bar and Old-school arcade games in the office\\nCompetitive salary, and participation in our employee stock option plan\\nBenefits plan including 401k retirement plan\\n\\nWe are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\\n\\nLocation\\n--------\\n\\nHouston, TX\\n\\nTravel\\n------\\n\\n\\nIn general, most work is conducted from Arundo offices\\nRequired travel may approach 2-3 days per week during key phases in customer projects. But in general, Arundo does not favor a full on-site presence in our projects.\\n\\nAdditional Information\\n----------------------\\n\\n\\nYou must successfully pass a pre-employment background check and drug screen\\nYou are able to work for any US employer without requiring sponsorship\\n\\nThis job description is intended to describe the general nature and level of the work being performed by individuals in the position. It is not intended to include every job duty and responsibility specific to the position. Arundo reserves the right to amend and change responsibilities to meet business and organizational needs as necessary.                                                                                                                                                                                                                                                                                                                                                                \n",
       "1   Are you ready to step up to the New and take your technology expertise to the next level?\\n Join Accenture and help transform leading organizations and communities around the world. The sheer scale of our capabilities and client engagements, in conjunction with the way we collaborate, operate and deliver value, provides an unparalleled opportunity to grow and advance. Choose Accenture and make delivering innovative work part of your extraordinary career.\\n People in our Client Delivery & Operations career track drive delivery and capability excellence through the design, development and/ or delivery of a solution, service, capability or offering. They grow into delivery-focused roles, and can progress within their current role, laterally or upward. We partner with our clients to help transform their data into an ‘Appreciating Business Asset.’\\n\\nAs part of our Data Business Group, you will lead technology innovation for our clients through robust delivery of world-class solutions. You will build better software better! There will never be a typical day and that’s why people love it here. The opportunities to make a difference within exciting client initiatives are unlimited in the ever-changing technology landscape. You will be part of a highly collaborative and growing network of technology and data experts, who are taking on today’s biggest, most complex business challenges using the latest data and analytics technologies. We will nurture your talent in an inclusive culture that values diversity. You will have an opportunity to work in roles such as Data Scientist, Data Engineer, or Chief Data Officer covering all aspects of Data including Data Management, Data Governance, Data Intelligence, Knowledge Graphs, and IoT. Come grow your career in Technology at Accenture!\\n\\nThe Azure Technical Architect Delivery is responsible for delivering Data On Cloud projects for Azure based deals. The ideal candidate would also be responsible for developing and delivering Azure cloud solutions to meet todays high demand in areas such as AIML, IoT, advanced analytics, open source, enterprise collaboration, microservices, serverless, etc. The Azure Data Engineer is a highly performant engineer responsible for delivering Cloud based Big Data and Analytical Solutions at our clients. Responsibilities include evangelizing data on cloud solutions with customers, leading Business and IT stakeholders through designing a robust, secure and optimized Azure architectures and ability to be hands-on delivering the target solution. This role will work with customers and leading internal engineering teams in delivering big data soltuions on cloud. Using Azure public cloud technologies, our Data Engineer professionals implement state of the art, scalable, high performance Data On Cloud solutions that meet the need of todays corporate and emerging digital applications\\n\\n Role & Responsibilities:Provide subject matter expertise and hands on delivery of data capture, curation and consumption pipelines on Azure and HadoopAbility to build cloud data solutions and provide domain perspective on storage, big data platform services, serverless architectures, hadoop ecosystem, vendor products, RDBMS, DW/DM, NoSQL databases and security.Participate in deep architectural discussions to build confidence and ensure customer success when building new solutions and migrating existing data applications on the Azure platform.Conduct full technical discovery, identifying pain points, business and technical requirements, “as is” and “to be” scenarios.\\n- Build full technology stack of services required including PaaS (Platform as-a-service), IaaS (Infrastructure as-a-service), SaaS (software as-a-service), operations, management and automation.Apply Accenture methodology, Accenture reusable assets, and previous work experience to delivery consistently high-quality work.Stay educated on new and emerging technologies/patterns/methodologies and market offerings that may be of interest to our clients.Adapt to existing methods and procedures to create possible alternative solutions to moderately complex problems.Understand the strategic direction set by senior management as it relates to team goals.Use considerable judgment to define solution and seeks guidance on complex problems.Primary upward interaction is with direct supervisor. May interact with peers and/or management levels at a client and/or within Accenture. Establish methods and procedures\\non new assignments with guidance.\\nManage small teams of deliver engineers successfully delivering work efforts\\n\\n (if in an independent contributor role) at a client or within Accenture.\\nExtensive travel may be required\\n\\nBasic Qualifications\\nAt least 5 years of consulting or client service delivery experience on Azure\\nAt least 5 years of experience in developing data ingestion, data processing and analytical pipelines for big data, relational databases, NoSQL and data warehouse solutions\\nExtensive experience providing practical direction within the Azure Native and HadoopMinimum of 5 years of hands-on experience in Azure and Big Data technologies such as Powershell, C#, Java, Node.js, Python, SQL, ADLS/Blob, Spark/SparkSQL, Hive/MR, Pig, Oozie and streaming technologies such as Kafka, EventHub, NiFI etc.\\nExtensive hands-on experience implementing data migration and data processing using Azure services: Networking, Windows/Linux virtual machines, Container, Storage, ELB, AutoScaling, Azure Functions, Serverless Architecture, ARM Templates, Azure SQL DB/DW, Data Factory, Azure Stream Analytics, Azure Analysis Service, HDInsight, Databricks Azure Data Catalog, Cosmo Db, ML Studio, AI/ML, etc.\\n Cloud migration methodologies and processes including tools like Azure Data Factory, Event Hub, etc.\\n5+ years of hands on experience in programming languages such as Java, c#, node.js, python, pyspark, spark, SQL, Unix shell/Perl scripting etc.\\nMinimum of 5 years of RDBMS experience\\nExperience in using Hadoop File Formats and compression techniquesExperience working with Developer tools such as Visual Studio, GitLabs, Jenkins, etc.\\nExperience with private and public cloud architectures, pros/cons, and migration considerations.\\nBachelors or higher degree in Computer Science or a related discipline.\\n\\nCandidate Must Have Completed The Following Certifications\\nMCSA Cloud Platform (Azure) Training & Certification\\nMCSE Cloud Platform & Infratsructiure Training & Certification\\nMCSD Azure Solutions Architect Training & Certification\\n\\nNice-to-Have Skills/Qualifications:\\nDevOps on an Azure platform\\nExperience developing and deploying ETL solutions on Azure\\nIoT, event-driven, microservices, containers/Kubernetes in the cloud\\nFamiliarity with the technology stack available in the industry for metadata management: Data Governance, Data Quality, MDM, Lineage, Data Catalog etc.\\nFamiliarity with the Technology stack available in the industry for data management, data ingestion, capture, processing and curation: Kafka, StreamSets, Attunity, GoldenGate, Map Reduce, Hadoop, Hive, Hbase, Cassandra, Spark, Flume, Hive, Impala, etc.\\n- Multi-cloud experience a plus - Azure, AWS, Google\\n\\nProfessional Skill Requirements\\n Proven ability to build, manage and foster a team-oriented environment\\n Proven ability to work creatively and analytically in a problem-solving environment\\n Desire to work in an information systems environment\\n Excellent communication (written and oral) and interpersonal skills\\n Excellent leadership and management skills\\n Excellent organizational, multi-tasking, and time-management skills\\n Proven ability to work independently\\n\\nAll of our professionals receive comprehensive training covering business acumen, technical and professional skills development. You'll also have opportunities to hone your functional skills and expertise in an area of specialization. We offer a variety of formal and informal training programs at every level to help you acquire and build specialized skills faster. Learning takes place both on the job and through formal training conducted online, in the classroom, or in collaboration with teammates. The sheer variety of work we do, and the experience it offers, provide an unbeatable platform from which to build a career.\\n\\nApplicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status).\\n\\nCandidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.\\n\\nAccenture is a Federal Contractor and an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities.\\n\\nEqual Employment Opportunity\\n\\nAll employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.\\n\\nJob candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.\\n\\nAccenture is committed to providing veteran employment opportunities to our service men and women.                                                                                                                                    \n",
       "2   MAJOR RESPONSIBILITIES:\\nDevelop and optimize the bioinformatics pipeline systems at Baylor Genetics.\\nDevelop and Install software and assist in administration of Linux systems in a virtualized environment, optimizing storage access and managing scientific software.\\nAssist in managing systems for the bioinformatics group.\\nDevelop software and modify existing software as needed.\\nHave deep experience with programming languages.\\nVast experience with using databases including relational and NoSQL structures.\\nJOB QUALIFICATIONS (REQUIRED):\\nComputer systems administration and programming background.\\n\\nSKILLS:\\nSenior Bioinformatics software Engineer (10+ years) with strong background in genomics.\\nGreat communication skills\\nExperience with building, optimizing, and architecting bioinformatic data pipelines\\nExperience with administration of Linux systems and software installation.\\nStrong experience with compiled programming languages (e.g. Java, C++, etc.) and interpreted programming languages (Python, Perl, bash etc.)\\nDeep knowledge of SQL and NoSQL databases and big data.\\nBackground with genomic cluster e.g. SLURM a plus.\\nExperience with optimizing a distributed system based on solr a plus.\\nWorking previously in health care related company a plus.\\nKnowledge of Agile methodology and frameworks like Scrum and Kanban a plus.\\n\\nBACKGROUND:\\nBachelor’s degree and ten (10) years background in bioinformatics software engineering and Linux/Unix Administration                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "3   Are you ready to step up to the New and take your technology expertise to the next level?\\n\\nJoin Accenture and help transform leading organizations and communities around the world. The sheer scale of our capabilities and client engagements, in conjunction with the way we collaborate, operate and deliver value, provides an unparalleled opportunity to grow and advance. Choose Accenture and make delivering innovative work part of your extraordinary career.\\n\\nPeople in our Client Delivery & Operations career track drive delivery and capability excellence through the design, development and/ or delivery of a solution, service, capability or offering. They grow into delivery-focused roles, and can progress within their current role, laterally or upward. We partner with our clients to help transform their data into an ‘Appreciating Business Asset.’\\n\\nAs part of our Data Business Group, you will lead technology innovation for our clients through robust delivery of world-class solutions. You will build better software better! There will never be a typical day and that’s why people love it here. The opportunities to make a difference within exciting client initiatives are unlimited in the ever-changing technology landscape. You will be part of a highly collaborative and growing network of technology and data experts, who are taking on today’s biggest, most complex business challenges using the latest data and analytics technologies. We will nurture your talent in an inclusive culture that values diversity. You will have an opportunity to work in roles such as Data Scientist, Data Engineer, or Chief Data Officer covering all aspects of Data including Data Management, Data Governance, Data Intelligence, Knowledge Graphs, and IoT. Come grow your career in Technology at Accenture!\\n\\nThe Amazon AWS Data Engineer is responsible for delivering Data On Cloud projects for Amazon AWS based deals. The ideal candidate would be responsible for developing and delivering AWS cloud solutions to meet today’s high demand in areas such as AIML, IoT, advanced analytics, open source, enterprise collaboration, microservices, serverless, etc. The AWS Data Engineer is a highly performant engineer responsible for delivering Cloud based Big Data and Analytical Solutions at our clients. Responsibilities include building data on cloud solutions at customers, leading Business and IT stakeholders through designing a robust, secure and optimized AWS solutions and ability to be hands-on delivering the target solution. This role will work with customers and leading internal engineering teams in delivering big data soltuions on cloud. Using Amazon AWS public cloud technologies, our AWS Data Engineer professionals implement state of the art, scalable, high performance Data On Cloud solutions that meet the need of today’s corporate and emerging digital applications.\\n\\nRole & Responsibilities:\\nProvide subject matter expertise and hands on delivery of data capture, curation and consumption pipelines on AWS and HadoopAbility to build cloud data solutions and provide domain perspective on storage, big data platform services, serverless architectures, hadoop ecosystem, RDBMS, DW/DM, NoSQL databases and security.Participate in deep architectural discussions to build confidence and ensure customer success when building new solutions and migrating existing data applications on the AWS platform.\\n- Build full technology stack of services required including PaaS (Platform as-a-service), IaaS (Infrastructure as-a-service), SaaS (software as-a-service), operations, management and automation.Apply Accenture methodology, Accenture reusable assets, and previous work experience to delivery consistently high-quality work.Stay educated on new and emerging technologies/patterns/methodologies and market offerings that may be of interest to our clients.Understand the strategic direction set by senior management as it relates to team goals.Use considerable judgment to define solution and seeks guidance on complex problems.Primary upward interaction is with direct supervisor. May interact with peers and/or management levels at a client and/or within Accenture. Establish methods and procedures\\non new assignments with guidance.Manage small teams of delivery engineers successfully delivering work efforts (if in an independent contributor role) at a client or within Accenture.Able to travel up to 100% (M-TH)\\n\\nBasic QualificationsAt least 5 years of Consulting or client service delivery experience on Amazon AWS (AWS)At least 5 years of experience in developing data ingestion, data processing and analytical pipelines for big data, relational databases, NoSQL and data warehouse solutionsExtensive experience providing practical direction within the AWS Native and HadoopExperience with private and public cloud architectures, pros/cons, and migration considerations.Minimum of 5 years of hands-on experience in AWS and Big Data technologies such as Java, Node.js, C##, Python, SQL, EC2, S3, Lambda, Spark/SparkSQL, Hive/MR, Pig, Oozie and streaming technologies such as Kafka, Kinesis, NiFI etc.Extensive hands-on experience implementing data migration and data processing using AWS services: VPC/SG, EC2, S3, AutoScaling, CloudFormation, LakeFormation, DMS, Kinesis, Kafka, Nifi, CDC processing Redshift, Snowflake, RDS, Aurora, Neptune, DynamoDB, Hive, NoSQL, Cloudtrail, CloudWatch, Docker, Lambda, Spark,Glue, Sage Maker, AI/ML, API GW, etc.5+ years of hands on experience in programming languages such as Java, c#, node.js, python, pyspark, spark, SQL, Unix shell/Perl scripting etc.Minimum of 5 years of RDBMS experienceExperience in using Hadoop File Formats and compression techniquesExperience working with DevOps tools such as GitLabs, Jenkins, CodeBuild, CoePipeline CodeDeploy, etc.Bachelors or higher degree in Computer Science or a related discipline.\\n\\nCandidate Must Have Completed The Following Certifications\\n§ Certified AWS Developer - Associate\\n§ Certified AWS DevOps – Professional (Nice to have)\\n§ Certified AWS Big Data Specialty (Nice to have)\\n\\nNice-to-Have Skills/Qualifications:DevOps on an AWS platform. Multi-cloud experience a plus.Experience developing and deploying ETL solutions on AWS using tools like Talend, Informatica, MatillionStrong in Java, C##, Spark, PySpark, Unix shell/Perl scriptingIoT, event-driven, microservices, containers/Kubernetes in the cloud\\nExperience in Apache Maven a plusUnderstanding and implementation of Data Lake architecturesUnderstanding NoSQL technologies such as MongoDB, Cassandra, Hbase is a plusUnderstanding Solr, Elasticsearch is a plus\\n\\nProfessional Skill Requirements Proven ability to build, manage and foster a team-oriented environment Proven ability to work creatively and analytically in a problem-solving environment Desire to work in an information systems environment Excellent communication (written and oral) and interpersonal skills Excellent leadership and management skills\\n\\nAll of our professionals receive comprehensive training covering business acumen, technical and professional skills development. You'll also have opportunities to hone your functional skills and expertise in an area of specialization. We offer a variety of formal and informal training programs at every level to help you acquire and build specialized skills faster. Learning takes place both on the job and through formal training conducted online, in the classroom, or in collaboration with teammates. The sheer variety of work we do, and the experience it offers, provide an unbeatable platform from which to build a career.\\n\\nApplicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status).\\n\\nCandidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.\\n\\nAccenture is a Federal Contractor and an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities.\\n\\nEqual Employment Opportunity\\n\\nAll employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.\\n\\nJob candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.\\n\\nAccenture is committed to providing veteran employment opportunities to our service men and women.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "4   JOIN US IN PROVIDING ENERGY AND IMPROVING LIVES.\\n\\nAt Phillips 66, we Provide Energy and Improve Lives, guided by our values of Safety, Honor and Commitment. Phillips 66 is dedicated to helping University New Hires make a smooth transition into the professional world. That is why we have developed career-specific programs designed to give you the tools you need to maximize your potential and succeed in your new career.\\n\\nInformation Technology (IT) is a valued business partner inside Phillips 66, driving digital transformation through the use of new technologies and delivery processes to impact the bottom line. By using agile product management and a DevOps approach to delivery, IT at Phillips 66 works directly with the businesses on their highest priorities. We believe in continuous learning and through our Digital University, we commit to making the latest skills training available throughout your career.\\n\\nAs a Phillips 66 IT University New Hire , you will have the unique opportunity to undergo a rigorous and exciting six-week program, Experience 66. The program provides you with a solid foundation to help jump start your career at Phillips 66 before beginning your new role.\\n\\nFollowing this program, you will move into the role of Data Engineer New Hire where you will play a key role in contributing to the success of advanced analytics and artificial intelligence projects across the company, by partnering with respective business owners and leveraging data to identify areas of improvement & optimization. The role sits in the sweet spot between technology and business worlds and provides opportunity for high business impact and working with seasoned business leaders. Start your career at our headquarters in Houston, TX.\\n\\nResponsibilities:\\nCreate systems for storing, extracting, transferring, loading, and modeling big data to be used for both production systems and machine learning projects\\n\\nImplement data engineering systems in Microsoft Azure, AWS, HANA and other systems, including open source data science tools to meet the needs of our internal customer.\\n\\nBuild end-to-end solutions to solve high value business needs in a sustainable, innovative manner\\n\\nEngage in constant process improvement, always looking for opportunities to increase efficiency and reduce failures\\n\\nRequirements for a Phillips 66 Data Engineer University New Hire:\\n\\nBasic/Required:\\nLegally authorized to work in the job posting country\\n\\nPursuing a Bachelor’s or Master’s degree in Computer Science, Analytics, Data Science, Engineering, Mathematics, or equivalent field of study\\n\\nGraduating in Winter 2019 or Spring/Summer 2020\\n\\nPreferred:\\nA minimum cumulative GPA of 3.0 on a 4.0 scale\\n\\nPrevious internship or co-op participant in related industry\\n\\nPrevious internship with Phillips 66\\n\\nPhillips 66 SHIELD Scholar recipient\\n\\nWilling to work in any of our operating locations\\n\\nProficiency in R or Python and familiarity with data science packages in that language\\n\\nUnderstanding of Computer Science fundamentals in object-oriented design, data structures, algorithm design, cloud technologies and problem solving\\n\\nFamiliarity with Agile Development\\n\\nTo apply and be considered:\\nYou must apply through your university prior to university deadlines (if applicable) AND\\n\\nApply online by going to http://www.p66oncampus.jobs and complete the entire application process\\n\\nAttach an electronic copy of your resume and unofficial transcript\\n\\nAnswer all prescreening questions and provide your eSignature\\n\\nCandidates for regular U.S. positions must be a U.S. citizen or national, or an alien admitted as permanent resident, refugee, asylee or temporary resident under 8 U.S.C. 1160(a)(1). Individuals with temporary visas such as E, F-1, H-1, H-2, L, B, J, or TN or who need sponsorship for work authorization now or in the future, are not eligible for hire.\\n\\nAbout Phillips 66\\n\\nPhillips 66 is a diversified energy manufacturing and logistics company. With a portfolio of Midstream, Chemicals, Refining, and Marketing and Specialties businesses, the company processes, transports, stores and markets fuels and products globally. Phillips 66 Partners, the company’s master limited partnership, is integral to the portfolio. Headquartered in Houston, the company has 14,300 employees committed to safety and operating excellence. Phillips 66 had $58 billion of assets as of March 31, 2019. For more information, visit http://www.phillips66.com/ or follow us on Twitter @Phillips66Co and @P66oncampus.\\n\\nPhillips 66 is an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities\\n\\nRequisition ID: 51351\\n\\nLocation: Texas - Houston\\n\\nJob Field: Internships, Graduate Positions, and Student Programs                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "5   Tailored Brands, Inc.’s purpose is to help our customers love how they look. We accomplish this by providing a personal, convenient, one-of-a-kind shopping experience with compelling products and world-class service. We help fulfill this mission by providing our employees with an engaging and inclusive workplace focused on teamwork, growth and respect.\\n\\n\\nTailored Brands currently has an exciting opportunity to join our engineering team consisting of developers from a wide array of backgrounds. Our data team primarily focuses on Java, SQL and Python. Our team is a tight knit, friendly group of engineers that are dedicated to learning from and teaching to each other. Team members regularly contribute to and optimize our engineering practices and processes.\\n\\n\\nKey Responsibilities:\\nEnhance and further develop Big Data processing pipelines for data sources containing structured and unstructured data\\nData Warehousing with Data modeler experience\\nMonitor and optimize key infrastructure components such as Databases, EC2 Clusters, and other aspects of the stack\\nHelp promote best practices for Big Data development\\nAct as a bridge between the infrastructure and application engineering teams\\nProvide infrastructure support with a focus on cloud based computing\\nBuild and support visualization and exploration capabilities around our Data Sets\\nWork with the Data Extraction and Data Science engineers on normalization and analytical processes\\nWork in an Agile manner with business users and data scientists to understand and discover the potential business value of new and existing Data Sets and help productize those discoveries\\nHelp design and implement disaster recovery efforts\\nAnalyze requirements and architecture specifications to create detailed design\\nResearch areas of interest to the team and help facilitate solutions\\nDesign Cloud Architecture, SaaS, PaaS, and SaaS\\n\\nRequired Experience:\\nBachelor’s degree in Computer Science or Information Systems required; Masters preferred\\n3-5 years minimum retail work experience (preferred) with:\\nProduction deployments\\nTraditional ETL, SQL and RDBMS: Oracle, MSSQL, MySQL, DataStage, and Talend\\nObject Oriented programming languages development (Java/Python preferred) as well as SQL and Unix Shell scripting\\nModern data technical stack experience such as: Hadoop, Hive, Pig, Sqoop, Flume, MapReduce, Spark, Storm, Apex, Kafka, NiFi, HBase, and MongoDB\\nKnowledge and experience with:\\nDatalakes design, Teradata and/or Snowflake (preferred)\\nNice to have AWS and Azure Cloud\\nBigData technologies and techniques, NoSQL systems (Hortonworks/Hadoop Ecosystem, Cassandra, Couchbase)\\n\\n\\nRequired Experience, continued:\\nExposure working with:\\nRest/SOAP clients\\nRelational and Non-relational Data Modeling\\nData Warehousing concepts\\nFamiliarity with:\\nGit/SVN\\nUC4 and BMC Control-M\\nJboss/JavaEE\\nObject Oriented Design Patterns\\nSerialization technologies such as Apache Avro\\nMicroStrategy and Tableau Data Visualization concepts\\n#LI-JE1\\nWork Environment, Physical & Mental Demands\\nAbility to sit and work at a computer keyboard for extended periods of time\\nAbility to stoop, kneel, bend at the waist, and reach on a daily basis\\nAble to lift and move up to 25 pounds occasionally\\nMust utilize visual acuity, speech and hearing, hand and eye coordination and manual dexterity necessary to operate a computer and office equipment\\nHours may exceed 40 hours per week+\\n\\nNote: To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed are representative of the knowledge, skill, and/or ability required and is not intended to be an exhaustive list of all duties, responsibilities or qualifications associated with this job.\\n\\n\\n\\nWork Locations: 01099I IT Dept. 6380 Rogerdale Rd Houston 77072\\nJob: Information Technology (IT)\\nOrganization: Tailored Shared Services\\nShift: Day Job                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "6   Job Description\\nIf you want to bring your technical expertise, ‘challenge-accepted!’ mentality and passion for building amazing products with real-world impact for hundreds of millions of people come join our group! We have been looking for you! We have an amazing team with deep backgrounds across technology and energy.\\n\\nShell New Energies\\n\\nShell is leading the transition towards a low-carbon future. We aim to cut the net carbon footprint of our energy products in half by 2050. Our New Energies business, set up in 2016, supports this ambition. New Energies is an emerging opportunity, in which we plan to invest on average $1-2 billion a year until 2020 as we look for commercial investments in new and fast-growing segments of the energy industry.\\n\\nShell New Energies focuses on two areas: new fuels and power. New Fuels consists of investments in hydrogen, biofuels, and electric vehicle charging. In Power, we are building up positions across the full electricity value chain, including in renewable generation, retail energy, distributed energy resources, power trading and marketing, and grid services. Within these focus areas, we look for ways to connect customers with new business models for mobility and energy services, enabled by digital technologies and decentralization of energy systems. Development of our IoT platform for Shell New Energy will be paramount in achieving these goals.\\n\\nEnergy Platform Team\\n\\nThe Energy Platform team is a nimble, cross-functional, deeply technical and passionate group that embodies the speed and agility of a startup while embracing the scale of one of the largest companies in the world. Achieving a balance between agility and global scale provides unique opportunities, and the Energy Platform Team borrows from best-in-class product development, continuous delivery, and commercialization techniques while adapting them to the unique global context within Shell.\\n\\nThe Energy Platform team is empowered to coordinate and align Shell’s energy management platform objectives, strategies, and execution approaches across the company, as well as to design, deliver and maintain a mission-critical component of Shell’s ability to deliver differentiated products, offerings,and capabilities across its expanding global footprint.\\n\\nWe are looking for a Data Engineer with the ability to bring their expertise and excitement for solving complex problems while building one of the largest IoT platforms in the world. There will be no shortage of opportunities to lead, eat, drink, and be merry with the most dynamic team ever assembled in the energy industry.\\n\\nBuild, on a daily basis, real-time and big data processing pipelines, optimizing for scalability and performance, under multiple datastore concepts (Relational, NoSQL, Graph).\\nProficient in building large scale ETL jobs, leveraging big data infrastructure (Hadoop, Spark, Kafka) and modern container orchestration environments (Kubernetes).\\nComfortable working in a fast-paced environment building, running, testing and shipping data pipelines to serve ML/AI workloads under a common API.\\nWilling to work with a cross-functional team of market analysts, data scientists & software developers to translate their data needs into features inside the Energy Platform.\\nCreate data tooling that assists data scientists and analysts in building low latency, scalable and resilient pipelines for machine learning and optimization workloads.\\nEnthusiast of data quality, lifecycle and provenance management, helping establish a DataOps centric culture within Engineering teams.\\nAdvanced working knowledge of query authoring and tooling for cross source data aggregation: APIs, 3rd party DB, Object Storages, messaging bus.\\nYou have a proven history of working on large scale ETL jobs for data wrangling and cleansing of IoT time-series & telemetry data, as well as IIoT unstructured datasets, focusing on serving machine learning orchestrations.\\nYou have experience with Analytical Expression Compiling languages, for runtime analytics during SQL querying.\\nRequirements\\nLegal authorization to work in the US on a full-time basis for anyone other than current employer\\nBachelor's degree in a relevant technical discipline.\\n5+ years of experience with demonstrable proficiency in one or more DB and data pipeline tooling: mySQL, PostgreSQL, OSI Pi historian, TimescaleDB, Streamsets, Apache Drill, Apache Parquet, Dremio …\\nYou are passionate about building scalable, high performing, data pipelines, and analytic catalogs.\\nExperience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc\\nProficient with Containerized environments and workloads\\nExcellent analytical, problem-solving, and troubleshooting skills.\\nExperience architecting, deploying, and supporting production applications.\\nYou care deeply about performance, accessibility and API design.\\nGreat communication skills.\\nWork locations may include Houston, TX or San Francisco, CA\\nCompany Description\\nShell is a global group of energy and petrochemical companies with about 84,000 employees across more than 70 countries. We aim to meet the world’s growing need for more and cleaner energy solutions in ways that are economically, environmentally and socially responsible. We have expertise in exploration, production, refining and marketing of oil and natural gas, and the manufacturing and marketing of chemicals. As a global energy company operating in a challenging world, we set high standards of performance and ethical behaviors. We are judged by how we act and how we live up to our core values of honesty, integrity and respect for people. Our Business Principles are based on these. They promote trust, openness, teamwork and professionalism, as well as pride in what we do and how we conduct business.Building on our core values, we aspire to sustain a diverse and inclusive culture where everyone feels respected and valued, from our employees to our customers and partners. A diverse workforce and an inclusive work environment are vital to our success, leading to greater innovation and better energy solutions.\\nDisclaimer\\nPlease note: We occasionally amend or withdraw Shell jobs and reserve the right to do so at any time, including prior to the advertised closing date.\\n\\nBefore applying, you are advised to read our data protection policy. This policy describes the processing that may be associated with your personal data and informs you that your personal data may be transferred to Royal Dutch/Shell Group companies around the world.\\n\\nThe Shell Group and its approved recruitment consultants will never ask you for a fee to process or consider your application for a career with Shell. Anyone who demands such a fee is not an authorised Shell representative and you are strongly advised to refuse any such demand.\\n\\nShell participates in E-Verify.\\n\\nAll qualified applicants will receive consideration for employment without regard to race, color, sex, national origin, age, religion, disability, sexual orientation, gender identity, protected veteran status, citizenship, genetic information or other protected status under federal, state or local laws.\\n\\nShell is an Equal Opportunity Employer - Minorities/Females/Veterans/Disability.\\nEmployment TypeFull Time\\nSkillpool\\nIT Data and Analytics, Information\\nWork LocationHouston\\nNo. of Positions\\n1\\nJob Expires01-Nov-2019                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "7   Vroom.com is a venture-backed, fast-growing start-up focused on revolutionizing the car buying experience. Our approach is unique in that we recondition pre-owned vehicles to a high standard, sell online, and deliver anywhere across the US. We have experienced tremendous growth in our first 5 years of operation and have become a disruptive force in the automotive industry. Vroom is an exciting, accelerating workplace, and there's no better time to join the team than right now.\\n\\nWe are building a team of experienced Data Engineers to ensure that our data infrastructure supports and helps drive the dramatic growth that we expect! We're looking for an exceptional data engineer to help us organize, test, and operationalize our data. Our business depends on putting the right data in front of the right people at the right time. As a Data Engineer in this dynamic environment, you will be instrumental in pulling data from multiple sources, performing extensive analysis, and applying a variety of data science models to provide our internal customers with recommendations and feedback.\\nResponsibilities\\nEstablish and maintain best practices for our data infrastructure\\nDevelop next-gen data pipelining and ETL based on open source data pipeline tools and cloud-based ecosystems that can deal with varied data types from disparate sources\\nDevelop and tune data storage and processing systems at scale\\nBuild real-time data processing systems\\nBuild automated systems to continually monitor data quality and integrity\\nWork closely with stakeholders across Vroom to ensure data is accurate, timely, and useful\\nSkills\\n3+ years experience in data/software engineering or related field\\nFluency in Python and SQL, experience with Golang, C, C++, Java, or Scala is a plus\\nDemonstrated experience with distributed computing (Kafka, Storm, Spark, Hadoop, etc.)\\nExperience with NoSQL databases\\nProficiency in using and managing cloud infrastructure, preferably AWS\\nLinux and Bash competence\\nExperience integrating with Salesforce a plus\\nBenefits\\n\\nThis full-time role offers competitive compensation; health, dental, and vision insurance through United Healthcare; a 401k plan; fully company-paid short term disability, long term disability, and life insurance; access to a healthcare concierge service with virtual visits; and 15 annualized days of paid vacation.\\n\\nBut our biggest benefit is being part of a low-ego, high performing team that's transforming the used car market into a modern, online and data-driven industry. We are looking for people who want to be a part of a contemporary startup culture. What gets us out of bed is working with talented people on a mission that matters.\\n\\nTo Apply\\n\\nIf you think you might be who we’re looking for, apply below with your resume and a cover letter telling us why you think you’d be a great addition to the team.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "8   This position is for a Senior Azure Data Engineer within our North American team who will be designing and implementing Azure data projects for our clients. This qualified individual will work closely with clients to ensure that data technologies meet their needs and keep pace with the rapid changes in Publicis Sapient’s operations and policies/procedures.\\n\\nResponsibilities:\\nLead, design, develop, and deliver large-scale Azure data systems, data processing, and data transformation projects.\\nExecute technical feasibility assessments and project estimates for moving databases and data processing to Azure.\\nDesign and advocate solutions using modern cloud technologies, design principles, integration points, and automation methods.\\nMentor and share knowledge with customers as well as provide architecture reviews, discussions, and prototypes.\\nParticipate in overall engagement from strategy, assessment, migration, and implementations.\\nWork with customers to deploy, manage, and audit best practices for cloud products.\\nRequirements:\\nDemonstrated experience designing, implementing, and supporting enterprise-grade technical solutions in the cloud for meeting complex business data requirements.\\nExperience with Databricks and using Spark for data processing.\\nExperience with Azure Data Factory – ADF.\\nAdvanced experience with different query languages (i.e. T-SQL, PostgreSQL, PL-SQL).\\nExperience designing and building data marts, warehouses, customer profile databases, etc.\\nExperience with data modeling, table design, and mapping business needs to data structures.\\nExperience with Azure Data Lake, Azure SQL Data Warehouse, and Cosmos DB are a plus.\\nExperience with Data Management Gateway, Azure Storage Options, Stream Analytics, and Event Hubs is a plus.\\nExperience with other cloud based big data architectures is a plus.\\nExperience/Education:\\n5 to 10 years of professional experience in the information technology industry.\\nBS in Computer Science or equivalent education/professional experience is required.\\nPersonal Attributes:\\nStrong and innovative approach to problem solving and finding solutions.\\nExcellent communicator (written and verbal, formal, and informal).\\nFlexible and proactive/self-motivated working style with strong personal ownership.\\nAbility to multi-task and prioritize under pressure.\\nAbility to work independently with minimal supervision as well as in a team environment.\\nFlexibility and mobility is required to deliver this role as there may be requirements to spend time onsite with our clients to enable delivery of the first class services we pride ourselves in.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "9   Are you ready to step up to the New and take your technology expertise to the next level?\\nJoin Accenture and help transform leading organizations and communities around the world. The sheer scale of our capabilities and client engagements, in conjunction with the way we collaborate, operate and deliver value, provides an unparalleled opportunity to grow and advance. Choose Accenture and make delivering innovative work part of your extraordinary career.\\nPeople in our Client Delivery & Operations career track drive delivery and capability excellence through the design, development and/ or delivery of a solution, service, capability or offering. They grow into delivery-focused roles, and can progress within their current role, laterally or upward. We partner with our clients to help transform their data into an ‘Appreciating Business Asset.’\\n\\nAs part of our Data Business Group, you will lead technology innovation for our clients through robust delivery of world-class solutions. You will build better software better! There will never be a typical day and that’s why people love it here. The opportunities to make a difference within exciting client initiatives are unlimited in the ever-changing technology landscape. You will be part of a highly collaborative and growing network of technology and data experts, who are taking on today’s biggest, most complex business challenges using the latest data and analytics technologies. We will nurture your talent in an inclusive culture that values diversity. You will have an opportunity to work in roles such as Data Scientist, Data Engineer, or Chief Data Officer covering all aspects of Data including Data Management, Data Governance, Data Intelligence, Knowledge Graphs, and IoT. Come grow your career in Technology at Accenture!\\n\\nThe Azure Technical Architect Delivery is responsible for delivering Data On Cloud projects for Azure based deals. The ideal candidate would also be responsible for developing and delivering Azure cloud solutions to meet todays high demand in areas such as AIML, IoT, advanced analytics, open source, enterprise collaboration, microservices, serverless, etc. The Regional Azure Technical Architect is a highly performant Azure Architect responsible for delivering Cloud based Big Data and Analytical Solutions to our clients. Responsibilities include evangelizing data on cloud solutions with customers, leading Business and IT stakeholders through designing a robust, secure and optimized Azure architectures and ability to be hands-on delivering the target solution. This role will work with customers and leading internal data engineers in delivering big data solutions on cloud. Using Azure public cloud technologies, our Technical Architect professionals implement state of the art, scalable, high performance Data On Cloud solutions that meet the need of today's corporate and emerging digital applications.\\n\\nRole & Responsibilities:Work with Sales and Bus Dev teams in providing Azure Technical Architecture expertise while pursuing client opportunities.Ability to build cloud architectures and provide prescriptive guidance across network, storage, Big Data Platform Services, serverless architectures, hadoop ecosystem, vendor products, RDBMS & NoSQL databases and security.Participate in deep architectural discussions to build confidence and ensure customer success when building new solutions and migrating existing data applications on the Azure platform.Conduct full technical discovery, identifying pain points, business and technical requirements, “as is” and “to be” scenarios.\\n- Assess the full technology stack of services required including PaaS (Platform as-a-service), IaaS (Infrastructure as-a-service), SaaS (software as-a-service), operations, management and automation.Lead the discussions and early analysis of the cloud concepts as it relates to Clients’s Journey to Cloud methodology so that clear use cases are developed and prioritized as well as transitioning these concepts from ideas to proof-of-concepts all the way to production delivery with the full support of the appropriate teams.Compare solution alternatives across both technical and business parameters which support the define cost and service requirements.Apply Accenture methodology, Accenture reusable assets, and previous work experience to delivery consistently high-quality work.Stay educated on new and emerging technologies/patterns/methodologies and market offerings that may be of interest to our clients.Adapt to existing methods and procedures to create possible alternative solutions to moderately complex problems.Understand the strategic direction set by senior management as it relates to team goals.Use considerable judgment to define solution and seeks guidance on complex problems.Prepare and deliver product messaging in an effort to highlight value proposition and unique differentiators.Primary upward interaction is with direct supervisor. May interact with peers and/or management levels at a client and/or within Accenture. Establish methods and procedures\\non new assignments with guidance.\\nManage small teams of deliver engineers successfully delivering work efforts (if in an independent contributor role) at a client or within Accenture.\\nExtensive travel may be required\\n\\nQualifications\\nBasic Qualifications\\nAt least 5 years of consulting or client service delivery experience on Azure\\nAt least 10 years of experience in big data, database and data warehouse architecture and delivery\\nMinimum of 5 years of professional experience in 2 of the following areas:\\n§ Solution/technical architecture in the cloud\\n§ Big Data/analytics/information analysis/database management in the cloud\\n§ IoT/event-driven/microservices in the cloud\\nExperience with private and public cloud architectures, pros/cons, and migration considerations.\\nExtensive hands-on experience implementing data migration and data processing using Azure services: Networking, Windows/Linux virtual machines, Container, Storage, ELB, AutoScaling, Azure Functions, Serverless Architecture, ARM Templates, Azure SQL DB/DW, Data Factory, Azure Stream Analytics, Azure Analysis Service, HDInsight, Databricks Azure Data Catalog, Cosmo Db, ML Studio, AI/ML, etc.\\n Cloud migration methodologies and processes including tools like Azure Data Factory, Event Hub, etc.\\n - Familiarity with the Technology stack available in the industry for data management, data ingestion, capture, processing and curation: Kafka, StreamSets, Attunity, GoldenGate, Map Reduce, Hadoop, Hive, Hbase, Cassandra, Spark, Flume, Hive, Impala, etc.\\nBachelors or higher degree in Computer Science or a related discipline.\\n\\nCandidate Must Have Completed The Following Certifications\\nMCSA Cloud Platform (Azure) Training & Certification\\nMCSE Cloud Platform & Infratsructiure Training & Certification\\nMCSD Azure Solutions Architect Training & Certification\\n\\nNice-to-Have Skills/Qualifications:\\nDevOps on an Azure platform\\nExperience developing and deploying ETL solutions on Azure\\nStrong in Power BI, Java, C##, Spark, PySpark, Unix shell/Perl scripting\\nFamiliarity with the technology stack available in the industry for metadata management: Data Governance, Data Quality, MDM, Lineage, Data Catalog etc.\\n- Multi-cloud experience a plus - Azure, AWS, Google\\n\\nProfessional Skill Requirements\\n Proven ability to build, manage and foster a team-oriented environment\\n Proven ability to work creatively and analytically in a problem-solving environment\\n Desire to work in an information systems environment\\n Excellent communication (written and oral) and interpersonal skills\\n Excellent leadership and management skills\\n Excellent organizational, multi-tasking, and time-management skills\\n Proven ability to work independently\\n\\nAll of our professionals receive comprehensive training covering business acumen, technical and professional skills development. You'll also have opportunities to hone your functional skills and expertise in an area of specialization. We offer a variety of formal and informal training programs at every level to help you acquire and build specialized skills faster. Learning takes place both on the job and through formal training conducted online, in the classroom, or in collaboration with teammates. The sheer variety of work we do, and the experience it offers, provide an unbeatable platform from which to build a career.\\n\\nApplicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status).\\n\\nCandidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.\\n\\nAccenture is a Federal Contractor and an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities.\\n\\nEqual Employment Opportunity\\n\\nAll employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.\\n\\nJob candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.\\n\\nAccenture is committed to providing veteran employment opportunities to our service men and women.  \n",
       "10  Passionate about tech? Interested in Energy? Come work for Kayrros, a fast-growing start-up using artificial intelligence to transform the world’s biggest industry.\\n\\nKayrros is headquartered in Paris, with offices in New York, Houston, London, and Singapore. By working for Kayrros, you will join an energetic team of 150 people, with diverse professional backgrounds—from data science and petroleum engineering to sales and marketing—and over 15 different nationalities and 10 spoken languages.\\n\\nOur team of energy experts and tech wizards are working to bring transparency to the global energy market. We employ innovative technologies, like satellite imagery processing and artificial intelligence, to capture and analyse data across the energy sector. Combined with our expert analysis, we give our clients valuable information on global market movements to make better business decisions—whether that’s trading, investing or managing their operations.\\n\\nIn September 2018, Kayrros received €21M in Serie B funding to continue breaking the boundaries of the energy market.\\n\\nWe are currently recruiting for our Houston office,\\n\\na Data Engineer M/F\\n\\nData Engineers play a central role in Kayrros. Working hand in hand with Data Scientists and Analysts they gather and process raw data at scale and work closely with Software Engineers to integrate innovations and algorithms into our production system.\\n\\nAs a data engineer, you will therefore have to:\\n\\nArchitect, build and test industry-grade geospatial data pipelines leveraging Kayrros existing technologies.\\n\\nWork collaboratively with data scientists and software engineers to deploy data science models at scale in a production environment.\\n\\nAs the first Data Engineer of the Houston office, be able to work autonomously with the remote support of the Paris headquarter infrastructure and data teams.\\n\\nProvide technical support to Data Scientists during exploratory analysis\\n\\nEvaluate performance and optimize all parts of the stack\\n\\nContinuously provide ideas to improve products\\n\\nWork in a creative, fast-pace environment.\\nTechnology stack\\n\\n\\nLanguages: mainly Python (pypark, airflow). Knowledge in Java and/or C is a plus.\\n\\nTools : Message brokers (RabbitMQ, Kafka), machine learning packages (Sci-kit learn, Pandas), tests\\n\\n(Unittest...)\\n\\nStack data: Hadoop (Apache Spark, Hbase...), Elasticsearch\\n\\nInfrastructure : Docker, Rancher, AWS S3/OpenIO, GitlabProfile\\n\\nProfile\\nMinimum three years of industry experience building successful data pipelines at scale with an emphasis on software engineering, software architecture, code quality, best practices\\nBachelor's or Masters in Math, Engineering, Computer Science, or other quantitative field preferred.\\nStrong Python 3 skills to write reusable, testable and efficient code and coach others in doing so.\\nExperience with some of the following components: Spark, Docker, Elasticsearch, Pandas, Scikit-learn is a must.\\nExperience with geospatial and geolocation data is a plus.\\nAbility to work in a fast-paced environment\\nPlease note that we do not sponsor US visa.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "11  You are curious, persistent, logical and clever a true techie at heart. You enjoy living by the code of your craft and developing elegant solutions for complex problems. If this sounds like you, this could be the perfect opportunity to join EPAM as a Lead Data Enigneer. Scroll down to learn more about the position’s responsibilities and requirements.\\nWhat You’ll Do\\nArchitecture design of holistic Cloud data ecosystem with a focus on Google Cloud Platform capabilities and features\\nArchitecture design of Production, Staging/QA, and Development infrastructures running is 24/7 environments\\nRobust and consistent Cloud Strategy design aligned with business objectives\\nProvide guidelines for data migration approaches and techniques including ingest, store, process, analyze and explore/visualize data\\nAssistance with data migration and transformation\\nEvangelize Cloud computing expertise internally and externally to drive Cloud Adoption\\nWhat You Have\\nA degree in an associated field and/or other advanced certification along with significant experience\\nIn-depth cloud professional, competent of quickly establishing connections and credibility in how to address the business needs via design and operate cloud-based solutions\\nExperience in Agile or PMI methodology managed projects\\nExperience in enterprise applications, and big data solutions\\nExperience in platform and cloud migrations, including migration factory\\nIn-depth experience with databases and tools analysis\\nIn-depth experience with ETL tools\\nProcesses design and development for the data modeling, mining, and analysis\\nExtensive experience in methodologies and processes for large-scale databases management on-premises and cloud environment\\nIn-depth understanding and knowledge of distributed version control systems like Git\\nStrong understanding of concepts and experience with StackDriver and other cloud-based monitoring tools including application level and logging\\nNice to have\\nGoogle Cloud Certified Professional Data Engineer\\nExperience Creating automated tooling for cloud platforms\\nExperience with architecting and handling large datasets, structured and semi-structured data formats\\nExperience with streaming processing\\nExperience with messaging platforms\\nExperience with performance testing and tuning\\nExperience with GCP based security hardening including IAM, ACL, firewall rules, data traffic encryption\\nWhat We Offer\\nMedical, Dental and Vision Insurance (Subsidized)\\nHealth Savings Account\\nFlexible Spending Accounts (Healthcare, Dependent Care, Commuter)\\nShort-Term and Long-Term Disability (Company Provided)\\nLife and AD&D Insurance (Company Provided)\\nEmployee Assistance Program\\nUnlimited access to LinkedIn learning solutions\\nMatched 401(k) Retirement Savings Plan\\nPaid Time Off\\nLegal Plan and Identity Theft Protection\\nAccident Insurance\\nEmployee Discounts\\nPet Insurance                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "12  Equal Opportunity Employer: Minority/Female/Disability/Veteran\\nWM Logistics, LLC seeks a Big Data Engineer at our facility in Houston, Texas to create software solutions focused on large scale data analytics leveraging big data tools & technology. Position requires Bachelor’s Degree in Computer Science, Electrical Engineering, MIS, or related field. Must have 10 years of previous experience related to software development, software engineering, coding, and working with enterprise data warehouse databases, large databases or big data solutions and technologies. Must have experience with software development project life cycles, experience with large or enterprise databases, and SQL programming. Must also have experience with JavaScript, Angular, HTML 5, or jQuery. Must have experience using Amazon web services, Scala, and Oracle. Job location: Houston, TX. To apply, go to www.wm.com\\nI understand that applying to this job indicates that I have the legal right to work in the United States. I agree to perform physical duties of this position as outlined in the job with or without reasonable accommodations. I understand that if offered the position, I will be required to pass a drug screen.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "13  Are you ready to step up to the New and take your technology expertise to the next level?\\n\\nJoin Accenture and help transform leading organizations and communities around the world. The sheer scale of our capabilities and client engagements, in conjunction with the way we collaborate, operate and deliver value, provides an unparalleled opportunity to grow and advance. Choose Accenture and make delivering innovative work part of your extraordinary career.\\n\\nPeople in our Client Delivery & Operations career track drive delivery and capability excellence through the design, development and/ or delivery of a solution, service, capability or offering. They grow into delivery-focused roles, and can progress within their current role, laterally or upward. We partner with our clients to help transform their data into an ‘Appreciating Business Asset.’\\n\\nAs part of our Data Business Group, you will lead technology innovation for our clients through robust delivery of world-class solutions. You will build better software better! There will never be a typical day and that’s why people love it here. The opportunities to make a difference within exciting client initiatives are unlimited in the ever-changing technology landscape. You will be part of a highly collaborative and growing network of technology and data experts, who are taking on today’s biggest, most complex business challenges using the latest data and analytics technologies. We will nurture your talent in an inclusive culture that values diversity. You will have an opportunity to work in roles such as Data Scientist, Data Engineer, or Chief Data Officer covering all aspects of Data including Data Management, Data Governance, Data Intelligence, Knowledge Graphs, and IoT. Come grow your career in Technology at Accenture!\\n\\nThe North America Data Strategy & Architecture capability is part of the Data Business Group (DBG) within Accenture Technology. This team provides advisory services to clients that create an architecture blueprint and an execution roadmap to rotate to “Data in the New” and become intelligent data driven enterprises.\\n\\n Connect business vision and current state problems with data, analytics and technology solutions and architectural patterns Interview business stakeholders to understand their vision and challenges Understand and document current state pain points including limitations caused by existing data, analytics and technology gaps Identify and detail business ‘use cases’, or ways that stakeholders would like to drive business value (e.g. increase revenue, decrease expenses, increase efficiency) through data and analytics Aggregate use cases into business consumption patterns detailing the data and technology designs that would support the execution of multiple use cases Ensure alignment between the client’s business needs of the future state with data and technology architecture, operating model and governance recommendations Synthesize business needs with enabling target state recommendations into a vision that client executives, department heads, business and technical resources can understand and align around Develop an execution roadmap detailing a strategic journey from current state to realization of the future state vision with incremental release of technical and operational features and business value Analyze business case for execution against the strategy, including the collection of business case inputs (costs, value drivers) as well as the calculation of return on investment Present data strategy to clients and gain buy in Participate in defining data governance strategy and operating model\\n\\nRequired Skills 3+ years with business responsibilities (Business Analyst or Project Lead) of data and analytics solutions spanning:\\no Data Management solutions with capabilities, such as Data Ingestion, Data Curation, Metadata and Catalog, Data Security, Data Modeling, Data Wrangling\\no Data Warehousing / BI / Reporting solutions that generate business value using platforms and technologies such as Hadoop, Teradata, Netezza, Greenplum, MapReduce, Spark, etc.\\no Data Science, AI / ML, Advanced Analytic solutions that meet business problems 3+ years of consulting experience, interviewing business stakeholders and developing relationships within client organizations Strong communication, presentation, written and facilitation skills Superior critical thinking, analytical and problem-solving skills Ability to interface with client at any level, executive to engineer Competent in leveraging Microsoft Office tools, specifically PowerPoint, Word, and Excel\\n Able to travel up to 100% (Mon-Thu)\\n\\nOptional Skills (Plus): Industry knowledge in Life Sciences, Financial Services or Healthcare Experience in data governance and operating model\\n Experience in compiling business cases and roadmaps for data, analytics and technology investments\\n\\nAll of our professionals receive comprehensive training covering business acumen, technical and professional skills development. You'll also have opportunities to hone your functional skills and expertise in an area of specialization. We offer a variety of formal and informal training programs at every level to help you acquire and build specialized skills faster. Learning takes place both on the job and through formal training conducted online, in the classroom, or in collaboration with teammates. The sheer variety of work we do, and the experience it offers, provide an unbeatable platform from which to build a career.\\n\\nApplicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status).\\n\\nCandidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.\\n\\nAccenture is a Federal Contractor and an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities.\\n\\nEqual Employment Opportunity\\n\\nAll employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.\\n\\nJob candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.\\n\\nAccenture is committed to providing veteran employment opportunities to our service men and women.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "14  Are you ready to step up to the New and take your technology expertise to the next level?\\nJoin Accenture and help transform leading organizations and communities around the world. The sheer scale of our capabilities and client engagements, in conjunction with the way we collaborate, operate and deliver value, provides an unparalleled opportunity to grow and advance. Choose Accenture and make delivering innovative work part of your extraordinary career.\\nPeople in our Client Delivery & Operations career track drive delivery and capability excellence through the design, development and/ or delivery of a solution, service, capability or offering. They grow into delivery-focused roles, and can progress within their current role, laterally or upward. We partner with our clients to help transform their data into an ‘Appreciating Business Asset.’\\n\\nAs part of our Data Business Group, you will lead technology innovation for our clients through robust delivery of world-class solutions. You will build better software better! There will never be a typical day and that’s why people love it here. The opportunities to make a difference within exciting client initiatives are unlimited in the ever-changing technology landscape. You will be part of a highly collaborative and growing network of technology and data experts, who are taking on today’s biggest, most complex business challenges using the latest data and analytics technologies. We will nurture your talent in an inclusive culture that values diversity. You will have an opportunity to work in roles such as Data Scientist, Data Engineer, or Chief Data Officer covering all aspects of Data including Data Management, Data Governance, Data Intelligence, Knowledge Graphs, and IoT. Come grow your career in Technology at Accenture!\\n\\nThe Google GCP Data Engineer is responsible for delivering Data On Cloud projects for Google GCP based deals. The ideal candidate would be responsible for developing and delivering GCP cloud solutions to meet today’s high demand in areas such as AI/ML, IoT, advanced analytics, open source, enterprise collaboration, microservices, serverless, etc. The GCP Data Engineer is a highly performant engineer responsible for delivering Cloud based Big Data and Analytical Solutions for our clients. Responsibilities include building data on cloud solutions for customers, leading Business and IT stakeholders through designing a robust, secure and optimized GCP solutions and ability to be hands-on delivering the target solution. This role will work with customers and leading internal engineering teams in delivering big data solutions on cloud. Using Google GCP cloud technologies, our GCP Data Engineer professionals implement state of the art, scalable, high performance Data On Cloud solutions that meet the need of today’s corporate and emerging digital applications.\\n\\nBasic Qualifications\\nMinimum of 3 years previous Consulting or client service delivery experience on Google GCP\\nMinimum of 3 years of RDBMS experience\\nMinimum pf 3 years of experience in developing data ingestion, data processing and analytical pipelines for big data, relational databases, NoSQL, data lake and data warehouse solutions\\nExperience with private and public cloud architectures, pros/cons, and migration considerations.\\nExtensive hands-on experience implementing data migration and data processing using GCP services etc:\\nData Ingestion : Cloud Pub/Sub, Data Transfer Service, Cloud IoT Core\\nData Storage : Cloud Spanner, Cloud Storage, Cloud Datastore, Cloud SQL, Cloud Bigtable, Cloud Memorystore\\nStreaming Data Pipeline : Cloud Dataflow, Cloud Dataproc, Cloud Dataprep, Apache Beam\\nData Warehousing & Data Lake : BigQuery, Cloud Storage\\nAdvanced Analytics : Cloud ML engine, Google Data Studio, Google Datalab, Tensorflow & Sheets\\nBachelors or higher degree in Computer Science or a related discipline.\\nAble to trval 100% M-TH\\n\\nCandidate Must Have Completed The Following Certifications\\nCertified GCP Developer - Associate\\nCertified GCP DevOps – Professional (Nice to have)\\nCertified GCP Big Data Specialty (Nice to have)\\n\\nNice-to-Have Skills/Qualifications:\\nDevOps on an GCP platform. Multi-cloud experience a plus.\\nExperience developing and deploying ETL solutions on GCP using tools like Talend, Informatica, Matillion\\nIoT, event-driven, microservices, containers/Kubernetes in the cloud\\n\\nProfessional Skill Requirements\\nProven ability to build, manage and foster a team-oriented environment\\nProven ability to work creatively and analytically in a problem-solving environment\\nDesire to work in an information systems environment\\nExcellent communication (written and oral) and interpersonal skills\\nExcellent leadership and management skills\\n\\nAll of our professionals receive comprehensive training covering business acumen, technical and professional skills development. You'll also have opportunities to hone your functional skills and expertise in an area of specialization. We offer a variety of formal and informal training programs at every level to help you acquire and build specialized skills faster. Learning takes place both on the job and through formal training conducted online, in the classroom, or in collaboration with teammates. The sheer variety of work we do, and the experience it offers, provide an unbeatable platform from which to build a career.\\n\\nApplicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status).\\n\\nCandidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.\\n\\nAccenture is a Federal Contractor and an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities.\\n\\nEqual Employment Opportunity\\n\\nAll employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.\\n\\nJob candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.\\n\\nAccenture is committed to providing veteran employment opportunities to our service men and women.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "15  Seeking a Senior Data Engineer\\nThis exciting role will deepen and broaden your skills with leading edge technologies in the data and analytics space. Team members have a chance to make a difference in operational efficiency and help to improve customer experiences through data-driven insights. Let’s explore!\\n\\nJob overview and responsibilities\\nUnited Airlines is seeking talented people to join the Data Engineering team. Data Engineering organization is responsible for driving data driven insights & innovation to support the data needs for commercial and operational projects with a digital focus. As a Data Engineer on the team:\\n You will partner with various teams to define and execute data acquisition, transformation, processing and make data actionable for operational and analytics initiatives that create sustainable revenue and share growth\\n Design, develop, and implement streaming and near-real time data pipelines that feed systems that are the operational backbone of our business.\\n Execute unit tests and validating expected results to ensure accuracy & integrity of data and applications through analysis, coding, writing clear documentation and problem resolution.\\n This role will also drive the adoption of data processing and analysis within the Hadoop environment and help cross train other members of the team\\n Leverage strategic and analytical skills to understand and solve customer and business centric questions\\n Coordinate and guide cross-functional projects that involve team members across all areas of the enterprise, vendors, external agencies and partners\\n Leverage data from a variety of sources to develop data marts and insights that provide a comprehensive understanding of the business\\n Develop and implement innovative solutions leading to automation\\n Use of Agile methodologies to manage projects\\n Mentor and train junior engineers\\n\\nRequired\\n BS/BA, in computer science or related STEM field\\n We are seeking creative, driven, detail-oriented individuals who enjoy tackling tough problems with data and insights. Individuals who have a natural curiosity and desire to solve problems are encouraged to apply\\n 10+ years of IT experience in software development\\n 5+ years of development experience using Java, Python, Scala\\n 5+ years of experience with Big Data technologies like Hadoop, Hive, HBASE, Kafka, Nifi\\n 5+ years of experience with relational database systems like MS SQL Server, Oracle, Teradata\\n Must be legally authorized to work in the country of employment for any employer without sponsorship\\nPreferred\\n Masters in computer science or related STEM field\\n Experience with cloud based systems like AWS, AZURE or Google Cloud\\n Certified Developer / Architect on AWS\\n Strong experience with continuous integration & delivery using Agile methodologies\\n Data engineering experience with transportation/airline industry\\n Strong problem-solving skills\\n Strong knowledge in Big Data\\n\\n\\nEqual Opportunity Employer – Minorities/Women/Veterans/Disabled/LGBT                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "16  Need for a well-demonstrated Data Engineer who will work with the Data Science team to complete a major data project.\\nMode of Interview : Telephonic/F2F\\nJob Skills:\\nExperience working on Hadoop platform components\\nKnowledge of Big Data tools, such as zookeeper, Kafka Streaming.\\nShell scripting experience\\nExperience with integration of data from multiple data sources (NoSQL, Mongo, SQL)\\nExperience working with Structured/Unstructured data.\\nExperience creating ETL pipelines\\nExperience in Docker builds and Git file versioning\\nDemonstrated ability to quickly learn new tools and paradigms to deploy cutting edge solutions.\\nKnowledge of programming in Python\\nKnowledge of MapR\\nKnowledge of Scala framework\\nExperience with Spark, Storm or Flink\\nMinimum Experience: 8 Yrs\\nRoles & Responsibilities:\\nIntegrate Data from multiple data sources\\nCreate ETL Pipelines\\nWork under the guidance of Lead to develop based on design/architecture.\\nEducation:\\nBachelor’s Degree in Computer Science or equivalent work experience. Masters preferred                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "17  DirectViz Solutions DVS, is a high-level strategic consulting services firm that meets mission needs for Government clients, is seeking a full-time Data Engineer-Full Stack. This position is located in Houston, TX. U.S. citizenship is required with the ability to obtain and maintain a government security clearance.\\n\\nData Engineer-Full Stack\\nWe are currently seeking a Data Engineer Full Stack to contribute to an exciting federal project to create, transform, and modernize applications and data platforms. This is an exciting opportunity which will allow qualified candidates to further develop their skills and expand their area of expertise.\\n\\nRESPONSIBILITIES:\\nWork closely with the Project Manager, Technical Lead, and development team to provide overall data-engineering support and to understand project and application requirements.\\nLead technical efforts and development teams in the creation of customized infrastructure, applications, and tools designed to meet user requirements.\\nAs an engineer, build and deliver data storage, integrate with existing data, and migrate the built big data applications to cloud computing platform by leveraging new technologies.\\nCollect, build, cleanse, assemble and refine datasets to support the variety of data analytics needs put forward by business stakeholders including data scientists, law enforcement officials, and agency analysts.\\nBuild data ingestion and pipeline processes for innovative analytics platforms using best practices and open source tools such as, NiFi.\\nDevelop and apply quantitative and qualitative analytic methods to identify, collect, process and analyze large data sets for specified purposes.\\nDevelop analytical solutions that are scalable, repeatable, effective, and meet the expectations of the decision-makers and stakeholders.\\nNetworking, database, cloud engineering, security engineering teams to comply with the data security policies and procedures and trouble-shoot and resolve any issues in data engineering deliveries.\\n\\nREQUIREMENTS:\\nEducation and Tools/Technology\\nBachelor's Degree in Information Technology, Computer Science, quantitatively-focused social sciences, or other quantitative fields.\\n4+ years of experience working with large and varying data sets, applying qualitative and quantitative analysis to interpret the data.\\nExperience developing complex data ingestion, analysis, and visualization pipelines from disparate data sources in varying formats.\\n4+ years of experience utilizing open source tools and programming languages at least 2: Python, R, Java, Groovy, and/or SQL.\\n2+ years of experience with at least 2 AWS Cloud/Storage/ETL, NiFi, HBase, ElasticSearch, Kibana, Janus Graph, PostgreSQL, Kafka.\\n\\nSubject Matter Expertise and Knowledge\\nKnowledge and experience with Agile, Scrum and DevOps principles and practices and working on collaborative development teams. Experience acting as the technical lead for development teams.\\nDemonstrated extensive experience working in large-scale data environments which includes real time and batch processing requirements, as well as graph databases.\\nExtensive knowledge and experience with Agile, Scrum and DevOps principles and practices and working on collaborative development teams.\\nOutstanding interpersonal and communication skills with the ability to effectively communicate with diverse audiences and influence cross functionally.\\nStrong writing skills and experience conveying highly technical material to non-technical audiences.\\nExperience designing and delivering large scale, 24-7, mission-critical data pipelines and features using modern big data architectures.\\nWorking knowledge of data security management policies and procedures.\\nMust be a U.S. Citizen with the ability to obtain and maintain a government suitability clearance.\\nDirectViz Solutions, LLC provides equal employment opportunity to all individuals regardless of race, color, creed, religion, gender, age, sexual orientation, national origin or ancestry, disability, genetic information, veteran status, gender identification or any other characteristic protected by state, federal or local law.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "18  Duties:\\n\\n\\nSource data sets, both internal and external, that support machine learning and AI use cases. Leverage enterprise data lake architecture.\\n\\nIngest, curate, and provide access to structured and unstructured data sets\\n\\nBuild robust data pipelines on public Cloud using AWS Kinesis, Kafka or other Lambda technologies.\\n\\nResponsible to collect, process, and compute business metrics from activity & persisted data using Python/Spark.\\n\\nProcess, cleanse, and verify the integrity of data used for analysis; optimize data for consumption.\\n\\nBuild scalable OLAP backend storage for data in PB scale.\\n\\nDevelop data set processes for data discovery, modeling, mining, and archival.\\n\\n\\nRequirements:\\n\\n\\nMust have a Master's Degree in Computer Science, Software Engineering, or related field.\\n\\nMust have 3 years of experience in software or data engineering positions performing the following:\\n\\nBig data engineering\\n\\nWorking with data processing technologies such as Hadoop, Spark, Hive / Pig, and Java / MapReduce\\n\\nWorking with ETL/SQL including fundamental and optimization query techniques, normal forms, and processing semi-structured data, including CSV, XML, XQuery, JSON, and Parquet.\\n\\nData services using Amazon Web Services (AWS), Azure, and / or Google Cloud\\n\\nUtilizing programming languages such as Java, Python or Scala\\n\\nOperationalizing data sourcing/loading including automating/scheduling data ingestion.\\n\\nUtilizing experience with: Parallel computing, batch processing, and stream processing using tools such as Kinesis or Kafka; data warehousing and columnar databases such as Redshift; and NoSQL databases including AWS S3, MongoDB, Cassandra, HBase, and DynamoDB.\\n\\nSend resume to: Stephanie Nagy, HR Global Mobility Specialist, Invesco Group Services, Inc., 11 Greenway Plaza, Suite 1000, Houston, TX 77046.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "19  Regular-Full time\\nUnion/Non:\\nThis is a non-union position\\nW E= unlimited potential\\nWe didn’t get to be a leader in energy delivery or ranked on the Global 100 Most Sustainable Corporations index on our own. We did it in partnership with outstanding individuals who work together as a team to fuel people’s quality of life. Individuals like you. And now we’re looking for just such an individual to join our team.\\nTo learn more about us, visit www.enbridge.com .\\nLife takes energy. The Enbridge Technology + Innovation Lab works with data that powers our products to improve safety and reliability. By working hands-on with ground-breaking technology, the lab pioneers the development of innovative products through small agile teams. Our teams incorporate a variety of multidisciplinary skills, including industrial predictive algorithms, machine learning, and sentiment analysis.\\nAs a Data Engineer, you’ll help ingest, transform and store clean and enriched data in ready for business intelligence consumption.\\nWho you are\\nYou’ll have experience in a Data Engineer role (5+ years), with a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field\\nYou build and maintain optimal data pipeline architecture.\\nYou assemble large, complex data sets that meet functional / non-functional business requirements.\\nYou identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, data quality checks, minimize Cloud cost, etc.\\nYou build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL, Data Bricks, No-SQL\\nYou build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.\\nYou document and communicate standard methods and tools used.\\nYou work with other data engineers, data ingestion specialists, and experts across the company to consolidate methods and tool standards where practical.\\nYou’re experienced using the following software/tools:\\nBig data tools: Hadoop, HDI, & Spark\\nRelational SQL and NoSQL databases, including COSMOS\\nData pipeline and workflow management tools: Data Bricks (Spark), ADF, Dataflow\\nMicrosoft Azure\\nStream-processing systems: Storm, Streaming-Analytics, IoT Hub, Event Hub\\nObject-oriented/object function scripting languages: Python, Scala, SQL\\nWhat you’ll do\\nYou’ll work independently on complex data engineering problems to support data science strategy of products\\nYou’ll use broad and deep technical knowledge in the data engineering space to tackle complex data problems for product teams, with a core focus on using technical expertise\\nYou’ll improve the data availability by acting as a liaison between Lab teams and source systems\\nYou’ll collect, blend, and transform data using ETL tools, database management system tools, and code development\\nYou’ll implement data models and structures data in ready-for business consumption formats\\nYou’ll aggregate data across various warehousing models (e.g. OLAP cubes, star schemas, etc.) for BI purposes\\nYou’ll collaborate with business teams and understand how data needs to be structured for consumption\\nWe build advanced technology products to deliver energy in a safe and reliable way to fuel a rapidly innovating world. Here in our new Technology + Innovation Lab we believe in Agile way of working, focus on our people and value craftsmanship, in a ‘work is play’ environment where we offer a flexible, fun, and modern working style to support individual needs.\\nApply now to start a career with unlimited potential!\\nWe accept applications submitted via our online recruiting system only ( https://careers.enbridge.com ).\\nEnbridge is an Equal Opportunity and Affirmative Action Employer and is committed to provide employment opportunities to all individuals, without regard to race, religion, age, sex, color, national origin, sexual orientation, gender identity, veteran status, or disability. Accommodation for applicants with disabilities is available on request during the recruitment process. Applicants with disabilities can request accessible formats or communication supports by contacting careers@enbridge.com .\\nWe appreciate your interest in working with us; however, only those applicants selected for interviews will be contacted.\\nFinal candidates for this position may be required to undergo a security screening, including a criminal records check.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "20  Job Description\\nThe Data Engineer collects data from source systems, cleans data and adds metadata for context. Builds data pipelines and ensures that there is appropriate automation in the end-to-end process of gathering and loading data for advanced analytical processing. Builds a robust, fault-tolerant data pipeline that cleans, transforms and aggregates unorganized and messy data from multiple sources into a consolidated data model. This enables the deployment of analytical models and helps data scientists develop models and generate insights more quickly. Develops understanding of data availability, content and quality across a domain and uses this to support product owners and data scientists with feasibility assessments for new features and use cases.\\n\\nWe’re looking to you to bring your strong technical expertise in data engineering to help us find ways of increasing customer value and assist in the setup of a best-practice data science process, including determining the direction of future tooling, and how the company engages overall in data science.\\n\\nCalling on your expertise in software engineering and writing code, you’ll be pivotal to the drive to build products, working within small product teams across multiple projects that rely on data from a range of locations and systems.\\n\\nPlus, you’ll use your strong people skills to easily nurture and influence trustworthy, collaborative relationships with a range of virtual stakeholders, confidently and clearly communicating complex solutions.\\n\\nRequirements\\nMust have legal authorization to work in the US on a full-time basis for anyone other than current employer\\nBachelor's Degree preferably higher, in mathematics, statistics, computer science, or another relevant discipline\\nMinimum five (5) years of relevant experience with a strong background in data and software engineering, with experience of writing code.\\nStrong experience with Python and relevant libraries.\\nThe ability to work across structured, semi-structured, and unstructured data, extracting information and identifying irregularities and linkages across disparate data sets.\\nMeaningful experience in distributed processing.\\nDeep understanding of information security principles to ensure compliant handling and management of client data.\\nExperience in traditional data warehousing / ETL tools.\\nExperience and interest in cloud infrastructure and containerization.\\nPreferably some experience programming with Julia.\\nExperience or interest in building robust and practical data pipelines on top of cloud infrastructure will also be an advantage.\\nCompany Description\\nShell is a global group of energy and petrochemical companies with about 84,000 employees across more than 70 countries. We aim to meet the world’s growing need for more and cleaner energy solutions in ways that are economically, environmentally and socially responsible. We have expertise in exploration, production, refining and marketing of oil and natural gas, and the manufacturing and marketing of chemicals.\\n\\nAs a global energy company operating in a challenging world, we set high standards of performance and ethical behaviors. We are judged by how we act and how we live up to our core values of honesty, integrity and respect for people. Our Business Principles are based on these. They promote trust, openness, teamwork and professionalism, as well as pride in what we do and how we conduct business.\\n\\nBuilding on our core values, we aspire to sustain a diverse and inclusive culture where everyone feels respected and valued, from our employees to our customers and partners. A diverse workforce and an inclusive work environment are vital to our success, leading to greater innovation and better energy solutions.\\nDisclaimer\\nPlease note: We occasionally amend or withdraw Shell jobs and reserve the right to do so at any time, including prior to the advertised closing date.\\n\\nBefore applying, you are advised to read our data protection policy. This policy describes the processing that may be associated with your personal data and informs you that your personal data may be transferred to Royal Dutch/Shell Group companies around the world.\\n\\nThe Shell Group and its approved recruitment consultants will never ask you for a fee to process or consider your application for a career with Shell. Anyone who demands such a fee is not an authorised Shell representative and you are strongly advised to refuse any such demand.\\n\\nShell participates in E-Verify.\\n\\nAll qualified applicants will receive consideration for employment without regard to race, color, sex, national origin, age, religion, disability, sexual orientation, gender identity, protected veteran status, citizenship, genetic information or other protected status under federal, state or local laws.\\n\\nShell is an Equal Opportunity Employer - Minorities/Females/Veterans/Disability.\\nEmployment TypeFull Time\\nSkillpool\\nIT Service Management & Delivery\\nWork LocationHouston - EP Center Americas\\nNo. of Positions\\n1\\nJob Expires01-Nov-2019                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "21  Invesco is a leading global asset management firm with more than $888.2 billion* in assets under management. We provide our retail and institutional clients a diverse and comprehensive range of investment capabilities to help people get more out of life. Invesco is publicly traded on the New York Stock Exchange (IVZ) and has about 7,000 employees in over 20 countries.\\n(*As of December 31, 2018)\\n\\n\\nAbout Invesco Technology\\n\\nAt Invesco Technology, we are strategic problem solvers. Our mission is to create world-class technology solutions to enable global operations, lead in the innovative use of data and emerging technologies to redefine the investment experience, and help our clients “get more out of life.\" This mission is fueled by our high-performing teams, which thrive on collaboration, operate on shared trust, and leverage diversity of thought to deliver valuable results every day to Invesco, clients, and partners.\\n\\nWe wholeheartedly believe that our success is driven by our people. That is why we invest heavily in our top talent, providing opportunities for continuous learning and professional development. Our employees are encouraged and supported in taking advantage of development opportunities tied to their goals and are recognized for employing new skills to make an impact beyond the scope of their daily roles.\\n\\nTo continue building our high-performing, OneTech Team, we are seeking candidates who champion innovation, operate effectively in an agile environment, challenge the status quo and are empowered to take risks\\n\\n\\nJob Purpose (Job Summary):\\nWe’re seeking a Senior Data Engineer to join a fast-paced agile development team using the latest technologies to build portfolio construction and analysis applications. In this position, you will work closely with the Invesco Global Solutions group to envision, design, and deploy scalable technology solutions. You’ll be expected to have basic to intermediate investments knowledge to quickly and accurately collect and visualize investment processes. The environment is demanding, and you will be challenged. We expect that you are fluent in all things data, and you also understand the nuances of financial services and our investment capabilities. You’ll be a part of a dynamic, collaborative team that wants to hear your input because you have a sound foundation in technology and investments. The ideal candidate is passionate about speed, quality, automation, and continuous delivery. We’re actively cultivating a culture of innovation and excellence, and while not for everyone, this environment will be challenging and rewarding for the right individual who welcomes dynamism and solving complex problems. Our team is sensitive to an ever-evolving technological landscape where thirst for knowledge and learning is mandatory, and the mastery of new skills and best practices is essential.\\n\\nKey Responsibilities / Duties:\\nWork on new and innovative portfolio construction and analytics applications along with other experienced developers.\\nIdentify, ingest, and enrich a diverse set of structured and unstructured big data into datasets for analysis.\\nOperate and extend the data research platform to deliver production-quality data on time for analysis.\\nOwn end-to-end data workflows and develop deep domain expertise to ensure data quality and completeness\\nExperiment with new technologies and acquire new skills to find creative solutions to the unique challenges we will encounter along the way\\n\\nWork Experience / Knowledge:\\nMinimum 2 - 4 years of proven experience developing data analytics and visualization software and workflows\\nIntermediate experience with Python and libraries like numpy, pandas, scipy, and matplotlib\\nIntermediate database programming experience with both SQL (e.g. Oracle, SQL Server, PostgreSQL, MySQL) and noSQL (e.g. MongoDB, Parquet) data stores.\\nBasic to Intermediate experience with data visualization tools (e.g. Plotly, PowerBI, Tableau, Plotly Dash, or RShiny)\\nBasic to intermediate experience with HTML, CSS, React.js, and other front-end technologies.\\nIntermediate to advanced experience with Microsoft Excel\\nBasic to intermediate experience with Linux server administration\\nContainerized environments (Docker or LXC), git, continuous integration (e.g. Bamboo, Jenkins, Travis-CI, or CircleCI), documentation (e.g. Sphinx), IT security, distributed computing, and parallel computation\\nBasic to Intermediate understanding of Equity, Fixed Income, and Derivative instruments\\n\\nSkills / Other Personal Attributes Required:\\nComfortable working with ambiguity (e.g. imperfect data, loosely defined concepts, ideas, or goals) and translating these into more tangible outputs\\nStrong analytical and critical thinking skills\\nSelf-motivated. Capable of working with little or no supervision\\nStrong written and verbal communication skills\\nEnjoy challenging and thought-provoking work and have a strong desire to learn and progress\\nAbility to manage multiple tasks and requests\\nMust demonstrate a positive, team-focused attitude\\nAbility to react positively under pressure to meet tight deadlines\\nGood inter-personal skills combined with willingness to listen\\nStructured, disciplined approach to work, with attention to detail\\nFlexible – able to meet changing requirements and priorities\\nMaintenance of up-to-date knowledge in the appropriate technical areas\\nAble to work in a global, multicultural environment\\n\\nFormal Education: (minimum requirement to perform job duties)\\n\\nMasters in Statistics, Computer Science or other similar advanced degrees from a top tier educational institution preferred\\nCFA, CPA, CIPM, CAIA, and/or FRM preferred, but not required.\\n\\nWorking Conditions:\\nNormal office environment with little exposure to noise, dust and temperatures\\nThe ability to lift, carry or otherwise move objects of up to 10 pounds is also necessary\\nNormally works a regular schedule of hours, however hours may vary depending upon the project or assignment\\n\\nFLSA (US Only): Nonexempt\\n\\nThe above information on this description has been designed to indicate the general nature and level of work performed by employees within this role. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications required of employees assigned to this job. The job holder may be required to perform other duties as deemed appropriate by their manager from time to time.\\n\\nInvesco's culture of inclusivity and its commitment to diversity in the workplace are demonstrated through our people practices. We are proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, creed, color, religion, sex, gender, gender identity, sexual orientation, marital status, national origin, citizenship status, disability, age, or veteran status. Our equal opportunity employment efforts comply with all applicable U.S. state and federal laws governing non-discrimination in employment.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "22  JOIN US IN PROVIDING ENERGY AND IMPROVING LIVES.\\n\\nAt Phillips 66, we Provide Energy and Improve Lives guided by our values of Safety, Honor and Commitment. Internships are a great way for us to get to know you and for you to get to know our company. We will offer you the same types of challenging assignments as our full-time hires, and you will participate in our company-wide internship program.\\n\\nInternship activities may include the following:\\nOrientation and training events, field trips, social activities, weekly seminars and opportunities to meet and interact with functional leaders\\n\\nParticipating in continuous coaching conversations with your manager, who will provide guidance throughout your internship\\n\\nAn assigned mentor to provide further guidance. Your mentor will help you navigate both technical challenges of your role and give assistance in navigating through the day-to-day questions on working in the corporate world\\n\\nGiving a presentation at the end of your assignment to senior leaders in the IT organization. This presentation is an opportunity to share what you achieved in your work assignment and projects and provide feedback on what you learned from the internship program.\\n\\nThe Data Engineer will play a key role in contributing to the success of advanced analytics and artificial intelligence projects across the company, by partnering with respective business owners and leveraging data to identify areas of improvement & optimization. The role sits in the sweet spot between technology and business worlds and provides opportunity for high business impact and working with seasoned business leaders.\\n\\nAn internship with Phillips 66 Data Engineering is more than a summer job that will look good on your resume. It’s an excellent opportunity to roll up your sleeves and make important contributions as a valued member of our team. You will not only enhance your knowledge but will also learn how it applies and impacts the energy business daily. You’ll gain first-hand experience in the energy industry and participate in other activities that are based on service, networking, and learning. Your summer experience will include:\\n\\nCreate systems for storing, extracting, transferring, loading, and modeling big data to be used for both production systems and machine learning projects\\n\\nImplement data engineering systems in Microsoft Azure, AWS, HANA and other systems, including open source data science tools to meet the needs of our internal customer\\n\\nBuild end-to-end solutions to solve high value business needs in a sustainable, innovative manner\\n\\nNetwork with professionals at all levels in the company\\n\\nLearn about the Oil & Gas industry and the extensive use of technology that makes it possible\\n\\nInternship opportunities are located at our headquarters in Houston, Texas\\n\\nRequirements for a Phillips 66 Data Engineer Internship:\\nBasic/Required:\\nLegally authorized to work in the job posting country\\n\\nPursuing a Bachelor’s or Master’s degree in Computer Science, Analytics, Data Science, Engineering, Mathematics, or equivalent field of study\\n\\nCurrently enrolled in an undergraduate or postgraduate program as a Sophomore or higher\\n\\nScheduled to graduate from a Bachelor’s or Master’s degree program August 2020 or later\\n\\nAvailable for a minimum of ten continuous weeks\\n\\nPreferred:\\nA minimum cumulative GPA of 3.0 on a 4.0 scale\\n\\nPrevious internship or co-op participant in related industry\\n\\nPrevious internship with Phillips 66\\n\\nPhillips 66 SHIELD Scholar recipient\\n\\nWilling to work in any of our operating locations\\n\\nProficiency in R or Python and familiarity with data science packages in that language\\n\\nUnderstanding of Computer Science fundamentals in object-oriented design, data structures, algorithm design, cloud technologies and problem solving\\n\\nFamiliarity with Agile Development\\n\\nTo apply and be considered:\\nYou must apply through your university prior to university deadlines (if applicable) AND\\n\\nApply online by going to http://www.p66oncampus.jobs and complete the entire application process\\n\\nAttach an electronic copy of your resume and unofficial transcript\\n\\nAnswer all prescreening questions and provide your eSignature\\n\\nCandidates for regular U.S. positions must be a U.S. citizen or national, or an alien admitted as permanent resident, refugee, asylee or temporary resident under 8 U.S.C. 1160(a)(1). Individuals with temporary visas such as E, F-1, H-1, H-2, L, B, J, or TN or who need sponsorship for work authorization now or in the future, are not eligible for hire.\\n\\nAbout Phillips 66\\n\\nPhillips 66 is a diversified energy manufacturing and logistics company. With a portfolio of Midstream, Chemicals, Refining, and Marketing and Specialties businesses, the company processes, transports, stores and markets fuels and products globally. Phillips 66 Partners, the company’s master limited partnership, is integral to the portfolio. Headquartered in Houston, the company has 14,300 employees committed to safety and operating excellence. Phillips 66 had $58 billion of assets as of March 31, 2019. For more information, visit http://www.phillips66.com/ or follow us on Twitter @Phillips66Co and @P66oncampus.\\n\\nPhillips 66 is an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities\\n\\nRequisition ID: 51207\\n\\nLocation: Texas - Houston\\n\\nJob Field: Internships, Graduate Positions, and Student Programs                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "23  Onica is one of the fastest growing AWS Premier Partners in North America. As a full spectrum AWS integrator, we assist hundreds of companies to realize the value, efficiency, and productivity of the cloud. We take customers on their journey to enable, operate, and innovate using cloud technologies – from migration strategy to operational excellence and immersive transformation.\\n\\nIf you like a challenge, you'll love it here, because we're solving complex business problems every day, building and promoting great technology solutions that impact our customers' success. The best part is, we're committed to you and your growth, both professionally and personally.\\n\\nLocation: Texas or California\\n\\nOverview\\n\\nOur Data Engineers are experienced technologists with technical depth and breadth, along with strong interpersonal skills. In this role, you will work directly with customers and our team to help enable innovation through continuous, hands-on, deployment across technology stacks. You will work to build data pipelines and by developing data engineering code ( as well as writing complex data queries and algorithms.\\n\\nWhat You'll Be Doing\\n\\n\\nBuild complex ETL code\\nBuild complex SQL queries using MongoDB, Oracle, SQL Server, MariaDB, MySQL\\nWork on Data and Analytics Tools in the Cloud\\nDevelop code using Python, Scala, R languages\\nWork with technologies such as Spark, Hadoop, Kafka, etc.\\nBuild complex Data Engineering workflows\\nCreate complex data solutions and build data pipelines\\nEstablish credibility and build impactful relationships with our customers to enable them to be cloud advocates\\nCapture and share industry best practices amongst the Onica community\\nAttend and present valuable information at Industry Events\\nTraveling up to 50% of the time\\n\\nQualifications & Experience\\n\\n\\n3+ years design & implementation experience with distributed applications\\n2+ years of experience in database architectures and data pipeline development\\nDemonstrated knowledge of software development tools and methodologies\\nPresentation skills with a high degree of comfort speaking with executives, IT management, and developers\\nExcellent communication skills with an ability to right level conversations\\nTechnical degree required; Computer Science or Math background desired\\nDemonstrated ability to adapt to new technologies and learn quickly\\n\\nWhat's in It for You\\n\\n\\nCloud community-minded, meetups/conferences around North America\\nGenerous vacation policy\\nProfessional development and training\\nCell reimbursement and wellness program\\nRetirement plan\\nRecognition program\\nPet-friendly\\nFlexible work environment\\nCommunity involvement and activities\\nUnlimited snacks and beverages!\\n\\nIf you get a thrill working with cutting-edge technology and love to help solve customers' problems, we'd love to hear from you. It's time to rethink the possible. Are you ready?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "24  MAJOR RESPONSIBILITIES:\\nDevelop, Operate and help administer the bioinformatics pipeline systems at Baylor Genetics.\\nInstall software and assist in administration of linux systems in a virtualized environment, optimizing storage access and managing scientific software installations.\\nAssist in managing systems for the bioinformatics group.\\nDevelop software and modify existing software as needed.\\nHave familiarity with programming languages.\\nFamiliarity with database activities including relational and NoSQL structures.\\nJOB QUALIFICATIONS (REQUIRED):\\nComputer systems administration and programming background.\\n\\nSKILLS:\\nBioinformatics Pipeline Engineer\\nGreat communication skills\\nExperience with administration of Linux systems and software installation\\nExperience or exposure to one or more compiled programming languages (e.g. Java, C++, etc.) and one or more interpreted programming languages (Python, Perl, bash etc.)\\nWorking knowledge of SQL; Experience with big data, NoSQL databases, and health care a plus.\\nKnowledge of Agile methodology and frameworks like Scrum and Kanban a plus.\\n\\nBACKGROUND:\\nBachelor's degree in Computer Science or a related field or scientific degree AND two (2) years background in Linux/Unix Administration                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "25  The data engineer will collaborate within a team of technologists to produce enterprise scale solutions for our clients’ needs. They will utilize deep understanding of data integration and big data design principles in creating custom solutions or implementing package solutions. You will independently drive design decisions to insure the necessary health of the overall solution.\\n\\nRoles & Responsibilities:\\nLead, design, develop, and deliver large-scale Azure data systems, data processing, and data transformation projects.\\nExecute technical feasibility assessments and project estimates for moving databases and data processing to Azure.\\nDesign and advocate solutions using modern cloud technologies, design principles, integration points, and automation methods.\\nMentor and share knowledge with customers as well as provide architecture reviews, discussions, and prototypes.\\nParticipate in overall engagement from strategy, assessment, migration, and implementations.\\nWork with customers to deploy, manage, and audit best practices for cloud products.\\n\\nRequirements\\nDemonstrated experience designing, implementing, and supporting enterprise-grade technical solutions in the cloud for meeting complex business data requirements. Experience with Databricks and using Spark for data processing.\\nExperience with Azure Data Factory – ADF.\\nAdvanced experience with different query languages (i.e. T-SQL, PostgreSQL, PL-SQL). Experience designing and building data marts, warehouses, customer profile databases, etc.\\nExperience with data modeling, table design, and mapping business needs to data structures.\\nExperience with Azure Data Lake, Azure SQL Data Warehouse, and Cosmos DB are a plus. Experience with Data Management Gateway, Azure Storage Options, Stream Analytics, and Event Hubs is a plus.\\nExperience with other cloud based big data architectures is a plus.\\n\\nExperience/Education\\n5 to 10 years of professional experience in the information technology industry.\\nBS in Computer Science or equivalent education/professional experience is required.\\nPersonal Attributes\\nStrong and innovative approach to problem solving and finding solutions.\\nExcellent communicator (written and verbal, formal, and informal).\\nFlexible and proactive/self-motivated working style with strong personal ownership.\\nAbility to multi-task and prioritize under pressure.\\nAbility to work independently with minimal supervision as well as in a team environment. Flexibility and mobility are required to deliver this role as there may be requirements to spend time onsite with our clients to enable delivery of the first class services, we pride ourselves in.\\nGD-POST                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "26  This position is for a Senior Associate Data Engineer within our North American team who will be designing and implementing data projects for our clients.\\nThe qualified individual will work closely with clients to ensure that data technologies meet their needs and keep pace with the rapid changes in Publicis Sapient’s operations and policies/procedures.\\nRESPONSIBILITIES:\\nLead, design, develop, and deliver large-scale Azure data systems, data processing, and data transformation projects.\\nExecute technical feasibility assessments and project estimates for moving databases and data processing to Azure.\\nDesign and advocate solutions using modern cloud technologies, design principles, integration points, and automation methods.\\nMentor and share knowledge with customers as well as provide architecture reviews, discussions, and prototypes.\\nParticipate in overall engagement from strategy, assessment, migration, and implementations.\\nWork with customers to deploy, manage, and audit best practices for cloud products.\\nREQUIREMENTS:\\nDemonstrated experience designing, implementing, and supporting enterprise-grade technical solutions in the cloud for meeting complex business data requirements.\\nExperience with Databricks and using Spark for data processing.\\nExperience with Azure Data Factory – ADF.\\nAdvanced experience with different query languages (i.e. T-SQL, PostgreSQL, PL-SQL).\\nExperience designing and building data marts, warehouses, customer profile databases, etc.\\nExperience with data modeling, table design, and mapping business needs to data structures.\\nExperience with Azure Data Lake, Azure SQL Data Warehouse, and Cosmos DB are a plus.\\nExperience with Data Management Gateway, Azure Storage Options, Stream Analytics, and Event Hubs is a plus.\\nExperience with other cloud based big data architectures is a plus.\\nEXPERIENCE/EDUCATION:\\n5 to 10 years of professional experience in the information technology industry.\\nBS in Computer Science or equivalent education/professional experience is required.\\nPERSONAL ATTRIBUTES:\\nStrong and innovative approach to problem solving and finding solutions.\\nExcellent communicator (written and verbal, formal, and informal).\\nFlexible and proactive/self-motivated working style with strong personal ownership.\\nAbility to multi-task and prioritize under pressure.\\nAbility to work independently with minimal supervision as well as in a team environment.\\nFlexibility and mobility is required to deliver this role as there may be requirements to spend time onsite with our clients to enable delivery of the first class services we pride ourselves in.\\n\\nLI-SNNA*\\nGD-POST                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "27  This position is for a Senior Associate Data Engineer within our North American team who will be designing and implementing data projects for our clients.\\nThe qualified individual will work closely with clients to ensure that data technologies meet their needs and keep pace with the rapid changes in Publicis Sapient’s operations and policies/procedures.\\nRESPONSIBILITIES:\\nLead, design, develop, and deliver large-scale Azure data systems, data processing, and data transformation projects.\\nExecute technical feasibility assessments and project estimates for moving databases and data processing to Azure.\\nDesign and advocate solutions using modern cloud technologies, design principles, integration points, and automation methods.\\nMentor and share knowledge with customers as well as provide architecture reviews, discussions, and prototypes.\\nParticipate in overall engagement from strategy, assessment, migration, and implementations.\\nWork with customers to deploy, manage, and audit best practices for cloud products.\\nREQUIREMENTS:\\nDemonstrated experience designing, implementing, and supporting enterprise-grade technical solutions in the cloud for meeting complex business data requirements.\\nExperience with Databricks and using Spark for data processing.\\nExperience with Azure Data Factory – ADF.\\nAdvanced experience with different query languages (i.e. T-SQL, PostgreSQL, PL-SQL).\\nExperience designing and building data marts, warehouses, customer profile databases, etc.\\nExperience with data modeling, table design, and mapping business needs to data structures.\\nExperience with Azure Data Lake, Azure SQL Data Warehouse, and Cosmos DB are a plus.\\nExperience with Data Management Gateway, Azure Storage Options, Stream Analytics, and Event Hubs is a plus.\\nExperience with other cloud based big data architectures is a plus.\\nEXPERIENCE/EDUCATION:\\n5 to 10 years of professional experience in the information technology industry.\\nBS in Computer Science or equivalent education/professional experience is required.\\nPERSONAL ATTRIBUTES:\\nStrong and innovative approach to problem solving and finding solutions.\\nExcellent communicator (written and verbal, formal, and informal).\\nFlexible and proactive/self-motivated working style with strong personal ownership.\\nAbility to multi-task and prioritize under pressure.\\nAbility to work independently with minimal supervision as well as in a team environment.\\nFlexibility and mobility is required to deliver this role as there may be requirements to spend time onsite with our clients to enable delivery of the first class services we pride ourselves in.\\n\\nLI-SNNA*\\nGD-POST                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "28  Overview\\nHP Engineering entails utilizing established engineering disciplines to test and safeguard the manufacturing standards for new and existing HP products. Working with internal stakeholders and outsourced development partners, you will develop and execute solutions to resolve any existing issues, ensuring that our operating processes are cost-effective and uphold the highest quality.\\nFull Time\\nLevel: Middle\\nTravel: Minimal (if any)\\nSuccess profile\\nWhat makes a successful Engineer at HP? Check out the top traits we’re looking for and see if you have the right mix.\\n\\nCommunicator\\nDeadline-oriented\\nEntrepreneurial\\nOpen-minded\\nProblem-solver\\nTeam Player\\nRewards\\nMedical\\nHolidays\\nFlex Time\\nLife and Disability Insurance\\nWork/Life Balance\\nOnsite Gym/ Fitness Center\\nWe are looking for a talented Spark Data Engineer, to join a great team at HP! In this role, you'll bring advanced subject matter knowledge to solve complex business issues, and we'll look to your Spark data engineering subject matter expertise! In this role, you will frequently contribute to the development of new ideas and methods. You will also get to work on complex, interesting problems, where analysis of situations or data requires an in-depth evaluation of multiple factors. We'd love for you to lead and/or provide expertise to functional project teams, and you may also participate in cross-functional initiatives.\\nWe'll rely on your experience and expertise to provide direction and guidance to process improvements, including in helping to establish/advise on policies. You'll have the opportunity to work with a number of external clients, helping to provide them with effective solutions and insights. We'll trust you to utilize significant independent judgment within broadly defined policies and practices, including determining the best method for accomplishing work and achieving objectives. We'd love for you to also use your deep experience to occasionally help mentor and guide less experienced employees. Key skills will by Python, Scala, and Databricks Spark, as applied in a data engineering capacity. If you love data engineering as much as we do, we'd love to learn more about you!\\nResponsibilities\\nMines data using modern tools and programming languages.\\nDefines and implements models to uncover patterns and predictions creating business value and innovation.\\nManages relationships with business partners to evaluate and foster data driven innovation, provide domain-specific expertise in cross-organization projects/initiatives.\\nTies insights into effective visualizations communicating business value and innovation potential.\\nMaintains proficiency within the data science domain by keeping up with technology and trend shifts. Contributes to industry data science domain initiatives.\\nLeads project team(s) of data science professionals, assuring insights are communicated regularly and effectively, reviewing designs, models and accuracy and data compliance.\\nCollaborates and communicates with project team regarding project progress and issue resolution.\\nCommunicates and drives data insights/innovation into the business.\\nRepresents the data science team for all phases of larger and more-complex development projects.\\nProvides guidance, training and mentoring to less experienced staff members.\\nStrong Scala, Python programming experience is a must\\nDatabricks Spark experience\\nKnowledge & Skills\\nExtensive experience using statistics, mathematics, algorithms and programming languages to solve big data challenges.\\nFluent in structured and unstructured data, its management, and modern data transformation methodologies.\\nAbility to define and create complex models to pull valuable insights, predictions and innovation from data.\\nEffectively and creatively tell stories and create visualizations to describe and communicate data insights.\\nStrong analytical and problem-solving skills.\\nExcellent written and verbal communication skills; mastery in English and local language.\\nAbility to effectively communicate data insights and negotiate options at senior management levels.\\nScope & Impact\\nCollaborates with peers, junior engineers, data scientists and project team.\\nTypically interacts with high- level Individual Contributors, Managers, Directors and Program Core Teams.\\nLeads multiple projects requiring data engineering solutions development.\\nDrives design innovation.\\nEducation & Experience\\nBachelor's, Master's or PHD degree in Mathematics, Economics, Physics, Computer Science, or equivalent.\\n6-10 years’ professional experience.\\n#Li-Post                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "29  Darby Consulting is looking for an experienced Sr. Data Engineer with Azure experience to support our client in the oil and gas industry. The Sr. Data Engineer will have a minimum of four years working with big data processing utilizing Azure Dev Ops, Azure Data Factory and Azure Data Warehouse in an Agile development environment. This position is offered to candidates based in the Houston-area on a 1099 Independent Contractor or W2-Hourly Employee basis. Excellent pay, relocation assistance, top-tier client, excellent work environment, long-term assignment and flexible work schedule are just a few of the many perks for this opportunity.\\n\\nWORK HOURS AND LOCATION\\nServices to be provided in Houston, TX during normal business hours (typically Monday through Friday from 8:00AM to 5:00PM, excluding holidays when the client office is closed).\\n\\nABOUT DARBY CONSULTING\\n\\nIf you've worked for a few consulting firms by now, you know there's a lot of \"great\" places to work. We've worked with many of them too. But, let's be honest: if everyone claims to be great, then great really is just the new average.\\n\\nOur goal is to build an amazing place to work. That means designing and building a company that goes beyond average. We want amazing. For us, Amazing is the opportunity to join a growing company of highly talented and experienced professionals. It's about learning and working alongside great people who care as much about you and your success as they do about their clients. Amazing is about flexibility, work-life balance and opportunities to deliver solutions for respected companies who value your knowledge, skills and experience. If you want great, there's a lot of companies out there. But if you want amazing, welcome to Darby Consulting!\\n\\nWHAT WE DO\\n\\nDarby Consulting is a full-service IT consulting firm specializing in IT project management, systems design and deployment of software and hardware-related projects. Supporting clients in the energy, government and education sectors, Darby helps growing organizations to maximize the value from their IT projects by integrating experienced and specialized IT project professionals, success-based methodology and cloud-based project management tools at affordable rates for growing organizations.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "30  Are you ready to step up to the New and take your technology expertise to the next level?\\nJoin Accenture and help transform leading organizations and communities around the world. The sheer scale of our capabilities and client engagements, in conjunction with the way we collaborate, operate and deliver value, provides an unparalleled opportunity to grow and advance. Choose Accenture and make delivering innovative work part of your extraordinary career.\\nPeople in our Client Delivery & Operations career track drive delivery and capability excellence through the design, development and/ or delivery of a solution, service, capability or offering. They grow into delivery-focused roles, and can progress within their current role, laterally or upward. We partner with our clients to help transform their data into an ‘Appreciating Business Asset.’\\n\\nAs part of our Data Business Group, you will lead technology innovation for our clients through robust delivery of world-class solutions. You will build better software better! There will never be a typical day and that’s why people love it here. The opportunities to make a difference within exciting client initiatives are unlimited in the ever-changing technology landscape. You will be part of a highly collaborative and growing network of technology and data experts, who are taking on today’s biggest, most complex business challenges using the latest data and analytics technologies. We will nurture your talent in an inclusive culture that values diversity. You will have an opportunity to work in roles such as Data Scientist, Data Engineer, or Chief Data Officer covering all aspects of Data including Data Management, Data Governance, Data Intelligence, Knowledge Graphs, and IoT. Come grow your career in Technology at Accenture!\\n\\nThe Google Cloud Platform (GCP) Technical Architect Delivery is responsible for delivering Data On Cloud projects for Google GCP based deals. The ideal candidate would also be responsible for developing and delivering Google GCP cloud solutions to meet todays high demand in areas such as AI/ML, IoT, advanced analytics, open source, enterprise collaboration, microservices, serverless, etc. The Regional Google GCP Technical Architect is a highly performant GCP Architect responsible for delivering Cloud based Big Data and Analytical Solutions to our clients. Responsibilities include evangelizing data on cloud solutions with customers, leading Business and IT stakeholders through designing a robust, secure and optimized GCP architectures and ability to be hands-on delivering the target solution. This role will work with customers and leading internal data engineers in delivering big data soltuions on cloud. Using Google GCP public cloud technologies, our Technical Architect professionals implement state of the art, scalable, high performance Data On Cloud solutions that meet the need of todays corporate and emerging digital applications.\\n\\nRole & Responsibilities:Work with Sales and Bus Dev teams in providing Data and GCP Technical Architecture expertise while pursuing client opportunities.Ability to build cloud architectures and provide prescriptive guidance across network, storage, Big Data Platform Services, serverless architectures, hadoop ecosystem, vendor products, RDBMS & NoSQL databases and security.Participate in deep architectural discussions to build confidence and ensure customer success when building new solutions and migrating existing data applications on the GCP platform.Conduct full technical discovery, identifying pain points, business and technical requirements, “as is” and “to be” scenarios.\\n- Assess the full technology stack of services required including PaaS (Platform as-a-service), IaaS (Infrastructure as-a-service), SaaS (software as-a-service), operations, management and automation.Lead the discussions and early analysis of the cloud concepts as it relates to Clients’s Journey to Cloud methodology so that clear use cases are developed and prioritized as well as transitioning these concepts from ideas to proof-of-concepts all the way to production delivery with the full support of the appropriate teams.Compare solution alternatives across both technical and business parameters which support the define cost and service requirements.Apply Accenture methodology, Accenture reusable assets, and previous work experience to delivery consistently high-quality work.Stay educated on new and emerging technologies/patterns/methodologies and market offerings that may be of interest to our clients.Adapt to existing methods and procedures to create possible alternative solutions to moderately complex problems.Understand the strategic direction set by senior management as it relates to team goals.Use considerable judgment to define solution and seeks guidance on complex problems.Prepare and deliver product messaging in an effort to highlight value proposition and unique differentiators.Primary upward interaction is with direct supervisor. May interact with peers and/or management levels at a client and/or within Accenture. Establish methods and procedures\\non new assignments with guidance.\\nManage small teams of delivery engineers successfully delivering work efforts (if in an independent contributor role) at a client or within Accenture.\\nExtensive travel may be required\\n\\nBasic Qualifications\\nMinimum 5 years of Consulting or client service delivery experience on Google GCP\\nMinimum 10 years of experience in big data, database and data warehouse architecture and delivery\\nBachelors degree or 12 years previous professional experience\\nAble to travel 100% (M-TH)\\nMinimum of 5 years of professional experience in 2 of the following areas:\\nSolution/technical architecture in the cloud\\nBig Data/analytics/information analysis/database management in the cloud\\nIoT/event-driven/microservices in the cloud\\nExperience with private and public cloud architectures, pros/cons, and migration considerations.\\nExtensive hands-on experience implementing data migration and data processing using GCP services etc.:\\nData Ingestion : Cloud Pub/Sub, Data Transfer Service, Cloud IoT Core\\nStreaming Data Pipeline : Cloud Dataflow, Cloud Dataproc, Cloud Dataprep, Apache Beam\\nData Warehousing & Data Lake : BigQuery, Cloud Storage\\nAdvanced Analytics : Cloud ML engine, Google Data Studio, Tensorflow & Sheets\\n\\nFamiliarity with the Technology stack available in the industry for data management, data ingestion, capture, processing and curation: Kafka, StreamSets, Attunity, GoldenGate, Map Reduce, Hadoop, Hive, Hbase, Cassandra, Spark, Flume, Hive, Impala, etc.\\nBachelors or higher degree in Computer Science or a related discipline.\\n\\nCandidate Must Have Completed The Following Certifications\\nCertified GCP Solutions Architect - Associate\\nCertified GCP Solutions Architect – Professional (Nice to have)\\nCertified GCP Big Data Specialty (Nice to have)\\nCertified GCP AI/ML Specialty (Nice to have)\\n\\nNice-to-Have Skills/Qualifications:\\nDevOps on an GCP platform. Multi-cloud experience a plus.\\nExperience developing and deploying ETL solutions on GCP\\nStrong in Java, C##, Spark, PySpark, Unix shell/Perl scripting\\nFamiliarity with the technology stack available in the industry for metadata management: Data Governance, Data Quality, MDM, Lineage, Data Catalog etc.\\n- Multi-cloud experience beyond GCP a plus - AWS and Azure\\n\\nProfessional Skill Requirements\\nProven ability to build, manage and foster a team-oriented environment\\nProven ability to work creatively and analytically in a problem-solving environment\\nDesire to work in an information systems environment\\nExcellent communication (written and oral) and interpersonal skills\\nExcellent leadership and management skills\\n\\nAll of our professionals receive comprehensive training covering business acumen, technical and professional skills development. You'll also have opportunities to hone your functional skills and expertise in an area of specialization. We offer a variety of formal and informal training programs at every level to help you acquire and build specialized skills faster. Learning takes place both on the job and through formal training conducted online, in the classroom, or in collaboration with teammates. The sheer variety of work we do, and the experience it offers, provide an unbeatable platform from which to build a career.\\n\\nApplicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status).\\n\\nCandidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.\\n\\nAccenture is a Federal Contractor and an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities.\\n\\nEqual Employment Opportunity\\n\\nAll employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.\\n\\nJob candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.\\n\\nAccenture is committed to providing veteran employment opportunities to our service men and women.                                             \n",
       "31  We are:\\nApplied Intelligence, the people who love using data to tell a story. We’re also the world’s largest team of data scientists, data engineers, and experts in machine learning and AI. A great day for us? Solving big problems using the latest tech, serious brain power, and deep knowledge of just about every industry. We believe a mix of data, analytics, automation, and responsible AI can do almost anything—spark digital metamorphoses, widen the range of what humans can do, and breathe life into smart products and services. Want to join our crew of sharp analytical minds? Visit us here to find out more about Applied Intelligence.\\n\\nYou are:\\nAn expert engineer with an eye for AI. You want to change how the world works and lives by taking AI out of the lab and into everyday life.\\n\\nThe work:\\nYou’ll be part of a team with incredible end-to-end digital transformation capabilities that shares your passion for digital technology and takes pride in making a tangible difference. If you want to contribute on an incredible array of the biggest and most complex projects in the digital space, consider a career with Accenture Digital.\\n\\nHere’s what you need:\\nMinimum 2+ years of experience in designing, implementing large scale data pipelines for data curation and analysis, operating in production environments using Spark, pySpark, SparkSQL, with Java, Scala or Python on premise or on Cloud (AWS, Google or Azure)\\nMinimum 1 year of designing and building performant data tiers (or refactoring existing ones), that supports scaled AI and Analytics, using different Cloud native data stores on AWS (Kinesis, S3. GLUE, DynamoDB etc.) or Azure (HDInsights, AzureData Factory) or GCP (DataProc, PubSub, BigQuery) as well as using NoSQL and Graph Stores.\\nMinimum 1 year of designing and building streaming data ingestion, analysis and processing pipelines using Kafka, Kafka Streams, Spark Streaming and similar cloud native technologies\\nMinimum 1-year performance engineering, profiling, debugging very large big data and ML production solutions on Spark and native Cloud technologies\\nBonus points if:\\n\\nMinimum 6 months of experience in implementation with Databricks.\\nMinimum 1 year of designing and building secured and governed Big Data ETL pipelines, using Talend or Informatica technologies; for data curation and analysis of large le production deployed solutions.\\nExperience implementing smart data preparation tools such as Palate, Trifacta, Tamr for enhancing analytics solutions.\\nMinimum 1 year of building Business Data Catalogs or Data Marketplaces for powering business analytics using technologies such as Alation, Collibra, Informatica or custom solutions\\n\\n\\nImportant information\\n\\nApplicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture.\\n\\nAccenture is an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities.\\n\\nEqual Employment Opportunity\\n\\nAll employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.\\n\\nJob candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.\\n\\nAccenture is committed to providing veteran employment opportunities to our service men and women.\\n\\nCandidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "32  \\nHouston, TX\\nData department\\n\\nAlice helps small business owners launch and grow. Since launching in May 2017, our goal is to help 6 million owners succeed through our free digital platform,\\nhelloalice.com [http://www.helloalice.com]. Alice serves all entrepreneurs and we wholeheartedly believe that if underserved business owners -- women, people of color, veterans, the LGBTQ+ community, entrepreneurs with disabilities, people in small towns, and immigrants -- are provided better access to resources, they can change the world. Our vision is to be financially successful while making a positive impact on economies and job creation.\\n\\nAlice is growing a diverse team, and we’re looking for a Data Engineer to help us fulfill our mission of connecting all entrepreneurs to the resources they need to grow and scale their businesses. We’re leading a movement to connect every founder, regardless of geography, capitalization, prior experience, or cultural constraints, to the experts, tools, knowledge, and communities that will propel their companies forward. Alice is a Series A-backed company with teams in Houston, TX and San Francisco, CA. We are helping hundreds of thousands of owners a week in all fifty states. Led by co-founders Elizabeth Gore and Carolyn Rodz, we are hiring self-starters who can build the plane while flying it.\\n\\nEngineering is key to scaling our mission, and we’re growing our data engineering team to build new features, improve our AI, and better serve entrepreneurs from around the world. We believe in working fast, but smart, and work toward measurable results. As the first member of the data team you will be able to have a huge impact on the technologies, architecture, and tools we use. Data is key to Alice’s success and this position will have big visibility throughout the organization.\\n\\nRequired Skills/Experiences:\\n\\nThrives in a fast-paced, startup environment, is adaptable and versatile\\n3+ years of python\\nExperience in python data libraries (pandas, luigi, dask, etc)\\nSolid understanding of data structures and algorithms\\nBuilding distributed data systems\\n\\nDesired Skills / Experiences\\n\\nAWS and Google Cloud management\\nAnsible, Terraform or other cloud orchestration libraries\\nRabbitMQ, Kafka or other queuing systems\\ngRPC or other RPC libraries\\nProtobufs\\nMachine learning and statistics libraries\\nScraping websites for relevant information\\n\\nOur company values are important to us. We thought we would share them with you as someone interested in joining our team.\\n\\nINNOVATE ALWAYS. Seek out unique perspectives, diverse experiences, and disconnected dots. These are the seeds of big ideas and exceeded expectations, made even better through constant collaboration.\\nEMBRACE FAILURE. Learn from the inevitable failures that result from innovation, and move forward quickly with a pioneering spirit. Champion the doers, celebrate their contributions to the team, and don't shy away from difficult conversations.\\nDRIVE THE MISSION FORWARD. Everything we do is through the inclusive lens of helping all business owners launch and grow, regardless of who they are or where they come from. Hold yourself to the highest standards of quality and equality in everything you do.\\nEVERYONE TAKES OUT THE TRASH. No task is too small for the success of our company or our owners. Always be thoughtful and practice extreme kindness toward our team, partners, and owners.\\nSIMPLIFY AND COMMIT. Maintain a bias toward efficiency, acting quickly and testing often. Recognize the opportunity cost of every decision, commit to deadlines, be on time, and search for simple, smart solutions.\\n\\nAlice is an Equal Employment Opportunity employer that will consider all qualified applicants, regardless of race, color, religion, gender, sexual orientation, marital status, gender identity or expression, national origin, genetics, age, disability status, protected veteran status, or any other characteristic protected by applicable law.\\n\\nwww.helloalice.com [http://www.helloalice.com/] // Twitter\\n[https://twitter.com/HelloAlice] // Facebook\\n[http://www.facebook.com/aliceconnects] // Instagram\\n[https://www.instagram.com/helloalice_com/] // LinkedIn\\n[https://www.linkedin.com/company/25067438/]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Descriptions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Descriptions_df.to_csv('Descriptions_df_DE_Houston.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
